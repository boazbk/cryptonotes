<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Code as Data, Data as Code</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Code as Data, Data as Code" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.1</b> Exercises</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Code as Data, Data as Code</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_04_code_and_data.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="codeanddatachap" data-number="5">Code as data, data as code</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>See one of the most important concepts in computing: duality between code and data.<br />
</li>
<li>Build up comfort in moving between different representations of programs.<br />
</li>
<li>Follow the construction of a “universal circuit evaluator” that can evaluate other circuits given their representation.<br />
</li>
<li>See major result that complements the result of the last chapter: some functions require an <em>exponential</em> number of gates to compute.</li>
<li>Discussion of <em>Physical extended Church-Turing thesis</em> stating that Boolean circuits capture <em>all</em> feasible computation in the physical world, and its physical and philosophical implications.</li>
</ul>
</div>
<blockquote>
<p><em>“The term code script is, of course, too narrow. The chromosomal structures are at the same time instrumental in bringing about the development they foreshadow. They are law-code and executive power - or, to use another simile, they are architect’s plan and builder’s craft - in one.”</em> , Erwin Schrödinger, 1944.</p>
</blockquote>
<blockquote>
<p><em>“A mathematician would hardly call a correspondence between the set of 64 triples of four units and a set of twenty other units,”universal“, while such correspondence is, probably, the most fundamental general feature of life on Earth”</em>, Misha Gromov, 2013</p>
</blockquote>
<p>A program is simply a sequence of symbols, each of which can be encoded as a string of <span><span class="math inline">\(0\)</span></span>’s and <span><span class="math inline">\(1\)</span></span>’s using (for example) the ASCII standard. Therefore we can represent every NAND-CIRC program (and hence also every Boolean circuit) as a binary string. This statement seems obvious but it is actually quite profound. It means that we can treat circuits or NAND-CIRC programs both as instructions to carrying computation and also as <em>data</em> that could potentially be used as <em>inputs</em> to other computations.</p>
<div id="programisinput" class="bigidea" name="Bigidea 6">
<p>A <em>program</em> is a piece of text, and so it can be fed as input to other programs.</p>
</div>
<p>This correspondence between <em>code</em> and <em>data</em> is one of the most fundamental aspects of computing. It underlies the notion of <em>general purpose</em> computers, that are not pre-wired to compute only one task, and also forms the basis of our hope for obtaining <em>general</em> artificial intelligence. This concept finds immense use in all areas of computing, from scripting languages to machine learning, but it is fair to say that we haven’t yet fully mastered it. Many security exploits involve cases such as “buffer overflows” when attackers manage to inject code where the system expected only “passive” data (see <a href='#XKCDmomexploitsfig'>Figure 5.1</a>). The relation between code and data reaches beyond the realm of electronic computers. For example, DNA can be thought of as both a program and data (in the words of Schrödinger, who wrote before the discovery of DNA’s structure a book that inspired Watson and Crick, DNA is both “architect’s plan and builder’s craft”).</p>
<figure>
<img src="../figure/exploits_of_a_mom.png" alt="5.1: As illustrated in this xkcd cartoon, many exploits, including buffer overflow, SQL injections, and more, utilize the blurry line between “active programs” and “static strings”." id="XKCDmomexploitsfig" class="margin" /><figcaption>5.1: As illustrated in this xkcd cartoon, many exploits, including buffer overflow, SQL injections, and more, utilize the blurry line between “active programs” and “static strings”.</figcaption>
</figure>
<p>In this chapter, we will begin to explore some of the applications of this connection. We start by using the representation of programs/circuits as strings to <em>count</em> the number of programs/circuits up to a certain size, and use that to obtain a counterpart to the result we proved in <a href='lec_03a_computing_every_function.html#finiteuniversalchap'>Chapter 4</a>. There we proved that for <em>every</em> function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span>, there exists a circuit of <em>at most</em> <span><span class="math inline">\(100 \cdot 2^n / n\)</span></span> gates to compute it. (The number <span><span class="math inline">\(100\)</span></span> here is somewhat arbitrary and fixed for concreteness; <a href='lec_03a_computing_every_function.html#circuit-univ-thm-improved'>Theorem 4.16</a> states a bound of <span><span class="math inline">\(c \cdot 2^n /n\)</span></span> for some constant <span><span class="math inline">\(c\)</span></span>, but it can be verified that the proof yields <span><span class="math inline">\(c \leq 100\)</span></span>.) In this chapter we will prove that there are <em>some</em> functions <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> for which we cannot do much better: they require a circuit of size <em>at least</em> <span><span class="math inline">\(0.01 \cdot 2^n / n\)</span></span> (see <a href='#counting-lb'>Theorem 5.3</a>). We will also use the notion of representing programs/circuits as strings to show the existence of a <em>bounded universal circuit</em> <span><span class="math inline">\(U\)</span></span> that gets as input the string representation of another circuit <span><span class="math inline">\(C\)</span></span> and a string <span><span class="math inline">\(x\)</span></span>, and outputs <span><span class="math inline">\(C(x)\)</span></span>. (The qualifier “bounded” means that the circuit <span><span class="math inline">\(C\)</span></span> has to be of at most a certain size; we see computational models that overcome this limitation in <a href='lec_06_loops.html#chaploops'>Chapter 6</a>, which introduces the notion of programming languages with <em>loops</em> and the computational model of a <em>Turing Machine</em>.) Equivalently, taking the programming-language point of view, the bounded universal circuit corresponds to a “NAND-CIRC interpreter in NAND-CIRC”: a NAND-CIRC program that can evaluate other NAND-CIRC program. Such a program is known in Computer Science as a “meta-circular evaluator”, and is fundamental to both theory and practice of computing. See <a href='#codedataoverviewfig'>Figure 5.2</a> for an overview of the results of this chapter.</p>
<figure>
<img src="../figure/codedataoverview.png" alt="5.2: Overview of the results in this chapter. We use the representation of programs/circuits as strings to derive two main results. First we show the existence of a universal program/circuit, and in fact (with more work) the existence of such a program/circuit whose size is at most polynomial in the size of the program/circuit it evaluates. We then use the string representation to count the number of programs/circuits of a given size, and use that to establish that some functions require an exponential number of lines/gates to compute." id="codedataoverviewfig" /><figcaption>5.2: Overview of the results in this chapter. We use the representation of programs/circuits as strings to derive two main results. First we show the existence of a universal program/circuit, and in fact (with more work) the existence of such a program/circuit whose size is at most polynomial in the size of the program/circuit it evaluates. We then use the string representation to <em>count</em> the number of programs/circuits of a given size, and use that to establish that <em>some</em> functions require an <em>exponential</em> number of lines/gates to compute.</figcaption>
</figure>
<h2 id="representprogramsec" data-number="5.1">Representing programs as strings</h2>
<figure>
<img src="../figure/tapemarkI.png" alt="5.3: In the Harvard Mark I computer, a program was represented as a list of triples of numbers, which were then encoded by perforating holes in a control card." id="markonerep" class="margin" /><figcaption>5.3: In the Harvard Mark I computer, a program was represented as a list of triples of numbers, which were then encoded by perforating holes in a control card.</figcaption>
</figure>
<p>We can represent programs or circuits as strings in a myriad of ways. For example, since Boolean circuits are labeled directed acyclic graphs, we can use the <em>adjacency matrix</em> or <em>adjacency list</em> representations for them. However, since the code of a program is ultimately just a sequence of letters and symbols, arguably the conceptually simplest representation of a program is as such a sequence. For example, the following NAND-CIRC program <span><span class="math inline">\(P\)</span></span></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1">temp_0 <span class="op">=</span> NAND(X[<span class="dv">0</span>],X[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb1-2" title="2">temp_1 <span class="op">=</span> NAND(X[<span class="dv">0</span>],temp_0)</a>
<a class="sourceLine" id="cb1-3" title="3">temp_2 <span class="op">=</span> NAND(X[<span class="dv">1</span>],temp_0)</a>
<a class="sourceLine" id="cb1-4" title="4">Y[<span class="dv">0</span>] <span class="op">=</span> NAND(temp_1,temp_2)</a></code></pre></div>
<p>is simply a string of 107 symbols which include lower and upper case letters, digits, the underscore character <code>_</code> and equality sign <code>=</code>, punctuation marks such as “<code>(</code>”,“<code>)</code>”,“<code>,</code>”, spaces, and “new line” markers (often denoted as “<code>\ n</code>” or “↵”). Each such symbol can be encoded as a string of <span><span class="math inline">\(7\)</span></span> bits using the <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> encoding, and hence the program <span><span class="math inline">\(P\)</span></span> can be encoded as a string of length <span><span class="math inline">\(7 \cdot 107 = 749\)</span></span> bits.</p>
<p>Nothing in the above discussion was specific to the program <span><span class="math inline">\(P\)</span></span>, and hence we can use the same reasoning to prove that <em>every</em> NAND-CIRC program can be represented as a string in <span><span class="math inline">\(\{0,1\}^*\)</span></span>. In fact, we can do a bit better. Since the names of the working variables of a NAND-CIRC program do not affect its functionality, we can always transform a program to have the form of <span><span class="math inline">\(P&#39;\)</span></span> where all variables apart from the inputs and outputs have the form <code>temp_0</code>, <code>temp_1</code>, <code>temp_2</code>, etc.. Moreover, if the program has <span><span class="math inline">\(s\)</span></span> lines, then we will never need to use an index larger than <span><span class="math inline">\(3s\)</span></span> (since each line involves at most three variables), and similarly the indices of the input and output variables will all be at most <span><span class="math inline">\(3s\)</span></span>. Since a number between <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(3s\)</span></span> can be expressed using at most <span><span class="math inline">\(\lceil \log_{10}(3s+1) \rceil = O(\log s)\)</span></span> digits, each line in the program (which has the form <code>foo = NAND(bar,blah)</code>), can be represented using <span><span class="math inline">\(O(1) + O(\log s) = O(\log s)\)</span></span> symbols, each of which can be represented by <span><span class="math inline">\(7\)</span></span> bits. Hence an <span><span class="math inline">\(s\)</span></span> line program can be represented as a string of <span><span class="math inline">\(O(s \log s)\)</span></span> bits, resulting in the following theorem:</p>
<div id="asciirepprogramthm" class="theorem" title="Representing programs as strings" name="Theorem 5.1 (Representing programs as strings) ">
<p>There is a constant <span><span class="math inline">\(c\)</span></span> such that for <span><span class="math inline">\(f \in \ensuremath{\mathit{SIZE}}(s)\)</span></span>, there exists a program <span><span class="math inline">\(P\)</span></span> computing <span><span class="math inline">\(f\)</span></span> whose string representation has length at most <span><span class="math inline">\(c s \log s\)</span></span>.</p>
</div>
<div class="pause" name="Pause 5.1">
<p>We omit the formal proof of <a href='#asciirepprogramthm'>Theorem 5.1</a> but please make sure that you understand why it follows from the reasoning above.</p>
</div>
<h2 id="countingcircuitsec" data-number="5.2">Counting programs, and lower bounds on the size of NAND-CIRC programs</h2>
<p>One consequence of the representation of programs as strings is that the number of programs of certain length is bounded by the number of strings that represent them. This has consequences for the sets <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}(s)\)</span></span> that we defined in <a href='lec_03a_computing_every_function.html#secdefinesizeclasses'>Section 4.6</a>.</p>
<div id="program-count" class="theorem" title="Counting programs" name="Theorem 5.2 (Counting programs) ">
<p>For every <span><span class="math inline">\(s\in \N\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[|\ensuremath{\mathit{SIZE}}(s)| \leq 2^{O(s \log s)}.\]</span></div></span> That is, there are at most <span><span class="math inline">\(2^{O(s\log s)}\)</span></span> functions computed by NAND-CIRC programs of at most <span><span class="math inline">\(s\)</span></span> lines.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
</div>
<div class="proof" data-ref="program-count" name="Proof 5.2">
<p>We will show a one-to-one map <span><span class="math inline">\(E\)</span></span> from <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}(s)\)</span></span> to the set of strings of length <span><span class="math inline">\(c s \log s\)</span></span> for some constant <span><span class="math inline">\(c\)</span></span>. This will conclude the proof, since it implies that <span><span class="math inline">\(|\ensuremath{\mathit{SIZE}}(s)|\)</span></span> is smaller than the size of the set of all strings of length at most <span><span class="math inline">\(\ell\)</span></span>, which equals <span><span class="math inline">\(1+2+4+\cdots + 2^\ell = 2^{\ell +1} - 1\)</span></span> by the formula for sums of geometric progressions.</p>
<p>The map <span><span class="math inline">\(E\)</span></span> will simply map <span><span class="math inline">\(f\)</span></span> to the representation of the program computing <span><span class="math inline">\(f\)</span></span>. Specifically, we let <span><span class="math inline">\(E(f)\)</span></span> be the representation of the program <span><span class="math inline">\(P\)</span></span> computing <span><span class="math inline">\(f\)</span></span> given by <a href='#asciirepprogramthm'>Theorem 5.1</a>. This representation has size at most <span><span class="math inline">\(c s \log s\)</span></span>, and moreover the map <span><span class="math inline">\(E\)</span></span> is one to one, since if <span><span class="math inline">\(f \neq f&#39;\)</span></span> then every two programs computing <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(f&#39;\)</span></span> respectively must have different representations.</p>
</div>
<p>A function mapping <span><span class="math inline">\(\{0,1\}^2\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> can be identified with the table of its four values on the inputs <span><span class="math inline">\(00,01,10,11\)</span></span>. A function mapping <span><span class="math inline">\(\{0,1\}^3\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> can be identified with the table of its eight values on the inputs <span><span class="math inline">\(000,001,010,011,100,101,110,111\)</span></span>. More generally, every function <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> can be identified with the table of its <span><span class="math inline">\(2^n\)</span></span> values on the inputs <span><span class="math inline">\(\{0,1\}^n\)</span></span>. Hence the number of functions mapping <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> is equal to the number of such tables which (since we can choose either <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span> for every row) is exactly <span><span class="math inline">\(2^{2^n}\)</span></span>. Note that this is <em>double exponential</em> in <span><span class="math inline">\(n\)</span></span>, and hence even for small values of <span><span class="math inline">\(n\)</span></span> (e.g., <span><span class="math inline">\(n=10\)</span></span>) the number of functions from <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> is truly astronomical.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> This has the following important corollary:</p>
<div id="counting-lb" class="theorem" title="Counting argument lower bound" name="Theorem 5.3 (Counting argument lower bound) ">
<p>There is a constant <span><span class="math inline">\(\delta &gt; 0\)</span></span>, such that for every sufficiently large <span><span class="math inline">\(n\)</span></span>, there is a function <span><span class="math inline">\(f:\{0,1\}^n\rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(f \not\in \ensuremath{\mathit{SIZE}} \left(\tfrac{\delta 2^n}{n} \right)\)</span></span>. That is, the shortest NAND-CIRC program to compute <span><span class="math inline">\(F\)</span></span> requires at least <span><span class="math inline">\(\delta \cdot 2^n/n\)</span></span> lines.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>
</div>
<div class="proof" data-ref="counting-lb" name="Proof 5.2">
<p>The proof is simple. If we let <span><span class="math inline">\(c\)</span></span> be the constant such that <span><span class="math inline">\(|\ensuremath{\mathit{SIZE}}(s)| \leq 2^{c s \log s}\)</span></span> and <span><span class="math inline">\(\delta = 1/c\)</span></span>, then setting <span><span class="math inline">\(s = \delta 2^n/n\)</span></span> we see that <span>
<div class='myequationbox'><span class="math display">\[
|\ensuremath{\mathit{SIZE}}(\tfrac{\delta 2^n}{n})| \leq 2^{c \tfrac{\delta 2^n}{n} \log s} &lt; 2^{c \delta 2^n} = 2^{2^n}
\]</span></div></span> using the fact that since <span><span class="math inline">\(s &lt; 2^n\)</span></span>, <span><span class="math inline">\(\log s &lt; n\)</span></span> and <span><span class="math inline">\(\delta = 1/c\)</span></span>. But since <span><span class="math inline">\(|\ensuremath{\mathit{SIZE}}(s)|\)</span></span> is smaller than the total number of functions mapping <span><span class="math inline">\(n\)</span></span> bits to <span><span class="math inline">\(1\)</span></span> bit, there must be at least one such function not in <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}(s)\)</span></span>, which is what we needed to prove.</p>
</div>
<p>We have seen before that <em>every</em> function mapping <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> can be computed by an <span><span class="math inline">\(O(2^n /n)\)</span></span> line program. <a href='#counting-lb'>Theorem 5.3</a> shows that this is tight in the sense that some functions do require such an astronomical number of lines to compute.</p>
<div id="countinglb" class="bigidea" name="Bigidea 7">
<p>Some functions <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> <em>cannot</em> be computed by a Boolean circuit using fewer than exponential (in <span><span class="math inline">\(n\)</span></span>) number of gates.</p>
</div>
<p>In fact, as we explore in the exercises, this is the case for <em>most</em> functions. Hence functions that can be computed in a small number of lines (such as addition, multiplication, finding short paths in graphs, or even the <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}\)</span></span> function) are the exception, rather than the rule.</p>
<div id="efficientrepresentation" class="remark" title="More efficient representation (advanced, optional)" name="Remark 5.4 (More efficient representation (advanced, optional)) ">
<p>The ASCII representation is not the shortest representation for NAND-CIRC programs. NAND-CIRC programs are equivalent to circuits with NAND gates, which means that a NAND-CIRC program of <span><span class="math inline">\(s\)</span></span> lines, <span><span class="math inline">\(n\)</span></span> inputs, and <span><span class="math inline">\(m\)</span></span> outputs can be represented by a labeled directed graph of <span><span class="math inline">\(s+n\)</span></span> vertices, of which <span><span class="math inline">\(n\)</span></span> have in-degree zero, and the <span><span class="math inline">\(s\)</span></span> others have in-degree at most two. Using the adjacency matrix representation for such graphs, we can reduce the implicit constant in <a href='#program-count'>Theorem 5.2</a> to be arbitrarily close to <span><span class="math inline">\(5\)</span></span>, see <a href='#efficientrepresentationex'>Exercise 5.6</a></p>
</div>
<h3 id="size-hierarchy-theorem-optional" data-number="5.2.1">Size hierarchy theorem (optional)</h3>
<p>By <a href='lec_03a_computing_every_function.html#NAND-univ-thm-improved'>Theorem 4.15</a> the class <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n}(10 \cdot 2^n /n)\)</span></span> contains <em>all</em> functions from <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span>, while by <a href='#counting-lb'>Theorem 5.3</a>, there is <em>some</em> function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> that is <em>not contained</em> in <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n}(0.1 \cdot 2^n / n)\)</span></span>. In other words, for every sufficiently large <span><span class="math inline">\(n\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[
\ensuremath{\mathit{SIZE}}_n\left(0.1 \tfrac{2^n}{n} \right) \subsetneq \ensuremath{\mathit{SIZE}}_n\left(10 \tfrac{2^n}{n} \right) \;.
\]</span></div></span> It turns out that we can use <a href='#counting-lb'>Theorem 5.3</a> to show a more general result: whenever we increase our “budget” of gates we can compute new functions.</p>
<div id="sizehiearchythm" class="theorem" title="Size Hierarchy Theorem" name="Theorem 5.5 (Size Hierarchy Theorem) ">
<p>For every sufficiently large <span><span class="math inline">\(n\)</span></span> and <span><span class="math inline">\(10n &lt; s &lt; 0.1 \cdot 2^n /n\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[
\ensuremath{\mathit{SIZE}}_n(s) \subsetneq \ensuremath{\mathit{SIZE}}_n(s+10n) \;.
\]</span></div></span></p>
</div>
<div id="section-1" class="proofidea" data-ref="sizehiearchythm" name="Proofidea">
<p>To prove the theorem we need to find a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(f\)</span></span> <em>can</em> be computed by a circuit of <span><span class="math inline">\(s+10n\)</span></span> gates but it <em>cannot</em> be computed by a circuit of <span><span class="math inline">\(s\)</span></span> gates. We will do so by coming up with a sequence of functions <span><span class="math inline">\(f_0,f_1,f_2,\ldots,f_N\)</span></span> with the following properties: <strong>(1)</strong> <span><span class="math inline">\(f_0\)</span></span> <em>can</em> be computed by a circuit of at most <span><span class="math inline">\(10n\)</span></span> gates, <strong>(2)</strong> <span><span class="math inline">\(f_N\)</span></span> <em>cannot</em> be computed by a circuit of <span><span class="math inline">\(0.1 \cdot 2^n/n\)</span></span> gates, and <strong>(3)</strong> for every <span><span class="math inline">\(i\in \{0,\ldots, N\}\)</span></span>, if <span><span class="math inline">\(f_i\)</span></span> can be computed by a circuit of size <span><span class="math inline">\(s\)</span></span>, then <span><span class="math inline">\(f_{i+1}\)</span></span> can be computed by a circuit of size at most <span><span class="math inline">\(s + 10n\)</span></span>. Together these properties imply that if we let <span><span class="math inline">\(i\)</span></span> be the smallest number such that <span><span class="math inline">\(f_i \not\in \ensuremath{\mathit{SIZE}}_n(s)\)</span></span>, then since <span><span class="math inline">\(f_{i+1} \in \ensuremath{\mathit{SIZE}}(s)\)</span></span> it must hold that <span><span class="math inline">\(f_i \in \ensuremath{\mathit{SIZE}}(s+10n)\)</span></span> which is what we need to prove. See <a href='#hierarchyprooffig'>Figure 5.4</a> for an illustration.</p>
</div>
<figure>
<img src="../figure/hierarchyproof.png" alt="5.4: We prove  by coming up with a list f_0,\ldots,f_{2^n} of functions such that f_0 is the all zero function, f_{2^n} is a function (obtained from ) outside of \ensuremath{\mathit{SIZE}}(0.1\cdot 2^n/n) and such that f_{i-1} and f_i differ by one another on at most one input. We can show that for every i, the number of gates to compute f_i is at most 10n larger than the number of gates to compute f_{i-1} and so if we let i be the smallest number such that f_i \not\in \ensuremath{\mathit{SIZE}}(s), then f_i \in \ensuremath{\mathit{SIZE}}(s+10n)." id="hierarchyprooffig" class="margin" /><figcaption>5.4: We prove <a href='#sizehiearchythm'>Theorem 5.5</a> by coming up with a list <span><span class="math inline">\(f_0,\ldots,f_{2^n}\)</span></span> of functions such that <span><span class="math inline">\(f_0\)</span></span> is the all zero function, <span><span class="math inline">\(f_{2^n}\)</span></span> is a function (obtained from <a href='#counting-lb'>Theorem 5.3</a>) outside of <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}(0.1\cdot 2^n/n)\)</span></span> and such that <span><span class="math inline">\(f_{i-1}\)</span></span> and <span><span class="math inline">\(f_i\)</span></span> differ by one another on at most one input. We can show that for every <span><span class="math inline">\(i\)</span></span>, the number of gates to compute <span><span class="math inline">\(f_i\)</span></span> is at most <span><span class="math inline">\(10n\)</span></span> larger than the number of gates to compute <span><span class="math inline">\(f_{i-1}\)</span></span> and so if we let <span><span class="math inline">\(i\)</span></span> be the smallest number such that <span><span class="math inline">\(f_i \not\in \ensuremath{\mathit{SIZE}}(s)\)</span></span>, then <span><span class="math inline">\(f_i \in \ensuremath{\mathit{SIZE}}(s+10n)\)</span></span>.</figcaption>
</figure>
<div class="proof" data-ref="sizehiearchythm" name="Proof 5.2.1">
<p>Let <span><span class="math inline">\(f^*: \{0,1\}^n \rightarrow \{0,1\}\)</span></span> be the function (whose existence we are guaranteed by <a href='#counting-lb'>Theorem 5.3</a>) such that <span><span class="math inline">\(f^* \not\in \ensuremath{\mathit{SIZE}}_n(0.1 \cdot 2^n /n)\)</span></span>. We define the functions <span><span class="math inline">\(f_0,f_1,\ldots, f_{2^n}\)</span></span> mapping <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> as follows. For every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, if <span><span class="math inline">\(lex(x) \in \{0,1,\ldots, 2^n-1\}\)</span></span> is <span><span class="math inline">\(x\)</span></span>’s order in the lexicographical order then <span>
<div class='myequationbox'><span class="math display">\[
f_i(x) = \begin{cases} f^*(x) &amp; lex(x)&lt; i  \\ 0 &amp; \text{otherwise} \end{cases} \;.
\]</span></div></span></p>
<p>The function <span><span class="math inline">\(f_0\)</span></span> is simply the constant zero function, while the function <span><span class="math inline">\(f_{2^n}\)</span></span> is equal to <span><span class="math inline">\(f^*\)</span></span>. Moreover, for every <span><span class="math inline">\(i\in [2^n]\)</span></span>, the functions <span><span class="math inline">\(f_i\)</span></span> and <span><span class="math inline">\(f_{i+1}\)</span></span> differ on at most one input (i.e., the input <span><span class="math inline">\(x \in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(lex(x)=i\)</span></span>). Let <span><span class="math inline">\(10n &lt; s &lt; 0.1 \cdot 2^n /n\)</span></span>, and let <span><span class="math inline">\(i\)</span></span> be the first index such that <span><span class="math inline">\(f_i \not\in \ensuremath{\mathit{SIZE}}_n(s)\)</span></span>. Since <span><span class="math inline">\(f_{2^n} = f^* \not\in \ensuremath{\mathit{SIZE}}(0.1 \dot 2^n / n)\)</span></span> there must exist such an index <span><span class="math inline">\(i\)</span></span>, and moreover <span><span class="math inline">\(i&gt;0\)</span></span> since the constant zero function is a member of <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_n(10n)\)</span></span>.</p>
<p>By our choice of <span><span class="math inline">\(i\)</span></span>, <span><span class="math inline">\(f_{i-1}\)</span></span> is a member of <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_n(s)\)</span></span>. To complete the proof, we need to show that <span><span class="math inline">\(f_i \in \ensuremath{\mathit{SIZE}}_n(s + 10n)\)</span></span>. Let <span><span class="math inline">\(x^*\)</span></span> be the string such that <span><span class="math inline">\(lex(x^*)=i\)</span></span> <span><span class="math inline">\(b\in \{0,1\}\)</span></span> is the value of <span><span class="math inline">\(f^*(x^*)\)</span></span>. Then we can define <span><span class="math inline">\(f_i\)</span></span> also as follows <span>
<div class='myequationbox'><span class="math display">\[
f_i(x) = \begin{cases} b &amp; x=x^* \\ f_i(x) &amp; x \neq x^*
         \end{cases}
\]</span></div></span> or in other words <span>
<div class='myequationbox'><span class="math display">\[
f_i(x) = f_{i-1}(x) \wedge \ensuremath{\mathit{EQUAL}}(x^*,x) \; \vee \;  b \wedge \neg \ensuremath{\mathit{EQUAL}}(x^*,x)
\]</span></div></span> where <span><span class="math inline">\(\ensuremath{\mathit{EQUAL}}:\{0,1\}^{2n} \rightarrow \{0,1\}\)</span></span> is the function that maps <span><span class="math inline">\(x,x&#39; \in \{0,1\}^n\)</span></span> to <span><span class="math inline">\(1\)</span></span> if they are equal and to <span><span class="math inline">\(0\)</span></span> otherwise. Since (by our choice of <span><span class="math inline">\(i\)</span></span>), <span><span class="math inline">\(f_{i-1}\)</span></span> can be computed using at most <span><span class="math inline">\(s\)</span></span> gates and (as can be easily verified) that <span><span class="math inline">\(\ensuremath{\mathit{EQUAL}} \in \ensuremath{\mathit{SIZE}}_n(9n)\)</span></span>, we can compute <span><span class="math inline">\(f_i\)</span></span> using at most <span><span class="math inline">\(s + 9n +O(1) \leq s +10n\)</span></span> gates which is what we wanted to prove.</p>
</div>
<figure>
<img src="../figure/sizecomplexity.png" alt="5.5: An illustration of some of what we know about the size complexity classes (not to scale!). This figure depicts classes of the form \ensuremath{\mathit{SIZE}}_{n,n}(s) but the state of affairs for other size complexity classes such as \ensuremath{\mathit{SIZE}}_{n,1}(s) is similar. We know by  (with the improvement of ) that all functions mapping n bits to n bits can be computed by a circuit of size c \cdot 2^n for c \leq 10, while on the other hand the counting lower bound (, see also ) shows that some such functions will require 0.1 \cdot 2^n, and the size hierarchy theorem () shows the existence of functions in \ensuremath{\mathit{SIZE}}(S) \setminus \ensuremath{\mathit{SIZE}}(s) whenever s=o(S), see also . We also consider some specific examples: addition of two n/2 bit numbers can be done in O(n) lines, while we don’t know of such a program for multiplying two n bit numbers, though we do know it can be done in O(n^2) and in fact even better size. In the above, \ensuremath{\mathit{FACTOR}}_n corresponds to the inverse problem of multiplying- finding the prime factorization of a given number. At the moment we do not know of any circuit a polynomial (or even sub-exponential) number of lines that can compute \ensuremath{\mathit{FACTOR}}_n." id="sizeclassesfig" /><figcaption>5.5: An illustration of some of what we know about the size complexity classes (not to scale!). This figure depicts classes of the form <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n,n}(s)\)</span></span> but the state of affairs for other size complexity classes such as <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n,1}(s)\)</span></span> is similar. We know by <a href='lec_03a_computing_every_function.html#NAND-univ-thm'>Theorem 4.12</a> (with the improvement of <a href='lec_03a_computing_every_function.html#tight-upper-bound'>Subsection 4.4.2</a>) that all functions mapping <span><span class="math inline">\(n\)</span></span> bits to <span><span class="math inline">\(n\)</span></span> bits can be computed by a circuit of size <span><span class="math inline">\(c \cdot 2^n\)</span></span> for <span><span class="math inline">\(c \leq 10\)</span></span>, while on the other hand the counting lower bound (<a href='#counting-lb'>Theorem 5.3</a>, see also <a href='#countingmultibitex'>Exercise 5.4</a>) shows that <em>some</em> such functions will require <span><span class="math inline">\(0.1 \cdot 2^n\)</span></span>, and the size hierarchy theorem (<a href='#sizehiearchythm'>Theorem 5.5</a>) shows the existence of functions in <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}(S) \setminus \ensuremath{\mathit{SIZE}}(s)\)</span></span> whenever <span><span class="math inline">\(s=o(S)\)</span></span>, see also <a href='#sizehiearchyex'>Exercise 5.5</a>. We also consider some specific examples: addition of two <span><span class="math inline">\(n/2\)</span></span> bit numbers can be done in <span><span class="math inline">\(O(n)\)</span></span> lines, while we don’t know of such a program for <em>multiplying</em> two <span><span class="math inline">\(n\)</span></span> bit numbers, though we do know it can be done in <span><span class="math inline">\(O(n^2)\)</span></span> and in fact even better size. In the above, <span><span class="math inline">\(\ensuremath{\mathit{FACTOR}}_n\)</span></span> corresponds to the inverse problem of multiplying- finding the <em>prime factorization</em> of a given number. At the moment we do not know of any circuit a polynomial (or even sub-exponential) number of lines that can compute <span><span class="math inline">\(\ensuremath{\mathit{FACTOR}}_n\)</span></span>.</figcaption>
</figure>
<div id="explicitfunc" class="remark" title="Explicit functions" name="Remark 5.6 (Explicit functions) ">
<p>While the size hierarchy theorem guarantees that there exists <em>some</em> function that <em>can</em> be computed using, for example, <span><span class="math inline">\(n^2\)</span></span> gates, but not using <span><span class="math inline">\(100n\)</span></span> gates, we do not know of any explicit example of such a function. While we suspect that integer multiplication is such an example, we do not have any proof that this is the case.</p>
</div>
<h2 id="listoftuplesrepsec" data-number="5.3">The tuples representation</h2>
<p>ASCII is a fine presentation of programs, but for some applications it is useful to have a more concrete representation of NAND-CIRC programs. In this section we describe a particular choice, that will be convenient for us later on. A NAND-CIRC program is simply a sequence of lines of the form</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1">blah <span class="op">=</span> NAND(baz,boo)</a></code></pre></div>
<p>There is of course nothing special about the particular names we use for variables. Although they would be harder to read, we could write all our programs using only working variables such as <code>temp_0</code>, <code>temp_1</code> etc. Therefore, our representation for NAND-CIRC programs ignores the actual names of the variables, and just associate a <em>number</em> with each variable. We encode a <em>line</em> of the program as a triple of numbers. If the line has the form <code>foo = NAND(bar,blah)</code> then we encode it with the triple <span><span class="math inline">\((i,j,k)\)</span></span> where <span><span class="math inline">\(i\)</span></span> is the number corresponding to the variable <code>foo</code> and <span><span class="math inline">\(j\)</span></span> and <span><span class="math inline">\(k\)</span></span> are the numbers corresponding to <code>bar</code> and <code>blah</code> respectively.</p>
<p>More concretely, we will associate every variable with a number in the set <span><span class="math inline">\([t]= \{0,1,\ldots,t-1\}\)</span></span>. The first <span><span class="math inline">\(n\)</span></span> numbers <span><span class="math inline">\(\{0,\ldots,n-1\}\)</span></span> correspond to the <em>input</em> variables, the last <span><span class="math inline">\(m\)</span></span> numbers <span><span class="math inline">\(\{t-m,\ldots,t-1\}\)</span></span> correspond to the <em>output</em> variables, and the intermediate numbers <span><span class="math inline">\(\{ n,\ldots, t-m-1\}\)</span></span> correspond to the remaining “workspace” variables. Formally, we define our representation as follows:</p>
<div id="nandtuplesdef" class="definition" title="List of tuples representation" name="Definition 5.7 (List of tuples representation) ">
<p>Let <span><span class="math inline">\(P\)</span></span> be a NAND-CIRC program of <span><span class="math inline">\(n\)</span></span> inputs, <span><span class="math inline">\(m\)</span></span> outputs, and <span><span class="math inline">\(s\)</span></span> lines, and let <span><span class="math inline">\(t\)</span></span> be the number of distinct variables used by <span><span class="math inline">\(P\)</span></span>. The <em>list of tuples representation of <span><span class="math inline">\(P\)</span></span></em> is the triple <span><span class="math inline">\((n,m,L)\)</span></span> where <span><span class="math inline">\(L\)</span></span> is a list of triples of the form <span><span class="math inline">\((i,j,k)\)</span></span> for <span><span class="math inline">\(i,j,k \in [t]\)</span></span>.</p>
<p>We assign a number for variable of <span><span class="math inline">\(P\)</span></span> as follows:</p>
<ul>
<li><p>For every <span><span class="math inline">\(i\in [n]\)</span></span>, the variable <code>X[</code><span><span class="math inline">\(i\)</span></span><code>]</code> is assigned the number <span><span class="math inline">\(i\)</span></span>.</p></li>
<li><p>For every <span><span class="math inline">\(j\in [m]\)</span></span>, the variable <code>Y[</code><span><span class="math inline">\(j\)</span></span><code>]</code> is assigned the number <span><span class="math inline">\(t-m+j\)</span></span>.</p></li>
<li><p>Every other variable is assigned a number in <span><span class="math inline">\(\{n,n+1,\ldots,t-m-1\}\)</span></span> in the order in which the variable appears in the program <span><span class="math inline">\(P\)</span></span>.</p></li>
</ul>
</div>
<p>The list of tuples representation is our default choice for representing NAND-CIRC programs. Since “list of tuples representation” is a bit of a mouthful, we will often call it simply “the representation” for a program <span><span class="math inline">\(P\)</span></span>. Sometimes, when the number <span><span class="math inline">\(n\)</span></span> of inputs and number <span><span class="math inline">\(m\)</span></span> of outputs are known from the context, we will simply represent a program as the list <span><span class="math inline">\(L\)</span></span> instead of the triple <span><span class="math inline">\((n,m,L)\)</span></span>.</p>
<div id="representXOR" class="example" title="Representing the XOR program" name="Example 5.8 (Representing the XOR program) ">
<p>Our favorite NAND-CIRC program, the program</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1">u <span class="op">=</span> NAND(X[<span class="dv">0</span>],X[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb3-2" title="2">v <span class="op">=</span> NAND(X[<span class="dv">0</span>],u)</a>
<a class="sourceLine" id="cb3-3" title="3">w <span class="op">=</span> NAND(X[<span class="dv">1</span>],u)</a>
<a class="sourceLine" id="cb3-4" title="4">Y[<span class="dv">0</span>] <span class="op">=</span> NAND(v,w)</a></code></pre></div>
<p>computing the XOR function is represented as the tuple <span><span class="math inline">\((2,1,L)\)</span></span> where <span><span class="math inline">\(L=((2, 0, 1), (3, 0, 2), (4, 1, 2), (5, 3, 4))\)</span></span>. That is, the variables <code>X[0]</code> and <code>X[1]</code> are given the indices <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(1\)</span></span> respectively, the variables <code>u</code>,<code>v</code>,<code>w</code> are given the indices <span><span class="math inline">\(2,3,4\)</span></span> respectively, and the variable <code>Y[0]</code> is given the index <span><span class="math inline">\(5\)</span></span>.</p>
</div>
<p>Transforming a NAND-CIRC program from its representation as code to the representation as a list of tuples is a fairly straightforward programming exercise, and in particular can be done in a few lines of <em>Python</em>.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> The list-of-tuples representation loses information such as the particular names we used for the variables, but this is OK since these names do not make a difference to the functionality of the program.</p>
<h3 id="stringrepresentationrpgoramsec" data-number="5.3.1">From tuples to strings</h3>
<p>If <span><span class="math inline">\(P\)</span></span> is a program of size <span><span class="math inline">\(s\)</span></span>, then the number <span><span class="math inline">\(t\)</span></span> of variables is at most <span><span class="math inline">\(3s\)</span></span> (as every line touches at most three variables). Hence we can encode every variable index in <span><span class="math inline">\([t]\)</span></span> as a string of length <span><span class="math inline">\(\ell = \ceil{\log (3s)}\)</span></span>, by adding leading zeroes as needed. Since this is a fixed-length encoding, it is prefix free, and so we can encode the list <span><span class="math inline">\(L\)</span></span> of <span><span class="math inline">\(s\)</span></span> triples (corresponding to the encoding of the <span><span class="math inline">\(s\)</span></span> lines of the program) as simply the string of length <span><span class="math inline">\(3\ell s\)</span></span> obtained by concatenating all of these encodings.</p>
<p>We define <span><span class="math inline">\(S(s)\)</span></span> to be the length of the string representing the list <span><span class="math inline">\(L\)</span></span> corresponding to a size <span><span class="math inline">\(s\)</span></span> program. By the above we see that <span>
<div class='myequationbox'><span class="math display">\[
S(s) = 3s\ceil{\log (3s)} \;. \;\;(5.8)
\]</span><a id='lengthstringrepreseq'></a></div></span></p>
<p>We can represent <span><span class="math inline">\(P=(n,m,L)\)</span></span> as a string by prepending a prefix free representation of <span><span class="math inline">\(n\)</span></span> and <span><span class="math inline">\(m\)</span></span> to the list <span><span class="math inline">\(L\)</span></span>. Since <span><span class="math inline">\(n,m \leq 3s\)</span></span> (a program must touch at least once all its input and output variables), those prefix free representations can be encoded using strings of length <span><span class="math inline">\(O(\log s)\)</span></span>. In particular, every program <span><span class="math inline">\(P\)</span></span> of at most <span><span class="math inline">\(s\)</span></span> lines can be represented by a string of length <span><span class="math inline">\(O(s\log s)\)</span></span>. Similarly, every circuit <span><span class="math inline">\(C\)</span></span> of at most <span><span class="math inline">\(s\)</span></span> gates, can be represented by a string of length <span><span class="math inline">\(O(s \log s)\)</span></span> (for example by translating <span><span class="math inline">\(C\)</span></span> to the equivalent program <span><span class="math inline">\(P\)</span></span>).</p>
<h2 id="a-nand-circ-interpreter-in-nand-circ" data-number="5.4">A NAND-CIRC interpreter in NAND-CIRC</h2>
<p>Since we can represent programs as strings, we can also think of a program as an input to a function. In particular, for every natural number <span><span class="math inline">\(s,n,m&gt;0\)</span></span> we define the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}:\{0,1\}^{S(s)+n} \rightarrow \{0,1\}^m\)</span></span> as follows: <span>
<div class='myequationbox'><span class="math display">\[
\ensuremath{\mathit{EVAL}}_{s,n,m}(px) = \begin{cases} P(x) &amp; \text{$p\in \{0,1\}^{S(s)}$ represents a size-$s$ program $P$ with $n$ inputs and $m$ outputs}  \\ 0^m &amp; \text{otherwise} \end{cases} \;\;(5.9)
\]</span><a id='evalcirceq'></a></div></span> where <span><span class="math inline">\(S(s)\)</span></span> is defined as in <a href='#lengthstringrepreseq'>Equation 5.8</a> and we use the concrete representation scheme described in <a href='#representprogramsec'>Section 5.1</a>.</p>
<p>That is, <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> takes as input the concatenation of two strings: a string <span><span class="math inline">\(p\in \{0,1\}^{S(s)}\)</span></span> and a string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>. If <span><span class="math inline">\(p\)</span></span> is a string that represents a list of triples <span><span class="math inline">\(L\)</span></span> such that <span><span class="math inline">\((n,m,L)\)</span></span> is a list-of-tuples representation of a size-<span><span class="math inline">\(s\)</span></span> NAND-CIRC program <span><span class="math inline">\(P\)</span></span>, then <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}(px)\)</span></span> is equal to the evaluation <span><span class="math inline">\(P(x)\)</span></span> of the program <span><span class="math inline">\(P\)</span></span> on the input <span><span class="math inline">\(x\)</span></span>. Otherwise, <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}(px)\)</span></span> equals <span><span class="math inline">\(0^m\)</span></span> (this case is not very important: you can simply think of <span><span class="math inline">\(0^m\)</span></span> as some “junk value” that indicates an error).</p>
<p><strong>Take-away points.</strong> The fine details of <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>’s definition are not very crucial. Rather, what you need to remember about <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is that:</p>
<ul>
<li><p><span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is a finite function taking a string of fixed length as input and outputting a string of fixed length as output.</p></li>
<li><p><span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is a single function, such that computing <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> allows to evaluate <em>arbitrary</em> NAND-CIRC programs of a certain length on <em>arbitrary</em> inputs of the appropriate length.</p></li>
<li><p><span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is a <em>function</em>, not a <em>program</em> (recall the discussion in <a href='lec_03_computation.html#specvsimplrem'>Subsection 3.6.2</a>). That is, <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is a <em>specification</em> of what output is associated with what input. The existence of a <em>program</em> that computes <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> (i.e., an <em>implementation</em> for <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>) is a separate fact, which needs to be established (and which we will do in <a href='#bounded-univ'>Theorem 5.9</a>, with a more efficient program shown in <a href='#eff-bounded-univ'>Theorem 5.10</a>).</p></li>
</ul>
<p>One of the first examples of <em>self circularity</em> we will see in this book is the following theorem, which we can think of as showing a “NAND-CIRC interpreter in NAND-CIRC”:</p>
<div id="bounded-univ" class="theorem" title="Bounded Universality of NAND-CIRC programs" name="Theorem 5.9 (Bounded Universality of NAND-CIRC programs) ">
<p>For every <span><span class="math inline">\(s,n,m \in \N\)</span></span> with <span><span class="math inline">\(s\geq m\)</span></span> there is a NAND-CIRC program <span><span class="math inline">\(U_{s,n,m}\)</span></span> that computes the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>.</p>
</div>
<p>That is, the NAND-CIRC program <span><span class="math inline">\(U_{s,n,m}\)</span></span> takes the description of <em>any other NAND-CIRC program</em> <span><span class="math inline">\(P\)</span></span> (of the right length and inputs/outputs) and <em>any input</em> <span><span class="math inline">\(x\)</span></span>, and computes the result of evaluating the program <span><span class="math inline">\(P\)</span></span> on the input <span><span class="math inline">\(x\)</span></span>. Given the equivalence between NAND-CIRC programs and Boolean circuits, we can also think of <span><span class="math inline">\(U_{s,n,m}\)</span></span> as a circuit that takes as input the description of other circuits and their inputs, and returns their evaluation, see <a href='#universalcircfig'>Figure 5.6</a>. We call this NAND-CIRC program <span><span class="math inline">\(U_{s,n,m}\)</span></span> that computes <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> a <em>bounded universal program</em> (or a <em>universal circuit</em>, see <a href='#universalcircfig'>Figure 5.6</a>). “Universal” stands for the fact that this is a <em>single program</em> that can evaluate <em>arbitrary</em> code, where “bounded” stands for the fact that <span><span class="math inline">\(U_{s,n,m}\)</span></span> only evaluates programs of bounded size. Of course this limitation is inherent for the NAND-CIRC programming language, since a program of <span><span class="math inline">\(s\)</span></span> lines (or, equivalently, a circuit of <span><span class="math inline">\(s\)</span></span> gates) can take at most <span><span class="math inline">\(2s\)</span></span> inputs. Later, in <a href='lec_06_loops.html#chaploops'>Chapter 6</a>, we will introduce the concept of <em>loops</em> (and the model of <em>Turing Machines</em>), that allow to escape this limitation.</p>
<div class="proof" data-ref="bounded-univ" name="Proof">
<p><a href='#bounded-univ'>Theorem 5.9</a> is an important result, but it is actually not hard to prove. Specifically, since <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is a finite function <a href='#bounded-univ'>Theorem 5.9</a> is an immediate corollary of <a href='lec_03a_computing_every_function.html#NAND-univ-thm'>Theorem 4.12</a>, which states that <em>every</em> finite function can be computed by <em>some</em> NAND-CIRC program.</p>
</div>
<div id="section-2" class="pause" name="Pause">
<p><a href='#bounded-univ'>Theorem 5.9</a> is simple but important. Make sure you understand what this theorem means, and why it is a corollary of <a href='lec_03a_computing_every_function.html#NAND-univ-thm'>Theorem 4.12</a>.</p>
</div>
<figure>
<img src="../figure/universalcircuit.png" alt="5.6: A universal circuit U is a circuit that gets as input the description of an arbitrary (smaller) circuit P as a binary string, and an input x, and outputs the string P(x) which is the evaluation of P on x. We can also think of U as a straight-line program that gets as input the code of a straight-line program P and an input x, and outputs P(x)." id="universalcircfig" class="margin" /><figcaption>5.6: A <em>universal circuit</em> <span><span class="math inline">\(U\)</span></span> is a circuit that gets as input the description of an arbitrary (smaller) circuit <span><span class="math inline">\(P\)</span></span> as a binary string, and an input <span><span class="math inline">\(x\)</span></span>, and outputs the string <span><span class="math inline">\(P(x)\)</span></span> which is the evaluation of <span><span class="math inline">\(P\)</span></span> on <span><span class="math inline">\(x\)</span></span>. We can also think of <span><span class="math inline">\(U\)</span></span> as a straight-line program that gets as input the code of a straight-line program <span><span class="math inline">\(P\)</span></span> and an input <span><span class="math inline">\(x\)</span></span>, and outputs <span><span class="math inline">\(P(x)\)</span></span>.</figcaption>
</figure>
<h3 id="efficient-universal-programs" data-number="5.4.1">Efficient universal programs</h3>
<p><a href='#bounded-univ'>Theorem 5.9</a> establishes the existence of a NAND-CIRC program for computing <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>, but it provides no explicit bound on the size of this program. <a href='lec_03a_computing_every_function.html#NAND-univ-thm'>Theorem 4.12</a>, which we used to prove <a href='#bounded-univ'>Theorem 5.9</a>, guarantees the existence of a NAND-CIRC program whose size can be as large as <em>exponential</em> in the length of its input. This would mean that even for moderately small values of <span><span class="math inline">\(s,n,m\)</span></span> (for example <span><span class="math inline">\(n=100,s=300,m=1\)</span></span>), computing <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> might require a NAND program with more lines than there are atoms in the observable universe! Fortunately, we can do much better than that. In fact, for every <span><span class="math inline">\(s,n,m\)</span></span> there exists a NAND-CIRC program for computing <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> with size that is <em>polynomial</em> in its input length. This is shown in the following theorem.</p>
<div id="eff-bounded-univ" class="theorem" title="Efficient bounded universality of NAND-CIRC programs" name="Theorem 5.10 (Efficient bounded universality of NAND-CIRC programs) ">
<p>For every <span><span class="math inline">\(s,n,m \in \N\)</span></span> there is a NAND-CIRC program of at most <span><span class="math inline">\(O(s^2 \log s)\)</span></span> lines that computes the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}:\{0,1\}^{S+n} \rightarrow \{0,1\}^m\)</span></span> defined above (where <span><span class="math inline">\(S\)</span></span> is the number of bits needed to represent programs of <span><span class="math inline">\(s\)</span></span> lines).</p>
</div>
<div class="pause" name="Pause 5.4.1">
<p>If you haven’t done so already, now might be a good time to review <span><span class="math inline">\(O\)</span></span> notation in <a href='lec_00_1_math_background.html#secbigohnotation'>Subsection 1.4.8</a>. In particular, an equivalent way to state <a href='#eff-bounded-univ'>Theorem 5.10</a> is that it says that there <em>exists</em> some number <span><span class="math inline">\(c&gt;0\)</span></span> such that <em>for every</em> <span><span class="math inline">\(s,n,m \in \N\)</span></span>, there exists a NAND-CIRC program <span><span class="math inline">\(P\)</span></span> of at most <span><span class="math inline">\(c s^2 \log s\)</span></span> lines that computes the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>.</p>
</div>
<p>Unlike <a href='#bounded-univ'>Theorem 5.9</a>, <a href='#eff-bounded-univ'>Theorem 5.10</a> is not a trivial corollary of the fact that every finite function can be computed by some circuit. Proving <a href='#bounded-univ'>Theorem 5.9</a> requires us to present a concrete NAND-CIRC program for computing the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>. We will do so in several stages.</p>
<ol type="1">
<li><p>First, we will describe the algorithm to evaluate <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> in “pseudo code”.</p></li>
<li><p>Then, we will show how we can write a program to compute <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> in <em>Python</em>. We will not use much about Python, and a reader that has familiarity with programming in any language should be able to follow along.</p></li>
<li><p>Finally, we will show how we can transform this Python program into a NAND-CIRC program.</p></li>
</ol>
<p>This approach yields much more than just proving <a href='#eff-bounded-univ'>Theorem 5.10</a>: we will see that it is in fact always possible to transform (loop free) code in high level languages such as Python to NAND-CIRC programs (and hence to Boolean circuits as well).</p>
<h3 id="a-nand-circ-interpeter-in-pseudocode" data-number="5.4.2">A NAND-CIRC interpeter in “pseudocode”</h3>
<p>To prove <a href='#eff-bounded-univ'>Theorem 5.10</a> it suffices to give a NAND-CIRC program of <span><span class="math inline">\(O(s^2 \log s)\)</span></span> lines that can evaluate NAND-CIRC programs of <span><span class="math inline">\(s\)</span></span> lines. Let us start by thinking how we would evaluate such programs if we weren’t restricted to only performing NAND operations. That is, let us describe informally an <em>algorithm</em> that on input <span><span class="math inline">\(n,m,s\)</span></span>, a list of triples <span><span class="math inline">\(L\)</span></span>, and a string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, evaluates the program represented by <span><span class="math inline">\((n,m,L)\)</span></span> on the string <span><span class="math inline">\(x\)</span></span>.</p>
<div id="section-3" class="pause" name="Pause">
<p>It would be highly worthwhile for you to stop here and try to solve this problem yourself. For example, you can try thinking how you would write a program <code>NANDEVAL(n,m,s,L,x)</code> that computes this function in the programming language of your choice.</p>
</div>
<p>We will now describe such an algorithm. We assume that we have access to a <em>bit array</em> data structure that can store for every <span><span class="math inline">\(i\in [t]\)</span></span> a bit <span><span class="math inline">\(T_i \in \{0,1\}\)</span></span>. Specifically, if <code>Table</code> is a variable holding this data structure, then we assume we can perform the operations:</p>
<ul>
<li><p><code>GET(Table,i)</code> which retrieves the bit corresponding to <code>i</code> in <code>Table</code>. The value of <code>i</code> is assumed to be an integer in <span><span class="math inline">\([t]\)</span></span>.</p></li>
<li><p><code>Table = UPDATE(Table,i,b)</code> which updates <code>Table</code> so the the bit corresponding to <code>i</code> is now set to <code>b</code>. The value of <code>i</code> is assumed to be an integer in <span><span class="math inline">\([t]\)</span></span> and <code>b</code> is a bit in <span><span class="math inline">\(\{0,1\}\)</span></span>.</p></li>
</ul>
<div  class="pseudocodeoutput">
<div class="ps-root">
<div class="ps-algorithm with-caption" id = evalnandcircalg>
<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;">
<span class="ps-keyword">Algorithm 11 </span>Eval NAND-CIRC programs</p>
<div class="ps-algorithmic"><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">Input:</span>  Numbers \(n,m,s\) and \(t\leq 3s\), as well as  a list \(L\) of \(s\) triples of numbers in \([t]\), and  a string \(x\in \{0,1\}^n\).<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">Output:</span>  Evaluation of the program represented by \((n,m,L)\) on the <span class="ps-keyword">Input:</span> \(x\in \{0,1\}^n\).<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> Let \texttt{Vartable} be table of size \(t\)<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">for</span>{\(i\) in \([n]\)} 
                <div class="ps-block" style="margin-left:1.2em;">
                <p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \texttt{Vartable = UPDATE(Vartable,}\(i\)\texttt{,}\(x_i\)\texttt{)}
</div><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">endfor</span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">for</span>{\((i,j,k)\) in \(L\)} 
                <div class="ps-block" style="margin-left:1.2em;">
                <p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \(a \leftarrow\) \texttt{GET(Vartable,}\(j\)\texttt{)}<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \(b \leftarrow\) \texttt{GET(Vartable,}\(k\)\texttt{)}<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \texttt{Vartable = UPDATE(Vartable,}\(i\),\texttt{NAND(}\(a\)\texttt{,}\(b\)\texttt{))}
</div><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">endfor</span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">for</span>{\(j\) in \([m]\)} 
                <div class="ps-block" style="margin-left:1.2em;">
                <p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \(y_j \leftarrow\) \texttt{GET(Vartable,}\(t-m+j\)\texttt{)}
</div><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">endfor</span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">return</span> \(y_0,\ldots,y_{m-1}\)<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"></div>
</div>
</div>
</div>
<p><a href='#evalnandcircalg'>Algorithm 5.11</a> evaluates the program given to it as input one line at a time, updating the <code>Vartable</code> table to contain the value of each variable. At the end of the execution it outputs the variables at positions <span><span class="math inline">\(t-m,t-m+1,\ldots,t-1\)</span></span> which correspond to the input variables.</p>
<h3 id="nandevalpythonsec" data-number="5.4.3">A NAND interpreter in Python</h3>
<p>To make things more concrete, let us see how we implement <a href='#evalnandcircalg'>Algorithm 5.11</a> in the <em>Python</em> programming language. (There is nothing special about Python. We could have easily presented a corresponding function in JavaScript, C, OCaml, or any other programming language.) We will construct a function <code>NANDEVAL</code> that on input <span><span class="math inline">\(n,m,L,x\)</span></span> will output the result of evaluating the program represented by <span><span class="math inline">\((n,m,L)\)</span></span> on <span><span class="math inline">\(x\)</span></span>. To keep things simple, we will not worry about the case that <span><span class="math inline">\(L\)</span></span> does not represent a valid program of <span><span class="math inline">\(n\)</span></span> inputs and <span><span class="math inline">\(m\)</span></span> outputs. The code is presented in <a href='#nandevalcode'>Figure 5.7</a>.</p>
<div>
<p><i>Figure 5.7: Code for evaluating a NAND-CIRC program given in the list-of-tuples representation</i></p>

<div class="sourceCode" id="nandevalcode" title="Code for evaluating a NAND-CIRC program given in the list-of-tuples representation"><pre class="sourceCode python full"><code class="sourceCode python"><a class="sourceLine" id="nandevalcode-1" title="1"><span class="kw">def</span> NANDEVAL(n,m,L,X):</a>
<a class="sourceLine" id="nandevalcode-2" title="2">    <span class="co"># Evaluate a NAND-CIRC program from list of tuple representation.</span></a>
<a class="sourceLine" id="nandevalcode-3" title="3">    s <span class="op">=</span> <span class="bu">len</span>(L) <span class="co"># num of lines</span></a>
<a class="sourceLine" id="nandevalcode-4" title="4">    t <span class="op">=</span> <span class="bu">max</span>(<span class="bu">max</span>(a,b,c) <span class="cf">for</span> (a,b,c) <span class="kw">in</span> L)<span class="op">+</span><span class="dv">1</span> <span class="co"># max index in L + 1</span></a>
<a class="sourceLine" id="nandevalcode-5" title="5">    Vartable <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> t <span class="co"># initialize array</span></a>
<a class="sourceLine" id="nandevalcode-6" title="6"></a>
<a class="sourceLine" id="nandevalcode-7" title="7">    <span class="co"># helper functions</span></a>
<a class="sourceLine" id="nandevalcode-8" title="8">    <span class="kw">def</span> GET(V,i): <span class="cf">return</span> V[i]</a>
<a class="sourceLine" id="nandevalcode-9" title="9">    <span class="kw">def</span> UPDATE(V,i,b):</a>
<a class="sourceLine" id="nandevalcode-10" title="10">        V[i]<span class="op">=</span>b</a>
<a class="sourceLine" id="nandevalcode-11" title="11">        <span class="cf">return</span> V</a>
<a class="sourceLine" id="nandevalcode-12" title="12"></a>
<a class="sourceLine" id="nandevalcode-13" title="13">    <span class="co"># load input values to Vartable:</span></a>
<a class="sourceLine" id="nandevalcode-14" title="14">    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</a>
<a class="sourceLine" id="nandevalcode-15" title="15">        Vartable <span class="op">=</span> UPDATE(Vartable,i,X[i])</a>
<a class="sourceLine" id="nandevalcode-16" title="16"></a>
<a class="sourceLine" id="nandevalcode-17" title="17">    <span class="co"># Run the program</span></a>
<a class="sourceLine" id="nandevalcode-18" title="18">    <span class="cf">for</span> (i,j,k) <span class="kw">in</span> L:</a>
<a class="sourceLine" id="nandevalcode-19" title="19">        a <span class="op">=</span> GET(Vartable,j)</a>
<a class="sourceLine" id="nandevalcode-20" title="20">        b <span class="op">=</span> GET(Vartable,k)</a>
<a class="sourceLine" id="nandevalcode-21" title="21">        c <span class="op">=</span> NAND(a,b)</a>
<a class="sourceLine" id="nandevalcode-22" title="22">        Vartable <span class="op">=</span> UPDATE(Vartable,i,c)</a>
<a class="sourceLine" id="nandevalcode-23" title="23"></a>
<a class="sourceLine" id="nandevalcode-24" title="24">    <span class="co"># Return outputs Vartable[t-m], Vartable[t-m+1],....,Vartable[t-1]</span></a>
<a class="sourceLine" id="nandevalcode-25" title="25">    <span class="cf">return</span> [GET(Vartable,t<span class="op">-</span>m<span class="op">+</span>j) <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(m)]</a>
<a class="sourceLine" id="nandevalcode-26" title="26"></a>
<a class="sourceLine" id="nandevalcode-27" title="27"><span class="co"># Test on XOR (2 inputs, 1 output)</span></a>
<a class="sourceLine" id="nandevalcode-28" title="28">L <span class="op">=</span> ((<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>), (<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>), (<span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">2</span>), (<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>))</a>
<a class="sourceLine" id="nandevalcode-29" title="29"><span class="bu">print</span>(NANDEVAL(<span class="dv">2</span>,<span class="dv">1</span>,L,(<span class="dv">0</span>,<span class="dv">1</span>))) <span class="co"># XOR(0,1)</span></a>
<a class="sourceLine" id="nandevalcode-30" title="30"><span class="co"># [1]</span></a>
<a class="sourceLine" id="nandevalcode-31" title="31"><span class="bu">print</span>(NANDEVAL(<span class="dv">2</span>,<span class="dv">1</span>,L,(<span class="dv">1</span>,<span class="dv">1</span>))) <span class="co"># XOR(1,1)</span></a>
<a class="sourceLine" id="nandevalcode-32" title="32"><span class="co"># [0]</span></a></code></pre></div>
<p></p>
</div>
<p>Accessing an element of the array <code>Vartable</code> at a given index takes a constant number of basic operations. Hence (since <span><span class="math inline">\(n,m \leq s\)</span></span> and <span><span class="math inline">\(t \leq 3s\)</span></span>), the program above will use <span><span class="math inline">\(O(s)\)</span></span> basic operations.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup></p>
<h3 id="constructing-the-nand-circ-interpreter-in-nand-circ" data-number="5.4.4">Constructing the NAND-CIRC interpreter in NAND-CIRC</h3>
<p>We now turn to describing the proof of <a href='#eff-bounded-univ'>Theorem 5.10</a>. To prove the theorem it is not enough to give a Python program. Rather, we need to show how we compute the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> using a <em>NAND-CIRC program</em>. In other words, our job is to transform, for every <span><span class="math inline">\(s,n,m\)</span></span>, the Python code of <a href='#nandevalpythonsec'>Subsection 5.4.3</a> to a NAND-CIRC program <span><span class="math inline">\(U_{s,n,m}\)</span></span> that computes the function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>.</p>
<div id="section-4" class="pause" name="Pause">
<p>Before reading further, try to think how <em>you</em> could give a “constructive proof” of <a href='#eff-bounded-univ'>Theorem 5.10</a>. That is, think of how you would write, in the programming language of your choice, a function <code>universal(s,n,m)</code> that on input <span><span class="math inline">\(s,n,m\)</span></span> outputs the code for the NAND-CIRC program <span><span class="math inline">\(U_{s,n,m}\)</span></span> such that <span><span class="math inline">\(U_{s,n,m}\)</span></span> computes <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span>. There is a subtle but crucial difference between this function and the Python <code>NANDEVAL</code> program described above. Rather than actually evaluating a given program <span><span class="math inline">\(P\)</span></span> on some input <span><span class="math inline">\(w\)</span></span>, the function <code>universal</code> should output the <em>code</em> of a NAND-CIRC program that computes the map <span><span class="math inline">\((P,x) \mapsto P(x)\)</span></span>.</p>
</div>
<p>Our construction will follow very closely the Python implementation of <code>EVAL</code> above. We will use variables <code>Vartable[</code><span><span class="math inline">\(0\)</span></span><code>]</code>,<span><span class="math inline">\(\ldots\)</span></span>,<code>Vartable[</code><span><span class="math inline">\(2^\ell-1\)</span></span><code>]</code>, where <span><span class="math inline">\(\ell = \ceil{\log 3s}\)</span></span> to store our variables. However, NAND doesn’t have integer-valued variables, so we cannot write code such as <code>Vartable[i]</code> for some variable <code>i</code>. However, we <em>can</em> implement the function <code>GET(Vartable,i)</code> that outputs the <code>i</code>-th bit of the array <code>Vartable</code>. Indeed, this is nothing but the function <span><span class="math inline">\(\ensuremath{\mathit{LOOKUP}}_\ell\)</span></span> that we have seen in <a href='lec_03a_computing_every_function.html#lookup-thm'>Theorem 4.10</a>!</p>
<div id="section-5" class="pause" name="Pause">
<p>Please make sure that you understand why <code>GET</code> and <span><span class="math inline">\(\ensuremath{\mathit{LOOKUP}}_\ell\)</span></span> are the same function.</p>
</div>
<p>We saw that we can compute <span><span class="math inline">\(\ensuremath{\mathit{LOOKUP}}_\ell\)</span></span> in time <span><span class="math inline">\(O(2^\ell) = O(s)\)</span></span> for our choice of <span><span class="math inline">\(\ell\)</span></span>.</p>
<p>For every <span><span class="math inline">\(\ell\)</span></span>, let <span><span class="math inline">\(\ensuremath{\mathit{UPDATE}}_\ell:\{0,1\}^{2^\ell + \ell +1} \rightarrow \{0,1\}^{2^\ell}\)</span></span> correspond to the <code>UPDATE</code> function for arrays of length <span><span class="math inline">\(2^\ell\)</span></span>. That is, on input <span><span class="math inline">\(V\in \{0,1\}^{2^\ell}\)</span></span> , <span><span class="math inline">\(i\in \{0,1\}^\ell\)</span></span>, <span><span class="math inline">\(b\in \{0,1\}\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{UPDATE}}_\ell(V,b,i)\)</span></span> is equal to <span><span class="math inline">\(V&#39; \in \{0,1\}^{2^\ell}\)</span></span> such that <span>
<div class='myequationbox'><span class="math display">\[
V&#39;_j = \begin{cases} V_j &amp; j \neq i \\ b &amp; j = 1 \end{cases}
\]</span></div></span> where we identify the string <span><span class="math inline">\(i \in \{0,1\}^\ell\)</span></span> with a number in <span><span class="math inline">\(\{0,\ldots, 2^{\ell}-1 \}\)</span></span> using the binary representation. We can compute <span><span class="math inline">\(\ensuremath{\mathit{UPDATE}}_\ell\)</span></span> using an <span><span class="math inline">\(O(2^\ell \ell)=(s \log s)\)</span></span> line NAND-CIRC program as as follows:</p>
<ol type="1">
<li><p>For every <span><span class="math inline">\(j\in [2^\ell]\)</span></span>, there is an <span><span class="math inline">\(O(\ell)\)</span></span> line NAND-CIRC program to compute the function <span><span class="math inline">\(\ensuremath{\mathit{EQUALS}}_j: \{0,1\}^\ell \rightarrow \{0,1\}\)</span></span> that on input <span><span class="math inline">\(i\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(i\)</span></span> is equal to (the binary representation of) <span><span class="math inline">\(j\)</span></span>. (We leave verifying this as <a href='#equals'>Exercise 5.2</a> and <a href='#equalstwo'>Exercise 5.3</a>.)</p></li>
<li><p>We have seen that we can compute the function <span><span class="math inline">\(\ensuremath{\mathit{IF}}:\{0,1\}^3 \rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{IF}}(a,b,c)\)</span></span> equals <span><span class="math inline">\(b\)</span></span> if <span><span class="math inline">\(a=1\)</span></span> and <span><span class="math inline">\(c\)</span></span> if <span><span class="math inline">\(a=0\)</span></span>.</p></li>
</ol>
<p>Together, this means that we can compute <code>UPDATE</code> (using some “syntactic sugar” for bounded length loops) as follows:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">def</span> UPDATE_ell(V,i,b):</a>
<a class="sourceLine" id="cb4-2" title="2">    <span class="co"># Get V[0]...V[2^ell-1], i in {0,1}^ell, b in {0,1}</span></a>
<a class="sourceLine" id="cb4-3" title="3">    <span class="co"># Return NewV[0],...,NewV[2^ell-1]</span></a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="co"># updated array with NewV[i]=b and all</span></a>
<a class="sourceLine" id="cb4-5" title="5">    <span class="co"># else same as V</span></a>
<a class="sourceLine" id="cb4-6" title="6">    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span><span class="op">**</span>ell): <span class="co"># j = 0,1,2,....,2^ell -1</span></a>
<a class="sourceLine" id="cb4-7" title="7">        a <span class="op">=</span> EQUALS_j(i)</a>
<a class="sourceLine" id="cb4-8" title="8">        NewV[j] <span class="op">=</span> IF(a,b,V[j])</a>
<a class="sourceLine" id="cb4-9" title="9">    <span class="cf">return</span> NewV</a></code></pre></div>
<p>Since the loop over <code>j</code> in <code>UPDATE</code> is run <span><span class="math inline">\(2^\ell\)</span></span> times, and computing <code>EQUALS_j</code> takes <span><span class="math inline">\(O(\ell)\)</span></span> lines, the total number of lines to compute <code>UPDATE</code> is <span><span class="math inline">\(O(2^\ell \cdot \ell) = O(s \log s)\)</span></span>. Once we can compute <code>GET</code> and <code>UPDATE</code>, the rest of the implementation amounts to “book keeping” that needs to be done carefully, but is not too insightful, and hence we omit the full details. Since we run <code>GET</code> and <code>UPDATE</code> <span><span class="math inline">\(s\)</span></span> times, the total number of lines for computing <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}_{s,n,m}\)</span></span> is <span><span class="math inline">\(O(s^2) + O(s^2 \log s) = O(s^2 \log s)\)</span></span>. This completes (up to the omitted details) the proof of <a href='#eff-bounded-univ'>Theorem 5.10</a>.</p>
<div id="quasilinearevalrem" class="remark" title="Improving to quasilinear overhead (advanced optional note)" name="Remark 5.12 (Improving to quasilinear overhead (advanced optional note)) ">
<p>The NAND-CIRC program above is less efficient than its Python counterpart, since NAND does not offer arrays with efficient random access. Hence for example the <code>LOOKUP</code> operation on an array of <span><span class="math inline">\(s\)</span></span> bits takes <span><span class="math inline">\(\Omega(s)\)</span></span> lines in NAND even though it takes <span><span class="math inline">\(O(1)\)</span></span> steps (or maybe <span><span class="math inline">\(O(\log s)\)</span></span> steps, depending on how we count) in <em>Python</em>.</p>
<p>It turns out that it is possible to improve the bound of <a href='#eff-bounded-univ'>Theorem 5.10</a>, and evaluate <span><span class="math inline">\(s\)</span></span> line NAND-CIRC programs using a NAND-CIRC program of <span><span class="math inline">\(O(s \log s)\)</span></span> lines. The key is to consider the description of NAND-CIRC programs as circuits, and in particular as directed acyclic graphs (DAGs) of bounded in-degree. A universal NAND-CIRC program <span><span class="math inline">\(U_s\)</span></span> for <span><span class="math inline">\(s\)</span></span> line programs will correspond to a <em>universal graph</em> <span><span class="math inline">\(H_s\)</span></span> for such <span><span class="math inline">\(s\)</span></span> vertex DAGs. We can think of such a graph <span><span class="math inline">\(U_s\)</span></span> as fixed “wiring” for a communication network, that should be able to accommodate any arbitrary pattern of communication between <span><span class="math inline">\(s\)</span></span> vertices (where this pattern corresponds to an <span><span class="math inline">\(s\)</span></span> line NAND-CIRC program). It turns out that such efficient <a href="https://goo.gl/NnkkjM">routing networks</a> exist that allow embedding any <span><span class="math inline">\(s\)</span></span> vertex circuit inside a universal graph of size <span><span class="math inline">\(O(s \log s)\)</span></span>, see the bibliographical notes <a href='#bibnotescodeasdata'>Section 5.9</a> for more on this issue.</p>
</div>
<h2 id="a-python-interpreter-in-nand-circ-discussion" data-number="5.5">A Python interpreter in NAND-CIRC (discussion)</h2>
<p>To prove <a href='#eff-bounded-univ'>Theorem 5.10</a> we essentially translated every line of the Python program for <code>EVAL</code> into an equivalent NAND-CIRC snippet. However none of our reasoning was specific to the particular function <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}\)</span></span>. It is possible to translate <em>every</em> Python program into an equivalent NAND-CIRC program of comparable efficiency. (More concretely, if the Python program takes <span><span class="math inline">\(T(n)\)</span></span> operations on inputs of length at most <span><span class="math inline">\(n\)</span></span> then there exists NAND-CIRC program of <span><span class="math inline">\(O(T(n) \log T(n))\)</span></span> lines that agrees with the Python program on inputs of length <span><span class="math inline">\(n\)</span></span>.) Actually doing so requires taking care of many details and is beyond the scope of this book, but let me try to convince you why you should believe it is possible in principle.</p>
<p>For starters, one can use <a href="https://en.wikipedia.org/wiki/CPython">CPython</a> (the reference implementation for Python), to evaluate every Python program using a <code>C</code> program. We can combine this with a C compiler to transform a Python program to various flavors of “machine language”. So, to transform a Python program into an equivalent NAND-CIRC program, it is enough to show how to transform a <em>machine language</em> program into an equivalent NAND-CIRC program. One minimalistic (and hence convenient) family of machine languages is known as the <em>ARM architecture</em> which powers many mobile devices including essentially all Android devices.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup> There are even simpler machine languages, such as the <a href="https://github.com/frasercrmck/llvm-leg">LEG architecture</a> for which a backend for the <a href="http://llvm.org/">LLVM compiler</a> was implemented (and hence can be the target of compiling any of <a href="https://en.wikipedia.org/wiki/LLVM#Front_ends">large and growing list</a> of languages that this compiler supports). Other examples include the <a href="http://www.scipr-lab.org/doc/TinyRAM-spec-0.991.pdf">TinyRAM</a> architecture (motivated by interactive proof systems that we will discuss in <a href='lec_24_proofs.html#chapproofs'>Chapter 21</a>) and the teaching-oriented <a href="https://www.ece.umd.edu/~blj/RiSC/">Ridiculously Simple Computer</a> architecture. Going one by one over the instruction sets of such computers and translating them to NAND snippets is no fun, but it is a feasible thing to do. In fact, ultimately this is very similar to the transformation that takes place in converting our high level code to actual silicon gates that are not so different from the operations of a NAND-CIRC program. Indeed, tools such as <a href="http://www.myhdl.org/">MyHDL</a> that transform “Python to Silicon” can be used to convert a Python program to a NAND-CIRC program.</p>
<p>The NAND-CIRC programming language is just a teaching tool, and by no means do I suggest that writing NAND-CIRC programs, or compilers to NAND-CIRC, is a practical, useful, or enjoyable activity. What I do want is to make sure you understand why it <em>can</em> be done, and to have the confidence that if your life (or at least your grade) depended on it, then you would be able to do this. Understanding how programs in high level languages such as Python are eventually transformed into concrete low-level representation such as NAND is fundamental to computer science.</p>
<p>The astute reader might notice that the above paragraphs only outlined why it should be possible to find for every <em>particular</em> Python-computable function <span><span class="math inline">\(f\)</span></span>, a <em>particular</em> comparably efficient NAND-CIRC program <span><span class="math inline">\(P\)</span></span> that computes <span><span class="math inline">\(f\)</span></span>. But this still seems to fall short of our goal of writing a “Python interpreter in NAND” which would mean that for every parameter <span><span class="math inline">\(n\)</span></span>, we come up with a <em>single</em> NAND-CIRC program <span><span class="math inline">\(\ensuremath{\mathit{UNIV}}_s\)</span></span> such that given a description of a Python program <span><span class="math inline">\(P\)</span></span>, a particular input <span><span class="math inline">\(x\)</span></span>, and a bound <span><span class="math inline">\(T\)</span></span> on the number of operations (where the lengths of <span><span class="math inline">\(P\)</span></span> and <span><span class="math inline">\(x\)</span></span> and the value of <span><span class="math inline">\(T\)</span></span> are all at most <span><span class="math inline">\(s\)</span></span>) returns the result of executing <span><span class="math inline">\(P\)</span></span> on <span><span class="math inline">\(x\)</span></span> for at most <span><span class="math inline">\(T\)</span></span> steps. After all, the transformation above takes every Python program into a <em>different</em> NAND-CIRC program, and so does not yield “one NAND-CIRC program to rule them all” that can evaluate every Python program up to some given complexity. However, we can in fact obtain one NAND-CIRC program to evaluate <em>arbitrary</em> Python programs. The reason is that there exists a Python interpreter <em>in Python</em>: a Python program <span><span class="math inline">\(U\)</span></span> that takes a bit string, interprets it as Python code, and then runs that code. Hence, we only need to show a NAND-CIRC program <span><span class="math inline">\(U^*\)</span></span> that computes the same function as the particular Python program <span><span class="math inline">\(U\)</span></span>, and this will give us a way to evaluate <em>all</em> Python programs.</p>
<p>What we are seeing time and again is the notion of <em>universality</em> or <em>self reference</em> of computation, which is the sense that all reasonably rich models of computation are expressive enough that they can “simulate themselves”. The importance of this phenomenon to both the theory and practice of computing, as well as far beyond it, including the foundations of mathematics and basic questions in science, cannot be overstated.</p>
<h2 id="PECTTsec" data-number="5.6">The physical extended Church-Turing thesis (discussion)</h2>
<p>We’ve seen that NAND gates (and other Boolean operations) can be implemented using very different systems in the physical world. What about the reverse direction? Can NAND-CIRC programs simulate any physical computer?</p>
<p>We can take a leap of faith and stipulate that Boolean circuits (or equivalently NAND-CIRC programs) do actually encapsulate <em>every</em> computation that we can think of. Such a statement (in the realm of infinite functions, which we’ll encounter in <a href='lec_06_loops.html#chaploops'>Chapter 6</a>) is typically attributed to Alonzo Church and Alan Turing, and in that context is known as the <em>Church Turing Thesis</em>. As we will discuss in future lectures, the Church-Turing Thesis is not a mathematical theorem or conjecture. Rather, like theories in physics, the Church-Turing Thesis is about mathematically modeling the real world. In the context of finite functions, we can make the following informal hypothesis or prediction:</p>
<blockquote>
<p><strong>“Physical Extended Church-Turing Thesis” (PECTT):</strong> <em>If a function <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> can be computed in the physical world using <span><span class="math inline">\(s\)</span></span> amount of “physical resources” then it can be computed by a Boolean circuit program of roughly <span><span class="math inline">\(s\)</span></span> gates.</em></p>
</blockquote>
<p>A priori it might seem rather extreme to hypothesize that our meager model of NAND-CIRC programs or Boolean circuits captures all possible physical computation. But yet, in more than a century of computing technologies, no one has yet built any scalable computing device that challenges this hypothesis.</p>
<p>We now discuss the “fine print” of the PECTT in more detail, as well as the (so far unsuccessful) challenges that have been raised against it. There is no single universally-agreed-upon formalization of “roughly <span><span class="math inline">\(s\)</span></span> physical resources”, but we can approximate this notion by considering the size of any physical computing device and the time it takes to compute the output, and ask that any such device can be simulated by a Boolean circuit with a number of gates that is a polynomial (with not too large exponent) in the size of the system and the time it takes it to operate.</p>
<p>In other words, we can phrase the PECTT as stipulating that any function that can be computed by a device that takes a certain volume <span><span class="math inline">\(V\)</span></span> of space and requires <span><span class="math inline">\(t\)</span></span> time to complete the computation, must be computable by a Boolean circuit with a number of gates <span><span class="math inline">\(p(V,t)\)</span></span> that is polynomial in <span><span class="math inline">\(V\)</span></span> and <span><span class="math inline">\(t\)</span></span>.</p>
<p>The exact form of the function <span><span class="math inline">\(p(V,t)\)</span></span> is not universally agreed upon but it is generally accepted that if <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> is an <em>exponentially hard</em> function, in the sense that it has no NAND-CIRC program of fewer than, say, <span><span class="math inline">\(2^{n/2}\)</span></span> lines, then a demonstration of a physical device that can compute in the real world <span><span class="math inline">\(f\)</span></span> for moderate input lengths (e.g., <span><span class="math inline">\(n=500\)</span></span>) would be a violation of the PECTT.</p>
<div id="concretepectt" class="remark" title="Advanced note: making PECTT concrete (advanced, optional)" name="Remark 5.13 (Advanced note: making PECTT concrete (advanced, optional)) ">
<p>We can attempt a more exact phrasing of the PECTT as follows. Suppose that <span><span class="math inline">\(Z\)</span></span> is a physical system that accepts <span><span class="math inline">\(n\)</span></span> binary stimuli and has a binary output, and can be enclosed in a sphere of volume <span><span class="math inline">\(V\)</span></span>. We say that the system <span><span class="math inline">\(Z\)</span></span> <em>computes</em> a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> within <span><span class="math inline">\(t\)</span></span> seconds if whenever we set the stimuli to some value <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, if we measure the output after <span><span class="math inline">\(t\)</span></span> seconds then we obtain <span><span class="math inline">\(f(x)\)</span></span>.</p>
<p>One can then phrase the PECTT as stipulating that if there exists such a system <span><span class="math inline">\(Z\)</span></span> that computes <span><span class="math inline">\(F\)</span></span> within <span><span class="math inline">\(t\)</span></span> seconds, then there exists a NAND-CIRC program that computes <span><span class="math inline">\(F\)</span></span> and has at most <span><span class="math inline">\(\alpha(Vt)^2\)</span></span> lines, where <span><span class="math inline">\(\alpha\)</span></span> is some normalization constant. (We can also consider variants where we use <a href="https://goo.gl/ALgbVS">surface area</a> instead of volume, or take <span><span class="math inline">\((Vt)\)</span></span> to a different power than <span><span class="math inline">\(2\)</span></span>. However, none of these choices makes a qualitative difference to the discussion below.) In particular, suppose that <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> is a function that requires <span><span class="math inline">\(2^n/(100n)&gt;2^{0.8n}\)</span></span> lines for any NAND-CIRC program (such a function exists by <a href='#counting-lb'>Theorem 5.3</a>). Then the PECTT would imply that either the volume or the time of a system that computes <span><span class="math inline">\(F\)</span></span> will have to be at least <span><span class="math inline">\(2^{0.2 n}/\sqrt{\alpha}\)</span></span>. Since this quantity grows <em>exponentially</em> in <span><span class="math inline">\(n\)</span></span>, it is not hard to set parameters so that even for moderately large values of <span><span class="math inline">\(n\)</span></span>, such a system could not fit in our universe.</p>
<p>To fully make the PECTT concrete, we need to decide on the units for measuring time and volume, and the normalization constant <span><span class="math inline">\(\alpha\)</span></span>. One conservative choice is to assume that we could squeeze computation to the absolute physical limits (which are many orders of magnitude beyond current technology). This corresponds to setting <span><span class="math inline">\(\alpha=1\)</span></span> and using the <a href="https://goo.gl/gkpmBF">Planck units</a> for volume and time. The <em>Planck length</em> <span><span class="math inline">\(\ell_P\)</span></span> (which is, roughly speaking, the shortest distance that can theoretically be measured) is roughly <span><span class="math inline">\(2^{-120}\)</span></span> meters. The <em>Planck time</em> <span><span class="math inline">\(t_P\)</span></span> (which is the time it takes for light to travel one Planck length) is about <span><span class="math inline">\(2^{-150}\)</span></span> seconds. In the above setting, if a function <span><span class="math inline">\(F\)</span></span> takes, say, 1KB of input (e.g., roughly <span><span class="math inline">\(10^4\)</span></span> bits, which can encode a <span><span class="math inline">\(100\)</span></span> by <span><span class="math inline">\(100\)</span></span> bitmap image), and requires at least <span><span class="math inline">\(2^{0.8 n}= 2^{0.8 \cdot 10^4}\)</span></span> NAND lines to compute, then any physical system that computes it would require either volume of <span><span class="math inline">\(2^{0.2\cdot 10^4}\)</span></span> Planck length cubed, which is more than <span><span class="math inline">\(2^{1500}\)</span></span> meters cubed or take at least <span><span class="math inline">\(2^{0.2 \cdot 10^4}\)</span></span> Planck Time units, which is larger than <span><span class="math inline">\(2^{1500}\)</span></span> seconds. To get a sense of how big that number is, note that the universe is only about <span><span class="math inline">\(2^{60}\)</span></span> seconds old, and its observable radius is only roughly <span><span class="math inline">\(2^{90}\)</span></span> meters. The above discussion suggests that it is possible to <em>empirically falsify</em> the PECTT by presenting a smaller-than-universe-size system that computes such a function.</p>
<p>There are of course several hurdles to refuting the PECTT in this way, one of which is that we can’t actually test the system on all possible inputs. However, it turns out that we can get around this issue using notions such as <em>interactive proofs</em> and <em>program checking</em> that we might encounter later in this book. Another, perhaps more salient problem, is that while we know many hard functions exist, at the moment there is <em>no single explicit function</em> <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> for which we can <em>prove</em> an <span><span class="math inline">\(\omega(n)\)</span></span> (let alone <span><span class="math inline">\(\Omega(2^n/n)\)</span></span>) lower bound on the number of lines that a NAND-CIRC program needs to compute it.</p>
</div>
<h3 id="attempts-at-refuting-the-pectt" data-number="5.6.1">Attempts at refuting the PECTT</h3>
<p>One of the admirable traits of mankind is the refusal to accept limitations. In the best case this is manifested by people achieving longstanding “impossible” challenges such as heavier-than-air flight, putting a person on the moon, circumnavigating the globe, or even resolving <a href="https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem">Fermat’s Last Theorem</a>. In the worst case it is manifested by people continually following the footsteps of previous failures to try to do proven-impossible tasks such as build a <a href="https://en.wikipedia.org/wiki/Perpetual_motion">perpetual motion machine</a>, <a href="https://en.wikipedia.org/wiki/Angle_trisection">trisect an angle</a> with a compass and straightedge, or refute <a href="https://en.wikipedia.org/wiki/Bell%27s_theorem">Bell’s inequality</a>. The Physical Extended Church Turing thesis (in its various forms) has attracted both types of people. Here are some physical devices that have been speculated to achieve computational tasks that cannot be done by not-too-large NAND-CIRC programs:</p>
<ul>
<li><p><strong>Spaghetti sort:</strong> One of the first lower bounds that Computer Science students encounter is that sorting <span><span class="math inline">\(n\)</span></span> numbers requires making <span><span class="math inline">\(\Omega(n \log n)\)</span></span> comparisons. The “spaghetti sort” is a description of a proposed “mechanical computer” that would do this faster. The idea is that to sort <span><span class="math inline">\(n\)</span></span> numbers <span><span class="math inline">\(x_1,\ldots,x_n\)</span></span>, we could cut <span><span class="math inline">\(n\)</span></span> spaghetti noodles into lengths <span><span class="math inline">\(x_1,\ldots,x_n\)</span></span>, and then if we simply hold them together in our hand and bring them down to a flat surface, they will emerge in sorted order. There are a great many reasons why this is not truly a challenge to the PECTT hypothesis, and I will not ruin the reader’s fun in finding them out by her or himself.</p></li>
<li><p><strong>Soap bubbles:</strong> One function <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> that is conjectured to require a large number of NAND lines to solve is the <em>Euclidean Steiner Tree</em> problem. This is the problem where one is given <span><span class="math inline">\(m\)</span></span> points in the plane <span><span class="math inline">\((x_1,y_1),\ldots,(x_m,y_m)\)</span></span> (say with integer coordinates ranging from <span><span class="math inline">\(1\)</span></span> till <span><span class="math inline">\(m\)</span></span>, and hence the list can be represented as a string of <span><span class="math inline">\(n=O(m \log m)\)</span></span> size) and some number <span><span class="math inline">\(K\)</span></span>. The goal is to figure out whether it is possible to connect all the points by line segments of total length at most <span><span class="math inline">\(K\)</span></span>. This function is conjectured to be hard because it is <em>NP complete</em> - a concept that we’ll encounter later in this course - and it is in fact reasonable to conjecture that as <span><span class="math inline">\(m\)</span></span> grows, the number of NAND lines required to compute this function grows <em>exponentially</em> in <span><span class="math inline">\(m\)</span></span>, meaning that the PECTT would predict that if <span><span class="math inline">\(m\)</span></span> is sufficiently large (such as few hundreds or so) then no physical device could compute <span><span class="math inline">\(F\)</span></span>. Yet, some people claimed that there is in fact a very simple physical device that could solve this problem, that can be constructed using some wooden pegs and soap. The idea is that if we take two glass plates, and put <span><span class="math inline">\(m\)</span></span> wooden pegs between them in the locations <span><span class="math inline">\((x_1,y_1),\ldots,(x_m,y_m)\)</span></span> then bubbles will form whose edges touch those pegs in a way that will minimize the total energy which turns out to be a function of the total length of the line segments. The problem with this device is that nature, just like people, often gets stuck in “local optima”. That is, the resulting configuration will not be one that achieves the absolute minimum of the total energy but rather one that can’t be improved with local changes. <a href="http://www.scottaaronson.com/papers/npcomplete.pdf">Aaronson</a> has carried out actual experiments (see <a href='#aaronsonsoapfig'>Figure 5.8</a>), and saw that while this device often is successful for three or four pegs, it starts yielding suboptimal results once the number of pegs grows beyond that.</p></li>
</ul>
<figure>
<img src="../figure/aaronsonsoapbubble.jpg" alt="5.8: Scott Aaronson tests a candidate device for computing Steiner trees using soap bubbles." id="aaronsonsoapfig" class="margin" /><figcaption>5.8: Scott Aaronson <a href="http://www.scottaaronson.com/blog/?p=266">tests</a> a candidate device for computing Steiner trees using soap bubbles.</figcaption>
</figure>
<ul>
<li><p><strong>DNA computing.</strong> People have suggested using the properties of DNA to do hard computational problems. The main advantage of DNA is the ability to potentially encode a lot of information in a relatively small physical space, as well as compute on this information in a highly parallel manner. At the time of this writing, it was <a href="http://science.sciencemag.org/content/337/6102/1628.full">demonstrated</a> that one can use DNA to store about <span><span class="math inline">\(10^{16}\)</span></span> bits of information in a region of radius about a millimeter, as opposed to about <span><span class="math inline">\(10^{10}\)</span></span> bits with the best known hard disk technology. This does not posit a real challenge to the PECTT but does suggest that one should be conservative about the choice of constant and not assume that current hard disk + silicon technologies are the absolute best possible.<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup></p></li>
<li><p><strong>Continuous/real computers.</strong> The physical world is often described using continuous quantities such as time and space, and people have suggested that analog devices might have direct access to computing with real-valued quantities and would be inherently more powerful than discrete models such as NAND machines. Whether the “true” physical world is continuous or discrete is an open question. In fact, we do not even know how to precisely <em>phrase</em> this question, let alone answer it. Yet, regardless of the answer, it seems clear that the effort to measure a continuous quantity grows with the level of accuracy desired, and so there is no “free lunch” or way to bypass the PECTT using such machines (see also <a href="http://www.cs.princeton.edu/~ken/MCS86.pdf">this paper</a>). Related to that are proposals known as “hypercomputing” or “Zeno’s computers” which attempt to use the continuity of time by doing the first operation in one second, the second one in half a second, the third operation in a quarter second and so on.. These fail for a similar reason to the one guaranteeing that Achilles will eventually catch the tortoise despite the original Zeno’s paradox.</p></li>
<li><p><strong>Relativity computer and time travel.</strong> The formulation above assumed the notion of time, but under the theory of relativity time is in the eye of the observer. One approach to solve hard problems is to leave the computer to run for a lot of time from <em>his</em> perspective, but to ensure that this is actually a short while from <em>our</em> perspective. One approach to do so is for the user to start the computer and then go for a quick jog at close to the speed of light before checking on its status. Depending on how fast one goes, few seconds from the point of view of the user might correspond to centuries in computer time (it might even finish updating its Windows operating system!). Of course the catch here is that the energy required from the user is proportional to how close one needs to get to the speed of light. A more interesting proposal is to use time travel via <em>closed timelike curves (CTCs)</em>. In this case we could run an arbitrarily long computation by doing some calculations, remembering the current state, and then travelling back in time to continue where we left off. Indeed, if CTCs exist then we’d probably have to revise the PECTT (though in this case I will simply travel back in time and edit these notes, so I can claim I never conjectured it in the first place…)</p></li>
<li><p><strong>Humans.</strong> Another computing system that has been proposed as a counterexample to the PECTT is a 3 pound computer of about 0.1m radius, namely the human brain. Humans can walk around, talk, feel, and do other things that are not commonly done by NAND-CIRC programs, but can they compute partial functions that NAND-CIRC programs cannot? There are certainly computational tasks that <em>at the moment</em> humans do better than computers (e.g., play some <a href="http://www.theverge.com/2016/11/4/13518210/deepmind-starcraft-ai-google-blizzard">video games</a>, at the moment), but based on our current understanding of the brain, humans (or other animals) have no <em>inherent</em> computational advantage over computers. The brain has about <span><span class="math inline">\(10^{11}\)</span></span> neurons, each operating at a speed of about <span><span class="math inline">\(1000\)</span></span> operations per seconds. Hence a rough first approximation is that a Boolean circuit of about <span><span class="math inline">\(10^{14}\)</span></span> gates could simulate one second of a brain’s activity.<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup> Note that the fact that such a circuit (likely) exists does not mean it is easy to <em>find</em> it. After all, constructing this circuit took evolution billions of years. Much of the recent efforts in artificial intelligence research is focused on finding programs that replicate some of the brain’s capabilities and they take massive computational effort to discover, these programs often turn out to be much smaller than the pessimistic estimates above. For example, at the time of this writing, Google’s <a href="https://arxiv.org/pdf/1609.08144.pdf">neural network for machine translation</a> has about <span><span class="math inline">\(10^4\)</span></span> nodes (and can be simulated by a NAND-CIRC program of comparable size). Philosophers, priests and many others have since time immemorial argued that there is something about humans that cannot be captured by mechanical devices such as computers; whether or not that is the case, the evidence is thin that humans can perform computational tasks that are inherently impossible to achieve by computers of similar complexity.<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup></p></li>
<li><p><strong>Quantum computation.</strong> The most compelling attack on the Physical Extended Church Turing Thesis comes from the notion of <em>quantum computing</em>. The idea was initiated by the observation that systems with strong quantum effects are very hard to simulate on a computer. Turning this observation on its head, people have proposed using such systems to perform computations that we do not know how to do otherwise. At the time of this writing, Scalable quantum computers have not yet been built, but it is a fascinating possibility, and one that does not seem to contradict any known law of nature. We will discuss quantum computing in much more detail in <a href='lec_26_quantum_computing.html#quantumchap'>Chapter 22</a>. Modeling quantum computation involves extending the model of Boolean circuits into <em>Quantum circuits</em> that have one more (very special) gate. However, the main takeaway is that while quantum computing does suggest we need to amend the PECTT, it does <em>not</em> require a complete revision of our worldview. Indeed, almost all of the content of this book remains the same regardless of whether the underlying computational model is Boolean circuits or quantum circuits.</p></li>
</ul>
<div id="pcettcrypto" class="remark" title="Physical Extended Church-Turing Thesis and Cryptography" name="Remark 5.14 (Physical Extended Church-Turing Thesis and Cryptography) ">
<p>While even the precise phrasing of the PECTT, let alone understanding its correctness, is still a subject of active research, some variants of it are already implicitly assumed in practice. Governments, companies, and individuals currently rely on <em>cryptography</em> to protect some of their most precious assets, including state secrets, control of weapon systems and critical infrastructure, securing commerce, and protecting the confidentiality of personal information. In applied cryptography, one often encounters statements such as “cryptosystem <span><span class="math inline">\(X\)</span></span> provides 128 bits of security”. What such a statement really means is that <strong>(a)</strong> it is conjectured that there is no Boolean circuit (or, equivalently, a NAND-CIRC program) of size much smaller than <span><span class="math inline">\(2^{128}\)</span></span> that can break <span><span class="math inline">\(X\)</span></span>, and <strong>(b)</strong> we assume that no other physical mechanism can do better, and hence it would take roughly a <span><span class="math inline">\(2^{128}\)</span></span> amount of “resources” to break <span><span class="math inline">\(X\)</span></span>. We say “conjectured” and not “proved” because, while we can phrase the statement that breaking the system cannot be done by an <span><span class="math inline">\(s\)</span></span>-gate circuit as a precise mathematical conjecture, at the moment we are unable to <em>prove</em> such a statement for any non-trivial cryptosystem. This is related to the <span><span class="math inline">\(\mathbf{P}\)</span></span> vs <span><span class="math inline">\(\mathbf{NP}\)</span></span> question we will discuss in future chapters. We will explore Cryptography in <a href='lec_19_cryptography.html#chapcryptography'>Chapter 20</a>.</p>
</div>
<div id="section-6" class="recap" name="Recap">
<ul>
<li>We can think of programs both as describing a <em>process</em>, as well as simply a list of symbols that can be considered as <em>data</em> that can be fed as input to other programs.</li>
<li>We can write a NAND-CIRC program that evaluates arbitrary NAND-CIRC programs (or equivalently a circuit that evaluates other circuits). Moreover, the efficiency loss in doing so is not too large.</li>
<li>We can even write a NAND-CIRC program that evaluates programs in other programming languages such as Python, C, Lisp, Java, Go, etc.</li>
<li>By a leap of faith, we could hypothesize that the number of gates in the smallest circuit that computes a function <span><span class="math inline">\(f\)</span></span> captures roughly the amount of physical resources required to compute <span><span class="math inline">\(f\)</span></span>. This statement is known as the <em>Physical Extended Church-Turing Thesis (PECTT)</em>.</li>
<li>Boolean circuits (or equivalently AON-CIRC or NAND-CIRC programs) capture a surprisingly wide array of computational models. The strongest currently known challenge to the PECTT comes from the potential for using quantum mechanical effects to speed-up computation, a model known as <em>quantum computers</em>.</li>
</ul>
</div>
<figure>
<img src="../figure/finitecomprecap.png" alt="5.9: A finite computational task is specified by a function f:\{0,1\}^n \rightarrow \{0,1\}^m. We can model a computational process using Boolean circuits (of varying gate sets) or straight-line program. Every function can be computed by many programs. We say that f \in \ensuremath{\mathit{SIZE}}_{n,m}(s) if there exists a NAND circuit of at most s gates (equivalently a NAND-CIRC program of at most s lines) that computes f. Every function f:\{0,1\}^n \rightarrow \{0,1\}^m can be computed by a circuit of O(m \cdot 2^n/n) gates. Many functions such as multiplication, addition, solving linear equations, computing the shortest path in a graph, and others, can be computed by circuits of much fewer gates. In particular there is an O(s^2 \log s)-size circuit that computes the map C,x \mapsto C(x) where C is a string describing a circuit of s gates. However, the counting argument shows there do exist some functions f:\{0,1\}^n \rightarrow \{0,1\}^m that require \Omega(m \cdot 2^n /n) gates to compute." id="finiterecapfig" /><figcaption>5.9: A finite computational task is specified by a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span>. We can model a computational process using Boolean circuits (of varying gate sets) or straight-line program. Every function can be computed by many programs. We say that <span><span class="math inline">\(f \in \ensuremath{\mathit{SIZE}}_{n,m}(s)\)</span></span> if there exists a NAND circuit of at most <span><span class="math inline">\(s\)</span></span> gates (equivalently a NAND-CIRC program of at most <span><span class="math inline">\(s\)</span></span> lines) that computes <span><span class="math inline">\(f\)</span></span>. Every function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> can be computed by a circuit of <span><span class="math inline">\(O(m \cdot 2^n/n)\)</span></span> gates. Many functions such as multiplication, addition, solving linear equations, computing the shortest path in a graph, and others, can be computed by circuits of much fewer gates. In particular there is an <span><span class="math inline">\(O(s^2 \log s)\)</span></span>-size circuit that computes the map <span><span class="math inline">\(C,x \mapsto C(x)\)</span></span> where <span><span class="math inline">\(C\)</span></span> is a string describing a circuit of <span><span class="math inline">\(s\)</span></span> gates. However, the counting argument shows there do exist some functions <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> that require <span><span class="math inline">\(\Omega(m \cdot 2^n /n)\)</span></span> gates to compute.</figcaption>
</figure>
<h2 id="recap-of-part-i-finite-computation" data-number="5.7">Recap of Part I: Finite Computation</h2>
<p>This chapter concludes the first part of this book that deals with <em>finite computation</em> (computing functions that map a fixed number of Boolean inputs to a fixed number of Boolean outputs). The main take-aways from <a href='lec_03_computation.html#compchap'>Chapter 3</a>, <a href='lec_03a_computing_every_function.html#finiteuniversalchap'>Chapter 4</a>, and <a href='#codeanddatachap'>Chapter 5</a> are as follows (see also <a href='#finiterecapfig'>Figure 5.9</a>):</p>
<ul>
<li><p>We can formally define the notion of a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> being computable using <span><span class="math inline">\(s\)</span></span> basic operations. Whether these operations are AND/OR/NOT, NAND, or some other universal basis does not make much difference. We can describe such a computation either using a <em>circuit</em> or using a <em>straight-line program</em>.</p></li>
<li><p>We define <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n,m}(s)\)</span></span> to be the set of <em>functions</em> that are computable by NAND circuits of at most <span><span class="math inline">\(s\)</span></span> gates. This set is equal to the set of functions computable by a NAND-CIRC program of at most <span><span class="math inline">\(s\)</span></span> lines and up to a constant factor in <span><span class="math inline">\(s\)</span></span> (which we will not care about); this is also the same as the set of functions that are computable by a Boolean circuit of at most <span><span class="math inline">\(s\)</span></span> AND/OR/NOT gates. The class <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n,m}(s)\)</span></span> is a set of <em>functions</em>, not of programs/circuits.</p></li>
<li><p><em>Every</em> function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> can be computed using a circuit of <em>at most</em> <span><span class="math inline">\(O(m \cdot 2^n / n)\)</span></span> gates. <em>Some</em> functions require <em>at least</em> <span><span class="math inline">\(\Omega(m \cdot 2^n /n)\)</span></span> gates. We define <span><span class="math inline">\(\ensuremath{\mathit{SIZE}}_{n,m}(s)\)</span></span> to be the set of functions from <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}^m\)</span></span> that can be computed using at most <span><span class="math inline">\(s\)</span></span> gates.</p></li>
<li><p>We can describe a circuit/program <span><span class="math inline">\(P\)</span></span> as a string. For every <span><span class="math inline">\(s\)</span></span>, there is a <em>universal</em> circuit/program <span><span class="math inline">\(U_s\)</span></span> that can evaluate programs of length <span><span class="math inline">\(s\)</span></span> given their description as strings. We can use this representation also to <em>count</em> the number of circuits of at most <span><span class="math inline">\(s\)</span></span> gates and hence prove that some functions cannot be computed by circuits of smaller-than-exponential size.</p></li>
<li><p>If there is a circuit of <span><span class="math inline">\(s\)</span></span> gates that computes a function <span><span class="math inline">\(f\)</span></span>, then we can build a physical device to compute <span><span class="math inline">\(f\)</span></span> using <span><span class="math inline">\(s\)</span></span> basic components (such as transistors). The “Physical Extended Church-Turing Thesis” postulates that the reverse direction is true as well: if <span><span class="math inline">\(f\)</span></span> is a function for which <em>every</em> circuit requires at least <span><span class="math inline">\(s\)</span></span> gates then that <em>every</em> physical device to compute <span><span class="math inline">\(f\)</span></span> will require about <span><span class="math inline">\(s\)</span></span> “physical resources”. The main challenge to the PECTT is <em>quantum computing</em>, which we will discuss in <a href='lec_26_quantum_computing.html#quantumchap'>Chapter 22</a>.</p></li>
</ul>
<p><strong>Sneak preview:</strong> In the next part we will discuss how to model computational tasks on <em>unbounded inputs</em>, which are specified using functions <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span> (or <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>) that can take an unbounded number of Boolean inputs.</p>
<h2 id="exercises" data-number="5.8">Exercises</h2>
<div id="reading-comp" class="exercise" name="Exercise 5.1">
<p>Which one of the following statements is false:</p>
<ol type="a">
<li><p>There is an <span><span class="math inline">\(O(s^3)\)</span></span> line NAND-CIRC program that given as input program <span><span class="math inline">\(P\)</span></span> of <span><span class="math inline">\(s\)</span></span> lines in the list-of-tuples representation computes the output of <span><span class="math inline">\(P\)</span></span> when all its input are equal to <span><span class="math inline">\(1\)</span></span>.</p></li>
<li><p>There is an <span><span class="math inline">\(O(s^3)\)</span></span> line NAND-CIRC program that given as input program <span><span class="math inline">\(P\)</span></span> of <span><span class="math inline">\(s\)</span></span> characters encoded as a string of <span><span class="math inline">\(7s\)</span></span> bits using the ASCII encoding, computes the output of <span><span class="math inline">\(P\)</span></span> when all its input are equal to <span><span class="math inline">\(1\)</span></span>.</p></li>
<li><p>There is an <span><span class="math inline">\(O(\sqrt{s})\)</span></span> line NAND-CIRC program that given as input program <span><span class="math inline">\(P\)</span></span> of <span><span class="math inline">\(s\)</span></span> lines in the list-of-tuples representation computes the output of <span><span class="math inline">\(P\)</span></span> when all its input are equal to <span><span class="math inline">\(1\)</span></span>.</p></li>
</ol>
</div>
<div id="equals" class="exercise" title="Equals function" name="Exercise 5.2 (Equals function) ">
<p>For every <span><span class="math inline">\(k \in \N\)</span></span>, show that there is an <span><span class="math inline">\(O(k)\)</span></span> line NAND-CIRC program that computes the function <span><span class="math inline">\(\ensuremath{\mathit{EQUALS}}_k:\{0,1\}^{2k} \rightarrow \{0,1\}\)</span></span> where <span><span class="math inline">\(\ensuremath{\mathit{EQUALS}}(x,x&#39;)=1\)</span></span> if and only if <span><span class="math inline">\(x=x&#39;\)</span></span>.</p>
</div>
<div id="equalstwo" class="exercise" title="Equal to constant function" name="Exercise 5.3 (Equal to constant function) ">
<p>For every <span><span class="math inline">\(k \in \N\)</span></span> and <span><span class="math inline">\(x&#39; \in \{0,1\}^k\)</span></span>, show that there is an <span><span class="math inline">\(O(k)\)</span></span> line NAND-CIRC program that computes the function <span><span class="math inline">\(\ensuremath{\mathit{EQUALS}}_{x&#39;} : \{0,1\}^k \rightarrow \{0,1\}\)</span></span> that on input <span><span class="math inline">\(x\in \{0,1\}^k\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(x=x&#39;\)</span></span>.</p>
</div>
<div id="countingmultibitex" class="exercise" title="Counting lower bound for multibit functions" name="Exercise 5.4 (Counting lower bound for multibit functions) ">
<p>Prove that there exists a number <span><span class="math inline">\(\delta&gt;0\)</span></span> such that for every <span><span class="math inline">\(n,m\)</span></span> there exists a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> that requires at least <span><span class="math inline">\(\delta m \cdot 2^n / n\)</span></span> NAND gates to compute. See footnote for hint.<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup></p>
</div>
<div id="sizehiearchyex" class="exercise" title="Size hierarchy theorem for multibit functions" name="Exercise 5.5 (Size hierarchy theorem for multibit functions) ">
<p>Prove that there exists a number <span><span class="math inline">\(C\)</span></span> such that for every <span><span class="math inline">\(n,m\)</span></span> and <span><span class="math inline">\(n+m &lt; s &lt; m\cdot 2^n / (Cn)\)</span></span> there exists a function <span><span class="math inline">\(f \in \ensuremath{\mathit{SIZE}}_{n,m}(C\cdot s) \setminus \ensuremath{\mathit{SIZE}}_{n,m}(s)\)</span></span>. See footnote for hint.<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup></p>
</div>
<div id="efficientrepresentationex" class="exercise" title="Efficient representation of circuits and a tighter counting upper bound" name="Exercise 5.6 (Efficient representation of circuits and a tighter counting upper bound) ">
<p>Use the ideas of <a href='#efficientrepresentation'>Remark 5.4</a> to show that for every <span><span class="math inline">\(\epsilon&gt;0\)</span></span> and sufficiently large <span><span class="math inline">\(s,n,m\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[|\ensuremath{\mathit{SIZE}}_{n,m}(s)| &lt; 2^{(2+\epsilon)s \log s + n\log n + m\log s}\;.\]</span></div></span> Conclude that the implicit constant in <a href='#program-count'>Theorem 5.2</a> can be made arbitrarily close to <span><span class="math inline">\(5\)</span></span>. See footnote for hint.<sup id="fnref:12"><a href="#fn:12" rel="footnote">12</a></sup></p>
</div>
<div id="efficientlbex" class="exercise" title="Tighter counting lower bound" name="Exercise 5.7 (Tighter counting lower bound) ">
<p>Prove that for every <span><span class="math inline">\(\delta&lt; 1/2\)</span></span>, if <span><span class="math inline">\(n\)</span></span> is sufficiently large then there exists a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(f \not\in \ensuremath{\mathit{SIZE}}_{n,1}\left( \tfrac{\delta 2^n}{n} \right)\)</span></span>. See footnote for hint.<sup id="fnref:13"><a href="#fn:13" rel="footnote">13</a></sup></p>
</div>
<div id="rand-lb-id" class="exercise" title="Random functions are hard" name="Exercise 5.8 (Random functions are hard) ">
<p>Suppose <span><span class="math inline">\(n&gt;1000\)</span></span> and that we choose a function <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> at random, choosing for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> the value <span><span class="math inline">\(F(x)\)</span></span> to be the result of tossing an independent unbiased coin. Prove that the probability that there is a <span><span class="math inline">\(2^n/(1000n)\)</span></span> line program that computes <span><span class="math inline">\(F\)</span></span> is at most <span><span class="math inline">\(2^{-100}\)</span></span>.<sup id="fnref:14"><a href="#fn:14" rel="footnote">14</a></sup></p>
</div>
<div class="exercise" name="Exercise 5.9">
<p>The following is a tuple representing a NAND program: <span><span class="math inline">\((3, 1, ((3, 2, 2), (4, 1, 1), (5, 3, 4), (6, 2, 1), (7, 6, 6), (8, 0, 0), (9, 7, 8), (10, 5, 0), (11, 9, 10))\)</span></span>.</p>
<ol type="1">
<li><p>Write a table with the eight values <span><span class="math inline">\(P(000)\)</span></span>, <span><span class="math inline">\(P(001)\)</span></span>, <span><span class="math inline">\(P(010)\)</span></span>, <span><span class="math inline">\(P(011)\)</span></span>, <span><span class="math inline">\(P(100)\)</span></span>, <span><span class="math inline">\(P(101)\)</span></span>, <span><span class="math inline">\(P(110)\)</span></span>, <span><span class="math inline">\(P(111)\)</span></span> in this order.</p></li>
<li><p>Describe what the programs does in words.</p></li>
</ol>
</div>
<div id="XOREVAL" class="exercise" title="EVAL with XOR" name="Exercise 5.10 (EVAL with XOR) ">
<p>For every sufficiently large <span><span class="math inline">\(n\)</span></span>, let <span><span class="math inline">\(E_n:\{0,1\}^{n^2} \rightarrow \{0,1\}\)</span></span> be the function that takes an <span><span class="math inline">\(n^2\)</span></span>-length string that encodes a pair <span><span class="math inline">\((P,x)\)</span></span> where <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(P\)</span></span> is a NAND program of <span><span class="math inline">\(n\)</span></span> inputs, a single output, and at most <span><span class="math inline">\(n^{1.1}\)</span></span> lines, and returns the output of <span><span class="math inline">\(P\)</span></span> on <span><span class="math inline">\(x\)</span></span>.<sup id="fnref:15"><a href="#fn:15" rel="footnote">15</a></sup> That is, <span><span class="math inline">\(E_n(P,x)=P(x)\)</span></span>.</p>
<p>Prove that for every sufficiently large <span><span class="math inline">\(n\)</span></span>, there <em>does not exist</em> an XOR circuit <span><span class="math inline">\(C\)</span></span> that computes the function <span><span class="math inline">\(E_n\)</span></span>, where a XOR circuit has the <span><span class="math inline">\(\ensuremath{\mathit{XOR}}\)</span></span> gate as well as the constants <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(1\)</span></span> (see <a href='lec_03_computation.html#xorex'>Exercise 3.5</a>). That is, prove that there is some constant <span><span class="math inline">\(n_0\)</span></span> such that for every <span><span class="math inline">\(n&gt;n_0\)</span></span> and XOR circuit <span><span class="math inline">\(C\)</span></span> of <span><span class="math inline">\(n^2\)</span></span> inputs and a single output, there exists a pair <span><span class="math inline">\((P,x)\)</span></span> such that <span><span class="math inline">\(C(P,x) \neq E_n(P,x)\)</span></span>.</p>
</div>
<div id="learningcircuitsex" class="exercise" title="Learning circuits (challenge, optional, assumes more background)" name="Exercise 5.11 (Learning circuits (challenge, optional, assumes more background)) ">
<p>(This exercise assumes background in probability theory and/or machine learning that you might not have at this point. Feel free to come back to it at a later point and in particular after going over <a href='lec_15_probability.html#probabilitychap'>Chapter 17</a>.) In this exercise we will use our bound on the number of circuits of size <span><span class="math inline">\(s\)</span></span> to show that (if we ignore the cost of computation) every such circuit can be <em>learned</em> from not too many training samples. Specifically, if we find a size-<span><span class="math inline">\(s\)</span></span> circuit that classifies correctly a training set of <span><span class="math inline">\(O(s \log s)\)</span></span> samples from some distribution <span><span class="math inline">\(D\)</span></span>, then it is guaranteed to do well on the whole distribution <span><span class="math inline">\(D\)</span></span>. Since Boolean circuits model very many physical processes (maybe even all of them, if the (controversial) physical extended Church-Turing thesis is true), this shows that all such processes could be learned as well (again, ignoring the computation cost of finding a classifier that does well on the training data).</p>
<p>Let <span><span class="math inline">\(D\)</span></span> be any probability distribution over <span><span class="math inline">\(\{0,1\}^n\)</span></span> and let <span><span class="math inline">\(C\)</span></span> be a NAND circuit with <span><span class="math inline">\(n\)</span></span> inputs, one output, and size <span><span class="math inline">\(s \geq n\)</span></span>. Prove that there is some constant <span><span class="math inline">\(c\)</span></span> such that with probability at least <span><span class="math inline">\(0.999\)</span></span> the following holds: if <span><span class="math inline">\(m = c s \log s\)</span></span> and <span><span class="math inline">\(x_0,\ldots,x_{m-1}\)</span></span> are chosen independently from <span><span class="math inline">\(D\)</span></span>, then for every circuit <span><span class="math inline">\(C&#39;\)</span></span> such that <span><span class="math inline">\(C&#39;(x_i)=C(x_i)\)</span></span> on every <span><span class="math inline">\(i \in [m]\)</span></span>, <span><span class="math inline">\(\Pr_{x \sim D}[C&#39;(x) \leq C(x)] \leq 0.99\)</span></span>.</p>
<p>In other words, if <span><span class="math inline">\(C&#39;\)</span></span> is a so called “empirical risk minimizer” that agrees with <span><span class="math inline">\(C\)</span></span> on all the training examples <span><span class="math inline">\(x_0,\ldots,x_{n-1}\)</span></span>, then it will also agree with <span><span class="math inline">\(C\)</span></span> with high probability for samples drawn from the distribution <span><span class="math inline">\(D\)</span></span> (i.e., it “generalizes”, to use Machine-Learning lingo). See footnote for hint.<sup id="fnref:16"><a href="#fn:16" rel="footnote">16</a></sup></p>
</div>
<h2 id="bibnotescodeasdata" data-number="5.9">Bibliographical notes</h2>
<p>The <span><span class="math inline">\(\ensuremath{\mathit{EVAL}}\)</span></span> function is usually known as a <em>universal circuit</em>. The implementation we describe is not the most efficient known. Valiant  (<a href="https://scholar.google.com/scholar?hl=en&q=Valiant+Universal+circuits+(preliminary+report)" target="_blank">Valiant, 1976</a>)  first showed a universal circuit of <span><span class="math inline">\(O(n \log n)\)</span></span> size where <span><span class="math inline">\(n\)</span></span> is the size of the input. Universal circuits have seen in recent years new motivations due to their applications for cryptography, see  (<a href="https://scholar.google.com/scholar?hl=en&q=Lipmaa,+Mohassel,+Sadeghian+Valiant's+Universal+Circuit:+Improvements,+Implementation,+and+Applications." target="_blank">Lipmaa, Mohassel, Sadeghian, 2016</a>)  (<a href="https://scholar.google.com/scholar?hl=en&q=Günther,+Kiss,+Schneider+More+efficient+universal+circuit+constructions" target="_blank">Günther, Kiss, Schneider, 2017</a>)  .</p>
<p>While we’ve seen that “most” functions mapping <span><span class="math inline">\(n\)</span></span> bits to one bit require circuits of exponential size <span><span class="math inline">\(\Omega(2^n/n)\)</span></span>, we actually do not know of any <em>explicit</em> function for which we can <em>prove</em> that it requires, say, at least <span><span class="math inline">\(n^{100}\)</span></span> or even <span><span class="math inline">\(100n\)</span></span> size. At the moment, the strongest such lower bound we know is that there are quite simple and explicit <span><span class="math inline">\(n\)</span></span>-variable functions that require at least <span><span class="math inline">\((5-o(1))n\)</span></span> lines to compute, see <a href="http://www.wisdom.weizmann.ac.il/~ranraz/publications/P5nlb.pdf">this paper of Iwama et al</a> as well as this more recent <a href="http://logic.pdmi.ras.ru/~kulikov/papers/2012_5n_lower_bound_cie.pdf">work of Kulikov et al</a>. Proving lower bounds for restricted models of circuits is an extremely interesting research area, for which Jukna’s book  (<a href="https://scholar.google.com/scholar?hl=en&q=Jukna+Boolean+function+complexity:+advances+and+frontiers" target="_blank">Jukna, 2012</a>)  (see also Wegener  (<a href="https://scholar.google.com/scholar?hl=en&q=Wegener+The+complexity+of+Boolean+functions" target="_blank">Wegener, 1987</a>) ) provides a very good introduction and overview. I learned of the proof of the size hierarchy theorem (<a href='#sizehiearchythm'>Theorem 5.5</a>) from Sasha Golovnev.</p>
<p>Scott Aaronson’s blog post on how <a href="http://www.scottaaronson.com/blog/?p=3327">information is physical</a> is a good discussion on issues related to the physical extended Church-Turing Physics. Aaronson’s survey on NP complete problems and physical reality  (<a href="https://scholar.google.com/scholar?hl=en&q=Aaronson+NP-complete+problems+and+physical+reality" target="_blank">Aaronson, 2005</a>)  discusses these issues as well, though it might be easier to read after we reach <a href='lec_13_Cook_Levin.html#cooklevinchap'>Chapter 14</a> on <span><span class="math inline">\(\mathbf{NP}\)</span></span> and <span><span class="math inline">\(\mathbf{NP}\)</span></span>-completeness.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>The implicit constant in the <span><span class="math inline">\(O(\cdot)\)</span></span> notation is smaller than <span><span class="math inline">\(10\)</span></span>. That is, for all sufficiently large <span><span class="math inline">\(s\)</span></span>, <span><span class="math inline">\(|\ensuremath{\mathit{SIZE}}(s)|&lt; 2^{10s\log s}\)</span></span>, see <a href='#efficientrepresentation'>Remark 5.4</a>. As discussed in <a href='lec_00_1_math_background.html#notationsec'>Section 1.7</a>, we use the bound <span><span class="math inline">\(10\)</span></span> simply because it is a round number.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>“Astronomical” here is an understatement: there are much fewer than <span><span class="math inline">\(2^{2^{10}}\)</span></span> stars, or even particles, in the observable universe.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>The constant <span><span class="math inline">\(\delta\)</span></span> is at least <span><span class="math inline">\(0.1\)</span></span> and in fact, can be improved to be arbitrarily close to <span><span class="math inline">\(1/2\)</span></span>, see <a href='#efficientlbex'>Exercise 5.7</a>.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>If you’re curious what these few lines are, see our <a href="https://github.com/boazbk/tcscode">GitHub repository</a>.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>Python does not distinguish between lists and arrays, but allows constant time random access to an indexed elements to both of them. One could argue that if we allowed programs of truly unbounded length (e.g., larger than <span><span class="math inline">\(2^{64}\)</span></span>) then the price would not be constant but logarithmic in the length of the array/lists, but the difference between <span><span class="math inline">\(O(s)\)</span></span> and <span><span class="math inline">\(O(s \log s)\)</span></span> will not be important for our discussions.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p>ARM stands for “Advanced RISC Machine” where RISC in turn stands for “Reduced instruction set computer”.</p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:7"><p>
<div>
<p>We were extremely conservative in the suggested parameters for the PECTT, having assumed that as many as <span><span class="math inline">\(\ell_P^{-2}10^{-6} \sim 10^{61}\)</span></span> bits could potentially be stored in a millimeter radius region.</p>
</div>
<a href="#fnref:7" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:8"><p>
<div>
<p>This is a very rough approximation that could be wrong to a few orders of magnitude in either direction. For one, there are other structures in the brain apart from neurons that one might need to simulate, hence requiring higher overhead. On the other hand, it is by no mean clear that we need to fully clone the brain in order to achieve the same computational tasks that it does.</p>
</div>
<a href="#fnref:8" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:9"><p>
<div>
<p>There are some well known scientists that have <a href="http://www.telegraph.co.uk/science/2017/03/14/can-solve-chess-problem-holds-key-human-consciousness/">advocated</a> that humans have inherent computational advantages over computers. See also <a href="https://arxiv.org/abs/1508.05929">this</a>.</p>
</div>
<a href="#fnref:9" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:10"><p>
<div>
<p>How many functions from <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}^m\)</span></span> exist?</p>
</div>
<a href="#fnref:10" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:11"><p>
<div>
<p>Follow the proof of <a href='#sizehiearchythm'>Theorem 5.5</a>, replacing the use of the counting argument with <a href='#countingmultibitex'>Exercise 5.4</a>.</p>
</div>
<a href="#fnref:11" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:12"><p>
<div>
<p>Using the adjacency list representation, a graph with <span><span class="math inline">\(n\)</span></span> in-degree zero vertices and <span><span class="math inline">\(s\)</span></span> in-degree two vertices can be represented using roughly <span><span class="math inline">\(2s\log(s+n) \leq 2s (\log s + O(1))\)</span></span> bits. The labeling of the <span><span class="math inline">\(n\)</span></span> input and <span><span class="math inline">\(m\)</span></span> output vertices can be specified by a list of <span><span class="math inline">\(n\)</span></span> labels in <span><span class="math inline">\([n]\)</span></span> and <span><span class="math inline">\(m\)</span></span> labels in <span><span class="math inline">\([m]\)</span></span>.</p>
</div>
<a href="#fnref:12" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:13"><p>
<div>
<p><em>Hint:</em> Use the results of <a href='#efficientrepresentationex'>Exercise 5.6</a> and the fact that in this regime <span><span class="math inline">\(m=1\)</span></span> and <span><span class="math inline">\(n\ll s\)</span></span>.</p>
</div>
<a href="#fnref:13" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:14"><p>
<div>
<p><strong>Hint:</strong> An equivalent way to say this is that you need to prove that the set of functions that can be computed using at most <span><span class="math inline">\(2^n/(1000n)\)</span></span> lines has fewer than <span><span class="math inline">\(2^{-100}2^{2^n}\)</span></span> elements. Can you see why?</p>
</div>
<a href="#fnref:14" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:15"><p>
<div>
<p>Note that if <span><span class="math inline">\(n\)</span></span> is big enough, then it is easy to represent such a pair using <span><span class="math inline">\(n^2\)</span></span> bits, since we can represent the program using <span><span class="math inline">\(O(n^{1.1}\log n)\)</span></span> bits, and we can always pad our representation to have exactly <span><span class="math inline">\(n^2\)</span></span> length.</p>
</div>
<a href="#fnref:15" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:16"><p>
<div>
<p><em>Hint:</em> Use our bound on the number of programs/circuits of size <span><span class="math inline">\(s\)</span></span> (<a href='#program-count'>Theorem 5.2</a>), as well as the Chernoff Bound ( <a href='lec_15_probability.html#chernoffthm'>Theorem 17.12</a>) and the union bound.</p>
</div>
<a href="#fnref:16" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 21:39:41</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_04_code_and_data.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
