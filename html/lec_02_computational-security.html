<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An intensive introduction to cryptography: Computational security</title>
  <meta name="description" content="Lecture notes on Cryptography by Boaz Barak">

  <meta property="og:title" content="An intensive introduction to cryptography: Computational security" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://intensecrypto.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="github-repo" content="boazbk/crypto" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An intensive introduction to cryptography" />
  <meta name="twitter:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="twitter:image" content="https://intensecrypto.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">An intensive introduction to cryptography</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html"><i class="fa fa-check"></i><b>p</b> Foreword and Syllabus</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#syllabus"><i class="fa fa-check"></i><b>p.1</b> Syllabus</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#prerequisites"><i class="fa fa-check"></i><b>p.1.1</b> Prerequisites</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#why-is-cryptography-hard"><i class="fa fa-check"></i><b>p.2</b> Why is cryptography hard?</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html"><i class="fa fa-check"></i><b>0</b> Mathematical Background</a><ul><li class="chapter" data-level="0.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#a-quick-overview-of-mathematical-prerequisites"><i class="fa fa-check"></i><b>0.1</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="0.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#mathematical-proofs"><i class="fa fa-check"></i><b>0.2</b> Mathematical Proofs</a><ul><li class="chapter" data-level="0.2.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#example-the-existence-of-infinitely-many-primes."><i class="fa fa-check"></i><b>0.2.1</b> Example: The existence of infinitely many primes.</a></li></ul></li><li class="chapter" data-level="0.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#probability-and-sample-spaces"><i class="fa fa-check"></i><b>0.3</b> Probability and Sample spaces</a><ul><li class="chapter" data-level="0.3.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#random-variables"><i class="fa fa-check"></i><b>0.3.1</b> Random variables</a></li><li class="chapter" data-level="0.3.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#distributions-over-strings"><i class="fa fa-check"></i><b>0.3.2</b> Distributions over strings</a></li><li class="chapter" data-level="0.3.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>0.3.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="0.4" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#correlations-and-independence"><i class="fa fa-check"></i><b>0.4</b> Correlations and independence</a><ul><li class="chapter" data-level="0.4.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#independent-random-variables"><i class="fa fa-check"></i><b>0.4.1</b> Independent random variables</a></li><li class="chapter" data-level="0.4.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>0.4.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="0.5" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>0.5</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>0.5.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="0.5.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#the-chernoff-bound"><i class="fa fa-check"></i><b>0.5.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#exercises-1"><i class="fa fa-check"></i><b>0.7</b> Exercises</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul><li class="chapter" data-level="1.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#some-history"><i class="fa fa-check"></i><b>1.1</b> Some history</a></li><li class="chapter" data-level="1.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-encryptions"><i class="fa fa-check"></i><b>1.2</b> Defining encryptions</a></li><li class="chapter" data-level="1.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>1.3</b> Defining security of encryption</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#generating-randomness-in-actual-cryptographic-systems"><i class="fa fa-check"></i><b>1.3.1</b> Generating randomness in actual cryptographic systems</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-the-secrecy-requirement."><i class="fa fa-check"></i><b>1.4</b> Defining the secrecy requirement.</a></li><li class="chapter" data-level="1.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#perfect-secrecy"><i class="fa fa-check"></i><b>1.5</b> Perfect Secrecy</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#achieving-perfect-secrecy"><i class="fa fa-check"></i><b>1.5.1</b> Achieving perfect secrecy</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>1.6</b> Necessity of long keys</a></li><li class="chapter" data-level="1.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bibliographical-notes"><i class="fa fa-check"></i><b>1.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html"><i class="fa fa-check"></i><b>2</b> Computational Security</a><ul><li><ul><li class="chapter" data-level="2.0.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#proof-by-reduction"><i class="fa fa-check"></i><b>2.0.1</b> Proof by reduction</a></li></ul></li><li class="chapter" data-level="2.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#the-asymptotic-approach"><i class="fa fa-check"></i><b>2.1</b> The asymptotic approach</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#counting-number-of-operations."><i class="fa fa-check"></i><b>2.1.1</b> Counting number of operations.</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#our-first-conjecture"><i class="fa fa-check"></i><b>2.2</b> Our first conjecture</a></li><li class="chapter" data-level="2.3" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#why-care-about-the-cipher-conjecture"><i class="fa fa-check"></i><b>2.3</b> Why care about the cipher conjecture?</a></li><li class="chapter" data-level="2.4" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#prelude-computational-indistinguishability"><i class="fa fa-check"></i><b>2.4</b> Prelude: Computational Indistinguishability</a></li><li class="chapter" data-level="2.5" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#the-length-extension-theorem"><i class="fa fa-check"></i><b>2.5</b> The Length Extension Theorem</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#appendix-the-computational-model"><i class="fa fa-check"></i><b>2.5.1</b> Appendix: The computational model</a></li></ul></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html"><i class="fa fa-check"></i><b>3</b> Pseudorandomness</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#stream-ciphers"><i class="fa fa-check"></i><b>3.1</b> Stream ciphers</a></li><li class="chapter" data-level="3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#what-do-pseudorandom-generators-actually-look-like"><i class="fa fa-check"></i><b>3.2</b> What do pseudorandom generators actually look like?</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-0-the-counter-generator"><i class="fa fa-check"></i><b>3.2.1</b> Attempt 0: The counter generator</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-1-the-linear-checksum-linear-feedback-shift-register-lfsr"><i class="fa fa-check"></i><b>3.2.2</b> Attempt 1: The linear checksum / linear feedback shift register (LFSR)</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#from-insecurity-to-security"><i class="fa fa-check"></i><b>3.2.3</b> From insecurity to security</a></li><li class="chapter" data-level="3.2.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-2-linear-congruential-generators-with-dropped-bits"><i class="fa fa-check"></i><b>3.2.4</b> Attempt 2: Linear Congruential Generators with dropped bits</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#successful-examples"><i class="fa fa-check"></i><b>3.3</b> Successful examples</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-1-subset-sum-generator"><i class="fa fa-check"></i><b>3.3.1</b> Case Study 1: Subset Sum Generator</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-2-rc4"><i class="fa fa-check"></i><b>3.3.2</b> Case Study 2: RC4</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#non-constructive-existence-of-pseudorandom-generators"><i class="fa fa-check"></i><b>3.4</b> Non-constructive existence of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html"><i class="fa fa-check"></i><b>4</b> Pseudorandom functions</a><ul><li class="chapter" data-level="4.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#one-time-passwords-e.g.-google-authenticator-rsa-id-etc."><i class="fa fa-check"></i><b>4.1</b> One time passwords (e.g. Google Authenticator, RSA ID, etc.)</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#how-do-pseudorandom-functions-help-in-the-login-problem"><i class="fa fa-check"></i><b>4.1.1</b> How do pseudorandom functions help in the login problem?</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#message-authentication-codes"><i class="fa fa-check"></i><b>4.2</b> Message Authentication Codes</a></li><li class="chapter" data-level="4.3" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#macs-from-prfs"><i class="fa fa-check"></i><b>4.3</b> MACs from PRFs</a></li><li class="chapter" data-level="4.4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#input-length-extension-for-macs-and-prfs"><i class="fa fa-check"></i><b>4.4</b> Input length extension for MACs and PRFs</a></li><li class="chapter" data-level="4.5" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#aside-natural-proofs"><i class="fa fa-check"></i><b>4.5</b> Aside: natural proofs</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html"><i class="fa fa-check"></i><b>5</b> Pseudorandom functions from pseudorandom generators</a><ul><li class="chapter" data-level="5.1" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#securely-encrypting-many-messages---chosen-plaintext-security"><i class="fa fa-check"></i><b>5.1</b> Securely encrypting many messages - chosen plaintext security</a></li><li class="chapter" data-level="5.2" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#pseudorandom-permutations-block-ciphers"><i class="fa fa-check"></i><b>5.2</b> Pseudorandom permutations / block ciphers</a></li><li class="chapter" data-level="5.3" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#encryption-modes"><i class="fa fa-check"></i><b>5.3</b> Encryption modes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html"><i class="fa fa-check"></i><b>6</b> Chosen Ciphertext Security</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#short-recap"><i class="fa fa-check"></i><b>6.1</b> Short recap</a></li><li class="chapter" data-level="6.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#going-beyond-cpa"><i class="fa fa-check"></i><b>6.2</b> Going beyond CPA</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#example-the-wired-equivalence-protocol-wep"><i class="fa fa-check"></i><b>6.2.1</b> Example: The Wired Equivalence Protocol (WEP)</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-security-1"><i class="fa fa-check"></i><b>6.2.2</b> Chosen ciphertext security</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#constructing-cca-secure-encryption"><i class="fa fa-check"></i><b>6.3</b> Constructing CCA secure encryption</a></li><li class="chapter" data-level="6.4" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#simplified-gcm-encryption"><i class="fa fa-check"></i><b>6.4</b> (Simplified) GCM encryption</a></li><li class="chapter" data-level="6.5" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#padding-chopping-and-their-pitfalls-the-buffer-overflow-of-cryptography"><i class="fa fa-check"></i><b>6.5</b> Padding, chopping, and their pitfalls: the "buffer overflow" of cryptography</a></li><li class="chapter" data-level="6.6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-attack-as-implementing-metaphors"><i class="fa fa-check"></i><b>6.6</b> Chosen ciphertext attack as implementing metaphors</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html"><i class="fa fa-check"></i><b>7</b> Hash functions and random oracles</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-problem"><i class="fa fa-check"></i><b>7.1</b> The "bitcoin" problem</a><ul><li class="chapter" data-level="7.1.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-currency-problem"><i class="fa fa-check"></i><b>7.1.1</b> The currency problem</a></li><li class="chapter" data-level="7.1.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#bitcoin-architecture"><i class="fa fa-check"></i><b>7.1.2</b> Bitcoin architecture</a></li></ul></li><li class="chapter" data-level="7.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-ledger"><i class="fa fa-check"></i><b>7.2</b> The bitcoin ledger</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#from-proof-of-work-to-consensus-on-ledger"><i class="fa fa-check"></i><b>7.2.1</b> From proof of work to consensus on ledger</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#collision-resistance-hash-functions-and-creating-short-unique-identifiers"><i class="fa fa-check"></i><b>7.3</b> Collision resistance hash functions and creating short "unique" identifiers</a></li><li class="chapter" data-level="7.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-constructions-of-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4</b> Practical constructions of cryptographic hash functions</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-random-ish-functions"><i class="fa fa-check"></i><b>7.4.1</b> Practical random-ish functions</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#some-history"><i class="fa fa-check"></i><b>7.4.2</b> Some history</a></li><li class="chapter" data-level="7.4.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-nsa-and-hash-functions."><i class="fa fa-check"></i><b>7.4.3</b> The NSA and hash functions.</a></li><li class="chapter" data-level="7.4.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#cryptographic-vs-non-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4.4</b> Cryptographic vs non-cryptographic hash functions:</a></li></ul></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html"><i class="fa fa-check"></i><b>8</b> Key derivation, protecting passwords, slow hashes, Merkle trees</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#keys-from-passwords"><i class="fa fa-check"></i><b>8.1</b> Keys from passwords</a></li><li class="chapter" data-level="8.2" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#merkle-trees-and-verifying-storage."><i class="fa fa-check"></i><b>8.2</b> Merkle trees and verifying storage.</a></li><li class="chapter" data-level="8.3" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#proofs-of-retrievability"><i class="fa fa-check"></i><b>8.3</b> Proofs of Retrievability</a></li><li class="chapter" data-level="8.4" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#entropy-extraction"><i class="fa fa-check"></i><b>8.4</b> Entropy extraction</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#forward-and-backward-secrecy"><i class="fa fa-check"></i><b>8.4.1</b> Forward and backward secrecy</a></li></ul></li></ul></li><li class="chapter" data-level="9" data-path="lec_09_priv_recap.html"><a href="lec_09_priv_recap.html"><i class="fa fa-check"></i><b>9</b> Private key crypto recap</a><ul><li><ul><li class="chapter" data-level="9.0.1" data-path="lec_09_priv_recap.html"><a href="lec_09_priv_recap.html#attacks-on-private-key-cryptosystems"><i class="fa fa-check"></i><b>9.0.1</b> Attacks on private key cryptosystems</a></li></ul></li></ul></li><li class="chapter" data-level="10" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html"><i class="fa fa-check"></i><b>10</b> Public key cryptography</a><ul><li class="chapter" data-level="10.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#private-key-crypto-recap"><i class="fa fa-check"></i><b>10.1</b> Private key crypto recap</a></li><li class="chapter" data-level="10.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#public-key-encryptions-definition"><i class="fa fa-check"></i><b>10.2</b> Public Key Encryptions: Definition</a><ul><li class="chapter" data-level="10.2.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-obfuscation-paradigm"><i class="fa fa-check"></i><b>10.2.1</b> The obfuscation paradigm</a></li></ul></li><li class="chapter" data-level="10.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#some-concrete-candidates"><i class="fa fa-check"></i><b>10.3</b> Some concrete candidates:</a><ul><li class="chapter" data-level="10.3.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#diffie-hellman-encryption-aka-el-gamal"><i class="fa fa-check"></i><b>10.3.1</b> Diffie-Hellman Encryption (aka El-Gamal)</a></li><li class="chapter" data-level="10.3.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#sampling-random-primes"><i class="fa fa-check"></i><b>10.3.2</b> Sampling random primes</a></li><li class="chapter" data-level="10.3.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#a-little-bit-of-group-theory."><i class="fa fa-check"></i><b>10.3.3</b> A little bit of group theory.</a></li><li class="chapter" data-level="10.3.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#digital-signatures"><i class="fa fa-check"></i><b>10.3.4</b> Digital Signatures</a></li><li class="chapter" data-level="10.3.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-digital-signature-algorithm-dsa"><i class="fa fa-check"></i><b>10.3.5</b> The Digital Signature Algorithm (DSA)</a></li></ul></li><li class="chapter" data-level="10.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#putting-everything-together---security-in-practice."><i class="fa fa-check"></i><b>10.4</b> Putting everything together - security in practice.</a></li><li class="chapter" data-level="10.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#appendix-an-alternative-proof-of-the-density-of-primes"><i class="fa fa-check"></i><b>10.5</b> Appendix: An alternative proof of the density of primes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html"><i class="fa fa-check"></i><b>11</b> Concrete candidates for public key crypto</a><ul><li class="chapter" data-level="11.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#some-number-theory."><i class="fa fa-check"></i><b>11.1</b> Some number theory.</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#primaliy-testing"><i class="fa fa-check"></i><b>11.1.1</b> Primaliy testing</a></li><li class="chapter" data-level="11.1.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#fields"><i class="fa fa-check"></i><b>11.1.2</b> Fields</a></li><li class="chapter" data-level="11.1.3" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#chinese-remainder-theorem"><i class="fa fa-check"></i><b>11.1.3</b> Chinese remainder theorem</a></li><li class="chapter" data-level="11.1.4" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#the-rsa-and-rabin-functions"><i class="fa fa-check"></i><b>11.1.4</b> The RSA and Rabin functions</a></li><li class="chapter" data-level="11.1.5" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#abstraction-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.5</b> Abstraction: trapdoor permutations</a></li><li class="chapter" data-level="11.1.6" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#public-key-encryption-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.6</b> Public key encryption from trapdoor permutations</a></li><li class="chapter" data-level="11.1.7" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#digital-signatures-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.7</b> Digital signatures from trapdoor permutations</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#hardcore-bits-and-security-without-random-oracles"><i class="fa fa-check"></i><b>11.2</b> Hardcore bits and security without random oracles</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html"><i class="fa fa-check"></i><b>12</b> Lattice based cryptography</a><ul><li class="chapter" data-level="12.1" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#a-world-without-gaussian-elimination"><i class="fa fa-check"></i><b>12.1</b> A world without Gaussian elimination</a></li><li class="chapter" data-level="12.2" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#security-in-the-real-world."><i class="fa fa-check"></i><b>12.2</b> Security in the real world.</a></li><li class="chapter" data-level="12.3" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#search-to-decision"><i class="fa fa-check"></i><b>12.3</b> Search to decision</a></li><li class="chapter" data-level="12.4" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#an-lwe-based-encryption-scheme"><i class="fa fa-check"></i><b>12.4</b> An LWE based encryption scheme</a></li><li class="chapter" data-level="12.5" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#but-what-are-lattices"><i class="fa fa-check"></i><b>12.5</b> But what are lattices?</a></li><li class="chapter" data-level="12.6" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#ring-based-lattices"><i class="fa fa-check"></i><b>12.6</b> Ring based lattices</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12a_CCA_public_key.html"><a href="lec_12a_CCA_public_key.html"><i class="fa fa-check"></i><b>13</b> Chosen ciphertext security for public key encryption</a></li><li class="chapter" data-level="14" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html"><i class="fa fa-check"></i><b>14</b> Establishing secure connections over insecure channels</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cryptographys-obsession-with-adjectives."><i class="fa fa-check"></i><b>14.1</b> Cryptography’s obsession with adjectives.</a></li><li class="chapter" data-level="14.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#basic-key-exchange-protocol"><i class="fa fa-check"></i><b>14.2</b> Basic Key Exchange protocol</a></li><li class="chapter" data-level="14.3" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#authenticated-key-exchange"><i class="fa fa-check"></i><b>14.3</b> Authenticated key exchange</a><ul><li class="chapter" data-level="14.3.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#bleichenbachers-attack-on-rsa-pkcs-v1.5-and-ssl-v3.0"><i class="fa fa-check"></i><b>14.3.1</b> Bleichenbacher’s attack on RSA PKCS V1.5 and SSL V3.0</a></li></ul></li><li class="chapter" data-level="14.4" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#chosen-ciphertext-attack-security-for-public-key-cryptography"><i class="fa fa-check"></i><b>14.4</b> Chosen ciphertext attack security for public key cryptography</a></li><li class="chapter" data-level="14.5" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cca-secure-public-key-encryption-in-the-random-oracle-model"><i class="fa fa-check"></i><b>14.5</b> CCA secure public key encryption in the Random Oracle Model</a><ul><li class="chapter" data-level="14.5.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#defining-secure-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.1</b> Defining secure authenticated key exchange</a></li><li class="chapter" data-level="14.5.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#the-compiler-approach-for-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.2</b> The compiler approach for authenticated key exchange</a></li></ul></li><li class="chapter" data-level="14.6" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#password-authenticated-key-exchange."><i class="fa fa-check"></i><b>14.6</b> Password authenticated key exchange.</a></li><li class="chapter" data-level="14.7" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#client-to-client-key-exchange-for-secure-text-messaging---zrtp-otr-textsecure"><i class="fa fa-check"></i><b>14.7</b> Client to client key exchange for secure text messaging - ZRTP, OTR, TextSecure</a></li><li class="chapter" data-level="14.8" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#heartbleed-and-logjam-attacks"><i class="fa fa-check"></i><b>14.8</b> Heartbleed and logjam attacks</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html"><i class="fa fa-check"></i><b>15</b> Zero knowledge proofs</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#applications-for-zero-knowledge-proofs."><i class="fa fa-check"></i><b>15.1</b> Applications for zero knowledge proofs.</a><ul><li class="chapter" data-level="15.1.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#nuclear-disarmament"><i class="fa fa-check"></i><b>15.1.1</b> Nuclear disarmament</a></li><li class="chapter" data-level="15.1.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#voting"><i class="fa fa-check"></i><b>15.1.2</b> Voting</a></li><li class="chapter" data-level="15.1.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#more-applications"><i class="fa fa-check"></i><b>15.1.3</b> More applications</a></li></ul></li><li class="chapter" data-level="15.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-and-constructing-zero-knowledge-proofs"><i class="fa fa-check"></i><b>15.2</b> Defining and constructing zero knowledge proofs</a></li><li class="chapter" data-level="15.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-zero-knowledge"><i class="fa fa-check"></i><b>15.3</b> Defining zero knowledge</a></li><li class="chapter" data-level="15.4" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#zero-knowledge-proof-for-hamiltonicity."><i class="fa fa-check"></i><b>15.4</b> Zero knowledge proof for Hamiltonicity.</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#why-is-this-interesting"><i class="fa fa-check"></i><b>15.4.1</b> Why is this interesting?</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#parallel-repetition-and-turning-zero-knowledge-proofs-to-signatures."><i class="fa fa-check"></i><b>15.5</b> Parallel repetition and turning zero knowledge proofs to signatures.</a><ul><li class="chapter" data-level="15.5.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#bonus-features-of-zero-knowledge"><i class="fa fa-check"></i><b>15.5.1</b> "Bonus features" of zero knowledge</a></li></ul></li></ul></li><li class="chapter" data-level="16" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html"><i class="fa fa-check"></i><b>16</b> Fully homomorphic encryption: Introduction and bootstrapping</a><ul><li class="chapter" data-level="16.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#defining-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>16.1</b> Defining fully homomorphic encryption</a><ul><li class="chapter" data-level="16.1.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#another-application-fully-homomorphic-encryption-for-verifying-computation"><i class="fa fa-check"></i><b>16.1.1</b> Another application: fully homomorphic encryption for verifying computation</a></li></ul></li><li class="chapter" data-level="16.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#example-an-xor-homomorphic-encryption"><i class="fa fa-check"></i><b>16.2</b> Example: An XOR homomorphic encryption</a><ul><li class="chapter" data-level="16.2.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#abstraction-a-trapdoor-pseudorandom-generator."><i class="fa fa-check"></i><b>16.2.1</b> Abstraction: A trapdoor pseudorandom generator.</a></li></ul></li><li class="chapter" data-level="16.3" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#from-linear-homomorphism-to-full-homomorphism"><i class="fa fa-check"></i><b>16.3</b> From linear homomorphism to full homomorphism</a></li><li class="chapter" data-level="16.4" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#bootstrapping-fully-homomorphic-escape-velocity"><i class="fa fa-check"></i><b>16.4</b> Bootstrapping: Fully Homomorphic "escape velocity"</a><ul><li class="chapter" data-level="16.4.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#radioactive-legos-analogy"><i class="fa fa-check"></i><b>16.4.1</b> Radioactive legos analogy</a></li><li class="chapter" data-level="16.4.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#proving-the-bootstrapping-theorem"><i class="fa fa-check"></i><b>16.4.2</b> Proving the bootstrapping theorem</a></li></ul></li></ul></li><li class="chapter" data-level="17" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html"><i class="fa fa-check"></i><b>17</b> Fully homomorphic encryption : Construction</a><ul><li class="chapter" data-level="17.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#prelude-from-vectors-to-matrices"><i class="fa fa-check"></i><b>17.1</b> Prelude: from vectors to matrices</a></li><li class="chapter" data-level="17.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#real-world-partially-homomorphic-encryption"><i class="fa fa-check"></i><b>17.2</b> Real world partially homomorphic encryption</a></li><li class="chapter" data-level="17.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#noise-management-via-encoding"><i class="fa fa-check"></i><b>17.3</b> Noise management via encoding</a></li><li class="chapter" data-level="17.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#putting-it-all-together"><i class="fa fa-check"></i><b>17.4</b> Putting it all together</a></li><li class="chapter" data-level="17.5" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#analysis-of-our-scheme"><i class="fa fa-check"></i><b>17.5</b> Analysis of our scheme</a><ul><li class="chapter" data-level="17.5.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#correctness"><i class="fa fa-check"></i><b>17.5.1</b> Correctness</a></li><li class="chapter" data-level="17.5.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#cpa-security"><i class="fa fa-check"></i><b>17.5.2</b> CPA Security</a></li><li class="chapter" data-level="17.5.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#homomorphism"><i class="fa fa-check"></i><b>17.5.3</b> Homomorphism</a></li><li class="chapter" data-level="17.5.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#shallow-decryption-circuit"><i class="fa fa-check"></i><b>17.5.4</b> Shallow decryption circuit</a></li></ul></li><li class="chapter" data-level="17.6" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#example-application-private-information-retrieval"><i class="fa fa-check"></i><b>17.6</b> Example application: Private information retrieval</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html"><i class="fa fa-check"></i><b>18</b> Multiparty secure computation I: Definition and Honest-But-Curious to Malicious complier</a><ul><li class="chapter" data-level="18.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#ideal-vs.-real-model-security."><i class="fa fa-check"></i><b>18.1</b> Ideal vs. Real Model Security.</a></li><li class="chapter" data-level="18.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#formally-defining-secure-multiparty-computation"><i class="fa fa-check"></i><b>18.2</b> Formally defining secure multiparty computation</a><ul><li class="chapter" data-level="18.2.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#first-attempt-a-slightly-too-ideal-definition"><i class="fa fa-check"></i><b>18.2.1</b> First attempt: a slightly "too ideal" definition</a></li><li class="chapter" data-level="18.2.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#allowing-for-aborts"><i class="fa fa-check"></i><b>18.2.2</b> Allowing for aborts</a></li><li class="chapter" data-level="18.2.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#some-comments"><i class="fa fa-check"></i><b>18.2.3</b> Some comments:</a></li></ul></li><li class="chapter" data-level="18.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#example-second-price-auction-using-bitcoin"><i class="fa fa-check"></i><b>18.3</b> Example: Second price auction using bitcoin</a><ul><li class="chapter" data-level="18.3.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#another-example-distributed-and-threshold-cryptography"><i class="fa fa-check"></i><b>18.3.1</b> Another example: distributed and threshold cryptography</a></li></ul></li><li class="chapter" data-level="18.4" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#proving-the-fundamental-theorem"><i class="fa fa-check"></i><b>18.4</b> Proving the fundamental theorem:</a></li><li class="chapter" data-level="18.5" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#malicious-to-honest-but-curious-reduction"><i class="fa fa-check"></i><b>18.5</b> Malicious to honest but curious reduction</a><ul><li class="chapter" data-level="18.5.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#handling-probabilistic-strategies"><i class="fa fa-check"></i><b>18.5.1</b> Handling probabilistic strategies:</a></li></ul></li></ul></li><li class="chapter" data-level="19" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html"><i class="fa fa-check"></i><b>19</b> Multiparty secure computation: Construction using Fully Homomorphic Encryption</a><ul><li class="chapter" data-level="19.1" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#constructing-2-party-honest-but-curious-computation-from-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.1</b> Constructing 2 party honest but curious computation from fully homomorphic encryption</a></li><li class="chapter" data-level="19.2" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#achieving-circuit-privacy-in-a-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.2</b> Achieving circuit privacy in a fully homomorphic encryption</a></li><li class="chapter" data-level="19.3" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#bottom-line-a-two-party-honest-but-curious-two-party-secure-computation-protocol"><i class="fa fa-check"></i><b>19.3</b> Bottom line: A two party honest but curious two party secure computation protocol</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html"><i class="fa fa-check"></i><b>20</b> Quantum computing and cryptography I</a><ul><li><ul><li class="chapter" data-level="20.0.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>20.0.1</b> Quantum computing and computation - an executive summary.</a></li></ul></li><li class="chapter" data-level="20.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-101"><i class="fa fa-check"></i><b>20.1</b> Quantum 101</a><ul><li class="chapter" data-level="20.1.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>20.1.1</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="20.1.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bra-ket-notation"><i class="fa fa-check"></i><b>20.1.2</b> Bra-ket notation</a></li><li class="chapter" data-level="20.1.3" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bells-inequality"><i class="fa fa-check"></i><b>20.1.3</b> Bell’s Inequality</a></li></ul></li><li class="chapter" data-level="20.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#grovers-algorithm"><i class="fa fa-check"></i><b>20.2</b> Grover’s Algorithm</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html"><i class="fa fa-check"></i><b>21</b> Quantum computing and cryptography II</a><ul><li class="chapter" data-level="21.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-order-finding-to-factoring-and-discrete-log"><i class="fa fa-check"></i><b>21.1</b> From order finding to factoring and discrete log</a></li><li class="chapter" data-level="21.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#finding-periods-of-a-function-simons-algorithm"><i class="fa fa-check"></i><b>21.2</b> Finding periods of a function: Simon’s Algorithm</a></li><li class="chapter" data-level="21.3" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-simon-to-shor"><i class="fa fa-check"></i><b>21.3</b> From Simon to Shor</a><ul><li class="chapter" data-level="21.3.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.1</b> The Fourier transform over \Z_m</a><ul><li class="chapter" data-level="21.3.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#fast-fourier-transform."><i class="fa fa-check"></i><b>21.3.1.1</b> Fast Fourier Transform.</a></li></ul></li><li class="chapter" data-level="21.3.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.2</b> Quantum Fourier Transform over \Z_m</a></li></ul></li><li class="chapter" data-level="21.4" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#shors-order-finding-algorithm."><i class="fa fa-check"></i><b>21.4</b> Shor’s Order-Finding Algorithm.</a><ul><li class="chapter" data-level="21.4.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#analysis-the-case-that-rm"><i class="fa fa-check"></i><b>21.4.1</b> Analysis: the case that r|m</a><ul><li class="chapter" data-level="21.4.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-general-case"><i class="fa fa-check"></i><b>21.4.1.1</b> The general case</a></li></ul></li></ul></li><li class="chapter" data-level="21.5" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#rational-approximation-of-real-numbers"><i class="fa fa-check"></i><b>21.5</b> Rational approximation of real numbers</a><ul><li class="chapter" data-level="21.5.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-cryptography"><i class="fa fa-check"></i><b>21.5.1</b> Quantum cryptography</a></li></ul></li></ul></li><li class="chapter" data-level="22" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html"><i class="fa fa-check"></i><b>22</b> Software Obfuscation</a><ul><li class="chapter" data-level="22.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#witness-encryption"><i class="fa fa-check"></i><b>22.1</b> Witness encryption</a></li><li class="chapter" data-level="22.2" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#deniable-encryption"><i class="fa fa-check"></i><b>22.2</b> Deniable encryption</a></li><li class="chapter" data-level="22.3" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#functional-encryption"><i class="fa fa-check"></i><b>22.3</b> Functional encryption</a></li><li class="chapter" data-level="22.4" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#the-software-patch-problem"><i class="fa fa-check"></i><b>22.4</b> The software patch problem</a></li><li class="chapter" data-level="22.5" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#software-obfuscation-1"><i class="fa fa-check"></i><b>22.5</b> Software obfuscation</a></li><li class="chapter" data-level="22.6" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#applications-of-obfuscation"><i class="fa fa-check"></i><b>22.6</b> Applications of obfuscation</a></li><li class="chapter" data-level="22.7" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#impossibility-of-obfuscation"><i class="fa fa-check"></i><b>22.7</b> Impossibility of obfuscation</a><ul><li class="chapter" data-level="22.7.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#proof-of-impossibility-of-vbb-obfuscation"><i class="fa fa-check"></i><b>22.7.1</b> Proof of impossibility of VBB obfuscation</a></li></ul></li><li class="chapter" data-level="22.8" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#indistinguishability-obfuscation"><i class="fa fa-check"></i><b>22.8</b> Indistinguishability obfuscation</a></li></ul></li><li class="chapter" data-level="23" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html"><i class="fa fa-check"></i><b>23</b> More obfuscation, exotic encryptions</a><ul><li class="chapter" data-level="23.1" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#slower-weaker-less-securer"><i class="fa fa-check"></i><b>23.1</b> Slower, weaker, less securer</a></li><li class="chapter" data-level="23.2" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#how-to-get-ibe-from-pairing-based-assumptions."><i class="fa fa-check"></i><b>23.2</b> How to get IBE from pairing based assumptions.</a></li><li class="chapter" data-level="23.3" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#beyond-pairing-based-cryptography"><i class="fa fa-check"></i><b>23.3</b> Beyond pairing based cryptography</a></li></ul></li><li class="chapter" data-level="24" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html"><i class="fa fa-check"></i><b>24</b> Anonymous communication</a><ul><li class="chapter" data-level="24.1" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#steganography"><i class="fa fa-check"></i><b>24.1</b> Steganography</a></li><li class="chapter" data-level="24.2" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#anonymous-routing"><i class="fa fa-check"></i><b>24.2</b> Anonymous routing</a></li><li class="chapter" data-level="24.3" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#tor"><i class="fa fa-check"></i><b>24.3</b> Tor</a></li><li class="chapter" data-level="24.4" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#telex"><i class="fa fa-check"></i><b>24.4</b> Telex</a></li><li class="chapter" data-level="24.5" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#riposte"><i class="fa fa-check"></i><b>24.5</b> Riposte</a></li></ul></li><li class="chapter" data-level="25" data-path="lec_24_policy.html"><a href="lec_24_policy.html"><i class="fa fa-check"></i><b>25</b> Ethical, moral, and policy dimensions to cryptography</a><ul><li class="chapter" data-level="25.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#reading-prior-to-lecture"><i class="fa fa-check"></i><b>25.1</b> Reading prior to lecture:</a></li><li class="chapter" data-level="25.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#case-studies."><i class="fa fa-check"></i><b>25.2</b> Case studies.</a><ul><li class="chapter" data-level="25.2.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#the-snowden-revelations"><i class="fa fa-check"></i><b>25.2.1</b> The Snowden revelations</a></li><li class="chapter" data-level="25.2.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#fbi-vs-apple-case"><i class="fa fa-check"></i><b>25.2.2</b> FBI vs Apple case</a></li><li class="chapter" data-level="25.2.3" data-path="lec_24_policy.html"><a href="lec_24_policy.html#juniper-backdoor-case-and-the-opm-break-in"><i class="fa fa-check"></i><b>25.2.3</b> Juniper backdoor case and the OPM break-in</a></li></ul></li></ul></li><li class="chapter" data-level="26" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html"><i class="fa fa-check"></i><b>26</b> Course recap</a><ul><li class="chapter" data-level="26.1" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#some-things-we-did-not-cover"><i class="fa fa-check"></i><b>26.1</b> Some things we did not cover</a></li><li class="chapter" data-level="26.2" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#what-i-hope-you-learned"><i class="fa fa-check"></i><b>26.2</b> What I hope you learned</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational security</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/crypto/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/crypto/lec_02_computational-security.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="computational-security" data-number="2">Computational Security</h1>
<p><strong>Additional reading:</strong> Sections 2.3 and 2.4 in Boneh-Shoup book. Chapter 3 up to and including Section 3.3 in Katz-Lindell book.</p>
<p>Recall our cast of characters- Alice and Bob want to communicate securely over a channel that is monitored by the nosy Eve. In the last lecture, we have seen the definition of <em>perfect secrecy</em> that guarantees that Eve cannot learn <em>anything</em> about their communication beyond what she already knew. However, this security came at a price. For every bit of communication, Alice and Bob have to exchange in advance a bit of a secret key. In fact, the proof of this result gives rise to the following simple Python program that can break every encryption scheme that uses, say, a <span><span class="math inline">\(128\)</span></span> bit key, with a <span><span class="math inline">\(129\)</span></span> bit message:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1"><span class="im">from</span> itertools <span class="im">import</span> product <span class="co"># Import an iterator for cartesian products</span></a>
<a class="sourceLine" id="cb1-2" title="2"></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="co"># Gets ciphertext as input and two potential plaintexts</span></a>
<a class="sourceLine" id="cb1-4" title="4"><span class="co"># Positive return value means first is more likely,</span></a>
<a class="sourceLine" id="cb1-5" title="5"><span class="co"># negative means second is more likely,</span></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="co"># 0 means both have same likelihood.</span></a>
<a class="sourceLine" id="cb1-7" title="7"><span class="co">#</span></a>
<a class="sourceLine" id="cb1-8" title="8"><span class="co"># We assume we have access to the function Decrypt(key,ciphertext)</span></a>
<a class="sourceLine" id="cb1-9" title="9"><span class="kw">def</span> Distinguish(ciphertext,plaintext1,plaintext2):</a>
<a class="sourceLine" id="cb1-10" title="10">    bias <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb1-11" title="11">    <span class="cf">for</span> key <span class="kw">in</span> product([<span class="dv">0</span>,<span class="dv">1</span>], repeat <span class="op">=</span> <span class="dv">128</span>): <span class="co"># Iterate over all possible keys of lenght 128</span></a>
<a class="sourceLine" id="cb1-12" title="12">        p <span class="op">=</span> Decrypt(key, ciphertext)</a>
<a class="sourceLine" id="cb1-13" title="13">        <span class="cf">if</span> p <span class="op">==</span> plaintext1: bias <span class="op">+=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb1-14" title="14">        <span class="cf">if</span> p <span class="op">==</span> plaintext2: bias <span class="op">-=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb1-15" title="15">    <span class="cf">return</span> bias</a></code></pre></div>
<p>Now, generating, distributing, and protecting huge keys causes immense logistical problems, which is why almost all encryption schemes used in practice do in fact utilize short keys (e.g., <span><span class="math inline">\(128\)</span></span> bits long) with messages that can be much longer (sometimes even terabytes or more of data).</p>
<p>So, why can’t we use the above Python program to break all encryptions in the Internet and win infamy and fortune? We can in fact, but we’ll have to wait a <em>really</em> long time, since the loop in <code>Distinguish</code> will run <span><span class="math inline">\(2^{128}\)</span></span> times, which will take much more than the lifetime of the universe to complete, even if we used all the computers on the planet.</p>
<p>However, the fact that <em>this</em> particular program is not a feasible attack, does not mean there does not exist a different attack. But this still suggests a tantalizing possibility: if we consider a relaxed version of perfect secrecy that restricts Eve to performing computations that can be done in this universe (e.g., less than <span><span class="math inline">\(2^{256}\)</span></span> steps should be safe not just for human but for all potential alien civilizations) then can we bypass the impossibility result and allow the key to be much shorter than the message?</p>
<p>This in fact does seem to be the case, but as we’ve seen, defining security is a subtle task, and will take some care. As before, the way we avoid (at least some of) the pitfalls of so many cryptosystems in history is that we insist on very precisely <em>defining</em> what it means for a scheme to be secure.</p>
<p>Let us defer the discussion how one defines a function being computable in “less than <span><span class="math inline">\(T\)</span></span> operations” and just say that there is a way to formally do so. Given the perfect secrecy definition we saw last time, a natural attempt for defining Computational secrecy would be the following:</p>
<div id="firstcompdef" class="definition" title="Computational secrecy (first attempt)" data-number="2" name="Definition 2.1 (Computational secrecy (first attempt)) ">
<p>An encryption scheme <span><span class="math inline">\((E,D)\)</span></span> has <em><span><span class="math inline">\(t\)</span></span> bits of computational secrecy</em> if for every two distinct plaintexts <span><span class="math inline">\(\{m_0,m_1\} \subseteq {\{0,1\}}^\ell\)</span></span> and every strategy of Eve using at most <span><span class="math inline">\(2^t\)</span></span> computational steps, if we choose at random <span><span class="math inline">\(b\in{\{0,1\}}\)</span></span> and a random key <span><span class="math inline">\(k\in{\{0,1\}}^n\)</span></span>, then the probability that Eve guesses <span><span class="math inline">\(m_b\)</span></span> after seeing <span><span class="math inline">\(E_k(m_b)\)</span></span> is at most <span><span class="math inline">\(1/2\)</span></span>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
</div>
<p><a href='#firstcompdef'>Definition 2.1</a> seems very natural, but is in fact <em>impossible</em> to achieve if the key is shorter than the message.</p>
<div id="section" class="pause" data-number="2" name="Pause">
<p>Before reading further, you might want to stop and think if you can <em>prove</em> that there is no, say, <span><span class="math inline">\(\sqrt{n}\)</span></span> secure encryption scheme satisfying <a href='#firstcompdef'>Definition 2.1</a> with <span><span class="math inline">\(\ell = n+1\)</span></span> and where the time to compute the encryption is polynomial.</p>
</div>
<p>The reason <a href='#firstcompdef'>Definition 2.1</a> can’t be achieved that if the message is even one bit longer than the key, we can always have a very efficient procedure that achieves success probability of about <span><span class="math inline">\(1/2 + 2^{-n-1}\)</span></span> by guessing the key. That is, we can replace the loop in the Python program <code>Distinguish</code> by choosing the key at random. Since we have some small chance of guessing correctly, we will get a small advantage over half.</p>
<p>To fix this definition, we do not consider guessing with such a tiny advantage as a “true break” of the scheme, and hence this will be the actual definition we use.</p>
<div id="compsecconcdef" class="definition" title="Computational secrecy (concrete)" data-number="2" name="Definition 2.2 (Computational secrecy (concrete)) ">
<p>An encryption scheme <span><span class="math inline">\((E,D)\)</span></span> has <em><span><span class="math inline">\(t\)</span></span> bits of computational secrecy<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></em> if for every two distinct plaintexts <span><span class="math inline">\(\{m_0,m_1\} \subseteq {\{0,1\}}^\ell\)</span></span> and every strategy of Eve using at most <span><span class="math inline">\(2^t\)</span></span> computational steps, if we choose at random <span><span class="math inline">\(b\in{\{0,1\}}\)</span></span> and a random key <span><span class="math inline">\(k\in{\{0,1\}}^n\)</span></span>, then the probability that Eve guesses <span><span class="math inline">\(m_b\)</span></span> after seeing <span><span class="math inline">\(E_k(m_b)\)</span></span> is at most <span><span class="math inline">\(1/2+2^{-t}\)</span></span>.</p>
</div>
<p>Having learned our lesson, let’s try to see that this strategy does give us the kind of conditions we desired. In particular, let’s verify that this definition implies the analogous condition to perfect secrecy.</p>
<div id="twotomanycomp" class="theorem" title="Guessing game for computational secrecy" data-number="2" name="Theorem 2.3 (Guessing game for computational secrecy) ">
<p>If <span><span class="math inline">\((E,D)\)</span></span> is has <span><span class="math inline">\(t\)</span></span> bits of Computational secrecy as per <a href='#compsecconcdef'>Definition 2.2</a> then every subset <span><span class="math inline">\(M \subseteq {\{0,1\}}^\ell\)</span></span> and every strategy of Eve using at most <span><span class="math inline">\(2^t-(100\ell+100)\)</span></span> computational steps, if we choose at random <span><span class="math inline">\(m\in M\)</span></span> and a random key <span><span class="math inline">\(k\in{\{0,1\}}^n\)</span></span>, then the probability that Eve guesses <span><span class="math inline">\(m\)</span></span> after seeing <span><span class="math inline">\(E_k(m_b)\)</span></span> is at most <span><span class="math inline">\(1/|M|+2^{-t+1}\)</span></span>.</p>
</div>
<p>Before proving this theorem note that it gives us a pretty strong guarantee. In the exercises we will strengthen it even further showing that no matter what prior information Eve had on the message before, she will never get any non-negligible new information on it. One way to phrase it is that if the sender used a <span><span class="math inline">\(256\)</span></span>-bit secure encryption to encrypt a message, then your chances of getting to learn any additional information about it before the universe collapses are more or less the same as the chances that a fairy will materialize and whisper it in your ear.</p>
<div id="section-1" class="pause" data-number="2" name="Pause">
<p>Before reading the proof, try to again review the proof of <a href='lec_01_introduction.html#twotomanythm'>Theorem 1.8</a>, and see if you can generalize it yourself to the computational setting.</p>
</div>
<div id="section-2" class="proof" data-ref="twotomanycomp" data-number="2" name="Proof">
<p>The proof is rather similar to the equivalence of guessing one of two messages vs. one of many messages for perfect secrecy (i.e., <a href='lec_01_introduction.html#twotomanythm'>Theorem 1.8</a>). However, in the computational context we need to be careful in keeping track of Eve’s running time. In the proof of <a href='lec_01_introduction.html#twotomanythm'>Theorem 1.8</a> we showed that if there exists:</p>
<ul>
<li>A subset <span><span class="math inline">\(M\subseteq {\{0,1\}}^\ell\)</span></span> of messages</li>
</ul>
<p>and</p>
<ul>
<li>An adversary <span><span class="math inline">\(Eve:{\{0,1\}}^o\rightarrow{\{0,1\}}^\ell\)</span></span> such that</li>
</ul>
<p><span>
<div class='myequationbox'><span class="math display">\[
\Pr_{m{\leftarrow_{\tiny R}}M, k{\leftarrow_{\tiny R}}{\{0,1\}}^n}[ Eve(E_k(m))=m ] &gt; 1/|M|
\]</span></div></span></p>
<p>Then there exist two messages <span><span class="math inline">\(m_0,m_1\)</span></span> and an adversary <span><span class="math inline">\(Eve&#39;:{\{0,1\}}^0\rightarrow{\{0,1\}}^\ell\)</span></span> such that <span><span class="math inline">\(\Pr_{b{\leftarrow_{\tiny R}}{\{0,1\}},k{\leftarrow_{\tiny R}}{\{0,1\}}^n}[Eve&#39;(E_k(m_b))=m_b ] &gt; 1/2\)</span></span>.</p>
<p>To adapt this proof to the computational setting and complete the proof of the current theorem it suffices to show that:</p>
<ul>
<li><p>If the probability of <span><span class="math inline">\(Eve\)</span></span> succeeding was <span><span class="math inline">\(\tfrac{1}{|M|} + \epsilon\)</span></span> then the probability of <span><span class="math inline">\(Eve&#39;\)</span></span> succeeding is at least <span><span class="math inline">\(\tfrac{1}{2} + \epsilon/2\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(Eve\)</span></span> can be computed in <span><span class="math inline">\(T\)</span></span> operations, then <span><span class="math inline">\(Eve&#39;\)</span></span> can be computed in <span><span class="math inline">\(T + 100\ell + 100\)</span></span> operations.</p></li>
</ul>
<p>This will imply that if <span><span class="math inline">\(Eve\)</span></span> ran in polynomial time and had polynomial advantage over <span><span class="math inline">\(1/|M|\)</span></span> in guessing a plaintext chosen from <span><span class="math inline">\(M\)</span></span>, then <span><span class="math inline">\(Eve&#39;\)</span></span> would run in polynomial time and have polynomial advantage over <span><span class="math inline">\(1/2\)</span></span> in guessing a plaintext chosen from <span><span class="math inline">\(\{ m_0,m_1\}\)</span></span>.</p>
<p>The first item can be shown by simply doing the same proof more carefully, keeping track how the advantage over <span><span class="math inline">\(\tfrac{1}{|M|}\)</span></span> for <span><span class="math inline">\(Eve\)</span></span> translates into an advantage over <span><span class="math inline">\(\tfrac{1}{2}\)</span></span> for <span><span class="math inline">\(Eve&#39;\)</span></span>. As the world’s most annoying saying goes, doing this is an excellent exercise for the reader. The item point is obtained by looking at the definition of <span><span class="math inline">\(Eve&#39;\)</span></span> from that proof. On input <span><span class="math inline">\(c\)</span></span>, <span><span class="math inline">\(Eve&#39;\)</span></span> computed <span><span class="math inline">\(m=Eve(c)\)</span></span> (which costs <span><span class="math inline">\(T\)</span></span> operations), checked if <span><span class="math inline">\(m=m_0\)</span></span> (which costs, say, at most <span><span class="math inline">\(5\ell\)</span></span> operations), and then outputted either <span><span class="math inline">\(1\)</span></span> or a random bit (which is a constant, say at most <span><span class="math inline">\(100\)</span></span> operations).</p>
</div>
<h3 id="proof-by-reduction" data-number="2.0.1">Proof by reduction</h3>
<p>The proof of <a href='#twotomanycomp'>Theorem 2.3</a> is a model to how a great many of the results in this course will look like. Generally we will have many theorems of the form:</p>
<blockquote>
<p>“If there is a scheme <span><span class="math inline">\(S&#39;\)</span></span> satisfying security definition <span><span class="math inline">\(X&#39;\)</span></span> then there is a scheme <span><span class="math inline">\(S\)</span></span> satisfying security definition <span><span class="math inline">\(X\)</span></span>”</p>
</blockquote>
<p>In the context of <a href='#twotomanycomp'>Theorem 2.3</a>, <span><span class="math inline">\(X&#39;\)</span></span> was “having <span><span class="math inline">\(t\)</span></span> bits of security” (in the context distinguishing between encryptions of two ciphertexts) and <span><span class="math inline">\(X\)</span></span> was the more general notion of hardness of getting a non-trivial advantage over guessing for an encryption of a random <span><span class="math inline">\(m\in M\)</span></span>. While in <a href='#twotomanycomp'>Theorem 2.3</a> the encryption scheme <span><span class="math inline">\(S\)</span></span> was the same as <span><span class="math inline">\(S&#39;\)</span></span>, this need not always be the case. However, all of the proofs of such statements will have the same global structure— we will assume towards a contradiction, that there is an efficient adversary strategy <span><span class="math inline">\(Eve\)</span></span> demonstrating that the scheme <span><span class="math inline">\(S\)</span></span> violates the security notion <span><span class="math inline">\(X\)</span></span>, and build from <span><span class="math inline">\(Eve\)</span></span> a strategy <span><span class="math inline">\(Eve&#39;\)</span></span> demonstrating that <span><span class="math inline">\(S&#39;\)</span></span> violates <span><span class="math inline">\(X\)</span></span>. This is such an important point that it deserves repeating:</p>
<blockquote>
<p><em>The way you show that if <span><span class="math inline">\(S&#39;\)</span></span> is secure then <span><span class="math inline">\(S\)</span></span> is secure is by giving a transformation from an adversary that breaks <span><span class="math inline">\(S\)</span></span> into an adversary that breaks <span><span class="math inline">\(S&#39;\)</span></span></em></p>
</blockquote>
<p>For computational secrecy, we will always want that <span><span class="math inline">\(Eve&#39;\)</span></span> will be efficient if <span><span class="math inline">\(Eve\)</span></span> is, and that will usually be the case because <span><span class="math inline">\(Eve&#39;\)</span></span> will simply use <span><span class="math inline">\(Eve\)</span></span> as a black box, which it will not invoke too many times, and addition will use some polynomial time preprocessing and postprocessing. The more challenging parts of such proofs are typically:</p>
<ul>
<li><p>Coming up with the strategy <span><span class="math inline">\(Eve&#39;\)</span></span>.</p></li>
<li><p>Analyzing the probability of success and in particular showing that if <span><span class="math inline">\(Eve\)</span></span> had non-negligible advantage then so will <span><span class="math inline">\(Eve&#39;\)</span></span>.</p></li>
</ul>
<figure>
<img src="../figure/reduction.jpg" alt="2.1: We show that the security of S&#39; implies the security of S by transforming an adversary Eve breaking S into an adversary Eve&#39; breaking S&#39;." id="reductiongenfig" class="margin" /><figcaption>2.1: We show that the security of <span><span class="math inline">\(S&#39;\)</span></span> implies the security of <span><span class="math inline">\(S\)</span></span> by transforming an adversary <span><span class="math inline">\(Eve\)</span></span> breaking <span><span class="math inline">\(S\)</span></span> into an adversary <span><span class="math inline">\(Eve&#39;\)</span></span> breaking <span><span class="math inline">\(S&#39;\)</span></span>.</figcaption>
</figure>
<p>Note that, just like in the context of NP completeness or uncomputability reductions, security reductions work <em>backwards</em>. That is, we construct the scheme <span><span class="math inline">\(S\)</span></span> based on the scheme <span><span class="math inline">\(S&#39;\)</span></span>, but then prove that we can transform an algorithm breaking <span><span class="math inline">\(S\)</span></span> into an algorithm breaking <span><span class="math inline">\(S&#39;\)</span></span>. Just like in computational complexity, it can sometimes be hard to keep track of the direction of the reduction. In fact, cryptographic reductions can be even subtler, since they involve an interplay of several entities (for example, sender, receiver, and adversary) and probabilistic choices (e.g., over the message to be sent and the key).</p>
<h2 id="the-asymptotic-approach" data-number="2.1">The asymptotic approach</h2>
<p>For practical security, often every bit of security matters. We want our keys to be as short as possible and our schemes to be as fast as possible while satisfying a particular level of security. However, for understanding the <em>principles</em> behind cryptography, keeping track of those bits can be a distraction, and so just like we do for algorithms, we will use <em>asymptotic analysis</em> (also known as <em>big Oh notation</em>) to sweep many of those details under the carpet.</p>
<p>To a first approximation, there will be only two types of running times we will encounter in this course:</p>
<ul>
<li><p><em>Polynomial</em> running time of the form <span><span class="math inline">\(d\cdot n^c\)</span></span> for some constants <span><span class="math inline">\(d,c&gt;0\)</span></span> (or <span><span class="math inline">\(poly(n)=n^{O(1)}\)</span></span> for short) , which we will consider as <em>efficient</em></p></li>
<li><p><em>Exponential</em> running time of the form <span><span class="math inline">\(2^{d\cdot n^{\epsilon}}\)</span></span> for some constants <span><span class="math inline">\(d,\epsilon &gt;0\)</span></span> (or <span><span class="math inline">\(2^{n^{\Omega(1)}}\)</span></span> for short) which we will consider as <em>infeasible</em>.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p></li>
</ul>
<p>Another way to say it is that in this course, if a scheme has any security at all, it will have at least <span><span class="math inline">\(n^{\epsilon}\)</span></span> bits of security where <span><span class="math inline">\(n\)</span></span> is the length of the key and <span><span class="math inline">\(\epsilon&gt;0\)</span></span> is some absolute constant such as <span><span class="math inline">\(\epsilon=1/3\)</span></span>.</p>
<p>These are not all the theoretically possible running times. One can have intermediate functions such as <span><span class="math inline">\(n^{\log n}\)</span></span> though we will generally not encounter those. To make things clean (and to correspond to standard terminology), we will say that an algorithm <span><span class="math inline">\(A\)</span></span> is <em>efficient</em> if it runs in time <span><span class="math inline">\(poly(n)\)</span></span> when <span><span class="math inline">\(n\)</span></span> is its input length (which will always be the same, up to polynomial factors, as the key length). If <span><span class="math inline">\(\mu(n)\)</span></span> is some probability that depends on the input/key length parameter <span><span class="math inline">\(n\)</span></span>, then we say that <span><span class="math inline">\(\mu(n)\)</span></span> is <em>negligible</em> if it’s smaller than every polynomial. That is, for every <span><span class="math inline">\(c,d\)</span></span> there is some <span><span class="math inline">\(N\)</span></span>, such that if <span><span class="math inline">\(n&gt;N\)</span></span> then <span><span class="math inline">\(\mu(n) &lt; 1/(cn)^d\)</span></span>. Note that for every non-constant polynomials <span><span class="math inline">\(p,q\)</span></span>, <span><span class="math inline">\(\mu(n)\)</span></span> is negligible if and only if the function <span><span class="math inline">\(\mu&#39;(n) = p(\mu(q(n)))\)</span></span> is negligible.</p>
<div id="asymptotic" class="remark" title="Asymptotic analysis" data-number="2.1" name="Remark 2.4 (Asymptotic analysis) ">
<p>The above definitions could be confusing if you haven’t encountered asymptotic analysis before. Reading the beginning of Chapter 3 (pages 43-51) in the KL book, as well as the mathematical background lecture in my <a href="http://www.introtcs.org/public/index.html">intro to TCS notes</a> can be extremely useful. As a rule of thumb, if every time you see the word “polynomial” you imagine the function <span><span class="math inline">\(n^{10}\)</span></span> and every time you see the word “negligible” you imagine the function <span><span class="math inline">\(2^{-\sqrt{n}}\)</span></span> then you will get the right intuition.</p>
<p>What you need to remember is that negligible is much smaller than any inverse polynomial, while polynomials are closed under multiplication, and so we have the “equations” <span><span class="math inline">\(negligible\times polynomial = negligible\)</span></span> and <span><span class="math inline">\(polynomial \times polynomial = polynomial\)</span></span>. As mentioned, in practice people really want to get as close as possible to <span><span class="math inline">\(n\)</span></span> bits of security with an <span><span class="math inline">\(n\)</span></span> bit key, but we would be happy as long as the security grows with the key, so when we say a scheme is “secure” you can think of it having <span><span class="math inline">\(\sqrt{n}\)</span></span> bits of security (though any function growing faster than <span><span class="math inline">\(\log n\)</span></span> would be fine as well).</p>
</div>
<p>From now on, we will require all of our encryption schemes to be <em>efficient</em> which means that the encryption and decryption algorithms should run in polynomial time. Security will mean that any efficient adversary can make at most a negligible gain in the probability of guessing the message over its a priori probability.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> That is, we make the following definition:</p>
<div id="compsecdef" class="definition" title="Computational secrecy (asymptotic)" data-number="2.1" name="Definition 2.5 (Computational secrecy (asymptotic)) ">
<p>An encryption scheme <span><span class="math inline">\((E,D)\)</span></span> is <em>computationally secret</em> if for every two distinct plaintexts <span><span class="math inline">\(\{m_0,m_1\} \subseteq {\{0,1\}}^\ell\)</span></span> and every efficient (i.e., polynomial time) strategy of Eve, if we choose at random <span><span class="math inline">\(b\in{\{0,1\}}\)</span></span> and a random key <span><span class="math inline">\(k\in{\{0,1\}}^n\)</span></span>, then the probability that Eve guesses <span><span class="math inline">\(m_b\)</span></span> after seeing <span><span class="math inline">\(E_k(m_b)\)</span></span> is at most <span><span class="math inline">\(1/2+\mu(n)\)</span></span> for some negligible function <span><span class="math inline">\(\mu(\cdot)\)</span></span>.</p>
</div>
<h3 id="counting-number-of-operations." data-number="2.1.1">Counting number of operations.</h3>
<p>One more detail that we’ve so far ignored is what does it mean exactly for a function to be computable using at most <span><span class="math inline">\(T\)</span></span> operations. Fortunately, when we don’t really care about the difference between <span><span class="math inline">\(T\)</span></span> and, say, <span><span class="math inline">\(T^2\)</span></span>, then essentially every reasonable definition gives the same answer. Formally, we can use the notions of Turing machines, Boolean circuits, or straightline programs to define complexity. For concreteness, lets define that a function <span><span class="math inline">\(F:{\{0,1\}}^n\rightarrow{\{0,1\}}^m\)</span></span> has complexity at most <span><span class="math inline">\(T\)</span></span> if there is a Boolean circuit that computes <span><span class="math inline">\(F\)</span></span> using at most <span><span class="math inline">\(T\)</span></span> NAND gates (or equivalently, there is a NAND program computing <span><span class="math inline">\(F\)</span></span> in at most <span><span class="math inline">\(T\)</span></span> lines). (There is nothing special about NAND, and we can use any other universal gate set.) We will often also consider <em>probabilistic</em> functions in which case we allow the circuit a RAND gate that outputs a single random bit (though this in general does not give extra power). The fact that we only care about asymptotics means you don’t really need to think of gates, etc.. when arguing in cryptography. However, it is comforting to know that this notion has a precise mathematical formulation.</p>
<h2 id="our-first-conjecture" data-number="2.2">Our first conjecture</h2>
<p>We are now ready to make our first conjecture:</p>
<blockquote>
<p><strong>The Cipher Conjecture:</strong><sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> There exists a computationally secret encryption scheme <span><span class="math inline">\((E,D)\)</span></span> (where <span><span class="math inline">\(E,D\)</span></span> are efficient) with a key of size <span><span class="math inline">\(n\)</span></span> for messages of size <span><span class="math inline">\(n+1\)</span></span>.</p>
</blockquote>
<p>A <em>conjecture</em> is a well defined mathematical statement which (1) we believe is true but (2) don’t know yet how to prove. Proving the cipher conjecture will be a great achievement and would in particular settle the P vs NP question, which is arguably <em>the</em> fundamental question of computer science. That is, the following theorem is known:</p>
<div id="PNPcipherthm" class="theorem" title="Breaking crypto if P=NP" data-number="2.2" name="Theorem 2.6 (Breaking crypto if P=NP) ">
<p>If <span><span class="math inline">\(P=\ensuremath{\mathit{NP}}\)</span></span> then there does not exist a computationally secret encryption with efficient <span><span class="math inline">\(E\)</span></span> and <span><span class="math inline">\(D\)</span></span> and where the message is longer than the key.</p>
</div>
<div id="section-3" class="proof" data-ref="PNPcipherthm" data-number="2.2" name="Proof">
<p>We just sketch the proof, as this is not the focus of this course. If <span><span class="math inline">\(P=\ensuremath{\mathit{NP}}\)</span></span> then whenever we have a loop that searches through some domain to find some string that satisfies a particular property (like the loop in the <code>Distinguish</code> subroutine above that searches over all keys) then this loop can be sped up <em>exponentially</em> .</p>
</div>
<p>While it is very widely believed that <span><span class="math inline">\(P\neq \ensuremath{\mathit{NP}}\)</span></span>, at the moment we do not know how to <em>prove</em> this, and so have to settle for accepting the cipher conjecture as essentially an axiom, though we will see later in this course that we can show it follows from some seemingly weaker conjectures.</p>
<p>There are several reasons to believe the cipher conjecture. We now briefly mention some of them:</p>
<ul>
<li><p><em>Intuition:</em> If the cipher conjecture is false then it means that for <em>every</em> possible cipher we can make the exponential time attack described above become efficient. It seems “too good to be true” in a similar way that the assumption that P=NP seems too good to be true.</p></li>
<li><p><em>Concrete candidates:</em> As we will see in the next lecture, there are several concrete candidate ciphers using keys shorter than messages for which despite <em>tons</em> of effort, no one knows how to break them. Some of them are widely used and hence governments and other benign or not so benign organizations have every reason to invest huge resources in trying to break them. Despite that as far as we know (and we know a little more after Edward Snowden’s revelations) there is no significant break known for the most popular ciphers. Moreover, there are other ciphers that can be based on canonical mathematical problems such as factoring large integers or decoding random linear codes that are immensely interesting in their own right, independently of their cryptographic applications.</p></li>
<li><p><em>Minimalism:</em> Clearly if the cipher conjecture is false then we also don’t have a secure encryption with a key, say, twice as long as the message. But it turns out the cipher conjecture is in fact <em>necessary</em> for essentially every cryptographic primitive, including not just private key and public key encryptions but also digital signatures, hash functions, pseudorandom generators, and more. That is, if the cipher conjecture is false then to a large extent cryptography does not exist, and so we essentially have to assume this conjecture if we want to do any kind of cryptography.</p></li>
</ul>
<h2 id="why-care-about-the-cipher-conjecture" data-number="2.3">Why care about the cipher conjecture?</h2>
<blockquote>
<p><em>“Give me a place to stand, and I shall move the world”</em> Archimedes, circa 250 BC</p>
</blockquote>
<p>Every perfectly secure encryption scheme is clearly also computationally secret, and so if we required a message of size <span><span class="math inline">\(n\)</span></span> instead <span><span class="math inline">\(n+1\)</span></span>, then the conjecture would have been trivially satisfied by the one-time pad. However, having a message longer than the key by just a single bit does not seem that impressive. Sure, if we used such a scheme with <span><span class="math inline">\(128\)</span></span>-bit long keys, our communication will be smaller by a factor of <span><span class="math inline">\(128/129\)</span></span> (or a saving of about <span><span class="math inline">\(0.8\%\)</span></span>) over the one-time pad, but this doesn’t seem worth the risk of using an unproven conjecture. However, it turns out that if we assume this rather weak condition, we can actually get a computationally secret encryption scheme with a message of size <span><span class="math inline">\(p(n)\)</span></span> for <em>every</em> polynomial <span><span class="math inline">\(p(\cdot)\)</span></span>. In essence, we can fix a single <span><span class="math inline">\(n\)</span></span>-bit long key and communicate securely as many bits as we want!</p>
<p>Moreover, this is just the beginning. There is a huge range of other useful cryptographic tools that we can obtain from this seemingly innocent conjecture: (We will see what all these names and some of these reductions mean later in the course.)</p>
<figure>
<img src="../figure/privatekey-reduction-web.jpg" alt="21.1: Web of reductions between notions equivalent to ciphers with larger than key messages" id="tmplabelfig" /><figcaption>21.1: Web of reductions between notions equivalent to ciphers with larger than key messages</figcaption>
</figure>
<p>We will soon see the first of the many reductions we’ll learn in this course. Together this “web of reductions” forms the scientific core of cryptography, connecting many of the core concepts and enabling us to construct increasingly sophisticated tools based on relatively simple “axioms” such as the cipher conjecture.</p>
<h2 id="prelude-computational-indistinguishability" data-number="2.4">Prelude: Computational Indistinguishability</h2>
<p>The task of Eve in breaking an encryption scheme is to <em>distinguish</em> between an encryption of <span><span class="math inline">\(m_0\)</span></span> and an encryption of <span><span class="math inline">\(m_1\)</span></span>. It turns out to be useful to consider this question of when two distributions are <em>computationally indistinguishable</em> more broadly:</p>
<div id="compindef" class="definition" title="Computational Indistinguishability" data-number="2.4" name="Definition 2.7 (Computational Indistinguishability) ">
<p>Let <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(Y\)</span></span> be two distributions over <span><span class="math inline">\({\{0,1\}}^o\)</span></span>. We say that <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(Y\)</span></span> are <span><span class="math inline">\((T,\epsilon)\)</span></span><em>-computationally indistinguishable</em>, denoted by <span><span class="math inline">\(X \approx_{T,\epsilon} Y\)</span></span>, if for every function <span><span class="math inline">\(Eve\)</span></span> computable with at most <span><span class="math inline">\(T\)</span></span> operations,</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
| \Pr[ Eve(X) = 1 ] - \Pr[ Eve(Y) = 1 ] | \leq \epsilon \;.
\]</span></div></span></p>
<p>We say that <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(Y\)</span></span> are simply <em>computationally indistinguishable</em>, denoted by <span><span class="math inline">\(X\approx Y\)</span></span>, if they are <span><span class="math inline">\((T,\epsilon)\)</span></span> indistinguishable for every polynomial <span><span class="math inline">\(T(o)\)</span></span> and inverse polynomial <span><span class="math inline">\(\epsilon(o)\)</span></span>.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup></p>
</div>
<p><strong>Note:</strong> The expression <span><span class="math inline">\(\Pr[ Eve(X)=1]\)</span></span> can also be written as <span><span class="math inline">\({\mathbb{E}}[Eve(X)]\)</span></span> (since we can assume that whenever <span><span class="math inline">\(Eve(x)\)</span></span> does not output <span><span class="math inline">\(1\)</span></span> it outputs zero). This notation will be useful for us sometimes.</p>
<p>We can use computational indistinguishability to phrase the definition of Computational secrecy more succinctly:</p>
<div id="compindsecthm" class="theorem" title="Computational Indistinguishability phrasing of security" data-number="2.4" name="Theorem 2.8 (Computational Indistinguishability phrasing of security) ">
<p>Let <span><span class="math inline">\((E,D)\)</span></span> be a valid encryption scheme. Then <span><span class="math inline">\((E,D)\)</span></span> is computationally secret if and only if for every two messages <span><span class="math inline">\(m_0,m_1 \in \{0,1\}^\ell\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[ \{ E_k(m_0) \}  \approx \{ E_k(m_1) \}  \]</span></div></span> where each of these two distributions is obtained by sampling a random <span><span class="math inline">\(k{\leftarrow_{\tiny R}}{\{0,1\}}^n\)</span></span>.</p>
</div>
<p>Working out the proof is an excellent way to make sure you understand both the definition of Computational secrecy and computational indistinguishability, and hence we leave it as an exercise.</p>
<p>One intuition for computational indistinguishability is that it is related to some notion of <em>distance</em>. If two distributions are computationally indistinguishable, then we can think of them as “very close” to one another, at least as far as efficient observers are concerned. Intuitively, if <span><span class="math inline">\(X\)</span></span> is close to <span><span class="math inline">\(Y\)</span></span> and <span><span class="math inline">\(Y\)</span></span> is close to <span><span class="math inline">\(Z\)</span></span> then <span><span class="math inline">\(X\)</span></span> should be close to <span><span class="math inline">\(Z\)</span></span>.<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup> Similarly if four distributions <span><span class="math inline">\(X,X&#39;,Y,Y&#39;\)</span></span> satisfy that <span><span class="math inline">\(X\)</span></span> is close to <span><span class="math inline">\(Y\)</span></span> and <span><span class="math inline">\(X&#39;\)</span></span> is close to <span><span class="math inline">\(Y&#39;\)</span></span>, then you might expect that the distribution <span><span class="math inline">\((X,X&#39;)\)</span></span> where we take two independent samples from <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(X&#39;\)</span></span> respectively, is close to the distribution <span><span class="math inline">\((Y,Y&#39;)\)</span></span> where we take two independent samples from <span><span class="math inline">\(Y\)</span></span> and <span><span class="math inline">\(Y&#39;\)</span></span> respectively. We will now verify that these intuitions are in fact correct:</p>
<div id="triangleeqthm" class="theorem" title="Triangle Inequality for Computational Indistinguishability" data-number="2.4" name="Theorem 2.9 (Triangle Inequality for Computational Indistinguishability) ">
<p>Suppose <span><span class="math inline">\(\{ X_1 \} \approx_{T,\epsilon} \{ X_2 \} \approx_{T,\epsilon} \cdots \approx_{T,\epsilon} \{ X_m \}\)</span></span>. Then <span><span class="math inline">\(\{ X_1 \} \approx_{T, (m-1)\epsilon} \{ X_m \}\)</span></span>.</p>
</div>
<div id="section-4" class="proof" data-ref="triangleeqthm" data-number="2.4" name="Proof">
<p>Suppose that there exists a <span><span class="math inline">\(T\)</span></span> time <span><span class="math inline">\(Eve\)</span></span> such that <span>
<div class='myequationbox'><span class="math display">\[
|\Pr[ Eve(X_1)=1] - \Pr[ Eve(X_m)=1]| &gt; (m-1)\epsilon  \;.
\]</span></div></span></p>
<p>Write <span>
<div class='myequationbox'><span class="math display">\[
\Pr[ Eve(X_1)=1] - \Pr[ Eve(X_m)=1] = \sum_{i=1}^{m-1} \left( \Pr[ Eve(X_i)=1] - \Pr[ Eve(X_{i+1})=1] \right)  \;.
\]</span></div></span></p>
<p>Thus, <span>
<div class='myequationbox'><span class="math display">\[
\sum_{i=1}^{m-1} \left| \Pr[ Eve(X_i)=1] - \Pr[ Eve(X_{i+1})=1] \right| &gt; (m-1)\epsilon
\]</span></div></span> and hence in particular there must exists some <span><span class="math inline">\(i\in\{1,\ldots,m-1\}\)</span></span> such that <span>
<div class='myequationbox'><span class="math display">\[
\left| \Pr[ Eve(X_i)=1] - \Pr[ Eve(X_{i+1})=1] \right| &gt; \epsilon
\]</span></div></span> contradicting the assumption that <span><span class="math inline">\(\{ X_i \} \approx_{T,\epsilon} \{ X_{i+1} \}\)</span></span> for all <span><span class="math inline">\(i\in\{1,\ldots,m-1\}\)</span></span>.</p>
</div>
<div id="compindrepthm" class="theorem" title="Computational Indistinguishability is preserved under repetition" data-number="2.4" name="Theorem 2.10 (Computational Indistinguishability is preserved under repetition) ">
<p>Suppose that <span><span class="math inline">\(X_1,\ldots,X_\ell,Y_1,\ldots,Y_\ell\)</span></span> are distributions over <span><span class="math inline">\({\{0,1\}}^n\)</span></span> such that <span><span class="math inline">\(X_i \approx_{T,\epsilon} Y_i\)</span></span>. Then <span><span class="math inline">\((X_1,\ldots,X_\ell) \approx_{T-10\ell n,\ell\epsilon} (Y_1,\ldots,Y_\ell)\)</span></span>.</p>
</div>
<div id="section-5" class="proof" data-ref="compindrepthm" data-number="2.4" name="Proof">
<p>For every <span><span class="math inline">\(i\in\{0,\ldots,\ell\}\)</span></span> we define <span><span class="math inline">\(H_i\)</span></span> to be the distribution <span><span class="math inline">\((X_1,\ldots,X_i,Y_{i+1},\ldots,Y_\ell)\)</span></span>. Clearly <span><span class="math inline">\(H_0 = (X_1,\ldots,X_\ell)\)</span></span> and <span><span class="math inline">\(H_\ell = (Y_1,\ldots,Y_\ell)\)</span></span>. We will prove that for every <span><span class="math inline">\(i\)</span></span>, <span><span class="math inline">\(H_i \approx_{T-10\ell n,\epsilon} H_{i+1}\)</span></span>, and the proof will then follow from the triangle inequality (can you see why?). Indeed, suppose towards the sake of contradiction that there was some <span><span class="math inline">\(i\in \{0,\ldots,\ell\}\)</span></span> and some <span><span class="math inline">\(T-10\ell n\)</span></span>-time <span><span class="math inline">\(Eve&#39;s:{\{0,1\}}^{n\ell}\rightarrow{\{0,1\}}\)</span></span> such that</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\left| {\mathbb{E}}[ Eve&#39;(H_i) ] - {\mathbb{E}}[ Eve(H_{i+1}) ] \right|  &gt; \epsilon\;.
\]</span></div></span></p>
<p>In other words <span>
<div class='myequationbox'><span class="math display">\[
\left| {\mathbb{E}}_{X_1,\ldots,X_{i-1},Y_i,\ldots,Y_\ell}[ Eve&#39;(X_1,\ldots,X_{i-1},Y_i,\ldots,Y_\ell) ] - {\mathbb{E}}_{X_1,\ldots,X_i,Y_{i+1},\ldots,Y_\ell}[ Eve&#39;(X_1,\ldots,X_i,Y_{i+1},\ldots,Y_\ell) ]   \right|  &gt; \epsilon\;.
\]</span></div></span></p>
<p>By linearity of expectation we can write the difference of these two expectations as <span>
<div class='myequationbox'><span class="math display">\[
{\mathbb{E}}_{X_1,\ldots,X_{i-1},X_i,Y_i,Y_{i+1},\ldots,Y_\ell}\left[ Eve&#39;(X_1,\ldots,X_{i-1},Y_i,Y_{i+1},\ldots,Y_\ell) -  Eve&#39;(X_1,\ldots,X_{i-1},X_i,Y_{i+1},\ldots,Y_\ell) \right]
\]</span></div></span></p>
<p>By the <em>averaging principle</em><sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup> this means that there exist some values <span><span class="math inline">\(x_1,\ldots,x_{i-1},y_{i+1},\ldots,y_\ell\)</span></span> such that <span>
<div class='myequationbox'><span class="math display">\[
\left|{\mathbb{E}}_{X_i,Y_i}\left[ Eve&#39;(x_1,\ldots,x_{i-1},Y_i,y_{i+1},\ldots,y_\ell) -  Eve&#39;(x_1,\ldots,x_{i-1},X_i,y_{i+1},\ldots,y_\ell) \right]\right|&gt;\epsilon
\]</span></div></span> Now <span><span class="math inline">\(X_i\)</span></span> and <span><span class="math inline">\(Y_i\)</span></span> are simply independent draws from the distributions <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(Y\)</span></span> respectively, and so if we define <span><span class="math inline">\(Eve(z) = Eve&#39;(x_1,\ldots,x_{i-1},z,y_{i+1},\ldots,y_\ell)\)</span></span> then <span><span class="math inline">\(Eve\)</span></span> runs in time at most the running time of <span><span class="math inline">\(Eve\)</span></span> plus <span><span class="math inline">\(2\ell n\)</span></span> and it satisfies <span>
<div class='myequationbox'><span class="math display">\[
\left| {\mathbb{E}}_{X_i} [ Eve(X_i) ] - {\mathbb{E}}_{Y_i} [ Eve(Y_i) ] \right| &gt; \epsilon
\]</span></div></span> contradicting the assumption that <span><span class="math inline">\(X_i \approx_{T,\epsilon} Y_i\)</span></span>.</p>
</div>
<div id="hybridrem" class="remark" title="The hybrid argument" data-number="2.4" name="Remark 2.11 (The hybrid argument) ">
<p>The above proof illustrates a powerful technique known as the <em>hybrid argument</em> whereby we show that two distribution <span><span class="math inline">\(C^0\)</span></span> and <span><span class="math inline">\(C^1\)</span></span> are close to each other by coming up with a sequence of distributions <span><span class="math inline">\(H_0,\ldots,H_t\)</span></span> such that <span><span class="math inline">\(H_t = C^1, H_0 = C^0\)</span></span>, and we can argue that <span><span class="math inline">\(H_i\)</span></span> is close to <span><span class="math inline">\(H_{i+1}\)</span></span> for all <span><span class="math inline">\(i\)</span></span>. This type of argument repeats itself time and again in cryptography, and so it is important to get comfortable with it.</p>
</div>
<h2 id="the-length-extension-theorem" data-number="2.5">The Length Extension Theorem</h2>
<p>We now turn to show the <em>length extension theorem</em>, stating that if we have an encryption for <span><span class="math inline">\(n+1\)</span></span>-length messages with <span><span class="math inline">\(n\)</span></span>-length keys, then we can obtain an encryption with <span><span class="math inline">\(p(n)\)</span></span>-length messages for every polynomial <span><span class="math inline">\(p(n)\)</span></span>. For a warm-up, let’s show that the easier fact that we can transform an encryption such as above, into one that has keys of length <span><span class="math inline">\(tn\)</span></span> and messages of length <span><span class="math inline">\(t(n+1)\)</span></span> for every integer <span><span class="math inline">\(t\)</span></span>:</p>
<div id="secrepthm" class="theorem" title="Security of repetition" data-number="2.5" name="Theorem 2.12 (Security of repetition) ">
<p>Suppose that <span><span class="math inline">\((E&#39;,D&#39;)\)</span></span> is a computationally secret encryption scheme with <span><span class="math inline">\(n\)</span></span> bit keys and <span><span class="math inline">\(n+1\)</span></span> bit messages. Then the scheme <span><span class="math inline">\((E,D)\)</span></span> where <span><span class="math inline">\(E_{k_1,\ldots,k_t}(m_1,\ldots,m_t)= (E&#39;_{k_1}(m_1),\ldots, E&#39;_{k_T}(m_t))\)</span></span> and <span><span class="math inline">\(D_{k_1,\ldots,k_t}(c_1,\ldots,c_t)= (D&#39;_{k_1}(c_1),\ldots, D&#39;_{k_t}(c_t))\)</span></span> is a computationally secret scheme with <span><span class="math inline">\(tn\)</span></span> bit keys and <span><span class="math inline">\(t(n+1)\)</span></span> bit messages.</p>
</div>
<div id="section-6" class="proof" data-ref="secrepthm" data-number="2.5" name="Proof">
<p>This might seem “obvious” but in cryptography, even obvious facts are sometimes wrong, so it’s important to prove this formally. Luckily, this is a fairly straightforward implication of the fact that computational indisinguishability is preserved under many samples. That is, by the security of <span><span class="math inline">\((E&#39;,D&#39;)\)</span></span> we know that for every two messages <span><span class="math inline">\(m,m&#39; \in {\{0,1\}}^{n+1}\)</span></span>, <span><span class="math inline">\(E_k(m) \approx E_k(m&#39;)\)</span></span> where <span><span class="math inline">\(k\)</span></span> is chosen from the distribution <span><span class="math inline">\(U_n\)</span></span>. Therefore by the indistinguishability of many samples lemma, for every two tuples <span><span class="math inline">\(m_1,\ldots,m_t \in {\{0,1\}}^{n+1}\)</span></span> and <span><span class="math inline">\(m&#39;_1,\ldots,m&#39;_t\in {\{0,1\}}^{n+1}\)</span></span>,</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
(E&#39;_{k_1}(m_1),\ldots,E&#39;_{k_t}(m_t)) \approx (E&#39;_{k_1}(m&#39;_1),\ldots,E&#39;_{k_t}(m&#39;_t))
\]</span></div></span></p>
<p>for random <span><span class="math inline">\(k_1,\ldots,k_t\)</span></span> chosen independently from <span><span class="math inline">\(U_n\)</span></span> which is exactly the condition that <span><span class="math inline">\((E,D)\)</span></span> is computationally secret.</p>
</div>
<p>We can now prove the full length extension theorem. Before doing so, we will need to generalize the notion of an encryption scheme to allow a <em>randomized encryption scheme</em>. That is, we will consider encryption schemes where the encryption algorithm can “toss coins” in its computation. There is a crucial difference between key material and such “as hoc” randomness. Keys need to be not only chosen at random, but also shared in advance between the sender and receiver, and stored securely throughout their lifetime. The “coin tosses” used by a randomized encryption scheme are generated “on the fly” and are not known to the receiver, nor do they need to be stored long term by the sender. So, allowing such randomized encryption does not make a difference for most applications of encryption schemes. In fact, as we will see later in this course, randomized encryption is <em>necessary</em> for security against more sophisticated attacks such as chosen plaintext and chosen ciphertext attacks, as well as for obtaining secure <em>public key</em> encryptions. We will use the notation <span><span class="math inline">\(E_k(m;r)\)</span></span> to denote the output of the encryption algorithm on key <span><span class="math inline">\(k\)</span></span>, message <span><span class="math inline">\(m\)</span></span> and using internal randomness <span><span class="math inline">\(r\)</span></span>. We often suppress the notation for the randomness, and hence use <span><span class="math inline">\(E_k(m)\)</span></span> to denote the random variable obtained by sampling a random <span><span class="math inline">\(r\)</span></span> and outputting <span><span class="math inline">\(E_k(m;r)\)</span></span>.</p>
<p>We can now show that given an encryption scheme with messages one bit longer than the key, we can obtain a (randomized) encryption scheme with arbitrarily long messages:</p>
<div id="lengthextendthm" class="theorem" title="Length extension of ciphers" data-number="2.5" name="Theorem 2.13 (Length extension of ciphers) ">
<p>Suppose that there exists a computationally secret encryption scheme <span><span class="math inline">\((E&#39;,D&#39;)\)</span></span> with key length <span><span class="math inline">\(n\)</span></span> and message length <span><span class="math inline">\(n+1\)</span></span>. Then for every polynomial <span><span class="math inline">\(t(n)\)</span></span> there exists a (randomized) computationally secret encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with key length <span><span class="math inline">\(n\)</span></span> and message length <span><span class="math inline">\(t(n)\)</span></span>.</p>
</div>
<figure>
<img src="../figure/length-extension.jpg" alt="21.1: Constructing a cipher with t bit long messages from one with n+1 long messages" id="tmplabelfig" /><figcaption>21.1: Constructing a cipher with <span><span class="math inline">\(t\)</span></span> bit long messages from one with <span><span class="math inline">\(n+1\)</span></span> long messages</figcaption>
</figure>
<div id="section-7" class="proof" data-ref="lengthextendthm" data-number="2.5" name="Proof">
<p>Let <span><span class="math inline">\(t=t(n)\)</span></span>. We are given a cipher <span><span class="math inline">\(E&#39;\)</span></span> which can encrypt <span><span class="math inline">\(n+1\)</span></span>-bit long messages with an <span><span class="math inline">\(n\)</span></span>-bit long key and we need to encrypt a <span><span class="math inline">\(t\)</span></span>-bit long message <span><span class="math inline">\(m=(m_1,\ldots,m_t) \in {\{0,1\}}^t\)</span></span>. Our idea is simple (at least in hindsight). Let <span><span class="math inline">\(k_0 {\leftarrow_{\tiny R}}{\{0,1\}}^n\)</span></span> be our key (which is chosen at random). To encrypt <span><span class="math inline">\(m\)</span></span> using <span><span class="math inline">\(k_0\)</span></span>, the encryption function will choose <span><span class="math inline">\(t\)</span></span> random strings <span><span class="math inline">\(k_1,\ldots, k_t {\leftarrow_{\tiny R}}{\{0,1\}}^n\)</span></span>. We will then encrypt the <span><span class="math inline">\(n+1\)</span></span>-bit long message <span><span class="math inline">\((k_1,m_1)\)</span></span> with the key <span><span class="math inline">\(k_0\)</span></span> to obtain the ciphertext <span><span class="math inline">\(c_1\)</span></span>, then encrypt the <span><span class="math inline">\(n+1\)</span></span>-bit long message <span><span class="math inline">\((k_2,m_2)\)</span></span> with the key <span><span class="math inline">\(k_1\)</span></span> to obtain the ciphertext <span><span class="math inline">\(c_2\)</span></span>, and so on and so forth until we encrypt the message <span><span class="math inline">\((k_t,m_t)\)</span></span> with the key <span><span class="math inline">\(k_{t-1}\)</span></span>.<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup> We output <span><span class="math inline">\((c_1,\ldots,c_t)\)</span></span> as the final ciphertext.<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup></p>
<p>To decrypt <span><span class="math inline">\((c_1,\ldots,c_t)\)</span></span> using the key <span><span class="math inline">\(k_0\)</span></span>, first decrypt <span><span class="math inline">\(c_1\)</span></span> to learn <span><span class="math inline">\((k_1,m_1)\)</span></span>, then use <span><span class="math inline">\(k_1\)</span></span> to decrypt <span><span class="math inline">\(c_2\)</span></span> to learn <span><span class="math inline">\((k_2,m_2)\)</span></span>, and so on until we use <span><span class="math inline">\(k_{t-1}\)</span></span> to decrypt <span><span class="math inline">\(c_t\)</span></span> and learn <span><span class="math inline">\((k_t,m_t)\)</span></span>. Finally we can simply output <span><span class="math inline">\((m_1,\ldots,m_t)\)</span></span>.</p>
<p>The above are clearly valid encryption and decryption algorithms, and hence the real question becomes <em>is it secure??</em>. The intuition is that <span><span class="math inline">\(c_1\)</span></span> hides all information about <span><span class="math inline">\((k_1,m_1)\)</span></span> and so in particular the first bit of the message is encrypted securely, and <span><span class="math inline">\(k_1\)</span></span> still can be treated as an unknown random string even to an adversary that saw <span><span class="math inline">\(c_1\)</span></span>. Thus, we can think of <span><span class="math inline">\(k_1\)</span></span> as a random secret key for the encryption <span><span class="math inline">\(c_2\)</span></span>, and hence the second bit of the message is encrypted securely, and so on and so forth.</p>
<p>Our discussion above looks like a reasonable intuitive argument, but to make sure it’s true we need to give an actual proof. Let <span><span class="math inline">\(m,m&#39; \in {\{0,1\}}^t\)</span></span> be two messages. We need to show that <span><span class="math inline">\(E_{U_n}(m) \approx E_{U_n}(m&#39;)\)</span></span>. The heart of the proof will be the following claim:</p>
<p><strong>Claim:</strong> Let <span><span class="math inline">\(\hat{E}\)</span></span> be the algorithm that on input a message <span><span class="math inline">\(m\)</span></span> and key <span><span class="math inline">\(k_0\)</span></span> works like <span><span class="math inline">\(E\)</span></span> except that its the <span><span class="math inline">\(i^{th}\)</span></span> block contains <span><span class="math inline">\(E&#39;_{k_{i-1}}(k&#39;_i,m_i)\)</span></span> where <span><span class="math inline">\(k&#39;_i\)</span></span> is a <em>random</em> string in <span><span class="math inline">\({\{0,1\}}^n\)</span></span>, that is chosen <em>independently</em> of everything else including the key <span><span class="math inline">\(k_i\)</span></span>. Then, for every message <span><span class="math inline">\(m\in{\{0,1\}}^t\)</span></span></p>
<p><span>
<div class='myequationbox'><span class="math display">\[
E_{U_n}(m) \approx \hat{E}_{U_n}(m)  \;\;(2.14) \;.
\]</span><a id='lengthextendclaimeq'></a></div></span></p>
<p>Note that <span><span class="math inline">\(\hat{E}\)</span></span> is not a valid encryption scheme since it’s not at all clear there is a decryption algorithm for it. It is just an hypothetical tool we use for the proof. Since both <span><span class="math inline">\(E\)</span></span> and <span><span class="math inline">\(\hat{E}\)</span></span> are randomized encryption schemes (with <span><span class="math inline">\(E\)</span></span> using <span><span class="math inline">\((t-1)n\)</span></span> bits of randomness for the ephemeral keys <span><span class="math inline">\(k_1,\ldots,k_{t-1}\)</span></span> and <span><span class="math inline">\(\hat{E}\)</span></span> using <span><span class="math inline">\((2t-1)n\)</span></span> bits of randomness for the ephemeral keys <span><span class="math inline">\(k_1,\ldots,k_t,k&#39;_2,\ldots,k&#39;_t\)</span></span>), we can also write <a href='#lengthextendclaimeq'>Equation 2.14</a> as <span>
<div class='myequationbox'><span class="math display">\[
E_{U_n}(m; U&#39;_{tn}) \approx \hat{E}_{U_n}(m; U&#39;_{(2t-1)n})  
\]</span></div></span> where we use <span><span class="math inline">\(U&#39;_\ell\)</span></span> to denote a random variable that is chosen uniformly at random from <span><span class="math inline">\(\{0,1\}^\ell\)</span></span> and independently from the choice of <span><span class="math inline">\(U_n\)</span></span> (which is chosen uniformly at random from <span><span class="math inline">\(\{0,1\}^n\)</span></span>).</p>
<p>Once we prove the claim then we are done since we know that for every pair of message <span><span class="math inline">\(m,m&#39;\)</span></span>, <span><span class="math inline">\(E_{U_n}(m) \approx \hat{E}_{U_n}(m)\)</span></span> and <span><span class="math inline">\(E_{U_n}(m&#39;) \approx \hat{E}_{U_n}(m&#39;)\)</span></span> but <span><span class="math inline">\(\hat{E}_{U_n}(m) \approx \hat{E}_{U_n}(m&#39;)\)</span></span> since <span><span class="math inline">\(\hat{E}\)</span></span> is essentially the same as the <span><span class="math inline">\(t\)</span></span>-times repetition scheme we analyzed above. Thus by the triangle inequality we can conclude that <span><span class="math inline">\(E_{U_n}(m) \approx E_{U_n}(m&#39;)\)</span></span> as we desired.</p>
<p><strong>Proof of claim:</strong> We prove the claim by the hybrid method. For <span><span class="math inline">\(j\in \{0,\ldots, \ell\}\)</span></span>, let <span><span class="math inline">\(H_j\)</span></span> be the distribution of ciphertexts where in the first <span><span class="math inline">\(j\)</span></span> blocks we act like <span><span class="math inline">\(\hat{E}\)</span></span> and in the last <span><span class="math inline">\(t-j\)</span></span> blocks we act like <span><span class="math inline">\(E\)</span></span>. That is, we choose <span><span class="math inline">\(k_0,\ldots,k_t,k&#39;_1,\ldots,k&#39;_t\)</span></span> independently at random from <span><span class="math inline">\(U_n\)</span></span> and the <span><span class="math inline">\(i^{th}\)</span></span> block of <span><span class="math inline">\(H_j\)</span></span> is equal to <span><span class="math inline">\(E&#39;_{k_{i-1}}(k_i,m_i)\)</span></span> if <span><span class="math inline">\(i&gt;j\)</span></span> and is equal to <span><span class="math inline">\(E&#39;_{k_{i-1}}(k&#39;_i,m_i)\)</span></span> if <span><span class="math inline">\(i\leq j\)</span></span>. Clearly, <span><span class="math inline">\(H_t = \hat{E}_{U_n}(m)\)</span></span> and <span><span class="math inline">\(H_0 = E_{U_n}(m)\)</span></span> and so it suffices to prove that for every <span><span class="math inline">\(j\)</span></span>, <span><span class="math inline">\(H_j \approx H_{j+1}\)</span></span>. Indeed, let <span><span class="math inline">\(j \in \{0,\ldots,\ell\}\)</span></span> and suppose towards the sake of contradiction that there exists an efficient <span><span class="math inline">\(Eve&#39;\)</span></span> such that</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\left| {\mathbb{E}}[ Eve&#39;(H_j)] - {\mathbb{E}}[ Eve&#39;(H_{j+1})]\right|\geq \epsilon \;\;(*)
\]</span></div></span></p>
<p>where <span><span class="math inline">\(\epsilon = \epsilon(n)\)</span></span> is noticeable. By the averaging principle, there exists some fixed choice for <span><span class="math inline">\(k&#39;_1,\ldots,k&#39;_t,k_0,\ldots,k_{j-2},k_j,\ldots,k_t\)</span></span> such that <span><span class="math inline">\((*)\)</span></span> still holds. Note that in this case the only randomness is the choice of <span><span class="math inline">\(k_{j-1}{\leftarrow_{\tiny R}}U_n\)</span></span> and moreover the first <span><span class="math inline">\(j-1\)</span></span> blocks and the last <span><span class="math inline">\(t-j\)</span></span> blocks of <span><span class="math inline">\(H_j\)</span></span> and <span><span class="math inline">\(H_{j+1}\)</span></span> would be identical and we can denote them by <span><span class="math inline">\(\alpha\)</span></span> and <span><span class="math inline">\(\beta\)</span></span> respectively and hence write <span><span class="math inline">\((*)\)</span></span> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\left| {\mathbb{E}}_{k_{j-1}}[ Eve&#39;(\alpha,E&#39;_{k_{j-1}}(k_{j},m_j),\beta) - Eve&#39;(\alpha,E&#39;_{k_{j-1}}(k&#39;_j,m_j),\beta) ] \right| \geq \epsilon \;\;(**)
\]</span></div></span></p>
<p>But now consider the adversary <span><span class="math inline">\(Eve\)</span></span> that is defined as <span><span class="math inline">\(Eve(c) = Eve&#39;(\alpha,c,\beta)\)</span></span>. Then <span><span class="math inline">\(Eve\)</span></span> is also efficient and by <span><span class="math inline">\((**)\)</span></span> it can distinguish between <span><span class="math inline">\(E&#39;_{U_n}(k_j,m_j)\)</span></span> and <span><span class="math inline">\(E&#39;_{U_n}(k&#39;_j,m_j)\)</span></span> thus contradicting the security of <span><span class="math inline">\((E&#39;,D&#39;)\)</span></span>. This concludes the proof of the claim and hence the theorem.</p>
</div>
<h3 id="appendix-the-computational-model" data-number="2.5.1">Appendix: The computational model</h3>
<p>For concreteness sake let us give a precise definition of what it means for a function or probabilistic process <span><span class="math inline">\(f\)</span></span> mapping <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}^m\)</span></span> to be computable using <span><span class="math inline">\(T\)</span></span> operations. This is the model of RAND programs as in my <a href="http://introtcs.org">introduction to TCS lecture notes</a>, also known as the model of (probabilistic) Boolean circuits.</p>
<div id="randprogdef" class="definition" title="Probabilistic straightline program" data-number="2.5.1" name="Definition 2.14 (Probabilistic straightline program) ">
<p>A <em>probabilistic straightline program</em> consists of a sequence of lines, each one of them one of the following forms:</p>
<ul>
<li><code>foo = bar NAND baz</code> where <code>foo</code>,<code>bar</code>,<code>baz</code> are variable identifiers.<br />
</li>
<li><code>foo = RAND</code> where <code>foo</code> is a variable identifier.<br />
</li>
</ul>
<p>Given a program <span><span class="math inline">\(\pi\)</span></span>, we say that its <em>size</em> is the number of lines it contains. Variables beginning with <code>x_</code> and <code>y_</code> are considered input and output variables respectively. We require such variables to have the forms <code>x_</code><span><span class="math inline">\(0\)</span></span>,<span><span class="math inline">\(\ldots\)</span></span>,<code>x_</code><span><span class="math inline">\(n-1\)</span></span> for some <span><span class="math inline">\(n&gt;0\)</span></span> and <code>y_</code><span><span class="math inline">\(0\)</span></span>, <span><span class="math inline">\(\ldots\)</span></span>, <code>y_</code><span><span class="math inline">\(m-1\)</span></span>. The program computes the probabilistic process that maps <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}^m\)</span></span> in the natural way. If <span><span class="math inline">\(F\)</span></span> is a (probabilistic or deterministic) map of <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}^m\)</span></span>, the <em>complexity</em> of <span><span class="math inline">\(F\)</span></span> is the size of the smallest program <span><span class="math inline">\(P\)</span></span> that computes it.</p>
</div>
<p>If you haven’t taken a class such as CS121 before, you might wonder how such a simple model captures complicated programs that use loops, conditionals, and more complex data types than simply a bit in <span><span class="math inline">\(\{0,1\}\)</span></span>, not to mention some special purpose crypto-breaking devices that might involve tailor-made hardware. It turns out that it does (for the same reason we can compile complicated programming languages to run on silicon chips with a very limited instruction set). In fact, as far as we know, this model can capture even computations that happen in nature, whether it’s in a bee colony or the human brain (which contains about <span><span class="math inline">\(10^{10}\)</span></span> neurons, so should in principle be simulatable by a program that has up to a few order of magnitudes of the same number of lines). Crucially, for cryptography, we care about such programs not because we want to actually run them, but because we want to argue about their <em>non existence</em>.<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup> If we have a process that cannot be computed by a straightline program of length shorter than <span><span class="math inline">\(2^{128}&gt;10^{38}\)</span></span> then it seems safe to say that a computer the size of the human brain (or even all the human and nonhuman brains on this planet) will not be able to perform it either.</p>
<blockquote>
<p><strong>Advanced note:</strong> The computational model we use in this class is <em>non uniform</em> (corresponding to Boolean circuits) as opposed to <em>uniform</em> (corresponding to Turing machines). If this distinction doesn’t mean anything to you, you can ignore it as it won’t play a significant role in what we do next. It basically means that we do allow our programs to have hardwired constants of <span><span class="math inline">\(poly(n)\)</span></span> bits where <span><span class="math inline">\(n\)</span></span> is the input/key length. In fact, to be precise, we will hold ourselves to a higher standard than our adversary, in the sense that we require our algorithms to be efficient in the stronger sense of being computable in uniform probabilistic polynomial time (for some fixed polynomial, often <span><span class="math inline">\(O(n)\)</span></span> or <span><span class="math inline">\(O(n^2\)</span></span>)), while the adversary is allowed to use non uniformity.</p>
</blockquote>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>It is important to keep track of what is known and unknown to the adversary Eve. The adversary knows the set <span><span class="math inline">\(\{ m_0,m_1 \}\)</span></span> of potential messages, and the ciphertext <span><span class="math inline">\(y=E_k(m_b)\)</span></span>. The only things she doesn’t know are whether <span><span class="math inline">\(b=0\)</span></span> or <span><span class="math inline">\(b=1\)</span></span>, and the value of the secret key <span><span class="math inline">\(k\)</span></span>. In particular, because <span><span class="math inline">\(m_0\)</span></span> and <span><span class="math inline">\(m_1\)</span></span> are known to Eve, it does not matter whether we define Eve’s goal in this “security game” as outputting <span><span class="math inline">\(m_b\)</span></span> or as outputting <span><span class="math inline">\(b\)</span></span>.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>This is a slight simplification of the typical notion of “<span><span class="math inline">\(t\)</span></span> bits of security”. In the more standard definition we’d say that a scheme has <span><span class="math inline">\(t\)</span></span> bits of security if for every <span><span class="math inline">\(t_1+t_2 \leq t\)</span></span>, an attacker running in <span><span class="math inline">\(2^{t_1}\)</span></span> time can’t get success probability advantage more than <span><span class="math inline">\(2^{-t_2}\)</span></span>. However these two definitions only differ from one another by at most a factor of two. This may be important for practical applications (where the difference between <span><span class="math inline">\(64\)</span></span> and <span><span class="math inline">\(32\)</span></span> bits of security could be crucial) but won’t matter for our concerns.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>Some texts reserve the term <em>exponential</em> to functions of the form <span><span class="math inline">\(2^{\epsilon n}\)</span></span> for some <span><span class="math inline">\(\epsilon &gt; 0\)</span></span> and call a function such as, say, <span><span class="math inline">\(2^{\sqrt{n}}\)</span></span> <em>subexponential</em> . However, we will generally not make this distinction in this course.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>Note that there is a subtle issue here with the order of quantifiers. For a scheme to be efficient, the algorithms such as encryption and decryption need to run in some <em>fixed</em> polynomial time such as <span><span class="math inline">\(n^2\)</span></span> or <span><span class="math inline">\(n^3\)</span></span>. In contrast we allow the adversary to run in <em>any</em> polynomial time. That is, for every <span><span class="math inline">\(c\)</span></span>, if <span><span class="math inline">\(n\)</span></span> is large enough, then the scheme should be secure against an adversary that runs in time <span><span class="math inline">\(n^c\)</span></span>. This is a general principle in cryptography that we always allow the adversary potentially much more resources than those used by the honest users. In practical security we often assume that the gap between the honest use and the adversary resources can be <em>exponential</em>. For example, a low power embedded device can encrypt messages that, as far as we know, are undecipherable even by a nation-state using super-computers and massive data centers.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>As will be the case for other conjectures we talk about, the name “The Cipher Conjecture” is not a standard name, but rather one we’ll use in this course. In the literature this conjecture is mostly referred to as the conjecture of existence of <em>one way functions</em>, a notion we will learn about later. These two conjectures a priori seem quite different but have been shown to be equivalent.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p>This definition implicitly assumes that <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(Y\)</span></span> are actually <em>parameterized</em> by some number <span><span class="math inline">\(n\)</span></span> (that is polynomially related to <span><span class="math inline">\(o\)</span></span>) so for every polynomial <span><span class="math inline">\(T(o)\)</span></span> and inverse polynomial <span><span class="math inline">\(\epsilon(o)\)</span></span> we can take <span><span class="math inline">\(n\)</span></span> to be large enough so that <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(Y\)</span></span> will be <span><span class="math inline">\((T,\epsilon)\)</span></span> indistinguishable. In all the cases we will consider, the choice of the parameter <span><span class="math inline">\(n\)</span></span> (which is usually the length of the key) will be clear from the context.</p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:7"><p>
<div>
<p>Results of this form are known as “triangle inequalities” since they can be viewed as generalizations of the statement that for every three points on the plane <span><span class="math inline">\(x,y,z\)</span></span>, the distance from <span><span class="math inline">\(x\)</span></span> to <span><span class="math inline">\(z\)</span></span> is not larger than the distance from <span><span class="math inline">\(x\)</span></span> to <span><span class="math inline">\(y\)</span></span> plus the distance from <span><span class="math inline">\(y\)</span></span> to <span><span class="math inline">\(z\)</span></span>. In other words, the edge <span><span class="math inline">\(\overline{x,z}\)</span></span> of the triangle <span><span class="math inline">\((x,y,z)\)</span></span> is not longer than the sum of the lengths of the other two edges <span><span class="math inline">\(\overline{x,y}\)</span></span> and <span><span class="math inline">\(\overline{y,z}\)</span></span>.</p>
</div>
<a href="#fnref:7" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:8"><p>
<div>
<p>This is the principle that if the average grade in an exam was at least <span><span class="math inline">\(\alpha\)</span></span> then <em>someone</em> must have gotten at least <span><span class="math inline">\(\alpha\)</span></span>, or in other words that if a real-valued random variable <span><span class="math inline">\(Z\)</span></span> satisfies <span><span class="math inline">\({\mathbb{E}}Z \geq \alpha\)</span></span> then <span><span class="math inline">\(\Pr[Z\geq \alpha]&gt;0\)</span></span>.</p>
</div>
<a href="#fnref:8" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:9"><p>
<div>
<p>The keys <span><span class="math inline">\(k_1,\ldots,k_t\)</span></span> are sometimes known as <em>ephemeral keys</em> in the crypto literature, since they are created only for the purposes of this particular interaction.</p>
</div>
<a href="#fnref:9" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:10"><p>
<div>
<p>The astute reader might note that the key <span><span class="math inline">\(k_t\)</span></span> is actually not used anywhere in the encryption nor decryption and hence we could encrypt <span><span class="math inline">\(n\)</span></span> more bits of the message instead in this final round. We used the current description for the sake of symmetry and simplicity of exposition.</p>
</div>
<a href="#fnref:10" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:11"><p>
<div>
<p>An interesting potential exception to this principle that every natural process should be simulatable by a straightline program of comparable complexity are processes where the quantum mechanical notions of <em>interference</em> and <em>entanglement</em> play a significant role. We will talk about this notion of <em>quantum computing</em> towards the end of the course, though note that much of what we say does not really change when we add quantum into the picture. As discussed in <a href="http://introtcs.org">my lecture notes</a>, we can still capture these processes by straightline programs (that now have somewhat more complex form), and so most of what we’ll do just carries over in the same way to the quantum realm as long as we are fine with conjecturing the strong form of the cipher conjecture, namely that the cipher is infeasible to break even for quantum computers. (All current evidence points toward this strong form being true as well.)</p>
</div>
<a href="#fnref:11" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/crypto/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/crypto/issues?q=Computational security+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 01/07/2020 13:14:04</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/crypto/lec_02_computational-security.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
