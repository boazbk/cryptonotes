<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Restricted computational models</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Restricted computational models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#lecture-summary"><i class="fa fa-check"></i><b>16.1</b> Lecture summary</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.2</b> Exercises</a></li><li class="chapter" data-level="16.3" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.3</b> Bibliographical notes</a></li><li class="chapter" data-level="16.4" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#further-explorations"><i class="fa fa-check"></i><b>16.4</b> Further explorations</a></li><li class="chapter" data-level="16.5" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#acknowledgements"><i class="fa fa-check"></i><b>16.5</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Restricted computational models</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_08a_restricted_models.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="restrictedchap" data-number="9">Restricted computational models</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>See that Turing completeness is not always a good thing</li>
<li>Two important examples of non-Turing-complete, always-halting formalisms: <em>regular expressions</em> and <em>context-free grammars</em>.</li>
<li>The pumping lemmas for both these formalisms, and examples of non regular and non context-free functions.</li>
<li>Examples of computable and uncomputable <em>semantic properties</em> of regular expressions and context-free grammars.</li>
</ul>
</div>
<blockquote>
<p><em>“Happy families are all alike; every unhappy family is unhappy in its own way”</em>, Leo Tolstoy (opening of the book “Anna Karenina”).</p>
</blockquote>
<p>We have seen that many models of computation are <em>Turing equivalent</em>, including Turing machines, NAND-TM/NAND-RAM programs, standard programming languages such as C/Python/Javascript, as well as other models such as the <span><span class="math inline">\(\lambda\)</span></span> calculus and even the game of life. The flip side of this is that for all these models, Rice’s theorem (<a href='lec_08_uncomputability.html#rice-thm'>Theorem 8.16</a>) holds as well, which means that any semantic property of programs in such a model is <em>uncomputable</em>.</p>
<p>The uncomputability of halting and other semantic specification problems for Turing equivalent models motivates <strong>restricted computational models</strong> that are <strong>(a)</strong> powerful enough to capture a set of functions useful for certain applications but <strong>(b)</strong> weak enough that we can still solve semantic specification problems on them. In this chapter we discuss several such examples.</p>
<div id="restrictedmodel" class="bigidea" name="Bigidea 13">
<p>We can use <em>restricted computational models</em> to bypass limitations such as uncomputability of the Halting problem and Rice’s Theorem. Such models can compute only a restricted subclass of functions, but allow to answer at least some <em>semantic questions</em> on programs.</p>
</div>
<figure>
<img src="../figure/restrictedoverview.png" alt="9.1: Some restricted computational models we study in this chapter. We show two equivalent models of computation: regular expressions and deterministic finite automata. We show a more powerful model: context-free grammars. We also present tools to demonstrate that some functions can not be computed in these models." id="restrictedmodelsoverviewfig" /><figcaption>9.1: Some restricted computational models we study in this chapter. We show two equivalent models of computation: regular expressions and deterministic finite automata. We show a more powerful model: context-free grammars. We also present tools to demonstrate that some functions <em>can not</em> be computed in these models.</figcaption>
</figure>
<h2 id="turing-completeness-as-a-bug" data-number="9.1">Turing completeness as a bug</h2>
<p>We have seen that seemingly simple computational models or systems can turn out to be Turing complete. The <a href="https://goo.gl/xRXq7p">following webpage</a> lists several examples of formalisms that “accidentally” turned out to Turing complete, including supposedly limited languages such as the C preprocessor, CSS, (certain variants of) SQL, sendmail configuration, as well as games such as Minecraft, Super Mario, and the card game “Magic: The Gathering”. Turing completeness is not always a good thing, as it means that such formalisms can give rise to arbitrarily complex behavior. For example, the postscript format (a precursor of PDF) is a Turing-complete programming language meant to describe documents for printing. The expressive power of postscript can allow for short descriptions of very complex images, but it also gave rise to some nasty surprises, such as the attacks described in <a href="http://hacking-printers.net/wiki/index.php/PostScript">this page</a> ranging from using infinite loops as a denial of service attack, to accessing the printer’s file system.</p>
<div id="ethereum" class="example" title="The DAO Hack" name="Example 9.1 (The DAO Hack) ">
<p>An interesting recent example of the pitfalls of Turing-completeness arose in the context of the cryptocurrency <a href="https://www.ethereum.org/">Ethereum</a>. The distinguishing feature of this currency is the ability to design “smart contracts” using an expressive (and in particular Turing-complete) programming language. In our current “human operated” economy, Alice and Bob might sign a contract to agree that if condition X happens then they will jointly invest in Charlie’s company. Ethereum allows Alice and Bob to create a joint venture where Alice and Bob pool their funds together into an account that will be governed by some program <span><span class="math inline">\(P\)</span></span> that decides under what conditions it disburses funds from it. For example, one could imagine a piece of code that interacts between Alice, Bob, and some program running on Bob’s car that allows Alice to rent out Bob’s car without any human intervention or overhead.</p>
<p>Specifically Ethereum uses the Turing-complete programming language <a href="https://solidity.readthedocs.io/en/develop/index.html">solidity</a> which has a syntax similar to JavaScript. The flagship of Ethereum was an experiment known as The “Decentralized Autonomous Organization” or <a href="https://goo.gl/NegW77">The DAO</a>. The idea was to create a smart contract that would create an autonomously run decentralized venture capital fund, without human managers, where shareholders could decide on investment opportunities. The DAO was at the time the biggest crowdfunding success in history. At its height the DAO was worth 150 million dollars, which was more than ten percent of the total Ethereum market. Investing in the DAO (or entering any other “smart contract”) amounts to providing your funds to be run by a computer program. i.e., “code is law”, or to use the words the DAO described itself: <em>“The DAO is borne from immutable, unstoppable, and irrefutable computer code”</em>. Unfortunately, it turns out that (as we saw in <a href='lec_08_uncomputability.html#chapcomputable'>Chapter 8</a>) understanding the behavior of computer programs is quite a hard thing to do. A hacker (or perhaps, some would say, a savvy investor) was able to fashion an input that caused the DAO code to enter into an infinite recursive loop in which it continuously transferred funds into the hacker’s account, thereby <a href="https://www.bloomberg.com/features/2017-the-ether-thief/">cleaning out about 60 million dollars</a> out of the DAO. While this transaction was “legal” in the sense that it complied with the code of the smart contract, it was obviously not what the humans who wrote this code had in mind. The Ethereum community struggled with the response to this attack. Some tried to the “Robin Hood” approach of using the same loophole to drain the DAO funds into a secure account, but it only had limited success. Eventually, the Ethereum community decided that the code can be mutable, stoppable, and refutable. Specifically, the Ethereum maintainers and miners agreed on a “hard fork” (also known as a “bailout”) to revert history to before the hacker’s transaction occurred. Some community members strongly opposed this decision, and so an alternative currency called <a href="https://ethereumclassic.github.io/">Ethereum Classic</a> was created that preserved the original history.</p>
</div>
<h2 id="regular-expressions" data-number="9.2">Regular expressions</h2>
<p><em>Searching</em> for a piece of text is a common task in computing. At its heart, the <em>search problem</em> is quite simple. We have a collection <span><span class="math inline">\(X = \{ x_0, \ldots, x_k \}\)</span></span> of strings (e.g., files on a hard-drive, or student records in a database), and the user wants to find out the subset of all the <span><span class="math inline">\(x \in X\)</span></span> that are <em>matched</em> by some pattern (e.g., all files whose names end with the string <code>.txt</code>). In full generality, we can allow the user to specify the pattern by specifying a (computable) <em>function</em> <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>, where <span><span class="math inline">\(F(x)=1\)</span></span> corresponds to the pattern matching <span><span class="math inline">\(x\)</span></span>. That is, the user provides a <em>program</em> <span><span class="math inline">\(P\)</span></span> in some Turing-complete programming language such as <em>Python</em>, and the system will return all the <span><span class="math inline">\(x \in X\)</span></span> such that <span><span class="math inline">\(P(x)=1\)</span></span>. For example, one could search for all text files that contain the string <code>important document</code> or perhaps (letting <span><span class="math inline">\(P\)</span></span> correspond to a neural-network based classifier) all images that contain a cat. However, we don’t want our system to get into an infinite loop just trying to evaluate the program <span><span class="math inline">\(P\)</span></span>!</p>
<p>Because the Halting problem for Turing-complete computational models is uncomputable, we cannot in general verify that a given program <span><span class="math inline">\(P\)</span></span> will halt on a given input. For this reason, typical systems for searching files or databases do <em>not</em> allow users to specify the patterns using full-fledged programming languages. Rather, such systems use <em>restricted computational models</em> that on the one hand are <em>rich enough</em> to capture many of the queries needed in practice (e.g., all filenames ending with <code>.txt</code>, or all phone numbers of the form <code>(617) xxx-xxxx</code>), but on the other hand are <em>restricted</em> enough so that they cannot result in an infinite loop.</p>
<p>One of the most popular such computational models is <a href="https://goo.gl/2vTAFU">regular expressions</a>. If you ever used an advanced text editor, a command line shell, or have done any kind of manipulation of text files, then you have probably come across regular expressions.</p>
<p>A <em>regular expression</em> over some alphabet <span><span class="math inline">\(\Sigma\)</span></span> is obtained by combining elements of <span><span class="math inline">\(\Sigma\)</span></span> with the operation of concatenation, as well as <span><span class="math inline">\(|\)</span></span> (corresponding to <em>or</em>) and <span><span class="math inline">\(*\)</span></span> (corresponding to repetition zero or more times). (Common implementations of regular expressions in programming languages and shells typically include some extra operations on top of <span><span class="math inline">\(|\)</span></span> and <span><span class="math inline">\(*\)</span></span>, but these operations can be implemented as “syntactic sugar” using the operators <span><span class="math inline">\(|\)</span></span> and <span><span class="math inline">\(*\)</span></span>.) For example, the following regular expression over the alphabet <span><span class="math inline">\(\{0,1\}\)</span></span> corresponds to the set of all strings <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> where every digit is repeated at least twice: <span>
<div class='myequationbox'><span class="math display">\[
(00(0^*)|11(1^*))^* \;.
\]</span></div></span></p>
<p>The following regular expression over the alphabet <span><span class="math inline">\(\{ a,\ldots,z,0,\ldots,9 \}\)</span></span> corresponds to the set of all strings that consist of a sequence of one or more of the letters <span><span class="math inline">\(a\)</span></span>-<span><span class="math inline">\(d\)</span></span> followed by a sequence of one or more digits (without a leading zero):</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
(a|b|c|d)(a|b|c|d)^*(1|2|3|4|5|6|7|8|9)(0|1|2|3|4|5|6|7|8|9)^* \;. \;\;(9.2)
\]</span><a id='regexpeq'></a></div></span></p>
<p>Formally, regular expressions are defined by the following recursive definition:</p>
<div id="regexp" class="definition" title="Regular expression" name="Definition 9.2 (Regular expression) ">
<p>A <em>regular expression</em> <span><span class="math inline">\(e\)</span></span> over an alphabet <span><span class="math inline">\(\Sigma\)</span></span> is a string over <span><span class="math inline">\(\Sigma \cup \{ (,),|,*,\emptyset, \ensuremath{\text{\texttt{&quot;&quot;}}} \}\)</span></span> that has one of the following forms:</p>
<ol type="1">
<li><p><span><span class="math inline">\(e = \sigma\)</span></span> where <span><span class="math inline">\(\sigma \in \Sigma\)</span></span></p></li>
<li><p><span><span class="math inline">\(e = (e&#39; | e&#39;&#39;)\)</span></span> where <span><span class="math inline">\(e&#39;, e&#39;&#39;\)</span></span> are regular expressions.</p></li>
<li><p><span><span class="math inline">\(e = (e&#39;)(e&#39;&#39;)\)</span></span> where <span><span class="math inline">\(e&#39;,e&#39;&#39;\)</span></span> are regular expressions. (We often drop the parentheses when there is no danger of confusion and so write this as <span><span class="math inline">\(e&#39; \; e&#39;&#39;\)</span></span>.)</p></li>
<li><p><span><span class="math inline">\(e = (e&#39;)^*\)</span></span> where <span><span class="math inline">\(e&#39;\)</span></span> is a regular expression.</p></li>
</ol>
<p>Finally we also allow the following “edge cases”: <span><span class="math inline">\(e = \emptyset\)</span></span> and <span><span class="math inline">\(e = \ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span>. These are the regular expressions corresponding to accepting no strings, and accepting only the empty string respectively.</p>
</div>
<p>We will drop parenthesis when they can be inferred from the context. We also use the convention that OR and concatenation are left-associative, and give higher precedence to <span><span class="math inline">\(*\)</span></span>, then concatenation, and then OR. Thus for example we write <span><span class="math inline">\(00^*|11\)</span></span> instead of <span><span class="math inline">\(((0)(0^*))|((1)(1))\)</span></span>.</p>
<p>Every regular expression <span><span class="math inline">\(e\)</span></span> corresponds to a function <span><span class="math inline">\(\Phi_{e}:\Sigma^* \rightarrow \{0,1\}\)</span></span> where <span><span class="math inline">\(\Phi_{e}(x)=1\)</span></span> if <span><span class="math inline">\(x\)</span></span> <em>matches</em> the regular expression. For example, if <span><span class="math inline">\(e = (00|11)^*\)</span></span> then <span><span class="math inline">\(\Phi_e(110011)=1\)</span></span> but <span><span class="math inline">\(\Phi_e(101)=0\)</span></span> (can you see why?).</p>
<div class="pause" name="Pause 9.2">
<p>The formal definition of <span><span class="math inline">\(\Phi_{e}\)</span></span> is one of those definitions that is more cumbersome to write than to grasp. Thus it might be easier for you to first work it out on your own and then check that your definition matches what is written below.</p>
</div>
<div id="matchingregexpdef" class="definition" title="Matching a regular expression" name="Definition 9.3 (Matching a regular expression) ">
<p>Let <span><span class="math inline">\(e\)</span></span> be a regular expression over the alphabet <span><span class="math inline">\(\Sigma\)</span></span>. The function <span><span class="math inline">\(\Phi_{e}:\Sigma^* \rightarrow \{0,1\}\)</span></span> is defined as follows:</p>
<ol type="1">
<li><p>If <span><span class="math inline">\(e = \sigma\)</span></span> then <span><span class="math inline">\(\Phi_{e}(x)=1\)</span></span> iff <span><span class="math inline">\(x=\sigma\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(e = (e&#39; | e&#39;&#39;)\)</span></span> then <span><span class="math inline">\(\Phi_{e}(x) = \Phi_{e&#39;}(x) \vee \Phi_{e&#39;&#39;}(x)\)</span></span> where <span><span class="math inline">\(\vee\)</span></span> is the OR operator.</p></li>
<li><p>If <span><span class="math inline">\(e = (e&#39;)(e&#39;&#39;)\)</span></span> then <span><span class="math inline">\(\Phi_{e}(x) = 1\)</span></span> iff there is some <span><span class="math inline">\(x&#39;,x&#39;&#39; \in \Sigma^*\)</span></span> such that <span><span class="math inline">\(x\)</span></span> is the concatenation of <span><span class="math inline">\(x&#39;\)</span></span> and <span><span class="math inline">\(x&#39;&#39;\)</span></span> and <span><span class="math inline">\(\Phi_{e&#39;}(x&#39;)=\Phi_{e&#39;&#39;}(x&#39;&#39;)=1\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(e= (e&#39;)*\)</span></span> then <span><span class="math inline">\(\Phi_{e}(x)=1\)</span></span> iff there are is <span><span class="math inline">\(k\in \N\)</span></span> and some <span><span class="math inline">\(x_0,\ldots,x_{k-1} \in \Sigma^*\)</span></span> such that <span><span class="math inline">\(x\)</span></span> is the concatenation <span><span class="math inline">\(x_0 \cdots x_{k-1}\)</span></span> and <span><span class="math inline">\(\Phi_{e&#39;}(x_i)=1\)</span></span> for every <span><span class="math inline">\(i\in [k]\)</span></span>.</p></li>
<li><p>Finally, for the edge cases <span><span class="math inline">\(\Phi_{\emptyset}\)</span></span> is the constant zero function, and <span><span class="math inline">\(\Phi_{\ensuremath{\text{\texttt{&quot;&quot;}}}}\)</span></span> is the function that only outputs <span><span class="math inline">\(1\)</span></span> on the empty string <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span>.</p></li>
</ol>
<p>We say that a regular expression <span><span class="math inline">\(e\)</span></span> over <span><span class="math inline">\(\Sigma\)</span></span> <em>matches</em> a string <span><span class="math inline">\(x \in \Sigma^*\)</span></span> if <span><span class="math inline">\(\Phi_{e}(x)=1\)</span></span>. We say that a function <span><span class="math inline">\(F:\Sigma^* \rightarrow \{0,1\}\)</span></span> is <em>regular</em> if <span><span class="math inline">\(F=\Phi_{e}\)</span></span> for some regular expression <span><span class="math inline">\(e\)</span></span>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
</div>
<div id="section-1" class="pause" name="Pause">
<p>The definitions above are not inherently difficult, but are a bit cumbersome. So you should pause here and go over it again until you understand why it corresponds to our intuitive notion of regular expressions. This is important not just for understanding regular expressions themselves (which are used time and again in a great many applications) but also for getting better at understanding recursive definitions in general.</p>
</div>
<div id="regularexpmatching" class="example" title="A regular function" name="Example 9.4 (A regular function) ">
<p>Let <span><span class="math inline">\(\Sigma=\{ a,b,c,d,0,1,2,3,4,5,6,7,8,9 \}\)</span></span> and <span><span class="math inline">\(F:\Sigma^* \rightarrow \{0,1\}\)</span></span> be the function such that <span><span class="math inline">\(F(x)\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> iff <span><span class="math inline">\(x\)</span></span> consists of one or more of the letters <span><span class="math inline">\(a\)</span></span>-<span><span class="math inline">\(d\)</span></span> followed by a sequence of one or more digits (without a leading zero). Then <span><span class="math inline">\(F\)</span></span> is a regular function, since <span><span class="math inline">\(F=\Phi_e\)</span></span> where <span>
<div class='myequationbox'><span class="math display">\[e = (a|b|c|d)(a|b|c|d)^*(0|1|2|3|4|5|6|7|8|9)(0|1|2|3|4|5|6|7|8|9)^*\]</span></div></span> is the expression we saw in <a href='#regexpeq'>Equation 9.2</a>.</p>
<p>If we wanted to verify, for example, that <span><span class="math inline">\(\Phi_e(abc12078)=1\)</span></span>, we can do so by noticing that the expression <span><span class="math inline">\((a|b|c|d)\)</span></span> matches the string <span><span class="math inline">\(a\)</span></span>, <span><span class="math inline">\((a|b|c|d)^*\)</span></span> matches <span><span class="math inline">\(bc\)</span></span>, <span><span class="math inline">\((0|1|2|3|4|5|6|7|8|9)\)</span></span> matches the string <span><span class="math inline">\(1\)</span></span>, and the expression <span><span class="math inline">\((0|1|2|3|4|5|6|7|8|9)^*\)</span></span> matches the string <span><span class="math inline">\(2078\)</span></span>. Each one of those boils down to a simpler expression. For example, the expression <span><span class="math inline">\((a|b|c|d)^*\)</span></span> matches the string <span><span class="math inline">\(bc\)</span></span> because both of the one-character strings <span><span class="math inline">\(b\)</span></span> and <span><span class="math inline">\(c\)</span></span> are matched by the expression <span><span class="math inline">\(a|b|c|d\)</span></span>.</p>
</div>
<p>Regular expression can be defined over any finite alphabet <span><span class="math inline">\(\Sigma\)</span></span>, but as usual, we will focus our attention on the <em>binary case</em>, where <span><span class="math inline">\(\Sigma = \{0,1\}\)</span></span>. Most (if not all) of the theoretical and practical general insights about regular expressions can be gleaned from studying the binary case.</p>
<p>We can think of regular expressions as a type of “programming language”. That is, we can think of a regular expression <span><span class="math inline">\(e\)</span></span> over the alphabet <span><span class="math inline">\(\Sigma\)</span></span> as a program that computes the function <span><span class="math inline">\(\Phi_{e}:\Sigma^* \rightarrow \{0,1\}\)</span></span>. (You can also think of regular expressions as <em>generative models</em>, since you can think of them as giving a recipe how to generate strings that match them.) This “regular expression programming language” is simpler than general programming languages, in the sense that for every regular expression <span><span class="math inline">\(e\)</span></span>, the function <span><span class="math inline">\(\Phi_e\)</span></span> is computable (and so in particular can be evaluated by an always-halting Turing machine).</p>
<div id="regularexphalt" class="theorem" title="Regular expression always halt" name="Theorem 9.5 (Regular expression always halt) ">
<p>For every regular expression <span><span class="math inline">\(e\)</span></span> over <span><span class="math inline">\(\{0,1\}\)</span></span>, the function <span><span class="math inline">\(\Phi_e:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is computable.</p>
<p>That is, there is a Turing machine <span><span class="math inline">\(M\)</span></span> such that for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, on input <span><span class="math inline">\(x\)</span></span>, <span><span class="math inline">\(M\)</span></span> halts with the output <span><span class="math inline">\(\Phi_e(x)\)</span></span>.</p>
</div>
<p>We state <a href='#regularexphalt'>Theorem 9.5</a> for regular expressions over the binary alphabet <span><span class="math inline">\(\{0,1\}\)</span></span>, but it generalizes to any finite alphabet <span><span class="math inline">\(\Sigma\)</span></span>.</p>
<div id="section-2" class="proofidea" data-ref="regularexphalt" name="Proofidea">
<p>The proof relies on the observation that <a href='#matchingregexpdef'>Definition 9.3</a> actually specifies a recursive algorithm for <em>computing</em> <span><span class="math inline">\(\Phi_{e}\)</span></span>. Specifically, each one of our operations -concatenation, OR, and star- can be thought of as reducing the task of testing whether an expression <span><span class="math inline">\(e\)</span></span> matches a string <span><span class="math inline">\(x\)</span></span> to testing whether some sub-expressions of <span><span class="math inline">\(e\)</span></span> match substrings of <span><span class="math inline">\(x\)</span></span>. Since these sub-expressions are always shorter than the original expression, this yields a recursive algorithm for checking if <span><span class="math inline">\(e\)</span></span> matches <span><span class="math inline">\(x\)</span></span> which will eventually terminate at the base cases of the expressions that correspond to a single symbol or the empty string.</p>
</div>
<div class="proof" data-ref="regularexphalt" name="Proof">
<p><a href='#matchingregexpdef'>Definition 9.3</a> gives a way of recursively computing <span><span class="math inline">\(\Phi_{e}\)</span></span>. The key observation is that in our recursive definition of regular expressions, whenever <span><span class="math inline">\(e\)</span></span> is made up of one or two expressions <span><span class="math inline">\(e&#39;,e&#39;&#39;\)</span></span> then these two regular expressions are <em>smaller</em> than <span><span class="math inline">\(e\)</span></span>, and eventually (when they have size <span><span class="math inline">\(1\)</span></span>) then they must correspond to the non-recursive case of a single alphabet symbol.</p>
<p>Therefore, we can prove the theorem by induction over the length <span><span class="math inline">\(m\)</span></span> of <span><span class="math inline">\(e\)</span></span> (i.e., the number of symbols in the string <span><span class="math inline">\(e\)</span></span>, also denoted as <span><span class="math inline">\(|e|\)</span></span>). For <span><span class="math inline">\(m=1\)</span></span>, <span><span class="math inline">\(e\)</span></span> is either a single alphabet symbol, <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> or <span><span class="math inline">\(\emptyset\)</span></span>, and so computing the function <span><span class="math inline">\(\Phi_{e}\)</span></span> is straightforward. In the general case, for <span><span class="math inline">\(m=|e|\)</span></span> we assume by the induction hypothesis that we have proven the theorem for all expressions of length smaller than <span><span class="math inline">\(m\)</span></span>. Now, such an expression of length larger than one can obtained through one of three cases: OR, concatenation, or star operations. We now show that <span><span class="math inline">\(\Phi_{e}\)</span></span> will be computable in all these cases:</p>
<p><strong>Case 1:</strong> <span><span class="math inline">\(e = (e&#39; | e&#39;&#39;)\)</span></span> where <span><span class="math inline">\(e&#39;, e&#39;&#39;\)</span></span> are shorter regular expressions.</p>
<p>In this case by the inductive hypothesis we can compute <span><span class="math inline">\(\Phi_{e&#39;}\)</span></span> and <span><span class="math inline">\(\Phi_{e&#39;&#39;}\)</span></span> and so can compute <span><span class="math inline">\(\Phi_{e}(x)\)</span></span> as <span><span class="math inline">\(\Phi_{e&#39;}(x) \vee \Phi_{e&#39;&#39;}(x)\)</span></span> (where <span><span class="math inline">\(\vee\)</span></span> is the OR operator).</p>
<p><strong>Case 2:</strong> <span><span class="math inline">\(e = (e&#39;)(e&#39;&#39;)\)</span></span> where <span><span class="math inline">\(e&#39;,e&#39;&#39;\)</span></span> are regular expressions.</p>
<p>In this case by the inductive hypothesis we can compute <span><span class="math inline">\(\Phi_{e&#39;}\)</span></span> and <span><span class="math inline">\(\Phi_{e&#39;&#39;}\)</span></span> and so can compute <span><span class="math inline">\(\Phi_{e}(x)\)</span></span> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\bigvee_{i=0}^{|x|-1}(\Phi_{e&#39;}(x_0\cdots x_{i-1})  \wedge \Phi_{e&#39;&#39;}(x_i \cdots x_{|x|-1}))\]</span></div></span></p>
<p>where <span><span class="math inline">\(\wedge\)</span></span> is the AND operator and for <span><span class="math inline">\(i&lt;j\)</span></span>, <span><span class="math inline">\(x_j \cdots x_{i}\)</span></span> refers to the empty string.</p>
<p><strong>Case 3:</strong> <span><span class="math inline">\(e = (e&#39;)*\)</span></span> where <span><span class="math inline">\(e&#39;\)</span></span> is a regular expression.</p>
<p>In this case by the inductive hypothesis we can compute <span><span class="math inline">\(\Phi_{e&#39;}\)</span></span> and so we can compute <span><span class="math inline">\(\Phi_{e}(x)\)</span></span> by enumerating over all <span><span class="math inline">\(k\)</span></span> from <span><span class="math inline">\(1\)</span></span> to <span><span class="math inline">\(|x|\)</span></span>, and all ways to write <span><span class="math inline">\(x\)</span></span> as the concatenation of <span><span class="math inline">\(k\)</span></span> nonempty strings <span><span class="math inline">\(x_0 \cdots x_{k-1}\)</span></span> (we can do so by enumerating over all possible <span><span class="math inline">\(k-1\)</span></span> positions in which one string stops and the other begins). If for one of those partitions, <span><span class="math inline">\(\Phi_{e&#39;}(x_0)=\cdots = \Phi_{e&#39;}(x_{k-1})=1\)</span></span> then we output <span><span class="math inline">\(1\)</span></span>. Otherwise we output <span><span class="math inline">\(0\)</span></span>. We can restrict attention to partitions of <span><span class="math inline">\(x\)</span></span> as <span><span class="math inline">\(x=x_0 \cdots x_{k-1}\)</span></span> where all the <span><span class="math inline">\(x_i\)</span></span>’s are nonempty since if some of the <span><span class="math inline">\(x_i\)</span></span>’s are empty we can simply drop them and still be left with a valid partition.</p>
<p>These three cases exhaust all the possibilities for an expression of length larger than one, and hence this completes the proof.</p>
</div>
<h2 id="deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional" data-number="9.3">Deterministic finite automata, and efficient matching of regular expressions (optional)</h2>
<p>The proof of <a href='#regularexphalt'>Theorem 9.5</a> gives a recursive algorithm to evaluate whether a given string matches or not a regular expression. But it is not a very efficient algorithm.</p>
<p>However, it turns out that there is a much more efficient algorithm that can match regular expressions in <em>linear</em> (i.e., <span><span class="math inline">\(O(n)\)</span></span>) time. Since we have not yet covered the topics of time and space complexity, we describe this algorithm in high level terms, without making the computational model precise, using the colloquial notion of <span><span class="math inline">\(O(n)\)</span></span> running time as is used in introduction to programming courses and whiteboard coding interviews. We will see a formal definition of time complexity in <a href='lec_11_running_time.html#chapmodelruntime'>Chapter 12</a>.</p>
<div id="reglintimethm" class="theorem" title="Matching regular expressions in linear time" name="Theorem 9.6 (Matching regular expressions in linear time) ">
<p>Let <span><span class="math inline">\(e\)</span></span> be a regular expression. Then there is an <span><span class="math inline">\(O(n)\)</span></span> time algorithm that computes <span><span class="math inline">\(\Phi_{e}\)</span></span>.</p>
</div>
<p>The implicit constant in the <span><span class="math inline">\(O(n)\)</span></span> term of <a href='#reglintimethm'>Theorem 9.6</a> depends on the expression <span><span class="math inline">\(e\)</span></span>. Thus, another way to state <a href='#reglintimethm'>Theorem 9.6</a> is that for every expression <span><span class="math inline">\(e\)</span></span>, there is some constant <span><span class="math inline">\(c\)</span></span> and an algorithm <span><span class="math inline">\(A\)</span></span> that computes <span><span class="math inline">\(\Phi_e\)</span></span> on <span><span class="math inline">\(n\)</span></span>-bit inputs using at most <span><span class="math inline">\(c\cdot n\)</span></span> steps. This makes sense, since in practice we often want to compute <span><span class="math inline">\(\Phi_e(x)\)</span></span> for a small regular expression <span><span class="math inline">\(e\)</span></span> and a large document <span><span class="math inline">\(x\)</span></span>. <a href='#reglintimethm'>Theorem 9.6</a> tells us that we can do so with running time that scales linearly with the size of the document, even if it has (potentially) worse dependence on the size of the regular expression.</p>
<div class="proofidea" data-ref="reglintimethm" name="Proofidea 9.3">
<p>The idea is to define a more efficient recursive algorithm, that determines whether <span><span class="math inline">\(e\)</span></span> matches a string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> by reducing this task to determining whether a related expression <span><span class="math inline">\(e&#39;\)</span></span> matches <span><span class="math inline">\(x_0,\ldots,x_{n-1}\)</span></span>. This will result in an expression for the running time of the form <span><span class="math inline">\(T(n) = T(n-1) + O(1)\)</span></span> which solves to <span><span class="math inline">\(T(n)=O(n)\)</span></span>.</p>
</div>
<div class="proof" data-ref="reglintimethm" name="Proof 9.3">
<p>The central definition for this proof is the notion of a <em>restriction</em> of a regular expression. The idea is that for every regular expression <span><span class="math inline">\(e\)</span></span> and symbol <span><span class="math inline">\(\sigma\)</span></span> in its alphabet, it is possible to define a regular expression <span><span class="math inline">\(e[\sigma]\)</span></span> such that <span><span class="math inline">\(e[\sigma]\)</span></span> matches a string <span><span class="math inline">\(x\)</span></span> if and only if <span><span class="math inline">\(e\)</span></span> matches the string <span><span class="math inline">\(x\sigma\)</span></span>. For example, if <span><span class="math inline">\(e\)</span></span> is the regular expression <span><span class="math inline">\(01|(01)*(01)\)</span></span> (i.e., one or more occurrences of <span><span class="math inline">\(01\)</span></span>) then <span><span class="math inline">\(e[1]\)</span></span> is equal to <span><span class="math inline">\(0|(01)*0\)</span></span> and <span><span class="math inline">\(e[0]\)</span></span> will be <span><span class="math inline">\(\emptyset\)</span></span>. (Can you see why?)</p>
<p>For simplicity, from now on we fix our attention to the case that the alphabet <span><span class="math inline">\(\Sigma\)</span></span> is <span><span class="math inline">\(\{0,1\}\)</span></span>. Given a regular expression <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(\sigma\in \{0,1\}\)</span></span>, we can compute <span><span class="math inline">\(e[\sigma]\)</span></span> recursively as follows:</p>
<ol type="1">
<li><p>If <span><span class="math inline">\(e\)</span></span> consists of a single symbol (i.e. <span><span class="math inline">\(e=\tau\)</span></span> for <span><span class="math inline">\(\tau \in \{0,1\}\)</span></span>) then <span><span class="math inline">\(e[\sigma]=\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> if <span><span class="math inline">\(\tau=\sigma\)</span></span> and <span><span class="math inline">\(e[\sigma]=\emptyset\)</span></span> otherwise.</p></li>
<li><p>If <span><span class="math inline">\(e = e&#39; | e&#39;&#39;\)</span></span> then <span><span class="math inline">\(e[\sigma] = e&#39;[\sigma] | e&#39;&#39;[\sigma]\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(e = e&#39; \; e&#39;&#39;\)</span></span> then <span><span class="math inline">\(e[\sigma] = e&#39; \; e&#39;&#39;[\sigma]\)</span></span> if <span><span class="math inline">\(e&#39;&#39;\)</span></span> can not match the empty string. Otherwise, <span><span class="math inline">\(e[\sigma] = e&#39; \; e&#39;&#39;[\sigma] \; | \; e&#39;[\sigma]\)</span></span></p></li>
<li><p>If <span><span class="math inline">\(e = (e&#39;)^*\)</span></span> then <span><span class="math inline">\(e[\sigma] = (e&#39;)^*(e&#39;[\sigma])\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(e = \ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> or <span><span class="math inline">\(e= \emptyset\)</span></span> then <span><span class="math inline">\(e[\sigma] = \emptyset\)</span></span>.</p></li>
</ol>
<p>By checking all these cases, one can verify that it is indeed the case that for every regular expression <span><span class="math inline">\(e\)</span></span>, <span><span class="math inline">\(\sigma \in \{0,1\}\)</span></span> and <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(e[\sigma]\)</span></span> matches <span><span class="math inline">\(x\)</span></span> if and only if <span><span class="math inline">\(e\)</span></span> matches <span><span class="math inline">\(x\sigma\)</span></span>. We let <span><span class="math inline">\(C(\ell)\)</span></span> denote the time to compute <span><span class="math inline">\(e[\sigma]\)</span></span> for regular expressions of length at most <span><span class="math inline">\(\ell\)</span></span>. The value <span><span class="math inline">\(C(\ell)\)</span></span> can be shown to be polynomial in <span><span class="math inline">\(\ell\)</span></span>, though this is not important for this theorem, since we only care about the dependence of the time to compute <span><span class="math inline">\(\Phi_e(x)\)</span></span> on the length of <span><span class="math inline">\(x\)</span></span> and not about the dependence of this time on the length of <span><span class="math inline">\(e\)</span></span>.</p>
<p>Using this notion of restriction, we can define the following recursive algorithm for regular expression matching:</p>
<div id="regexpmatchlinearalg" class="algorithm" title="Regular expression matching in linear time" name="Algorithm 9.7 (Regular expression matching in linear time) ">
<p><strong>Input:</strong> Regular expression <span><span class="math inline">\(e\)</span></span> over <span><span class="math inline">\(\{0,1\}\)</span></span> and <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> for <span><span class="math inline">\(n\in \N\)</span></span>.</p>
<p><strong>Goal:</strong> Compute <span><span class="math inline">\(\Phi_e(x)\)</span></span></p>
<p><strong>Operation:</strong></p>
<ol type="1">
<li><p>If <span><span class="math inline">\(x=\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> then return <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(\Phi_e(\ensuremath{\text{\texttt{&quot;&quot;}}})=1\)</span></span>. (This can be either computed directly or using the algorithm of <a href='#regularexphalt'>Theorem 9.5</a> in time which is a constant depending only on the regular expression <span><span class="math inline">\(e\)</span></span>.)</p></li>
<li><p>Otherwise, compute <span><span class="math inline">\(\Phi_{e[x_{n-1}]}(x_0\cdots x_{n-1})\)</span></span> recursively and output the result.</p></li>
</ol>
</div>
<p>By the definition of a restriction, for every <span><span class="math inline">\(\sigma\in \{0,1\}\)</span></span> and <span><span class="math inline">\(x&#39;\in \{0,1\}^*\)</span></span>, the expression <span><span class="math inline">\(e\)</span></span> matches <span><span class="math inline">\(x&#39;\sigma\)</span></span> if and only if <span><span class="math inline">\(e[\sigma]\)</span></span> matches <span><span class="math inline">\(x&#39;\)</span></span>. Hence for every <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, <span><span class="math inline">\(\Phi_{e[x_{n-1}]}(x_0\cdots x_{n-2}) = \Phi_e(x)\)</span></span> and <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> does return the correct answer. The only remaining task is to analyze its <em>running time</em>.</p>
<p><a href='#regexpmatchlinearalg'>Algorithm 9.7</a> is a recursive algorithm that on input an expression <span><span class="math inline">\(e\)</span></span> and a string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, does some constant time computation and then calls itself on input some expression <span><span class="math inline">\(e&#39;\)</span></span> and a string <span><span class="math inline">\(x\)</span></span> of length <span><span class="math inline">\(n-1\)</span></span>. It will terminate after <span><span class="math inline">\(n\)</span></span> steps when it reaches a string of length <span><span class="math inline">\(0\)</span></span>. So, to calculate the running time of <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> we need to analyze the cost of each step.</p>
<p>Specifically, the running time <span><span class="math inline">\(T(e,n)\)</span></span> that it takes for <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> to compute <span><span class="math inline">\(\Phi_e\)</span></span> for inputs of length <span><span class="math inline">\(n\)</span></span> satisfies the recursive equation:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[T(e,n) = \max \{ T(e[0],n-1) , T(e[1],n-1)  \} + C(|e|)
\;\;(9.5) \]</span><a id='matchregexprecursion'></a></div></span></p>
<p>where <span><span class="math inline">\(C(\ell)\)</span></span>, as before, denotes the time to compute <span><span class="math inline">\(e[\sigma]\)</span></span> for expressions <span><span class="math inline">\(e\)</span></span> of length at most <span><span class="math inline">\(\ell\)</span></span>. (In the base case <span><span class="math inline">\(n=0\)</span></span>, <span><span class="math inline">\(T(e,0)\)</span></span> is equal to some constant depending only on <span><span class="math inline">\(e\)</span></span>.)</p>
<p>To get some intuition for the expression <a href='#matchregexprecursion'>Equation 9.5</a>, let us open up the recursion for one level, writing <span><span class="math inline">\(T(e,n)\)</span></span> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\begin{aligned}T(e,n) &amp;= \max \{ T(e[0][0],n-2) + C(|e[0]|), \\ &amp;T(e[0][1],n-2) + C(|e[0]|), \\
&amp;T(e[1][0],n-2) + C(|e[1]|),  \\
&amp;T(e[1][1],n-2) + C(|e[1]|) \} + C(|e|)\;.\end{aligned}\]</span></div></span></p>
<p>Continuing this way, we can see that <span><span class="math inline">\(T(e,n) \leq n \cdot C(\ell) + O(1)\)</span></span> where <span><span class="math inline">\(\ell\)</span></span> is the largest length of any expression <span><span class="math inline">\(e&#39;\)</span></span> that we encounter along the way. Therefore, the following claim suffices to show that <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> runs in linear time:</p>
<p><strong>Claim:</strong> Let <span><span class="math inline">\(e\)</span></span> be a regular expression over <span><span class="math inline">\(\{0,1\}\)</span></span>, then there is some constant <span><span class="math inline">\(c\)</span></span> such that for every string <span><span class="math inline">\(\alpha\in \{0,1\}^*\)</span></span>, if we restrict <span><span class="math inline">\(e\)</span></span> to <span><span class="math inline">\(\alpha_0\)</span></span>, and then to <span><span class="math inline">\(\alpha_1\)</span></span> and so on and so forth, the resulting expression has length at most <span><span class="math inline">\(c\)</span></span>.</p>
<blockquote>
<div class="quote" name="Quote 9.3">
<p><strong>Proof of claim:</strong> For a regular expression <span><span class="math inline">\(e\)</span></span> over <span><span class="math inline">\(\{0,1\}\)</span></span> and <span><span class="math inline">\(\alpha\in \{0,1\}^m\)</span></span>, we denote by <span><span class="math inline">\(e[\alpha]\)</span></span> the expression <span><span class="math inline">\(e[\alpha_0][\alpha_1]\cdots [\alpha_{m-1}]\)</span></span> obtained by restricting <span><span class="math inline">\(e\)</span></span> to <span><span class="math inline">\(\alpha_0\)</span></span> and then to <span><span class="math inline">\(\alpha_1\)</span></span> and so on. We let <span><span class="math inline">\(S(e) = \{ e[\alpha] | \alpha \in \{0,1\}^* \}\)</span></span>. We will prove the claim by showing that for every <span><span class="math inline">\(e\)</span></span>, the set <span><span class="math inline">\(S(e)\)</span></span> is finite, and hence so is the number <span><span class="math inline">\(c(e)\)</span></span> which is the maximum length of <span><span class="math inline">\(e&#39;\)</span></span> for <span><span class="math inline">\(e&#39;\in S(e)\)</span></span>.</p>
<p>We prove this by induction on the structure of <span><span class="math inline">\(e\)</span></span>. If <span><span class="math inline">\(e\)</span></span> is a symbol, the empty string, or the empty set, then this is straightforward to show as the most expressions <span><span class="math inline">\(S(e)\)</span></span> can contain are the expression itself, <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span>, and <span><span class="math inline">\(\emptyset\)</span></span>. Otherwise we split to the two cases <strong>(i)</strong> <span><span class="math inline">\(e = e&#39;^*\)</span></span> and <strong>(ii)</strong> <span><span class="math inline">\(e = e&#39;e&#39;&#39;\)</span></span>, where <span><span class="math inline">\(e&#39;,e&#39;&#39;\)</span></span> are smaller expressions (and hence by the induction hypothesis <span><span class="math inline">\(S(e&#39;)\)</span></span> and <span><span class="math inline">\(S(e&#39;&#39;)\)</span></span> are finite). In the case <strong>(i)</strong>, if <span><span class="math inline">\(e = (e&#39;)^*\)</span></span> then <span><span class="math inline">\(e[\alpha]\)</span></span> is either equal to <span><span class="math inline">\((e&#39;)^* e&#39;[\alpha]\)</span></span> or it is simply the empty set if <span><span class="math inline">\(e&#39;[\alpha]=\emptyset\)</span></span>. Since <span><span class="math inline">\(e&#39;[\alpha]\)</span></span> is in the set <span><span class="math inline">\(S(e&#39;)\)</span></span>, the number of distinct expressions in <span><span class="math inline">\(S(e)\)</span></span> is at most <span><span class="math inline">\(|S(e&#39;)|+1\)</span></span>. In the case <strong>(ii)</strong>, if <span><span class="math inline">\(e = e&#39; e&#39;&#39;\)</span></span> then all the restrictions of <span><span class="math inline">\(e\)</span></span> to strings <span><span class="math inline">\(\alpha\)</span></span> will either have the form <span><span class="math inline">\(e&#39; e&#39;&#39;[\alpha]\)</span></span> or the form <span><span class="math inline">\(e&#39; e&#39;&#39;[\alpha] | e&#39;[\alpha&#39;]\)</span></span> where <span><span class="math inline">\(\alpha&#39;\)</span></span> is some string such that <span><span class="math inline">\(\alpha = \alpha&#39; \alpha&#39;&#39;\)</span></span> and <span><span class="math inline">\(e[\alpha&#39;&#39;]\)</span></span> matches the empty string. Since <span><span class="math inline">\(e&#39;&#39;[\alpha] \in S(e&#39;&#39;)\)</span></span> and <span><span class="math inline">\(e&#39;[\alpha&#39;] \in S(e&#39;)\)</span></span>, the number of the possible distinct expressions of the form <span><span class="math inline">\(e[\alpha]\)</span></span> is at most <span><span class="math inline">\(|S(e&#39;&#39;)| + |S(e&#39;&#39;)|\cdot |S(e&#39;)|\)</span></span>. This completes the proof of the claim.</p>
</div>
</blockquote>
<p>The bottom line is that while running <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> on a regular expression <span><span class="math inline">\(e\)</span></span>, all the expressions we ever encounter are in the finite set <span><span class="math inline">\(S(e)\)</span></span>, no matter how large the input <span><span class="math inline">\(x\)</span></span> is, and so the running time of <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> satisfies the equation <span><span class="math inline">\(T(n) = T(n-1) + C&#39;\)</span></span> for some constant <span><span class="math inline">\(C&#39;\)</span></span> depending on <span><span class="math inline">\(e\)</span></span>. This solves to <span><span class="math inline">\(O(n)\)</span></span> where the implicit constant in the Oh notation can (and will) depend on <span><span class="math inline">\(e\)</span></span> but crucially, not on the length of the input <span><span class="math inline">\(x\)</span></span>.</p>
</div>
<h3 id="matching-regular-expressions-using-constant-memory" data-number="9.3.1">Matching regular expressions using constant memory</h3>
<p><a href='#reglintimethm'>Theorem 9.6</a> is already quite impressive, but we can do even better. Specifically, no matter how long the string <span><span class="math inline">\(x\)</span></span> is, we can compute <span><span class="math inline">\(\Phi_e(x)\)</span></span> by maintaining only a constant amount of memory and moreover making a <em>single pass</em> over <span><span class="math inline">\(x\)</span></span>. That is, the algorithm will scan the input <span><span class="math inline">\(x\)</span></span> once from start to finish, and then determine whether or not <span><span class="math inline">\(x\)</span></span> is matched by the expression <span><span class="math inline">\(e\)</span></span>. This is important in the common case of trying to match a short regular expression over a huge file or document that might not even fit in our computer’s memory. A single-pass constant-memory algorithm is also known as a <a href="https://goo.gl/SG6DS7">deterministic finite automaton (DFA)</a> (see <a href='#secdfa'>Subsection 9.3.2</a>). There is a beautiful theory on the properties of DFA’s and their connections with regular expressions. In particular, as we’ll see in <a href='#dfaregequivthm'>Theorem 9.12</a>, a function is regular <em>if and only if</em> it can be computed by a DFA. We start with showing the “only if” direction:</p>
<div id="DFAforREGthm" class="theorem" title="DFA for regular expression matching" name="Theorem 9.8 (DFA for regular expression matching) ">
<p>Let <span><span class="math inline">\(e\)</span></span> be a regular expression. Then there is an algorithm that on input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> computes <span><span class="math inline">\(\Phi_e(x)\)</span></span> while making a single pass over <span><span class="math inline">\(x\)</span></span> and maintaining a constant amount of memory.</p>
</div>
<div id="section-3" class="proofidea" data-ref="DFAforREGthm" name="Proofidea">
<p>The idea is to replace the recursive algorithm of <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> with a <a href="https://goo.gl/kgLdX1">dynamic program</a>, using the technique of <a href="https://en.wikipedia.org/wiki/Memoization">memoization</a>. If you haven’t taken yet an algorithms course, you might not know these techniques. This is OK; while this more efficient algorithm is crucial for the many practical applications of regular expressions, it is not of great importance for this book.</p>
</div>
<div class="proof" data-ref="DFAforREGthm" name="Proof 9.3.1">
<p>We will replace the recursive <a href='#regexpmatchlinearalg'>Algorithm 9.7</a> with the following iterative algorithm:</p>
<div id="iterregexpmatchlinearalg" class="algorithm" title="Constant memory regular expression matching" name="Algorithm 9.9 (Constant memory regular expression matching) ">
<p><strong>Input:</strong> Regular expression <span><span class="math inline">\(e\)</span></span> over <span><span class="math inline">\(\{0,1\}\)</span></span>, string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>.</p>
<p><strong>Goals:</strong> Compute <span><span class="math inline">\(\Phi_e(x)\)</span></span>.</p>
<p><strong>Operation:</strong></p>
<ol type="1">
<li><p>Let <span><span class="math inline">\(S = S(e)\)</span></span> be the set <span><span class="math inline">\(\{ e[\alpha] | \alpha\in \{0,1\}^* \}\)</span></span> as defined in the proof of <a href='#reglintimethm'>Theorem 9.6</a>. Note that <span><span class="math inline">\(S\)</span></span> is finite and by definition, for every <span><span class="math inline">\(e&#39; \in S\)</span></span> and <span><span class="math inline">\(\sigma \in \{0,1\}\)</span></span>, <span><span class="math inline">\(e&#39;[\sigma]\)</span></span> is in <span><span class="math inline">\(S\)</span></span> as well.</p></li>
<li><p>Define a Boolean variable <span><span class="math inline">\(v_{e&#39;}\)</span></span> for every <span><span class="math inline">\(e&#39; \in S\)</span></span>. Initially we set <span><span class="math inline">\(v_{e&#39;}=1\)</span></span> if and only if <span><span class="math inline">\(e&#39;\)</span></span> matches the empty string.</p></li>
<li><p>For <span><span class="math inline">\(i=0,\ldots,n-1\)</span></span> do the following:</p>
<ol type="a">
<li><p><em>Copy the variables <span><span class="math inline">\(\{ v_{e&#39;} \}\)</span></span> to temporary variables:</em> For every <span><span class="math inline">\(e&#39; \in S\)</span></span>, we set <span><span class="math inline">\(temp_{e&#39;} = v_{e&#39;}\)</span></span>.</p></li>
<li><p><em>Update the variables <span><span class="math inline">\(\{ v_{e&#39;} \}\)</span></span> based on the <span><span class="math inline">\(i\)</span></span>-th bit of <span><span class="math inline">\(x\)</span></span>:</em> Let <span><span class="math inline">\(\sigma = x_i\)</span></span> and set <span><span class="math inline">\(v_{e&#39;} = temp_{e&#39;[\sigma]}\)</span></span> for every <span><span class="math inline">\(e&#39; \in S\)</span></span>.</p></li>
</ol></li>
<li><p>Output <span><span class="math inline">\(v_{e}\)</span></span>.</p></li>
</ol>
</div>
<p><a href='#iterregexpmatchlinearalg'>Algorithm 9.9</a> maintains the invariant that at the end of step <span><span class="math inline">\(i\)</span></span>, for every <span><span class="math inline">\(e&#39; \in S\)</span></span>, the variable <span><span class="math inline">\(v_{e&#39;}\)</span></span> is equal if and only if <span><span class="math inline">\(e&#39;\)</span></span> matches the string <span><span class="math inline">\(x_0\cdots x_{i-1}\)</span></span>. In particular, at the very end, <span><span class="math inline">\(v_{e}\)</span></span> is equal to <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(e\)</span></span> matches the full string <span><span class="math inline">\(x_0 \cdots x_{n-1}\)</span></span>. <a href='#iterregexpmatchlinearalg'>Algorithm 9.9</a> only maintains a constant number of variables (as <span><span class="math inline">\(S\)</span></span> is finite), and that it proceeds in one linear scan over the input, and so this proves the theorem.</p>
</div>
<h3 id="secdfa" data-number="9.3.2">Deterministic Finite Automata</h3>
<p>In Computer Science, a single-pass constant-memory algorithm is also known as a <em>Deterministic Finite Automaton</em> or <em>DFA</em> (another name for DFA’s is a <em>finite state machine</em>). That is, we can think of such an algorithm as a “machine” that can be in one of <span><span class="math inline">\(C\)</span></span> states, for some constant <span><span class="math inline">\(C\)</span></span>. The machine starts in some initial state, and then reads its input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> one bit at a time. Whenever the machine reads a bit <span><span class="math inline">\(\sigma \in \{0,1\}\)</span></span>, it transitions into a new state based on <span><span class="math inline">\(\sigma\)</span></span> and its prior state. The output of the machine is based on the final state. Every constant-memory one-pass algorithm corresponds to such a machine. If an algorithm uses <span><span class="math inline">\(c\)</span></span> bits of memory, then the contents of its memory are a string of length <span><span class="math inline">\(c\)</span></span>. Since there are <span><span class="math inline">\(2^c\)</span></span> such strings, at any point in the execution, such an algorithm can be in one of <span><span class="math inline">\(2^c\)</span></span> states.</p>
<div id="DFAforparity" class="example" title="DFA for XOR" name="Example 9.10 (DFA for XOR) ">
<p>Here is a DFA for computing the function <span><span class="math inline">\(\ensuremath{\mathit{XOR}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> that maps <span><span class="math inline">\(x\)</span></span> to <span><span class="math inline">\(\sum_{i\in [|x|]} x_i \mod 2\)</span></span>.</p>
<p>We will have two states: <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(1\)</span></span>. The set of accepting states is <span><span class="math inline">\(\{1 \}\)</span></span>, and if we are in a state <span><span class="math inline">\(v \in \{0,1\}\)</span></span> and read the bit <span><span class="math inline">\(\sigma\)</span></span>, we will transition to the state <span><span class="math inline">\(v\)</span></span> if <span><span class="math inline">\(\sigma=0\)</span></span> and to the state <span><span class="math inline">\(1-v\)</span></span> if <span><span class="math inline">\(\sigma = 1\)</span></span>. In other words, we transition to the state <span><span class="math inline">\(v \oplus \sigma\)</span></span>. Hence we can think of this algorithm’s execution on input <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> as follows:</p>
<ul>
<li><p>Let <span><span class="math inline">\(v_t\)</span></span> be the state of the automaton at step <span><span class="math inline">\(t\)</span></span>. We initialize <span><span class="math inline">\(v_t=0\)</span></span>.</p></li>
<li><p>For every <span><span class="math inline">\(i\in [n]\)</span></span>, let <span><span class="math inline">\(v_i = v_{i+1} \oplus x_i\)</span></span>.</p></li>
<li><p>Output <span><span class="math inline">\(v_n\)</span></span>.</p></li>
</ul>
<p>You can verify that the output of this algorithm is <span><span class="math inline">\(x_0 \oplus x_1 \oplus \cdots \oplus x_{n-1} = \ensuremath{\mathit{XOR}}(x)\)</span></span>. We can also describe this DFA graphically, see <a href='#xorautomatonfig'>Figure 9.2</a>.</p>
</div>
<figure>
<img src="../figure/xorautomaton.png" alt="9.2: A deterministic finite automaton that computes the \ensuremath{\mathit{XOR}} function. It has two states 0 and 1, and when it observes \sigma it transitions from v to v \oplus \sigma." id="xorautomatonfig" class="margin" /><figcaption>9.2: A deterministic finite automaton that computes the <span><span class="math inline">\(\ensuremath{\mathit{XOR}}\)</span></span> function. It has two states <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(1\)</span></span>, and when it observes <span><span class="math inline">\(\sigma\)</span></span> it transitions from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(v \oplus \sigma\)</span></span>.</figcaption>
</figure>
<p>The formal definition of a DFA is the following:</p>
<div id="DFAdef" class="definition" title="Deterministic Finite Automaton" name="Definition 9.11 (Deterministic Finite Automaton) ">
<p>A deterministic finite automaton (DFA) with <span><span class="math inline">\(C\)</span></span> states over <span><span class="math inline">\(\{0,1\}\)</span></span> is a pair <span><span class="math inline">\((T,\mathcal{S})\)</span></span> with <span><span class="math inline">\(T:[C]\times \{0,1\} \rightarrow [C]\)</span></span> and <span><span class="math inline">\(\mathcal{S} \subseteq [C]\)</span></span>. The function <span><span class="math inline">\(T\)</span></span> is known as the <em>transition function</em> of the DFA and the set <span><span class="math inline">\(\mathcal{S}\)</span></span> is known as the set of <em>accepting states</em>.</p>
<p>We say that <span><span class="math inline">\((T,\mathcal{S})\)</span></span> <em>computes</em> a function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> if for every <span><span class="math inline">\(n\in\N\)</span></span> and <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, if we define <span><span class="math inline">\(v_0=0\)</span></span> and <span><span class="math inline">\(v_{i+1} = T(v_i,x_i)\)</span></span> for every <span><span class="math inline">\(i\in [n]\)</span></span>, then <span>
<div class='myequationbox'><span class="math display">\[
v_n \in \mathcal{S}   \Leftrightarrow F(x)=1
\]</span></div></span></p>
</div>
<div class="pause" name="Pause 9.3.2">
<p>Our treatment of automata in this book is quite brief. If you find this definition confusing, there are plenty of resources that help you get more comfortable with DFA’s. In particular, Chapter 1 of Sipser’s book  (<a href="https://scholar.google.com/scholar?hl=en&q=Sipser+Introduction+to+the+theory+of+computation" target="_blank">Sipser, 1997</a>)  contains an excellent exposition of this material. There are also many websites with online simulators for automata, as well as translators from regular expressions to automata and vice versa (see for example <a href="http://ivanzuzak.info/noam/webapps/fsm2regex/">here</a> and <a href="https://cyberzhg.github.io/toolbox/nfa2dfa">here</a>).</p>
<p>Sipser defines a DFAs as a five-tuple <span><span class="math inline">\((Q,\Sigma,\delta,q_0,F)\)</span></span> where <span><span class="math inline">\(Q\)</span></span> is the set of states, <span><span class="math inline">\(\Sigma\)</span></span> is the alphabet, <span><span class="math inline">\(\delta\)</span></span> is the transition function, <span><span class="math inline">\(q_0\)</span></span> is the initial state, and <span><span class="math inline">\(F\)</span></span> is the set of accepting states. In this book the set of states is always of the form <span><span class="math inline">\(Q=\{0,\ldots,C-1 \}\)</span></span> and the initial state is always <span><span class="math inline">\(q_0 = 0\)</span></span>, but this makes no difference to the computational power of these models. Also, we restrict our attention to the case that the alphabet <span><span class="math inline">\(\Sigma\)</span></span> is equal to <span><span class="math inline">\(\{0,1\}\)</span></span>.</p>
</div>
<p>The following theorem is the central result of automata theory:</p>
<div id="dfaregequivthm" class="theorem" title="DFA and regular expression equivalency" name="Theorem 9.12 (DFA and regular expression equivalency) ">
<p>Let <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>. Then <span><span class="math inline">\(F\)</span></span> is regular if and only if there exists a DFA <span><span class="math inline">\((T,\mathcal{S})\)</span></span> that computes <span><span class="math inline">\(F\)</span></span>.</p>
</div>
<div id="section-4" class="proofidea" data-ref="dfaregequivthm" name="Proofidea">
<p>One direction follows from <a href='#DFAforREGthm'>Theorem 9.8</a>, which shows that for every regular expression <span><span class="math inline">\(e\)</span></span>, the function <span><span class="math inline">\(\Phi_e\)</span></span> can be computed by a DFA (see for example <a href='#automatonregfig'>Figure 9.3</a>). For the other direction, we show that given a DFA <span><span class="math inline">\((T,\mathcal{S})\)</span></span> for every <span><span class="math inline">\(v,w \in [C]\)</span></span> we can find a regular expression that would match <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> if and only if the DFA starting in state <span><span class="math inline">\(v\)</span></span>, will end up in state <span><span class="math inline">\(w\)</span></span> after reading <span><span class="math inline">\(x\)</span></span>.</p>
</div>
<figure>
<img src="../figure/automaton.png" alt="9.3: A deterministic finite automaton that computes the function \Phi_{(01)^*}." id="automatonregfig" class="margin" /><figcaption>9.3: A deterministic finite automaton that computes the function <span><span class="math inline">\(\Phi_{(01)^*}\)</span></span>.</figcaption>
</figure>
<figure>
<img src="../figure/dfatoreg1.png" alt="9.4: Given a DFA of C states, for every v,w \in [C] and number t\in \{0,\ldots,C\} we define the function F^t_{v,w}:\{0,1\}^* \rightarrow \{0,1\} to output one on input x\in \{0,1\}^* if and only if when the DFA is initialized in the state v and is given the input x, it will teach the state w while going only through the intermediate states \{0,\ldots,t-1\}." id="dfatoregonefig" class="margin" /><figcaption>9.4: Given a DFA of <span><span class="math inline">\(C\)</span></span> states, for every <span><span class="math inline">\(v,w \in [C]\)</span></span> and number <span><span class="math inline">\(t\in \{0,\ldots,C\}\)</span></span> we define the function <span><span class="math inline">\(F^t_{v,w}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> to output one on input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> if and only if when the DFA is initialized in the state <span><span class="math inline">\(v\)</span></span> and is given the input <span><span class="math inline">\(x\)</span></span>, it will teach the state <span><span class="math inline">\(w\)</span></span> while going only through the intermediate states <span><span class="math inline">\(\{0,\ldots,t-1\}\)</span></span>.</figcaption>
</figure>
<div class="proof" data-ref="dfaregequivthm" name="Proof">
<p>Since <a href='#DFAforREGthm'>Theorem 9.8</a> proves the “only if” direction, we only need to show the “if” direction. Let <span><span class="math inline">\(A=(T,\mathcal{S})\)</span></span> be a DFA with <span><span class="math inline">\(C\)</span></span> states that computes the function <span><span class="math inline">\(F\)</span></span>. We need to show that <span><span class="math inline">\(F\)</span></span> is regular.</p>
<p>For every <span><span class="math inline">\(v,w \in [C]\)</span></span>, we let <span><span class="math inline">\(F_{v,w}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> be the function that maps <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> to <span><span class="math inline">\(1\)</span></span> if and only if the DFA <span><span class="math inline">\(A\)</span></span>, starting at the state <span><span class="math inline">\(v\)</span></span>, will reach the state <span><span class="math inline">\(w\)</span></span> if it reads the input <span><span class="math inline">\(x\)</span></span>. We will prove that <span><span class="math inline">\(F_{v,w}\)</span></span> is regular for every <span><span class="math inline">\(v,w\)</span></span>. This will prove the theorem, since by <a href='#DFAdef'>Definition 9.11</a>, <span><span class="math inline">\(F(x)\)</span></span> is equal to the OR of <span><span class="math inline">\(F_{0,w}(x)\)</span></span> for every <span><span class="math inline">\(w\in \mathcal{S}\)</span></span>. Hence if we have a regular expression for every function of the form <span><span class="math inline">\(F_{v,w}\)</span></span> then (using the <span><span class="math inline">\(|\)</span></span> operation) we can obtain a regular expression for <span><span class="math inline">\(F\)</span></span> as well.</p>
<p>To give regular expressions for the functions <span><span class="math inline">\(F_{v,w}\)</span></span>, we start by defining the following functions <span><span class="math inline">\(F_{v,w}^t\)</span></span>: for every <span><span class="math inline">\(v,w \in [C]\)</span></span> and <span><span class="math inline">\(0 \leq t \leq C\)</span></span>, <span><span class="math inline">\(F_{v,w}^t(x)=1\)</span></span> if and only if starting from <span><span class="math inline">\(v\)</span></span> and observing <span><span class="math inline">\(x\)</span></span>, the automata reaches <span><span class="math inline">\(w\)</span></span> <em>with all intermediate states being in the set <span><span class="math inline">\([t]=\{0,\ldots, t-1\}\)</span></span></em> (see <a href='#dfatoregonefig'>Figure 9.4</a>). That is, while <span><span class="math inline">\(v,w\)</span></span> themselves might be outside <span><span class="math inline">\([t]\)</span></span>, <span><span class="math inline">\(F_{v,w}^t(x)=1\)</span></span> if and only if throughout the execution of the automaton on the input <span><span class="math inline">\(x\)</span></span> (when initiated at <span><span class="math inline">\(v\)</span></span>) it never enters any of the states outside <span><span class="math inline">\([t]\)</span></span> and still ends up at <span><span class="math inline">\(w\)</span></span>. If <span><span class="math inline">\(t=0\)</span></span> then <span><span class="math inline">\([t]\)</span></span> is the empty set, and hence <span><span class="math inline">\(F^0_{v,w}(x)=1\)</span></span> if and only if the automaton reaches <span><span class="math inline">\(w\)</span></span> from <span><span class="math inline">\(v\)</span></span> directly on <span><span class="math inline">\(x\)</span></span>, without any intermediate state. If <span><span class="math inline">\(t=C\)</span></span> then all states are in <span><span class="math inline">\([t]\)</span></span>, and hence <span><span class="math inline">\(F_{v,w}^t= F_{v,w}\)</span></span>.</p>
<p>We will prove the theorem by induction on <span><span class="math inline">\(t\)</span></span>, showing that <span><span class="math inline">\(F^t_{v,w}\)</span></span> is regular for every <span><span class="math inline">\(v,w\)</span></span> and <span><span class="math inline">\(t\)</span></span>. For the <strong>base case</strong> of <span><span class="math inline">\(t=0\)</span></span>, <span><span class="math inline">\(F^0_{v,w}\)</span></span> is regular for every <span><span class="math inline">\(v,w\)</span></span> since it can be described as one of the expressions <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span>, <span><span class="math inline">\(\emptyset\)</span></span>, <span><span class="math inline">\(0\)</span></span>, <span><span class="math inline">\(1\)</span></span> or <span><span class="math inline">\(0|1\)</span></span>. Specifically, if <span><span class="math inline">\(v=w\)</span></span> then <span><span class="math inline">\(F^0_{v,w}(x)=1\)</span></span> if and only if <span><span class="math inline">\(x\)</span></span> is the empty string. If <span><span class="math inline">\(v\neq w\)</span></span> then <span><span class="math inline">\(F^0_{v,w}(x)=1\)</span></span> if and only if <span><span class="math inline">\(x\)</span></span> consists of a single symbol <span><span class="math inline">\(\sigma \in \{0,1\}\)</span></span> and <span><span class="math inline">\(T(v,\sigma)=w\)</span></span>. Therefore in this case <span><span class="math inline">\(F^0_{v,w}\)</span></span> corresponds to one of the four regular expressions <span><span class="math inline">\(0|1\)</span></span>, <span><span class="math inline">\(0\)</span></span>, <span><span class="math inline">\(1\)</span></span> or <span><span class="math inline">\(\emptyset\)</span></span>, depending on whether <span><span class="math inline">\(A\)</span></span> transitions to <span><span class="math inline">\(w\)</span></span> from <span><span class="math inline">\(v\)</span></span> when it reads either <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span>, only one of these symbols, or neither.</p>
<p><strong>Inductive step:</strong> Now that we’ve seen the base case, let’s prove the general case by induction. Assume, via the induction hypothesis, that for every <span><span class="math inline">\(v&#39;,w&#39; \in [C]\)</span></span>, we have a regular expression <span><span class="math inline">\(R_{v,w}^t\)</span></span> that computes <span><span class="math inline">\(F_{v&#39;,w&#39;}^t\)</span></span>. We need to prove that <span><span class="math inline">\(F_{v,w}^{t+1}\)</span></span> is regular for every <span><span class="math inline">\(v,w\)</span></span>. If the automaton arrives from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(w\)</span></span> using the intermediate states <span><span class="math inline">\([t+1]\)</span></span>, then it visits the <span><span class="math inline">\(t\)</span></span>-th state zero or more times. If the path labeled by <span><span class="math inline">\(x\)</span></span> causes the automaton to get from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(w\)</span></span> without visiting the <span><span class="math inline">\(t\)</span></span>-th state at all, then <span><span class="math inline">\(x\)</span></span> is matched by the regular expression <span><span class="math inline">\(R_{v,w}^t\)</span></span>. If the path labeled by <span><span class="math inline">\(x\)</span></span> causes the automaton to get from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(w\)</span></span> while visiting the <span><span class="math inline">\(t\)</span></span>-th state <span><span class="math inline">\(k&gt;0\)</span></span> times then we can think of this path as:</p>
<ul>
<li><p>First travel from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(t\)</span></span> using only intermediate states in <span><span class="math inline">\([t-1]\)</span></span>.</p></li>
<li><p>Then go from <span><span class="math inline">\(t\)</span></span> back to itself <span><span class="math inline">\(k-1\)</span></span> using only intermediate states in <span><span class="math inline">\([t-1]\)</span></span></p></li>
<li><p>Then go from <span><span class="math inline">\(t\)</span></span> to <span><span class="math inline">\(w\)</span></span> using only intermediate states in <span><span class="math inline">\([t-1]\)</span></span>.</p></li>
</ul>
<p>Therefore in this case the string <span><span class="math inline">\(x\)</span></span> is matched by the regular expression <span><span class="math inline">\(R_{v,t}^t(R_{t,t}^t)^* R_{t,w}^t\)</span></span>. (See also <a href='#dfatoreginductivefig'>Figure 9.5</a>.)</p>
<p>Therefore we can compute <span><span class="math inline">\(F_{v,w}^{t+1}\)</span></span> using the regular expression</p>
<p><span>
<div class='myequationbox'><span class="math display">\[R_{v,w}^t \;|\; R_{v,t}^t(R_{t,t}^t)^* R_{t,w}^t\;.\]</span></div></span> This completes the proof of the inductive step and hence of the theorem.</p>
</div>
<figure>
<img src="../figure/dfatoreginduction.png" alt="9.5: If we have regular expressions R_{v&#39;,w&#39;}^{t} corresponding to F_{v&#39;,w&#39;}^{t} for every v&#39;,w&#39; \in [C], we can obtain a regular expression R_{v,w}^{t+1} corresponding to F_{v,w}^{t+1}. The key observation is that a path from v to w using \{0,\ldots, t \} either does not touch t at all, in which case it is captured by the expression R_{v,w}^{t}, or it goes from v to t, comes back to t zero or more times, and then goes from t to w, in which case it is captured by the expression R_{v,t}^{t}(R_{t,t}^{t})^* R_{t,w}^t." id="dfatoreginductivefig" /><figcaption>9.5: If we have regular expressions <span><span class="math inline">\(R_{v&#39;,w&#39;}^{t}\)</span></span> corresponding to <span><span class="math inline">\(F_{v&#39;,w&#39;}^{t}\)</span></span> for every <span><span class="math inline">\(v&#39;,w&#39; \in [C]\)</span></span>, we can obtain a regular expression <span><span class="math inline">\(R_{v,w}^{t+1}\)</span></span> corresponding to <span><span class="math inline">\(F_{v,w}^{t+1}\)</span></span>. The key observation is that a path from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(w\)</span></span> using <span><span class="math inline">\(\{0,\ldots, t \}\)</span></span> either does not touch <span><span class="math inline">\(t\)</span></span> at all, in which case it is captured by the expression <span><span class="math inline">\(R_{v,w}^{t}\)</span></span>, or it goes from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(t\)</span></span>, comes back to <span><span class="math inline">\(t\)</span></span> zero or more times, and then goes from <span><span class="math inline">\(t\)</span></span> to <span><span class="math inline">\(w\)</span></span>, in which case it is captured by the expression <span><span class="math inline">\(R_{v,t}^{t}(R_{t,t}^{t})^* R_{t,w}^t\)</span></span>.</figcaption>
</figure>
<h3 id="regular-functions-are-closed-under-complement" data-number="9.3.3">Regular functions are closed under complement</h3>
<p>Here is an important corollary of <a href='#dfaregequivthm'>Theorem 9.12</a>:</p>
<div id="regcomplementlem" class="lemma" title="Regular expressions closed under complement" name="Lemma 9.13 (Regular expressions closed under complement) ">
<p>If <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is regular then so is the function <span><span class="math inline">\(\overline{F}\)</span></span>, where <span><span class="math inline">\(\overline{F}(x) = 1 - F(x)\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>.</p>
</div>
<div class="proof" data-ref="regcomplementlem" name="Proof">
<p>If <span><span class="math inline">\(F\)</span></span> is regular then by <a href='#reglintimethm'>Theorem 9.6</a> it can be computed by a constant-space one-pass algorithm <span><span class="math inline">\(A\)</span></span>. But then the algorithm <span><span class="math inline">\(\overline{A}\)</span></span> which does the same computation and outputs the negation of the output of <span><span class="math inline">\(A\)</span></span> also utilizes constant space and one pass and computes <span><span class="math inline">\(\overline{F}\)</span></span>. By <a href='#dfaregequivthm'>Theorem 9.12</a> this implies that <span><span class="math inline">\(\overline{F}\)</span></span> is regular as well.</p>
</div>
<h2 id="limitations-of-regular-expressions" data-number="9.4">Limitations of regular expressions</h2>
<p>The fact that functions computed by regular expressions always halt is one of the reasons why they are so useful. When you make a regular expression search, you are guaranteed that that it will terminate with a result. This is why operating systems and text editors often restrict their search interface to regular expressions and don’t allow searching by specifying an arbitrary function. But this always-halting property comes at a cost. Regular expressions cannot compute every function that is computable by Turing machines. In fact there are some very simple (and useful!) functions that they cannot compute. Here is one example:</p>
<div id="regexpparn" class="lemma" title="Matching parenthesis" name="Lemma 9.14 (Matching parenthesis) ">
<p>Let <span><span class="math inline">\(\Sigma = \{\langle ,\rangle \}\)</span></span> and <span><span class="math inline">\(\ensuremath{\mathit{MATCHPAREN}}:\Sigma^* \rightarrow \{0,1\}\)</span></span> be the function that given a string of parentheses, outputs <span><span class="math inline">\(1\)</span></span> if and only if every opening parenthesis is matched by a corresponding closed one. Then there is no regular expression over <span><span class="math inline">\(\Sigma\)</span></span> that computes <span><span class="math inline">\(\ensuremath{\mathit{MATCHPAREN}}\)</span></span>.</p>
</div>
<p><a href='#regexpparn'>Lemma 9.14</a> is a consequence of the following result, which is known as the <em>pumping lemma</em>:</p>
<div id="pumping" class="theorem" title="Pumping Lemma" name="Theorem 9.15 (Pumping Lemma) ">
<p>Let <span><span class="math inline">\(e\)</span></span> be a regular expression over some alphabet <span><span class="math inline">\(\Sigma\)</span></span>. Then there is some number <span><span class="math inline">\(n_0\)</span></span> such that for every <span><span class="math inline">\(w\in \Sigma^*\)</span></span> with <span><span class="math inline">\(|w|&gt;n_0\)</span></span> and <span><span class="math inline">\(\Phi_{e}(w)=1\)</span></span>, we can write <span><span class="math inline">\(w=xyz\)</span></span> for strings <span><span class="math inline">\(x,y,z \in \Sigma^*\)</span></span> satisfying the following conditions:</p>
<ol type="1">
<li><p><span><span class="math inline">\(|y| \geq 1\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(|xy| \leq n_0\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(\Phi_{e}(xy^kz)=1\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>.</p></li>
</ol>
</div>
<figure>
<img src="../figure/pumpinglemma.png" alt="9.6: To prove the “pumping lemma” we look at a word w that is much larger than the regular expression e that matches it. In such a case, part of w must be matched by some sub-expression of the form (e&#39;)^*, since this is the only operator that allows matching words longer than the expression. If we look at the “leftmost” such sub-expression and define y^k to be the string that is matched by it, we obtain the partition needed for the pumping lemma." id="pumpinglemmafig" /><figcaption>9.6: To prove the “pumping lemma” we look at a word <span><span class="math inline">\(w\)</span></span> that is much larger than the regular expression <span><span class="math inline">\(e\)</span></span> that matches it. In such a case, part of <span><span class="math inline">\(w\)</span></span> must be matched by some sub-expression of the form <span><span class="math inline">\((e&#39;)^*\)</span></span>, since this is the only operator that allows matching words longer than the expression. If we look at the “leftmost” such sub-expression and define <span><span class="math inline">\(y^k\)</span></span> to be the string that is matched by it, we obtain the partition needed for the pumping lemma.</figcaption>
</figure>
<div id="section-5" class="proofidea" data-ref="pumping" name="Proofidea">
<p>The idea behind the proof the following. Let <span><span class="math inline">\(n_0\)</span></span> be twice the number of symbols that are used in the expression <span><span class="math inline">\(e\)</span></span>, then the only way that there is some <span><span class="math inline">\(w\)</span></span> with <span><span class="math inline">\(|w|&gt;n_0\)</span></span> and <span><span class="math inline">\(\Phi_{e}(w)=1\)</span></span> is that <span><span class="math inline">\(e\)</span></span> contains the <span><span class="math inline">\(*\)</span></span> (i.e. star) operator and that there is a nonempty substring <span><span class="math inline">\(y\)</span></span> of <span><span class="math inline">\(w\)</span></span> that was matched by <span><span class="math inline">\((e&#39;)^*\)</span></span> for some sub-expression <span><span class="math inline">\(e&#39;\)</span></span> of <span><span class="math inline">\(e\)</span></span>. We can now repeat <span><span class="math inline">\(y\)</span></span> any number of times and still get a matching string. See also <a href='#pumpinglemmafig'>Figure 9.6</a>.</p>
</div>
<div class="pause" name="Pause 9.4">
<p>The pumping lemma is a bit cumbersome to state, but one way to remember it is that it simply says the following: <em>“if a string matching a regular expression is long enough, one of its substrings must be matched using the <span><span class="math inline">\(*\)</span></span> operator”</em>.</p>
</div>
<div class="proof" data-ref="pumping" name="Proof 9.4">
<p>To prove the lemma formally, we use induction on the length of the expression. Like all induction proofs, this is going to be somewhat lengthy, but at the end of the day it directly follows the intuition above that <em>somewhere</em> we must have used the star operation. Reading this proof, and in particular understanding how the formal proof below corresponds to the intuitive idea above, is a very good way to get more comfortable with inductive proofs of this form.</p>
<p>Our inductive hypothesis is that for an <span><span class="math inline">\(n\)</span></span> length expression, <span><span class="math inline">\(n_0=2n\)</span></span> satisfies the conditions of the lemma. The <strong>base case</strong> is when the expression is a single symbol <span><span class="math inline">\(\sigma \in \Sigma\)</span></span> or that the expression is <span><span class="math inline">\(\emptyset\)</span></span> or <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span>. In all these cases the conditions of the lemma are satisfied simply because there <span><span class="math inline">\(n_0=2\)</span></span> and there is no string <span><span class="math inline">\(x\)</span></span> of length larger than <span><span class="math inline">\(n_0\)</span></span> that is matched by the expression.</p>
<p>We now prove the <strong>inductive step</strong>. Let <span><span class="math inline">\(e\)</span></span> be a regular expression with <span><span class="math inline">\(n&gt;1\)</span></span> symbols. We set <span><span class="math inline">\(n_0=2n\)</span></span> and let <span><span class="math inline">\(w\in \Sigma^*\)</span></span> be a string satisfying <span><span class="math inline">\(|w|&gt;n_0\)</span></span>. Since <span><span class="math inline">\(e\)</span></span> has more than one symbol, it has one of the the forms <strong>(a)</strong> <span><span class="math inline">\(e&#39; | e&#39;&#39;\)</span></span>, <strong>(b)</strong>, <span><span class="math inline">\((e&#39;)(e&#39;&#39;)\)</span></span>, or <strong>(c)</strong> <span><span class="math inline">\((e&#39;)^*\)</span></span> where in all these cases the subexpressions <span><span class="math inline">\(e&#39;\)</span></span> and <span><span class="math inline">\(e&#39;&#39;\)</span></span> have fewer symbols than <span><span class="math inline">\(e\)</span></span> and hence satisfy the induction hypothesis.</p>
<p>In the case <strong>(a)</strong>, every string <span><span class="math inline">\(w\)</span></span> matched by <span><span class="math inline">\(e\)</span></span> must be matched by either <span><span class="math inline">\(e&#39;\)</span></span> or <span><span class="math inline">\(e&#39;&#39;\)</span></span>. If <span><span class="math inline">\(e&#39;\)</span></span> matches <span><span class="math inline">\(w\)</span></span> then, since <span><span class="math inline">\(|w|&gt;2|e&#39;|\)</span></span>, by the induction hypothesis there exist <span><span class="math inline">\(x,y,z\)</span></span> with <span><span class="math inline">\(|y| \geq 1\)</span></span> and <span><span class="math inline">\(|xy| \leq 2|e&#39;| &lt;n_0\)</span></span> such that <span><span class="math inline">\(e&#39;\)</span></span> (and therefore also <span><span class="math inline">\(e=e&#39;|e&#39;&#39;\)</span></span>) matches <span><span class="math inline">\(xy^kz\)</span></span> for every <span><span class="math inline">\(k\)</span></span>. The same arguments works in the case that <span><span class="math inline">\(e&#39;&#39;\)</span></span> matches <span><span class="math inline">\(w\)</span></span>.</p>
<p>In the case <strong>(b)</strong>, if <span><span class="math inline">\(w\)</span></span> is matched by <span><span class="math inline">\((e&#39;)(e&#39;&#39;)\)</span></span> then we can write <span><span class="math inline">\(w=w&#39;w&#39;&#39;\)</span></span> where <span><span class="math inline">\(e&#39;\)</span></span> matches <span><span class="math inline">\(w&#39;\)</span></span> and <span><span class="math inline">\(e&#39;&#39;\)</span></span> matches <span><span class="math inline">\(w&#39;&#39;\)</span></span>. We split to subcases. If <span><span class="math inline">\(|w&#39;|&gt;2|e&#39;|\)</span></span> then by the induction hypothesis there exist <span><span class="math inline">\(x,y,z&#39;\)</span></span> with <span><span class="math inline">\(|y| \leq 1\)</span></span>, <span><span class="math inline">\(|xy| \leq 2|e&#39;| &lt; n_0\)</span></span> such that <span><span class="math inline">\(w&#39;=xyz&#39;\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span> matches <span><span class="math inline">\(xy^kz&#39;\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>. This completes the proof since if we set <span><span class="math inline">\(z=z&#39;w&#39;&#39;\)</span></span> then we see that <span><span class="math inline">\(w=w&#39;w&#39;&#39;=xyz\)</span></span> and <span><span class="math inline">\(e=(e&#39;)(e&#39;&#39;)\)</span></span> matches <span><span class="math inline">\(xy^kz\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>. Otherwise, if <span><span class="math inline">\(|w&#39;| \leq 2|e&#39;|\)</span></span> then since <span><span class="math inline">\(|w|=|w&#39;|+|w&#39;&#39;|&gt;n_0=2(|e&#39;|+|e&#39;&#39;|)\)</span></span>, it must be that <span><span class="math inline">\(|w&#39;&#39;|&gt;2|e&#39;&#39;|\)</span></span>. Hence by the induction hypothesis there exist <span><span class="math inline">\(x&#39;,y,z\)</span></span> such that <span><span class="math inline">\(|y| \geq 1\)</span></span>, <span><span class="math inline">\(|x&#39;y| \leq 2|e&#39;&#39;|\)</span></span> and <span><span class="math inline">\(e&#39;&#39;\)</span></span> matches <span><span class="math inline">\(x&#39;y^kz\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>. But now if we set <span><span class="math inline">\(x=w&#39;x&#39;\)</span></span> we see that <span><span class="math inline">\(|xy| \leq |w&#39;| + |x&#39;y| \leq 2|e&#39;| + 2|e&#39;&#39;| =n_0\)</span></span> and on the other hand the expression <span><span class="math inline">\(e=(e&#39;)(e&#39;&#39;)\)</span></span> matches <span><span class="math inline">\(xy^kz = w&#39;x&#39;y^kz\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>.</p>
<p>In case <strong>(c)</strong>, if <span><span class="math inline">\(w\)</span></span> is matched <span><span class="math inline">\((e&#39;)^*\)</span></span> then <span><span class="math inline">\(w= w_0\cdots w_t\)</span></span> where for every <span><span class="math inline">\(i\in [t]\)</span></span>, <span><span class="math inline">\(w_i\)</span></span> is a nonempty string matched by <span><span class="math inline">\(e&#39;\)</span></span>. If <span><span class="math inline">\(|w_0|&gt;2|e&#39;|\)</span></span> then we can use the same approach as in the concatenation case above. Otherwise, we simply note that if <span><span class="math inline">\(x\)</span></span> is the empty string, <span><span class="math inline">\(y=w_0\)</span></span>, and <span><span class="math inline">\(z=w_1\cdots w_t\)</span></span> then <span><span class="math inline">\(|xy| \leq n_0\)</span></span> and <span><span class="math inline">\(xy^kz\)</span></span> is matched by <span><span class="math inline">\((e&#39;)^*\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>.</p>
</div>
<div id="recursiveproofs" class="remark" title="Recursive definitions and inductive proofs" name="Remark 9.16 (Recursive definitions and inductive proofs) ">
<p>When an object is <em>recursively defined</em> (as in the case of regular expressions) then it is natural to prove properties of such objects by <em>induction</em>. That is, if we want to prove that all objects of this type have property <span><span class="math inline">\(P\)</span></span>, then it is natural to use an inductive steps that says that if <span><span class="math inline">\(o&#39;,o&#39;&#39;,o&#39;&#39;&#39;\)</span></span> etc have property <span><span class="math inline">\(P\)</span></span> then so is an object <span><span class="math inline">\(o\)</span></span> that is obtained by composing them.</p>
</div>
<p>Using the pumping lemma, we can easily prove <a href='#regexpparn'>Lemma 9.14</a> (i.e., the non-regularity of the “matching parenthesis” function):</p>
<div class="proof" data-ref="regexpparn" name="Proof 17.3">
<p>Suppose, towards the sake of contradiction, that there is an expression <span><span class="math inline">\(e\)</span></span> such that <span><span class="math inline">\(\Phi_{e}= \ensuremath{\mathit{MATCHPAREN}}\)</span></span>. Let <span><span class="math inline">\(n_0\)</span></span> be the number obtained from <a href='#pumping'>Theorem 9.15</a> and let <span><span class="math inline">\(w =\langle^{n_0}\rangle^{n_0}\)</span></span> (i.e., <span><span class="math inline">\(n_0\)</span></span> left parenthesis followed by <span><span class="math inline">\(n_0\)</span></span> right parenthesis). Then we see that if we write <span><span class="math inline">\(w=xyz\)</span></span> as in <a href='#regexpparn'>Lemma 9.14</a>, the condition <span><span class="math inline">\(|xy| \leq n_0\)</span></span> implies that <span><span class="math inline">\(y\)</span></span> consists solely of left parenthesis. Hence the string <span><span class="math inline">\(xy^2z\)</span></span> will contain more left parenthesis than right parenthesis. Hence <span><span class="math inline">\(\ensuremath{\mathit{MATCHPAREN}}(xy^2z)=0\)</span></span> but by the pumping lemma <span><span class="math inline">\(\Phi_{e}(xy^2z)=1\)</span></span>, contradicting our assumption that <span><span class="math inline">\(\Phi_{e}=\ensuremath{\mathit{MATCHPAREN}}\)</span></span>.</p>
</div>
<p>The pumping lemma is a very useful tool to show that certain functions are <em>not</em> computable by a regular expression. However, it is <em>not</em> an “if and only if” condition for regularity: there are non regular functions that still satisfy the conditions of the pumping lemma. To understand the pumping lemma, it is important to follow the order of quantifiers in <a href='#pumping'>Theorem 9.15</a>. In particular, the number <span><span class="math inline">\(n_0\)</span></span> in the statement of <a href='#pumping'>Theorem 9.15</a> depends on the regular expression (in the proof we chose <span><span class="math inline">\(n_0\)</span></span> to be twice the number of symbols in the expression). So, if we want to use the pumping lemma to rule out the existence of a regular expression <span><span class="math inline">\(e\)</span></span> computing some function <span><span class="math inline">\(F\)</span></span>, we need to be able to choose an appropriate input <span><span class="math inline">\(w\in \{0,1\}^*\)</span></span> that can be arbitrarily large and satisfies <span><span class="math inline">\(F(w)=1\)</span></span>. This makes sense if you think about the intuition behind the pumping lemma: we need <span><span class="math inline">\(w\)</span></span> to be large enough as to force the use of the star operator.</p>
<figure>
<img src="../figure/pumpinglemmaproof.png" alt="9.7: A cartoon of a proof using the pumping lemma that a function F is not regular. The pumping lemma states that if F is regular then there exists a number n_0 such that for every large enough w with F(w)=1, there exists a partition of w to w=xyz satisfying certain conditions such that for every k\in \N, F(xy^kz)=1. You can imagine a pumping-lemma based proof as a game between you and the adversary. Every there exists quantifier corresponds to an object you are free to choose on your own (and base your choice on previously chosen objects). Every for every quantifier corresponds to an object the adversary can choose arbitrarily (and again based on prior choices) as long as it satisfies the conditions. A valid proof corresponds to a strategy by which no matter what the adversary does, you can win the game by obtaining a contradiction which would be a choice of k that would result in F(xy^ky)=0, hence violating the conclusion of the pumping lemma." id="pumpingprooffig" class="full" /><figcaption>9.7: A cartoon of a proof using the pumping lemma that a function <span><span class="math inline">\(F\)</span></span> is not regular. The pumping lemma states that if <span><span class="math inline">\(F\)</span></span> is regular then <em>there exists</em> a number <span><span class="math inline">\(n_0\)</span></span> such that <em>for every</em> large enough <span><span class="math inline">\(w\)</span></span> with <span><span class="math inline">\(F(w)=1\)</span></span>, <em>there exists</em> a partition of <span><span class="math inline">\(w\)</span></span> to <span><span class="math inline">\(w=xyz\)</span></span> satisfying certain conditions such that <em>for every</em> <span><span class="math inline">\(k\in \N\)</span></span>, <span><span class="math inline">\(F(xy^kz)=1\)</span></span>. You can imagine a pumping-lemma based proof as a game between you and the adversary. Every <em>there exists</em> quantifier corresponds to an object you are free to choose on your own (and base your choice on previously chosen objects). Every <em>for every</em> quantifier corresponds to an object the adversary can choose arbitrarily (and again based on prior choices) as long as it satisfies the conditions. A valid proof corresponds to a strategy by which no matter what the adversary does, you can win the game by obtaining a contradiction which would be a choice of <span><span class="math inline">\(k\)</span></span> that would result in <span><span class="math inline">\(F(xy^ky)=0\)</span></span>, hence violating the conclusion of the pumping lemma.</figcaption>
</figure>
<div id="palindromenotreg" class="solvedexercise" title="Palindromes is not regular" name="Solvedexercise 9.1 (Palindromes is not regular) ">
<p>Prove that the following function over the alphabet <span><span class="math inline">\(\{0,1,; \}\)</span></span> is not regular: <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(w)=1\)</span></span> if and only if <span><span class="math inline">\(w = u;u^R\)</span></span> where <span><span class="math inline">\(u \in \{0,1\}^*\)</span></span> and <span><span class="math inline">\(u^R\)</span></span> denotes <span><span class="math inline">\(u\)</span></span> “reversed”: the string <span><span class="math inline">\(u_{|u|-1}\cdots u_0\)</span></span>. (The <em>Palindrome</em> function is most often defined without an explicit separator character <span><span class="math inline">\(;\)</span></span>, but the version with such a separator is a bit cleaner and so we use it here. This does not make much difference, as one can easily encode the separator as a special binary string instead.)</p>
</div>
<div class="solution" data-ref="stringreversed" name="Solution 9.4">
<p>We use the pumping lemma. Suppose towards the sake of contradiction that there is a regular expression <span><span class="math inline">\(e\)</span></span> computing <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span>, and let <span><span class="math inline">\(n_0\)</span></span> be the number obtained by the pumping lemma (<a href='#pumping'>Theorem 9.15</a>). Consider the string <span><span class="math inline">\(w = 0^{n_0};0^{n_0}\)</span></span>. Since the reverse of the all zero string is the all zero string, <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(w)=1\)</span></span>. Now, by the pumping lemma, if <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span> is computed by <span><span class="math inline">\(e\)</span></span>, then we can write <span><span class="math inline">\(w=xyz\)</span></span> such that <span><span class="math inline">\(|xy| \leq n_0\)</span></span>, <span><span class="math inline">\(|y|\geq 1\)</span></span> and <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(xy^kz)=1\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>. In particular, it must hold that <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(xz)=1\)</span></span>, but this is a contradiction, since <span><span class="math inline">\(xz=0^{n_0-|y|};0^{n_0}\)</span></span> and so its two parts are not of the same length and in particular are not the reverse of one another.</p>
</div>
<p>For yet another example of a pumping-lemma based proof, see <a href='#pumpingprooffig'>Figure 9.7</a> which illustrates a cartoon of the proof of the non-regularity of the function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> which is defined as <span><span class="math inline">\(F(x)=1\)</span></span> iff <span><span class="math inline">\(x=0^n1^n\)</span></span> for some <span><span class="math inline">\(n\in \N\)</span></span> (i.e., <span><span class="math inline">\(x\)</span></span> consists of a string of consecutive zeroes, followed by a string of consecutive ones of the same length).</p>
<h2 id="other-semantic-properties-of-regular-expressions" data-number="9.5">Other semantic properties of regular expressions</h2>
<p>Regular expressions are widely used beyond just searching. For example, regular expressions are often used to define <em>tokens</em> (such as what is a valid variable identifier, or keyword) in programming languages. But they also have other uses. One nice example is the recent work on the <a href="https://goo.gl/oeJNuw">NetKAT network programming language</a>. In recent years, the world of networking moved from fixed topologies to “software defined networks”. These are run by programmable switches that can implement policies such as “if packet is secured by SSL then forward it to A, otherwise forward it to B”. By its nature, one would want to use a formalism for such policies that is guaranteed to always halt (and quickly!) and such that it is possible to answer semantic questions such as “does C see the packets moved from A to B” etc. The NetKAT language uses a variant of regular expressions to achieve precisely that.</p>
<p>Such applications use the fact that because regular expressions are so restricted, we can not only solve the halting problem for them, but also answer other <em>semantic questions</em>. Such semantic questions would not be solvable for Turing-complete models due to Rice’s Theorem (<a href='lec_08_uncomputability.html#rice-thm'>Theorem 8.16</a>). For example, we can tell whether two regular expressions are <em>equivalent</em>, as well as whether a regular expression computes the constant zero function.</p>
<div id="regemptynessthm" class="theorem" title="Emptiness of regular languages is computable" name="Theorem 9.17 (Emptiness of regular languages is computable) ">
<p>There is an algorithm that given a regular expression <span><span class="math inline">\(e\)</span></span>, outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(\Phi_{e}\)</span></span> is the constant zero function.</p>
</div>
<div id="section-6" class="proofidea" data-ref="regemptynessthm" name="Proofidea">
<p>The idea is that we can directly observe this from the structure of the expression. The only way a regular expression <span><span class="math inline">\(e\)</span></span> computes the constant zero function is if <span><span class="math inline">\(e\)</span></span> has the form <span><span class="math inline">\(\emptyset\)</span></span> or is obtained by concatenating <span><span class="math inline">\(\emptyset\)</span></span> with other expressions.</p>
</div>
<div class="proof" data-ref="regemptynessthm" name="Proof 9.5">
<p>Define a regular expression to be “empty” if it computes the constant zero function. Given a regular expression <span><span class="math inline">\(e\)</span></span>, we can determine if <span><span class="math inline">\(e\)</span></span> is empty using the following rules:</p>
<ul>
<li><p>If <span><span class="math inline">\(e\)</span></span> has the form <span><span class="math inline">\(\sigma\)</span></span> or <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> then it is not empty.</p></li>
<li><p>If <span><span class="math inline">\(e\)</span></span> is not empty then <span><span class="math inline">\(e|e&#39;\)</span></span> is not empty for every <span><span class="math inline">\(e&#39;\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(e\)</span></span> is not empty then <span><span class="math inline">\(e^*\)</span></span> is not empty.</p></li>
<li><p>If <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span> are both not empty then <span><span class="math inline">\(e\; e&#39;\)</span></span> is not empty.</p></li>
<li><p><span><span class="math inline">\(\emptyset\)</span></span> is empty.</p></li>
</ul>
<p>Using these rules it is straightforward to come up with a recursive algorithm to determine emptiness.</p>
</div>
<div id="regequivalencethm" class="theorem" title="Equivalence of regular expressions is computable" name="Theorem 9.18 (Equivalence of regular expressions is computable) ">
<p>Let <span><span class="math inline">\(\ensuremath{\mathit{REGEQ}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> be the function that on input (a string representing) a pair of regular expressions <span><span class="math inline">\(e,e&#39;\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{REGEQ}}(e,e&#39;)=1\)</span></span> if and only if <span><span class="math inline">\(\Phi_{e} = \Phi_{e&#39;}\)</span></span>. Then <span><span class="math inline">\(\ensuremath{\mathit{REGEQ}}\)</span></span> is computable.</p>
</div>
<div id="section-7" class="proofidea" data-ref="regequivalencethm" name="Proofidea">
<p>The idea is to show that given a pair of regular expression <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span> we can find an expression <span><span class="math inline">\(e&#39;&#39;\)</span></span> such that <span><span class="math inline">\(\Phi_{e&#39;&#39;}(x)=1\)</span></span> if and only if <span><span class="math inline">\(\Phi_e(x) \neq \Phi_(e&#39;&#39;)(x)\)</span></span>. Therefore <span><span class="math inline">\(\Phi_{e&#39;&#39;}\)</span></span> is the constant zero function if and only if <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span> are equivalent, and thus we can test for emptiness of <span><span class="math inline">\(e&#39;&#39;\)</span></span> to determine equivalence of <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span>.</p>
</div>
<div class="proof" data-ref="regequivalencethm" name="Proof">
<p>We will prove <a href='#regequivalencethm'>Theorem 9.18</a> from <a href='#regemptynessthm'>Theorem 9.17</a>. (The two theorems are in fact equivalent: it is easy to prove <a href='#regemptynessthm'>Theorem 9.17</a> from <a href='#regequivalencethm'>Theorem 9.18</a>, since checking for emptiness is the same as checking equivalence with the expression <span><span class="math inline">\(\emptyset\)</span></span>.) Given two regular expressions <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span>, we will compute an expression <span><span class="math inline">\(e&#39;&#39;\)</span></span> such that <span><span class="math inline">\(\Phi_{e&#39;&#39;}(x) =1\)</span></span> if and only if <span><span class="math inline">\(\Phi_e(x) \neq \Phi_{e&#39;}(x)\)</span></span>. One can see that <span><span class="math inline">\(e\)</span></span> is equivalent to <span><span class="math inline">\(e&#39;\)</span></span> if and only if <span><span class="math inline">\(e&#39;&#39;\)</span></span> is empty.</p>
<p>We start with the observation that for every bit <span><span class="math inline">\(a,b \in \{0,1\}\)</span></span>, <span><span class="math inline">\(a \neq b\)</span></span> if and only if <span>
<div class='myequationbox'><span class="math display">\[
(a \wedge \overline{b}) \; \vee \;  (\overline{a} \wedge b) \;.
\]</span></div></span></p>
<p>Hence we need to construct <span><span class="math inline">\(e&#39;&#39;\)</span></span> such that for every <span><span class="math inline">\(x\)</span></span>,</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\Phi_{e&#39;&#39;}(x) = (\Phi_{e}(x) \wedge \overline{\Phi_{e&#39;}(x)}) \; \vee  \; (\overline{\Phi_{e}(x)} \wedge \Phi_{e&#39;}(x)) \;.
\;\;(9.10)
\]</span><a id='eqemptyequivreg'></a></div></span></p>
<p>To construct the expression <span><span class="math inline">\(e&#39;&#39;\)</span></span>, we will show how given any pair of expressions <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span>, we can construct expressions <span><span class="math inline">\(e\wedge e&#39;\)</span></span> and <span><span class="math inline">\(\overline{e}\)</span></span> that compute the functions <span><span class="math inline">\(\Phi_{e} \wedge \Phi_{e&#39;}\)</span></span> and <span><span class="math inline">\(\overline{\Phi_{e}}\)</span></span> respectively. (Computing the expression for <span><span class="math inline">\(e \vee e&#39;\)</span></span> is straightforward using the <span><span class="math inline">\(|\)</span></span> operation of regular expressions.)</p>
<p>Specifically, by <a href='#regcomplementlem'>Lemma 9.13</a>, regular functions are closed under negation, which means that for every regular expression <span><span class="math inline">\(e\)</span></span>, there is an expression <span><span class="math inline">\(\overline{e}\)</span></span> such that <span><span class="math inline">\(\Phi_{\overline{e}}(x) = 1 - \Phi_{e}(x)\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>. Now, for every two expression <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span>, the expression <span>
<div class='myequationbox'><span class="math display">\[
e \wedge e&#39; = \overline{(\overline{e} | \overline{e&#39;})}
\]</span></div></span> computes the AND of the two expressions. Given these two transformations, we see that for every regular expressions <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span> we can find a regular expression <span><span class="math inline">\(e&#39;&#39;\)</span></span> satisfying <a href='#eqemptyequivreg'>Equation 9.10</a> such that <span><span class="math inline">\(e&#39;&#39;\)</span></span> is empty if and only if <span><span class="math inline">\(e\)</span></span> and <span><span class="math inline">\(e&#39;\)</span></span> are equivalent.</p>
</div>
<h2 id="seccfg" data-number="9.6">Context free grammars</h2>
<p>If you have ever written a program, you’ve experienced a <em>syntax error</em>. You probably also had the experience of your program entering into an <em>infinite loop</em>. What is less likely is that the compiler or interpreter entered an infinite loop while trying to figure out if your program has a syntax error.</p>
<p>When a person designs a programming language, they need to determine its <em>syntax</em>. That is, the designer decides which strings corresponds to valid programs, and which ones do not (i.e., which strings contain a syntax error). To ensure that a compiler or interpreter always halts when checking for syntax errors, language designers typically <em>do not</em> use a general Turing-complete mechanism to express their syntax. Rather they use a <em>restricted</em> computational model. One of the most popular choices for such models is <em>context free grammars</em>.</p>
<p>To explain context free grammars, let us begin with a canonical example. Consider the function <span><span class="math inline">\(\ensuremath{\mathit{ARITH}}:\Sigma^* \rightarrow \{0,1\}\)</span></span> that takes as input a string <span><span class="math inline">\(x\)</span></span> over the alphabet <span><span class="math inline">\(\Sigma = \{ (,),+,-,\times,\div,0,1,2,3,4,5,6,7,8,9\}\)</span></span> and returns <span><span class="math inline">\(1\)</span></span> if and only if the string <span><span class="math inline">\(x\)</span></span> represents a valid arithmetic expression. Intuitively, we build expressions by applying an operation such as <span><span class="math inline">\(+\)</span></span>,<span><span class="math inline">\(-\)</span></span>,<span><span class="math inline">\(\times\)</span></span> or <span><span class="math inline">\(\div\)</span></span> to smaller expressions, or enclosing them in parenthesis, where the “base case” corresponds to expressions that are simply numbers. More precisely, we can make the following definitions:</p>
<ul>
<li><p>A <em>digit</em> is one of the symbols <span><span class="math inline">\(0,1,2,3,4,5,6,7,8,9\)</span></span>.</p></li>
<li><p>A <em>number</em> is a sequence of digits. (For simplicity we drop the condition that the sequence does not have a leading zero, though it is not hard to encode it in a context-free grammar as well.)</p></li>
<li><p>An <em>operation</em> is one of <span><span class="math inline">\(+,-,\times,\div\)</span></span></p></li>
<li><p>An <em>expression</em> has either the form “<em>number</em>”, the form “<em>sub-expression1 operation sub-expression2</em>”, or the form “(<em>sub-expression1</em>)”, where “sub-expression1” and “sub-expression2” are themselves expressions. (Note that this is a <em>recursive</em> definition.)</p></li>
</ul>
<p>A context free grammar (CFG) is a formal way of specifying such conditions. A CFG consists of a set of <em>rules</em> that tell us how to generate strings from smaller components. In the above example, one of the rules is “if <span><span class="math inline">\(exp1\)</span></span> and <span><span class="math inline">\(exp2\)</span></span> are valid expressions, then <span><span class="math inline">\(exp1 \times exp2\)</span></span> is also a valid expression”; we can also write this rule using the shorthand <span><span class="math inline">\(expression \; \Rightarrow \; expression \; \times \; expression\)</span></span>. As in the above example, the rules of a context-free grammar are often <em>recursive</em>: the rule <span><span class="math inline">\(expression \; \Rightarrow\; expression \; \times \; expression\)</span></span> defines valid expressions in terms of itself. We now formally define context-free grammars:</p>
<div id="defcfg" class="definition" title="Context Free Grammar" name="Definition 9.19 (Context Free Grammar) ">
<p>Let <span><span class="math inline">\(\Sigma\)</span></span> be some finite set. A <em>context free grammar (CFG) over <span><span class="math inline">\(\Sigma\)</span></span></em> is a triple <span><span class="math inline">\((V,R,s)\)</span></span> such that:</p>
<ul>
<li><p><span><span class="math inline">\(V\)</span></span>, known as the <em>variables</em>, is a set disjoint from <span><span class="math inline">\(\Sigma\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(v\in V\)</span></span> is known as the <em>initial variable</em>.</p></li>
<li><p><span><span class="math inline">\(R\)</span></span> is a set of <em>rules</em>. Each rule is a pair <span><span class="math inline">\((v,z)\)</span></span> with <span><span class="math inline">\(v\in V\)</span></span> and <span><span class="math inline">\(z\in (\Sigma \cup V)^*\)</span></span>. We often write the rule <span><span class="math inline">\((v,z)\)</span></span> as <span><span class="math inline">\(v \Rightarrow z\)</span></span> and say that the string <span><span class="math inline">\(z\)</span></span> <em>can be derived</em> from the variable <span><span class="math inline">\(v\)</span></span>.</p></li>
</ul>
</div>
<div id="cfgarithmeticex" class="example" title="Context free grammar for arithmetic expressions" name="Example 9.20 (Context free grammar for arithmetic expressions) ">
<p>The example above of well-formed arithmetic expressions can be captured formally by the following context free grammar:</p>
<ul>
<li><p>The alphabet <span><span class="math inline">\(\Sigma\)</span></span> is <span><span class="math inline">\(\{ (,),+,-,\times,\div,0,1,2,3,4,5,6,7,8,9\}\)</span></span></p></li>
<li><p>The variables are <span><span class="math inline">\(V = \{ expression \;,\; number \;,\; digit \;,\; operation \}\)</span></span>.</p></li>
<li><p>The rules are the set <span><span class="math inline">\(R\)</span></span> containing the following <span><span class="math inline">\(19\)</span></span> rules:</p>
<ul>
<li><p>The <span><span class="math inline">\(4\)</span></span> rules <span><span class="math inline">\(operation \Rightarrow +\)</span></span>, <span><span class="math inline">\(operation \Rightarrow -\)</span></span>, <span><span class="math inline">\(operation \Rightarrow \times\)</span></span>, and <span><span class="math inline">\(operation \Rightarrow \div\)</span></span>.</p></li>
<li><p>The <span><span class="math inline">\(10\)</span></span> rules <span><span class="math inline">\(digit \Rightarrow 0\)</span></span>,<span><span class="math inline">\(\ldots\)</span></span>, <span><span class="math inline">\(digit \Rightarrow 9\)</span></span>.</p></li>
<li><p>The rule <span><span class="math inline">\(number \Rightarrow digit\)</span></span>.</p></li>
<li><p>The rule <span><span class="math inline">\(number \Rightarrow digit\; number\)</span></span>.</p></li>
<li><p>The rule <span><span class="math inline">\(expression \Rightarrow number\)</span></span>.</p></li>
<li><p>The rule <span><span class="math inline">\(expression \Rightarrow expression \; operation \; expression\)</span></span>.</p></li>
<li><p>The rule <span><span class="math inline">\(expression \Rightarrow (expression)\)</span></span>.</p></li>
</ul></li>
<li><p>The starting variable is <span><span class="math inline">\(expression\)</span></span></p></li>
</ul>
</div>
<p>People use many different notations to write context free grammars. One of the most common notations is the <a href="https://goo.gl/R4qZji">Backus–Naur form</a>. In this notation we write a rule of the form <span><span class="math inline">\(v \Rightarrow a\)</span></span> (where <span><span class="math inline">\(v\)</span></span> is a variable and <span><span class="math inline">\(a\)</span></span> is a string) in the form <code>&lt;v&gt; := a</code>. If we have several rules of the form <span><span class="math inline">\(v \mapsto a\)</span></span>, <span><span class="math inline">\(v \mapsto b\)</span></span>, and <span><span class="math inline">\(v \mapsto c\)</span></span> then we can combine them as <code>&lt;v&gt; := a|b|c</code>. (In words we say that <span><span class="math inline">\(v\)</span></span> can derive either <span><span class="math inline">\(a\)</span></span>, <span><span class="math inline">\(b\)</span></span>, or <span><span class="math inline">\(c\)</span></span>.) For example, the Backus-Naur description for the context free grammar of <a href='#cfgarithmeticex'>Example 9.20</a> is the following (using ASCII equivalents for operations):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1">operation  :<span class="op">=</span> <span class="op">+|-|*|/</span></a>
<a class="sourceLine" id="cb1-2" title="2">digit      :<span class="op">=</span> <span class="dv">0</span><span class="op">|</span><span class="dv">1</span><span class="op">|</span><span class="dv">2</span><span class="op">|</span><span class="dv">3</span><span class="op">|</span><span class="dv">4</span><span class="op">|</span><span class="dv">5</span><span class="op">|</span><span class="dv">6</span><span class="op">|</span><span class="dv">7</span><span class="op">|</span><span class="dv">8</span><span class="op">|</span><span class="dv">9</span></a>
<a class="sourceLine" id="cb1-3" title="3">number     :<span class="op">=</span> digit<span class="op">|</span>digit number</a>
<a class="sourceLine" id="cb1-4" title="4">expression :<span class="op">=</span> number<span class="op">|</span>expression operation expression<span class="op">|</span>(expression)</a></code></pre></div>
<p>Another example of a context free grammar is the “matching parenthesis” grammar, which can be represented in Backus-Naur as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1">match  :<span class="op">=</span> <span class="st">&quot;&quot;</span><span class="op">|</span>match match<span class="op">|</span>(match)</a></code></pre></div>
<p>A string over the alphabet <span><span class="math inline">\(\{\)</span></span> <code>(</code>,<code>)</code> <span><span class="math inline">\(\}\)</span></span> can be generated from this grammar (where <code>match</code> is the starting expression and <code>""</code> corresponds to the empty string) if and only if it consists of a matching set of parenthesis. In contrast, by <a href='#regexpparn'>Lemma 9.14</a> there is no regular expression that matches a string <span><span class="math inline">\(x\)</span></span> if and only if <span><span class="math inline">\(x\)</span></span> contains a valid sequence of matching parenthesis.</p>
<h3 id="context-free-grammars-as-a-computational-model" data-number="9.6.1">Context-free grammars as a computational model</h3>
<p>We can think of a context-free grammar over the alphabet <span><span class="math inline">\(\Sigma\)</span></span> as defining a function that maps every string <span><span class="math inline">\(x\)</span></span> in <span><span class="math inline">\(\Sigma^*\)</span></span> to <span><span class="math inline">\(1\)</span></span> or <span><span class="math inline">\(0\)</span></span> depending on whether <span><span class="math inline">\(x\)</span></span> can be generated by the rules of the grammars. We now make this definition formally.</p>
<div id="CFGderive" class="definition" title="Deriving a string from a grammar" name="Definition 9.21 (Deriving a string from a grammar) ">
<p>If <span><span class="math inline">\(G=(V,R,s)\)</span></span> is a context-free grammar over <span><span class="math inline">\(\Sigma\)</span></span>, then for two strings <span><span class="math inline">\(\alpha,\beta \in (\Sigma \cup V)^*\)</span></span> we say that <span><span class="math inline">\(\beta\)</span></span> <em>can be derived in one step</em> from <span><span class="math inline">\(\alpha\)</span></span>, denoted by <span><span class="math inline">\(\alpha \Rightarrow_G \beta\)</span></span>, if we can obtain <span><span class="math inline">\(\beta\)</span></span> from <span><span class="math inline">\(\alpha\)</span></span> by applying one of the rules of <span><span class="math inline">\(G\)</span></span>. That is, we obtain <span><span class="math inline">\(\beta\)</span></span> by replacing in <span><span class="math inline">\(\alpha\)</span></span> one occurrence of the variable <span><span class="math inline">\(v\)</span></span> with the string <span><span class="math inline">\(z\)</span></span>, where <span><span class="math inline">\(v \Rightarrow z\)</span></span> is a rule of <span><span class="math inline">\(G\)</span></span>.</p>
<p>We say that <span><span class="math inline">\(\beta\)</span></span> <em>can be derived</em> from <span><span class="math inline">\(\alpha\)</span></span>, denoted by <span><span class="math inline">\(\alpha \Rightarrow_G^* \beta\)</span></span>, if it can be derived by some finite number <span><span class="math inline">\(k\)</span></span> of steps. That is, if there are <span><span class="math inline">\(\alpha_1,\ldots,\alpha_{k-1} \in (\Sigma \cup V)^*\)</span></span>, so that <span><span class="math inline">\(\alpha \Rightarrow_G \alpha_1 \Rightarrow_G \alpha_2 \Rightarrow_G \cdots \Rightarrow_G \alpha_{k-1} \Rightarrow_G \beta\)</span></span>.</p>
<p>We say that <span><span class="math inline">\(x\in \Sigma^*\)</span></span> is <em>matched</em> by <span><span class="math inline">\(G=(V,R,s)\)</span></span> if <span><span class="math inline">\(x\)</span></span> can be derived from the starting variable <span><span class="math inline">\(s\)</span></span> (i.e., if <span><span class="math inline">\(s \Rightarrow_G^* x\)</span></span>). We define the <em>function computed by</em> <span><span class="math inline">\((V,R,s)\)</span></span> to be the map <span><span class="math inline">\(\Phi_{V,R,s}:\Sigma^* \rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(\Phi_{V,R,s}(x)=1\)</span></span> iff <span><span class="math inline">\(x\)</span></span> is matched by <span><span class="math inline">\((V,R,s)\)</span></span>. A function <span><span class="math inline">\(F:\Sigma^* \rightarrow \{0,1\}\)</span></span> is <em>context free</em> if <span><span class="math inline">\(F = \Phi_{V,R,s}\)</span></span> for some CFG <span><span class="math inline">\((V,R,s)\)</span></span>.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>
</div>
<p>A priori it might not be clear that the map <span><span class="math inline">\(\Phi_{V,R,s}\)</span></span> is computable, but it turns out that this is the case.</p>
<div id="CFGhalt" class="theorem" title="Context-free grammars always halt" name="Theorem 9.22 (Context-free grammars always halt) ">
<p>For every CFG <span><span class="math inline">\((V,R,s)\)</span></span> over <span><span class="math inline">\(\{0,1\}\)</span></span>, the function <span><span class="math inline">\(\Phi_{V,R,s}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is computable.</p>
</div>
<p>As usual we restrict attention to grammars over <span><span class="math inline">\(\{0,1\}\)</span></span> although the proof extends to any finite alphabet <span><span class="math inline">\(\Sigma\)</span></span>.</p>
<div class="proof" data-ref="CFGhalt" name="Solution 12.6.2">
<p>We only sketch the proof. We start with the observation we can convert every CFG to an equivalent version of <em>Chomsky normal form</em>, where all rules either have the form <span><span class="math inline">\(u \rightarrow vw\)</span></span> for variables <span><span class="math inline">\(u,v,w\)</span></span> or the form <span><span class="math inline">\(u \rightarrow \sigma\)</span></span> for a variable <span><span class="math inline">\(u\)</span></span> and symbol <span><span class="math inline">\(\sigma \in \Sigma\)</span></span>, plus potentially the rule <span><span class="math inline">\(s \rightarrow \ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> where <span><span class="math inline">\(s\)</span></span> is the starting variable.</p>
<p>The idea behind such a transformation is to simply add new variables as needed, and so for example we can translate a rule such as <span><span class="math inline">\(v \rightarrow u\sigma w\)</span></span> into the three rules <span><span class="math inline">\(v \rightarrow ur\)</span></span>, <span><span class="math inline">\(r \rightarrow tw\)</span></span> and <span><span class="math inline">\(t \rightarrow \sigma\)</span></span>.</p>
<p>Using the Chomsky Normal form we get a natural recursive algorithm for computing whether <span><span class="math inline">\(s \Rightarrow_G^* x\)</span></span> for a given grammar <span><span class="math inline">\(G\)</span></span> and string <span><span class="math inline">\(x\)</span></span>. We simply try all possible guesses for the first rule <span><span class="math inline">\(s \rightarrow uv\)</span></span> that is used in such a derivation, and then all possible ways to partition <span><span class="math inline">\(x\)</span></span> as a concatenation <span><span class="math inline">\(x=x&#39;x&#39;&#39;\)</span></span>. If we guessed the rule and the partition correctly, then this reduces our task to checking whether <span><span class="math inline">\(u \Rightarrow_G^* x&#39;\)</span></span> and <span><span class="math inline">\(v \Rightarrow_G^* x&#39;&#39;\)</span></span>, which (as it involves shorter strings) can be done recursively. The base cases are when <span><span class="math inline">\(x\)</span></span> is empty or a single symbol, and can be easily handled.</p>
</div>
<div id="parsetreesrem" class="remark" title="Parse trees" name="Remark 9.23 (Parse trees) ">
<p>While we focus on the task of <em>deciding</em> whether a CFG matches a string, the algorithm to compute <span><span class="math inline">\(\Phi_{V,R,s}\)</span></span> actually gives more information than that. That is, on input a string <span><span class="math inline">\(x\)</span></span>, if <span><span class="math inline">\(\Phi_{V,R,s}(x)=1\)</span></span> then the algorithm yields the sequence of rules that one can apply from the starting vertex <span><span class="math inline">\(s\)</span></span> to obtain the final string <span><span class="math inline">\(x\)</span></span>. We can think of these rules as determining a <em>tree</em> with <span><span class="math inline">\(s\)</span></span> being the <em>root</em> vertex and the sinks (or <em>leaves</em>) corresponding to the substrings of <span><span class="math inline">\(x\)</span></span> that are obtained by the rules that do not have a variable in their second element. This tree is known as the <em>parse tree</em> of <span><span class="math inline">\(x\)</span></span>, and often yields very useful information about the structure of <span><span class="math inline">\(x\)</span></span>.</p>
<p>Often the first step in a compiler or interpreter for a programming language is a <em>parser</em> that transforms the source into the parse tree (also known as the <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">abstract syntax tree</a>). There are also tools that can automatically convert a description of a context-free grammars into a parser algorithm that computes the parse tree of a given string. (Indeed, the above recursive algorithm can be used to achieve this, but there are much more efficient versions, especially for grammars that have <a href="https://en.wikipedia.org/wiki/LR_parser">particular forms</a>, and programming language designers often try to ensure their languages have these more efficient grammars.)</p>
</div>
<h3 id="the-power-of-context-free-grammars" data-number="9.6.2">The power of context free grammars</h3>
<p>Context free grammars can capture every regular expression:</p>
<div id="CFGreg" class="theorem" title="Context free grammars and regular expressions" name="Theorem 9.24 (Context free grammars and regular expressions) ">
<p>Let <span><span class="math inline">\(e\)</span></span> be a regular expression over <span><span class="math inline">\(\{0,1\}\)</span></span>, then there is a CFG <span><span class="math inline">\((V,R,s)\)</span></span> over <span><span class="math inline">\(\{0,1\}\)</span></span> such that <span><span class="math inline">\(\Phi_{V,R,s}=\Phi_{e}\)</span></span>.</p>
</div>
<div class="proof" data-ref="CFGreg" name="Proof 15.4">
<p>We prove the theorem by induction on the length of <span><span class="math inline">\(e\)</span></span>. If <span><span class="math inline">\(e\)</span></span> is an expression of one bit length, then <span><span class="math inline">\(e=0\)</span></span> or <span><span class="math inline">\(e=1\)</span></span>, in which case we leave it to the reader to verify that there is a (trivial) CFG that computes it. Otherwise, we fall into one of the following case: <strong>case 1:</strong> <span><span class="math inline">\(e = e&#39;e&#39;&#39;\)</span></span>, <strong>case 2:</strong> <span><span class="math inline">\(e = e&#39;|e&#39;&#39;\)</span></span> or <strong>case 3:</strong> <span><span class="math inline">\(e=(e&#39;)^*\)</span></span> where in all cases <span><span class="math inline">\(e&#39;,e&#39;&#39;\)</span></span> are shorter regular expressions. By the induction hypothesis have grammars <span><span class="math inline">\((V&#39;,R&#39;,s&#39;)\)</span></span> and <span><span class="math inline">\((V&#39;&#39;,R&#39;&#39;,s&#39;&#39;)\)</span></span> that compute <span><span class="math inline">\(\Phi_{e&#39;}\)</span></span> and <span><span class="math inline">\(\Phi_{e&#39;&#39;}\)</span></span> respectively. By renaming of variables, we can also assume without loss of generality that <span><span class="math inline">\(V&#39;\)</span></span> and <span><span class="math inline">\(V&#39;&#39;\)</span></span> are disjoint.</p>
<p>In case 1, we can define the new grammar as follows: we add a new starting variable <span><span class="math inline">\(s \not\in V \cup V&#39;\)</span></span> and the rule <span><span class="math inline">\(s \mapsto s&#39;s&#39;&#39;\)</span></span>. In case 2, we can define the new grammar as follows: we add a new starting variable <span><span class="math inline">\(s \not\in V \cup V&#39;\)</span></span> and the rules <span><span class="math inline">\(s \mapsto s&#39;\)</span></span> and <span><span class="math inline">\(s \mapsto s&#39;&#39;\)</span></span>. Case 3 will be the only one that uses <em>recursion</em>. As before we add a new starting variable <span><span class="math inline">\(s \not\in V \cup V&#39;\)</span></span>, but now add the rules <span><span class="math inline">\(s \mapsto \ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span> (i.e., the empty string) and also add, for every rule of the form <span><span class="math inline">\((s&#39;,\alpha) \in R&#39;\)</span></span>, the rule <span><span class="math inline">\(s \mapsto s\alpha\)</span></span> to <span><span class="math inline">\(R\)</span></span>.</p>
<p>We leave it to the reader as (a very good!) exercise to verify that in all three cases the grammars we produce capture the same function as the original expression.</p>
</div>
<p>It turns out that CFG’s are strictly more powerful than regular expressions. In particular, as we’ve seen, the “matching parenthesis” function <span><span class="math inline">\(\ensuremath{\mathit{MATCHPAREN}}\)</span></span> can be computed by a context free grammar, whereas, as shown in <a href='#regexpparn'>Lemma 9.14</a>, it cannot be computed by regular expressions. Here is another example:</p>
<div id="reversedstringcfg" class="solvedexercise" title="Context free grammar for palindromes" name="Solvedexercise 9.2 (Context free grammar for palindromes) ">
<p>Let <span><span class="math inline">\(\ensuremath{\mathit{PAL}}:\{0,1,;\}^* \rightarrow \{0,1\}\)</span></span> be the function defined in <a href='#palindromenotreg'>Solvedexercise 9.1</a> where <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(w)=1\)</span></span> iff <span><span class="math inline">\(w\)</span></span> has the form <span><span class="math inline">\(u;u^R\)</span></span>. Then <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span> can be computed by a context-free grammar</p>
</div>
<div class="solution" data-ref="reversedstringcfg" name="Solution 9.6.2">
<p>A simple grammar computing <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span> can be described using Backus–Naur notation:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1">start      :<span class="op">=</span> <span class="op">;</span> <span class="op">|</span> <span class="dv">0</span> start <span class="dv">0</span> <span class="op">|</span> <span class="dv">1</span> start <span class="dv">1</span></a></code></pre></div>
<p>One can prove by induction that this grammar generates exactly the strings <span><span class="math inline">\(w\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(w)=1\)</span></span>.</p>
</div>
<p>A more interesting example is computing the strings of the form <span><span class="math inline">\(u;v\)</span></span> that are <em>not</em> palindromes:</p>
<div id="nonpalindrome" class="solvedexercise" title="Non palindromes" name="Solvedexercise 9.3 (Non palindromes) ">
<p>Prove that there is a context free grammar that computes <span><span class="math inline">\(\ensuremath{\mathit{NPAL}}:\{0,1,;\}^* \rightarrow \{0,1\}\)</span></span> where <span><span class="math inline">\(\ensuremath{\mathit{NPAL}}(w)=1\)</span></span> if <span><span class="math inline">\(w=u;v\)</span></span> but <span><span class="math inline">\(v \neq u^R\)</span></span>.</p>
</div>
<div class="solution" data-ref="nonpalindrome" name="Solution 9.6.2">
<p>Using Backus–Naur notation we can describe such a grammar as follows</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">palindrome      :<span class="op">=</span> <span class="op">;</span> <span class="op">|</span> <span class="dv">0</span> palindrome <span class="dv">0</span> <span class="op">|</span> <span class="dv">1</span> palindrome <span class="dv">1</span></a>
<a class="sourceLine" id="cb4-2" title="2">different       :<span class="op">=</span> <span class="dv">0</span> palindrome <span class="dv">1</span> <span class="op">|</span> <span class="dv">1</span> palindrome <span class="dv">0</span></a>
<a class="sourceLine" id="cb4-3" title="3">start           :<span class="op">=</span> different <span class="op">|</span> <span class="dv">0</span> start <span class="op">|</span> <span class="dv">1</span> start <span class="op">|</span> start <span class="dv">0</span> <span class="op">|</span> start <span class="dv">1</span></a></code></pre></div>
<p>In words, this means that we can characterize a string <span><span class="math inline">\(w\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{NPAL}}(w)=1\)</span></span> as having the following form</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
w = \alpha b u ; u^R b&#39; \beta
\]</span></div></span></p>
<p>where <span><span class="math inline">\(\alpha,\beta,u\)</span></span> are arbitrary strings and <span><span class="math inline">\(b \neq b&#39;\)</span></span>. Hence we can generate such a string by first generating a palindrome <span><span class="math inline">\(u; u^R\)</span></span> (<code>palindrome</code> variable), then adding either <span><span class="math inline">\(0\)</span></span> on the right and <span><span class="math inline">\(1\)</span></span> on the left to get something that is <em>not</em> a palindrome (<code>different</code> variable), and then we can add arbitrary number of <span><span class="math inline">\(0\)</span></span>’s and <span><span class="math inline">\(1\)</span></span>’s on either end (the <code>start</code> variable).</p>
</div>
<h3 id="limitations-of-context-free-grammars-optional" data-number="9.6.3">Limitations of context-free grammars (optional)</h3>
<p>Even though context-free grammars are more powerful than regular expressions, there are some simple languages that are <em>not</em> captured by context free grammars. One tool to show this is the context-free grammar analog of the “pumping lemma” (<a href='#pumping'>Theorem 9.15</a>):</p>
<div id="cfgpumping" class="theorem" title="Context-free pumping lemma" name="Theorem 9.25 (Context-free pumping lemma) ">
<p>Let <span><span class="math inline">\((V,R,s)\)</span></span> be a CFG over <span><span class="math inline">\(\Sigma\)</span></span>, then there is some numbers <span><span class="math inline">\(n_0,n_1 in \N\)</span></span> such that for every <span><span class="math inline">\(x \in \Sigma^*\)</span></span> with <span><span class="math inline">\(|x|&gt;n_0\)</span></span>, if <span><span class="math inline">\(\Phi_{V,R,s}(x)=1\)</span></span> then <span><span class="math inline">\(x=abcde\)</span></span> such that <span><span class="math inline">\(|b|+|c|+|d| \leq n_1\)</span></span>, <span><span class="math inline">\(|b|+|d| \geq 1\)</span></span>, and <span><span class="math inline">\(\Phi_{V,R,s}(ab^kcd^ke)=1\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span>.</p>
</div>
<div class="pause" name="Pause 9.6.3">
<p>The context-free pumping lemma is even more cumbersome to state than its regular analog, but you can remember it as saying the following: <em>“If a long enough string is matched by a grammar, there must be a variable that is repeated in the derivation.”</em></p>
</div>
<div class="proof" data-ref="cfgpumping" name="Solution 12.6.2">
<p>We only sketch the proof. The idea is that if the total number of symbols in the rules of the grammar is <span><span class="math inline">\(k_0\)</span></span>, then the only way to get <span><span class="math inline">\(|x|&gt;n_0\)</span></span> with <span><span class="math inline">\(\Phi_{V,R,s}(x)=1\)</span></span> is to use <em>recursion</em>. That is, there must be some variable <span><span class="math inline">\(v \in V\)</span></span> such that we are able to derive from <span><span class="math inline">\(v\)</span></span> the value <span><span class="math inline">\(bvd\)</span></span> for some strings <span><span class="math inline">\(b,d \in \Sigma^*\)</span></span>, and then further on derive from <span><span class="math inline">\(v\)</span></span> some string <span><span class="math inline">\(c\in \Sigma^*\)</span></span> such that <span><span class="math inline">\(bcd\)</span></span> is a substring of <span><span class="math inline">\(x\)</span></span> (in other words, <span><span class="math inline">\(x=abcde\)</span></span> for some <span><span class="math inline">\(a,e \in \{0,1\}^*\)</span></span>). If we take the variable <span><span class="math inline">\(v\)</span></span> satisfying this requirement with a minimum number of derivation steps, then we can ensure that <span><span class="math inline">\(|bcd|\)</span></span> is at most some constant depending on <span><span class="math inline">\(n_0\)</span></span> and we can set <span><span class="math inline">\(n_1\)</span></span> to be that constant (<span><span class="math inline">\(n_1=10 \cdot |R| \cdot n_0\)</span></span> will do, since we will not need more than <span><span class="math inline">\(|R|\)</span></span> applications of rules, and each such application can grow the string by at most <span><span class="math inline">\(n_0\)</span></span> symbols).</p>
<p>Thus by the definition of the grammar, we can repeat the derivation to replace the substring <span><span class="math inline">\(bcd\)</span></span> in <span><span class="math inline">\(x\)</span></span> with <span><span class="math inline">\(b^kcd^k\)</span></span> for every <span><span class="math inline">\(k\in \N\)</span></span> while retaining the property that the output of <span><span class="math inline">\(\Phi_{V,R,s}\)</span></span> is still one. Since <span><span class="math inline">\(bcd\)</span></span> is a substring of <span><span class="math inline">\(x\)</span></span>, we can write <span><span class="math inline">\(x=abcde\)</span></span> and are guaranteed that <span><span class="math inline">\(ab^kcd^ke\)</span></span> is matched by the grammar for every <span><span class="math inline">\(k\)</span></span>.</p>
</div>
<p>Using <a href='#cfgpumping'>Theorem 9.25</a> one can show that even the simple function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> defined as follows: <span>
<div class='myequationbox'><span class="math display">\[F(x) = \begin{cases}1 &amp; x =ww \text{ for some } w\in \{0,1\}^* \\ 0 &amp; \text{otherwise} \end{cases}\]</span></div></span> is not context free. (In contrast, the function <span><span class="math inline">\(G:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> defined as <span><span class="math inline">\(G(x)=1\)</span></span> iff <span><span class="math inline">\(x=w_0w_1\cdots w_{n-1}w_{n-1}w_{n-2}\cdots w_0\)</span></span> for some <span><span class="math inline">\(w\in \{0,1\}^*\)</span></span> and <span><span class="math inline">\(n=|w|\)</span></span> is context free, can you see why?.)</p>
<div id="equalisnotcfg" class="solvedexercise" title="Equality is not context-free" name="Solvedexercise 9.4 (Equality is not context-free) ">
<p>Let <span><span class="math inline">\(\ensuremath{\mathit{EQ}}:\{0,1,;\}^* \rightarrow \{0,1\}\)</span></span> be the function such that <span><span class="math inline">\(\ensuremath{\mathit{EQ}}(x)=1\)</span></span> if and only if <span><span class="math inline">\(x=u;u\)</span></span> for some <span><span class="math inline">\(u\in \{0,1\}^*\)</span></span>. Then <span><span class="math inline">\(\ensuremath{\mathit{EQ}}\)</span></span> is not context free.</p>
</div>
<div class="solution" data-ref="equalisnotcfg" name="Solution 9.6.3">
<p>We use the context-free pumping lemma. Suppose towards the sake of contradiction that there is a grammar <span><span class="math inline">\(G\)</span></span> that computes <span><span class="math inline">\(\ensuremath{\mathit{EQ}}\)</span></span>, and let <span><span class="math inline">\(n_0\)</span></span> be the constant obtained from <a href='#cfgpumping'>Theorem 9.25</a>.</p>
<p>Consider the string <span><span class="math inline">\(x= 1^{n_0}0^{n_0};1^{n_0}0^{n_0}\)</span></span>, and write it as <span><span class="math inline">\(x=abcde\)</span></span> as per <a href='#cfgpumping'>Theorem 9.25</a>, with <span><span class="math inline">\(|bcd| \leq n_0\)</span></span> and with <span><span class="math inline">\(|b|+|d| \geq 1\)</span></span>. By <a href='#cfgpumping'>Theorem 9.25</a>, it should hold that <span><span class="math inline">\(\ensuremath{\mathit{EQ}}(ace)=1\)</span></span>. However, by case analysis this can be shown to be a contradiction.</p>
<p>Firstly, unless <span><span class="math inline">\(b\)</span></span> is on the left side of the <span><span class="math inline">\(;\)</span></span> separator and <span><span class="math inline">\(d\)</span></span> is on the right side, dropping <span><span class="math inline">\(b\)</span></span> and <span><span class="math inline">\(d\)</span></span> will definitely make the two parts different. But if it is the case that <span><span class="math inline">\(b\)</span></span> is on the left side and <span><span class="math inline">\(d\)</span></span> is on the right side, then by the condition that <span><span class="math inline">\(|bcd| \leq n_0\)</span></span> we know that <span><span class="math inline">\(b\)</span></span> is a string of only zeros and <span><span class="math inline">\(d\)</span></span> is a string of only ones. If we drop <span><span class="math inline">\(b\)</span></span> and <span><span class="math inline">\(d\)</span></span> then since one of them is non empty, we get that there are either less zeroes on the left side than on the right side, or there are less ones on the right side than on the left side. In either case, we get that <span><span class="math inline">\(\ensuremath{\mathit{EQ}}(ace)=0\)</span></span>, obtaining the desired contradiction.</p>
</div>
<h2 id="semantic-properties-of-context-free-languages" data-number="9.7">Semantic properties of context free languages</h2>
<p>As in the case of regular expressions, the limitations of context free grammars do provide some advantages. For example, emptiness of context free grammars is decidable:</p>
<div id="cfgemptinessthem" class="theorem" title="Emptiness for CFG&#39;s is decidable" name="Theorem 9.26 (Emptiness for CFG&#39;s is decidable) ">
<p>There is an algorithm that on input a context-free grammar <span><span class="math inline">\(G\)</span></span>, outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(\Phi_G\)</span></span> is the constant zero function.</p>
</div>
<div id="section-8" class="proofidea" data-ref="cfgemptinessthem" name="Proofidea">
<p>The proof is easier to see if we transform the grammar to Chomsky Normal Form as in <a href='#CFGhalt'>Theorem 9.22</a>. Given a grammar <span><span class="math inline">\(G\)</span></span>, we can recursively define a non-terminal variable <span><span class="math inline">\(v\)</span></span> to be <em>non empty</em> if there is either a rule of the form <span><span class="math inline">\(v \Rightarrow \sigma\)</span></span>, or there is a rule of the form <span><span class="math inline">\(v \Rightarrow uw\)</span></span> where both <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(w\)</span></span> are non empty. Then the grammar is non empty if and only if the starting variable <span><span class="math inline">\(s\)</span></span> is non-empty.</p>
</div>
<div class="proof" data-ref="cfgemptinessthem" name="Proof 9.7">
<p>We assume that the grammar <span><span class="math inline">\(G\)</span></span> in Chomsky Normal Form as in <a href='#CFGhalt'>Theorem 9.22</a>. We consider the following procedure for marking variables as “non empty”:</p>
<ol type="1">
<li><p>We start by marking all variables <span><span class="math inline">\(v\)</span></span> that are involved in a rule of the form <span><span class="math inline">\(v \Rightarrow \sigma\)</span></span> as non empty.</p></li>
<li><p>We then continue to mark <span><span class="math inline">\(v\)</span></span> as non empty if it is involved in a rule of the form <span><span class="math inline">\(v \Rightarrow uw\)</span></span> where <span><span class="math inline">\(u,w\)</span></span> have been marked before.</p></li>
</ol>
<p>We continue this way until we cannot mark any more variables. We then declare that the grammar is empty if and only if <span><span class="math inline">\(s\)</span></span> has not been marked. To see why this is a valid algorithm, note that if a variable <span><span class="math inline">\(v\)</span></span> has been marked as “non empty” then there is some string <span><span class="math inline">\(\alpha\in \Sigma^*\)</span></span> that can be derived from <span><span class="math inline">\(v\)</span></span>. On the other hand, if <span><span class="math inline">\(v\)</span></span> has not been marked, then every sequence of derivations from <span><span class="math inline">\(v\)</span></span> will always have a variable that has not been replaced by alphabet symbols. Hence in particular <span><span class="math inline">\(\Phi_G\)</span></span> is the all zero function if and only if the starting variable <span><span class="math inline">\(s\)</span></span> is not marked “non empty”.</p>
</div>
<h3 id="uncomputability-of-context-free-grammar-equivalence-optional" data-number="9.7.1">Uncomputability of context-free grammar equivalence (optional)</h3>
<p>By analogy to regular expressions, one might have hoped to get an algorithm for deciding whether two given context free grammars are equivalent. Alas, no such luck. It turns out that the equivalence problem for context free grammars is <em>uncomputable</em>. This is a direct corollary of the following theorem:</p>
<div id="fullnesscfgdef" class="theorem" title="Fullness of CFG&#39;s is uncomputable" name="Theorem 9.27 (Fullness of CFG&#39;s is uncomputable) ">
<p>For every set <span><span class="math inline">\(\Sigma\)</span></span>, let <span><span class="math inline">\(\ensuremath{\mathit{CFGFULL}}_\Sigma\)</span></span> be the function that on input a context-free grammar <span><span class="math inline">\(G\)</span></span> over <span><span class="math inline">\(\Sigma\)</span></span>, outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(G\)</span></span> computes the constant <span><span class="math inline">\(1\)</span></span> function. Then there is some finite <span><span class="math inline">\(\Sigma\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{CFGFULL}}_\Sigma\)</span></span> is uncomputable.</p>
</div>
<p><a href='#fullnesscfgdef'>Theorem 9.27</a> immediately implies that equivalence for context-free grammars is uncomputable, since computing “fullness” of a grammar <span><span class="math inline">\(G\)</span></span> over some alphabet <span><span class="math inline">\(\Sigma = \{\sigma_0,\ldots,\sigma_{k-1} \}\)</span></span> corresponds to checking whether <span><span class="math inline">\(G\)</span></span> is equivalent to the grammar <span><span class="math inline">\(s \Rightarrow \ensuremath{\text{\texttt{&quot;&quot;}}}|s\sigma_0|\cdots|s\sigma_{k-1}\)</span></span>. Note that <a href='#fullnesscfgdef'>Theorem 9.27</a> and <a href='#cfgemptinessthem'>Theorem 9.26</a> together imply that context-free grammars, unlike regular expressions, are <em>not</em> closed under complement. (Can you see why?) Since we can encode every element of <span><span class="math inline">\(\Sigma\)</span></span> using <span><span class="math inline">\(\ceil{\log |\Sigma|}\)</span></span> bits (and this finite encoding can be easily carried out within a grammar) <a href='#fullnesscfgdef'>Theorem 9.27</a> implies that fullness is also uncomputable for grammars over the binary alphabet.</p>
<div class="proofidea" data-ref="fullnesscfgdef" name="Proofidea 9.7.1">
<p>We prove the theorem by reducing from the Halting problem. To do that we use the notion of <em>configurations</em> of NAND-TM programs, as defined in <a href='lec_07_other_models.html#configtmdef'>Definition 7.8</a>. Recall that a <em>configuration</em> of a program <span><span class="math inline">\(P\)</span></span> is a binary string <span><span class="math inline">\(s\)</span></span> that encodes all the information about the program in the current iteration.</p>
<p>We define <span><span class="math inline">\(\Sigma\)</span></span> to be <span><span class="math inline">\(\{0,1\}\)</span></span> plus some separator characters and define <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_P:\Sigma^* \rightarrow \{0,1\}\)</span></span> to be the function that maps every string <span><span class="math inline">\(L\in \Sigma^*\)</span></span> to <span><span class="math inline">\(1\)</span></span> if and only <span><span class="math inline">\(L\)</span></span> does <em>not</em> encode a sequence of configurations that correspond to a valid halting history of the computation of <span><span class="math inline">\(P\)</span></span> on the empty input.</p>
<p>The heart of the proof is to show that <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_P\)</span></span> is context-free. Once we do that, we see that <span><span class="math inline">\(P\)</span></span> halts on the empty input if and only if <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_P(L)=1\)</span></span> for <em>every</em> <span><span class="math inline">\(L\)</span></span>. To show that, we will encode the list in a special way that makes it amenable to deciding via a context-free grammar. Specifically we will reverse all the odd-numbered strings.</p>
</div>
<div class="proof" data-ref="fullnesscfgdef" name="Solution 12.6.2">
<p>We only sketch the proof. We will show that if we can compute <span><span class="math inline">\(\ensuremath{\mathit{CFGFULL}}\)</span></span> then we can solve <span><span class="math inline">\(\ensuremath{\mathit{HALTONZERO}}\)</span></span>, which has been proven uncomputable in <a href='lec_08_uncomputability.html#haltonzero-thm'>Theorem 8.10</a>. Let <span><span class="math inline">\(M\)</span></span> be an input Turing machine for <span><span class="math inline">\(\ensuremath{\mathit{HALTONZERO}}\)</span></span>. We will use the notion of <em>configurations</em> of a Turing machine, as defined in <a href='lec_07_other_models.html#configtmdef'>Definition 7.8</a>.</p>
<p>Recall that a <em>configuration</em> of Turing machine <span><span class="math inline">\(M\)</span></span> and input <span><span class="math inline">\(x\)</span></span> captures the full state of <span><span class="math inline">\(M\)</span></span> at some point of the computation. The particular details of configurations are not so important, but what you need to remember is that:</p>
<ul>
<li><p>A configuration can be encoded by a binary string <span><span class="math inline">\(\sigma \in \{0,1\}^*\)</span></span>.</p></li>
<li><p>The <em>initial</em> configuration of <span><span class="math inline">\(M\)</span></span> on the input <span><span class="math inline">\(0\)</span></span> is some fixed string.</p></li>
<li><p>A <em>halting configuration</em> will have the value a certain state (which can be easily “read off” from it) set to <span><span class="math inline">\(1\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(\sigma\)</span></span> is a configuration at some step <span><span class="math inline">\(i\)</span></span> of the computation, we denote by <span><span class="math inline">\(\ensuremath{\mathit{NEXT}}_M(\sigma)\)</span></span> as the configuration at the next step. <span><span class="math inline">\(\ensuremath{\mathit{NEXT}}_M(\sigma)\)</span></span> is a string that agrees with <span><span class="math inline">\(\sigma\)</span></span> on all but a constant number of coordinates (those encoding the position corresponding to the head position and the two adjacent ones). On those coordinates, the value of <span><span class="math inline">\(\ensuremath{\mathit{NEXT}}_M(\sigma)\)</span></span> can be computed by some finite function.</p></li>
</ul>
<p>We will let the alphabet <span><span class="math inline">\(\Sigma = \{0,1\} \cup \{ \| , \# \}\)</span></span>. A <em>computation history</em> of <span><span class="math inline">\(M\)</span></span> on the input <span><span class="math inline">\(0\)</span></span> is a string <span><span class="math inline">\(L\in \Sigma\)</span></span> that corresponds to a list <span><span class="math inline">\(\| \sigma_0 \# \sigma_1 \| \sigma_2 \# \sigma_3 \cdots \sigma_{t-2} \| \sigma_{t-1} \#\)</span></span> (i.e., <span><span class="math inline">\(\|\)</span></span> comes before an even numbered block, and <span><span class="math inline">\(\|\)</span></span> comes before an odd numbered one) such that if <span><span class="math inline">\(i\)</span></span> is even then <span><span class="math inline">\(\sigma_i\)</span></span> is the string encoding the configuration of <span><span class="math inline">\(P\)</span></span> on input <span><span class="math inline">\(0\)</span></span> at the beginning of its <span><span class="math inline">\(i\)</span></span>-th iteration, and if <span><span class="math inline">\(i\)</span></span> is odd then it is the same except the string is <em>reversed</em>. (That is, for odd <span><span class="math inline">\(i\)</span></span>, <span><span class="math inline">\(rev(\sigma_i)\)</span></span> encodes the configuration of <span><span class="math inline">\(P\)</span></span> on input <span><span class="math inline">\(0\)</span></span> at the beginning of its <span><span class="math inline">\(i\)</span></span>-th iteration.) Reversing the odd-numbered blocks is a technical trick to ensure that the function <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M\)</span></span> we define below is context free.</p>
<p>We now define <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M:\Sigma^* \rightarrow \{0,1\}\)</span></span> as follows:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\ensuremath{\mathit{INVALID}}_M(L) = \begin{cases}0 &amp; \text{$L$ is a valid computation history of $M$ on $0$} \\
                            1 &amp; \text{otherwise} \end{cases}
\]</span></div></span></p>
<p>We will show the following claim:</p>
<p><strong>CLAIM:</strong> <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M\)</span></span> is context-free.</p>
<p>The claim implies the theorem. Since <span><span class="math inline">\(M\)</span></span> halts on <span><span class="math inline">\(0\)</span></span> if and only if there exists a valid computation history, <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M\)</span></span> is the constant one function if and only if <span><span class="math inline">\(M\)</span></span> does <em>not</em> halt on <span><span class="math inline">\(0\)</span></span>. In particular, this allows us to reduce determining whether <span><span class="math inline">\(M\)</span></span> halts on <span><span class="math inline">\(0\)</span></span> to determining whether the grammar <span><span class="math inline">\(G_M\)</span></span> corresponding to <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M\)</span></span> is full.</p>
<p>We now turn to the proof of the claim. We will not show all the details, but the main point <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M(L)=1\)</span></span> if <em>at least one</em> of the following three conditions hold:</p>
<ol type="1">
<li><p><span><span class="math inline">\(L\)</span></span> is not of the right format, i.e. not of the form <span><span class="math inline">\(\langle \text{binary-string} \rangle \# \langle \text{binary-string} \rangle \| \langle \text{binary-string} \rangle \# \cdots\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(L\)</span></span> contains a substring of the form <span><span class="math inline">\(\| \sigma \# \sigma&#39; \|\)</span></span> such that <span><span class="math inline">\(\sigma&#39; \neq rev(\ensuremath{\mathit{NEXT}}_P(\sigma))\)</span></span></p></li>
<li><p><span><span class="math inline">\(L\)</span></span> contains a substring of the form <span><span class="math inline">\(\# \sigma \| \sigma&#39; \#\)</span></span> such that <span><span class="math inline">\(\sigma&#39; \neq \ensuremath{\mathit{NEXT}}_P(rev(\sigma))\)</span></span></p></li>
</ol>
<p>Since context-free functions are closed under the OR operation, the claim will follow if we show that we can verify conditions 1, 2 and 3 via a context-free grammar.</p>
<p>For condition 1 this is very simple: checking that <span><span class="math inline">\(L\)</span></span> <em>is</em> of the correct format can be done using a regular expression. Since regular expressions are closed under negation, this means that checking that <span><span class="math inline">\(L\)</span></span> is <em>not</em> of this format can also be done by a regular expression and hence by a context-free grammar.</p>
<p>For conditions 2 and 3, this follows via very similar reasoning to that showing that the function <span><span class="math inline">\(F\)</span></span> such that <span><span class="math inline">\(F(u\#v)=1\)</span></span> iff <span><span class="math inline">\(u \neq rev(v)\)</span></span> is context-free, see <a href='#nonpalindrome'>Solvedexercise 9.3</a>. After all, the <span><span class="math inline">\(\ensuremath{\mathit{NEXT}}_M\)</span></span> function only modifies its input in a constant number of places. We leave filling out the details as an exercise to the reader. Since <span><span class="math inline">\(\ensuremath{\mathit{INVALID}}_M(L)=1\)</span></span> if and only if <span><span class="math inline">\(L\)</span></span> satisfies one of the conditions 1., 2. or 3., and all three conditions can be tested for via a context-free grammar, this completes the proof of the claim and hence the theorem.</p>
</div>
<h2 id="summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars" data-number="9.8">Summary of semantic properties for regular expressions and context-free grammars</h2>
<p>To summarize, we can often trade <em>expressiveness</em> of the model for <em>amenability to analysis</em>. If we consider computational models that are <em>not</em> Turing complete, then we are sometimes able to bypass Rice’s Theorem and answer certain semantic questions about programs in such models. Here is a summary of some of what is known about semantic questions for the different models we have seen.</p>
<p><a name="semantictable"></a></p>
<table style="width:100%;">
<caption>Computability of semantic properties</caption>
<colgroup>
<col style="width: 35%" />
<col style="width: 19%" />
<col style="width: 21%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th><p><em>Model</em></p></th>
<th><p><strong>Halting</strong></p></th>
<th><p><strong>Emptiness</strong></p></th>
<th><p><strong>Equivalence</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><em>Regular expressions</em></p></td>
<td><p>Computable</p></td>
<td><p>Computable</p></td>
<td><p>Computable</p></td>
</tr>
<tr class="even">
<td><p><em>Context free grammars</em></p></td>
<td><p>Computable</p></td>
<td><p>Computable</p></td>
<td><p>Uncomputable</p></td>
</tr>
<tr class="odd">
<td><p><em>Turing-complete models</em></p></td>
<td><p>Uncomputable</p></td>
<td><p>Uncomputable</p></td>
<td><p>Uncomputable</p></td>
</tr>
</tbody>
</table>
<div id="section-9" class="recap" name="Recap">
<ul>
<li>The uncomputability of the Halting problem for general models motivates the definition of restricted computational models.</li>
<li>In some restricted models we can answer <em>semantic</em> questions such as: does a given program terminate, or do two programs compute the same function?</li>
<li><em>Regular expressions</em> are a restricted model of computation that is often useful to capture tasks of string matching. We can test efficiently whether an expression matches a string, as well as answer questions such as Halting and Equivalence.</li>
<li><em>Context free grammars</em> is a stronger, yet still not Turing complete, model of computation. The halting problem for context free grammars is computable, but equivalence is not computable.</li>
</ul>
</div>
<h2 id="exercises" data-number="9.9">Exercises</h2>
<div id="closureregex" class="exercise" title="Closure properties of regular functions" name="Exercise 9.1 (Closure properties of regular functions) ">
<p>Suppose that <span><span class="math inline">\(F,G:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> are regular. For each one of the following definitions of the function <span><span class="math inline">\(H\)</span></span>, either prove that <span><span class="math inline">\(H\)</span></span> is always regular or give a counterexample for regular <span><span class="math inline">\(F,G\)</span></span> that would make <span><span class="math inline">\(H\)</span></span> not regular.</p>
<ol type="1">
<li><p><span><span class="math inline">\(H(x) = F(x) \vee G(x)\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(H(x) = F(x) \wedge G(x)\)</span></span></p></li>
<li><p><span><span class="math inline">\(H(x) = \ensuremath{\mathit{NAND}}(F(x),G(x))\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(H(x) = F(x^R)\)</span></span> where <span><span class="math inline">\(x^R\)</span></span> is the reverse of <span><span class="math inline">\(x\)</span></span>: <span><span class="math inline">\(x^R = x_{n-1}x_{n-2} \cdots x_o\)</span></span> for <span><span class="math inline">\(n=|x|\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(H(x) = \begin{cases}1 &amp; x=uv \text{ s.t. } F(u)=G(v)=1 \\ 0 &amp; \text{otherwise} \end{cases}\)</span></span></p></li>
<li><p><span><span class="math inline">\(H(x) = \begin{cases}1 &amp; x=uu \text{ s.t. } F(u)=G(u)=1 \\ 0 &amp; \text{otherwise} \end{cases}\)</span></span></p></li>
<li><p><span><span class="math inline">\(H(x) = \begin{cases}1 &amp; x=uu^R \text{ s.t. } F(u)=G(u)=1 \\ 0 &amp; \text{otherwise} \end{cases}\)</span></span></p></li>
</ol>
</div>
<div id="regularno" class="exercise" name="Exercise 9.2">
<p>One among the following two functions that map <span><span class="math inline">\(\{0,1\}^*\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> can be computed by a regular expression, and the other one cannot. For the one that can be computed by a regular expression, write the expression that does it. For the one that cannot, prove that this cannot be done using the pumping lemma. * <span><span class="math inline">\(F(x)=1\)</span></span> if <span><span class="math inline">\(4\)</span></span> divides <span><span class="math inline">\(\sum_{i=0}^{|x|-1} x_i\)</span></span> and <span><span class="math inline">\(F(x)=0\)</span></span> otherwise.</p>
<ul>
<li><span><span class="math inline">\(G(x) = 1\)</span></span> if and only if <span><span class="math inline">\(\sum_{i=0}^{|x|-1} x_i \geq |x|/4\)</span></span> and <span><span class="math inline">\(G(x)=0\)</span></span> otherwise.</li>
</ul>
</div>
<div id="nonregex" class="exercise" title="Non regularity" name="Exercise 9.3 (Non regularity) ">
<ol type="1">
<li><p>Prove that the following function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is not regular. For every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F(x)=1\)</span></span> iff <span><span class="math inline">\(x\)</span></span> is of the form <span><span class="math inline">\(x=1^{3^i}\)</span></span> for some <span><span class="math inline">\(i&gt;0\)</span></span>.</p></li>
<li><p>Prove that the following function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is not regular. For every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F(x)=1\)</span></span> iff <span><span class="math inline">\(\sum_j x_j = 3^i\)</span></span> for some <span><span class="math inline">\(i&gt;0\)</span></span>.</p></li>
</ol>
</div>
<div id="closurecfgex" class="exercise" title="Closure properties of context-free functions" name="Exercise 9.4 (Closure properties of context-free functions) ">
<p>Suppose that <span><span class="math inline">\(F,G:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> are context free. For each one of the following definitions of the function <span><span class="math inline">\(H\)</span></span>, either prove that <span><span class="math inline">\(H\)</span></span> is always context free or give a counterexample for regular <span><span class="math inline">\(F,G\)</span></span> that would make <span><span class="math inline">\(H\)</span></span> not context free.</p>
<ol type="1">
<li><p><span><span class="math inline">\(H(x) = F(x) \vee G(x)\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(H(x) = F(x) \wedge G(x)\)</span></span></p></li>
<li><p><span><span class="math inline">\(H(x) = \ensuremath{\mathit{NAND}}(F(x),G(x))\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(H(x) = F(x^R)\)</span></span> where <span><span class="math inline">\(x^R\)</span></span> is the reverse of <span><span class="math inline">\(x\)</span></span>: <span><span class="math inline">\(x^R = x_{n-1}x_{n-2} \cdots x_o\)</span></span> for <span><span class="math inline">\(n=|x|\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(H(x) = \begin{cases}1 &amp; x=uv \text{ s.t. } F(u)=G(v)=1 \\ 0 &amp; \text{otherwise} \end{cases}\)</span></span></p></li>
<li><p><span><span class="math inline">\(H(x) = \begin{cases}1 &amp; x=uu \text{ s.t. } F(u)=G(u)=1 \\ 0 &amp; \text{otherwise} \end{cases}\)</span></span></p></li>
<li><p><span><span class="math inline">\(H(x) = \begin{cases}1 &amp; x=uu^R \text{ s.t. } F(u)=G(u)=1 \\ 0 &amp; \text{otherwise} \end{cases}\)</span></span></p></li>
</ol>
</div>
<div id="noncontextfreeex" class="exercise" name="Exercise 9.5">
<p>Prove that the function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(F(x)=1\)</span></span> if and only if <span><span class="math inline">\(|x|\)</span></span> is a power of two is not context free.</p>
</div>
<div id="proglanguagecfgex" class="exercise" title="Syntax for programming languages" name="Exercise 9.6 (Syntax for programming languages) ">
<p>Consider the following syntax of a “programming language” whose source can be written using the <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> character set:</p>
<ul>
<li><p><em>Variables</em> are obtained by a sequence of letters, numbers and underscores, but can’t start with a number.</p></li>
<li><p>A <em>statement</em> has either the form <code>foo = bar;</code> where <code>foo</code> and <code>bar</code> are variables, or the form <code>IF (foo) BEGIN ... END</code> where <code>...</code> is list of one or more statements, potentially separated by newlines.</p></li>
</ul>
<p>A <em>program</em> in our language is simply a sequence of statements (possibly separated by newlines or spaces).</p>
<ol type="1">
<li><p>Let <span><span class="math inline">\(\ensuremath{\mathit{VAR}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> be the function that given a string <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(x\)</span></span> corresponds to an ASCII encoding of a valid variable identifier. Prove that <span><span class="math inline">\(\ensuremath{\mathit{VAR}}\)</span></span> is regular.</p></li>
<li><p>Let <span><span class="math inline">\(\ensuremath{\mathit{SYN}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> be the function that given a string <span><span class="math inline">\(s \in \{0,1\}^*\)</span></span>, outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(s\)</span></span> is an ASCII encoding of a valid program in our language. Prove that <span><span class="math inline">\(\ensuremath{\mathit{SYN}}\)</span></span> is context free. (You do not have to specify the full formal grammar for <span><span class="math inline">\(\ensuremath{\mathit{SYN}}\)</span></span>, but you need to show that such a grammar exists.)</p></li>
<li><p>Prove that <span><span class="math inline">\(\ensuremath{\mathit{SYN}}\)</span></span> is not regular. See footnote for hint<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p></li>
</ol>
</div>
<h2 id="bibliographical-notes" data-number="9.10">Bibliographical notes</h2>
<p>The relation of regular expressions with finite automata is a beautiful topic, on which we only touch upon in this text. It is covered more extensively in  (<a href="https://scholar.google.com/scholar?hl=en&q=Sipser+Introduction+to+the+theory+of+computation" target="_blank">Sipser, 1997</a>)  (<a href="https://scholar.google.com/scholar?hl=en&q=Hopcroft,+Motwani,+Ullman+Introduction+to+automata+theory,+languages,+and+computation" target="_blank">Hopcroft, Motwani, Ullman, 2014</a>)  (<a href="https://scholar.google.com/scholar?hl=en&q=Kozen+Automata+and+computability" target="_blank">Kozen, 1997</a>) . These texts also discuss topics such as <em>non deterministic finite automata</em> (NFA) and the relation between context-free grammars and pushdown automata.</p>
<p>Our proof of <a href='#reglintimethm'>Theorem 9.6</a> is closely related to the <a href="https://goo.gl/mnKVMP">Myhill-Nerode Theorem</a>. One direction of the Myhill-Nerode theorem theorem can be stated as saying that if <span><span class="math inline">\(e\)</span></span> is a regular expression then there is at most a finite number of strings <span><span class="math inline">\(z_0,\ldots,z_{k-1}\)</span></span> such that <span><span class="math inline">\(\Phi_{e[z_i]} \neq \Phi_{e[z_j]}\)</span></span> for every <span><span class="math inline">\(0 \leq i\neq j &lt; k\)</span></span>.</p>
<p>As in the case of regular expressions, there are many resources available that cover context-free grammar in great detail. Chapter 2 of  (<a href="https://scholar.google.com/scholar?hl=en&q=Sipser+Introduction+to+the+theory+of+computation" target="_blank">Sipser, 1997</a>)  contains many examples of context-free grammars and their properties. There are also websites such as <a href="https://mdaines.github.io/grammophone/">Grammophone</a> where you can input grammars, and see what strings they generate, as well as some of the properties that they satisfy.</p>
<p>The adjective “context free” is used for CFG’s because a rule of the form <span><span class="math inline">\(v \mapsto a\)</span></span> means that we can <em>always</em> replace <span><span class="math inline">\(v\)</span></span> with the string <span><span class="math inline">\(a\)</span></span>, no matter what is the <em>context</em> in which <span><span class="math inline">\(v\)</span></span> appears. More generally, we might want to consider cases where the replacement rules depend on the context. This gives rise to the notion of <em>general (aka “Type 0”) grammars</em> that allow rules of the form <span><span class="math inline">\(a \Rightarrow b\)</span></span> where both <span><span class="math inline">\(a\)</span></span> and <span><span class="math inline">\(b\)</span></span> are strings over <span><span class="math inline">\((V \cup \Sigma)^*\)</span></span>. The idea is that if, for example, we wanted to enforce the condition that we only apply some rule such as <span><span class="math inline">\(v \mapsto 0w1\)</span></span> when <span><span class="math inline">\(v\)</span></span> is surrounded by three zeroes on both sides, then we could do so by adding a rule of the form <span><span class="math inline">\(000v000 \mapsto 0000w1000\)</span></span> (and of course we can add much more general conditions). Alas, this generality comes at a cost - general grammars are Turing complete and hence their halting problem is uncomputable. That is, there is no algorithm <span><span class="math inline">\(A\)</span></span> that can determine for every general grammar <span><span class="math inline">\(G\)</span></span> and a string <span><span class="math inline">\(x\)</span></span>, whether or not the grammar <span><span class="math inline">\(G\)</span></span> generates <span><span class="math inline">\(x\)</span></span>.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Chomsky_hierarchy">Chomsky Hierarchy</a> is a hierarchy of grammars from the least restrictive (most powerful) Type 0 grammars, which correspond to <em>recursively enumerable</em> languages (see <a href='lec_08_uncomputability.html#recursiveenumerableex'>Exercise 8.10</a>) to the most restrictive Type 3 grammars, which correspond to regular languages. Context-free languages correspond to Type 2 grammars. Type 1 grammars are <em>context sensitive grammars</em>. These are more powerful than context-free grammars but still less powerful than Turing machines. In particular functions/languages corresponding to context-sensitive grammars are always computable, and in fact can be computed by a <a href="https://en.wikipedia.org/wiki/Linear_bounded_automaton">linear bounded automatons</a> which are non-deterministic algorithms that take <span><span class="math inline">\(O(n)\)</span></span> space. For this reason, the class of functions/languages corresponding to context-sensitive grammars is also known as the complexity class <span><span class="math inline">\(\mathbf{NSPACE}O(n)\)</span></span>; we discuss space-bounded complexity in <a href='lec_14a_space_complexity.html#spacechap'>Chapter 16</a>). While Rice’s Theorem implies that we cannot compute any non-trivial semantic property of Type 0 grammars, the situation is more complex for other types of grammars: some semantic properties can be determined and some cannot, depending on the grammar’s place in the hierarchy.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>We use <em>function notation</em> in this book, but other texts often use the notion of <em>languages</em>, which are sets of strings. In that notation a language <span><span class="math inline">\(L \subseteq \Sigma^*\)</span></span> is called <em>regular</em> if and only if the corresponding function <span><span class="math inline">\(F_L\)</span></span> is regular, where <span><span class="math inline">\(F_L:\Sigma^* \rightarrow \{0,1\}\)</span></span> is the function that outputs <span><span class="math inline">\(1\)</span></span> on <span><span class="math inline">\(x\)</span></span> iff <span><span class="math inline">\(x\in L\)</span></span>.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>As in the case of <a href='#matchingregexpdef'>Definition 9.3</a> we can also use <em>language</em> rather than <em>function</em> notation and say that a language <span><span class="math inline">\(L \subseteq \Sigma^*\)</span></span> is <em>context free</em> if the function <span><span class="math inline">\(F\)</span></span> such that <span><span class="math inline">\(F(x)=1\)</span></span> iff <span><span class="math inline">\(x\in L\)</span></span> is context free.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>Try to see if you can “embed” in some way a function that looks similar to <span><span class="math inline">\(\ensuremath{\mathit{MATCHPAREN}}\)</span></span> in <span><span class="math inline">\(\ensuremath{\mathit{SYN}}\)</span></span>, so you can use a similar proof. Of course for a function to be non-regular, it does not need to utilize literal parentheses symbols.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 19:02:30</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_08a_restricted_models.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
