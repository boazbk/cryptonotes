<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Probabilistic computation</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Probabilistic computation" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.1</b> Exercises</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probabilistic computation</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_16_randomized_alg.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="randomizedalgchap" data-number="18">Probabilistic computation</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>See examples of randomized algorithms<br />
</li>
<li>Get more comfort with analyzing probabilistic processes and tail bounds<br />
</li>
<li>Success amplification using tail bounds<br />
</li>
</ul>
</div>
<blockquote>
<p><em>“in 1946 .. (I asked myself) what are the chances that a Canfield solitaire laid out with 52 cards will come out successfully? After spending a lot of time trying to estimate them by pure combinatorial calculations, I wondered whether a more practical method … might not be to lay it our say one hundred times and simple observe and count”</em>, Stanislaw Ulam, 1983</p>
</blockquote>
<blockquote>
<p><em>“The salient features of our method are that it is probabilistic … and with a controllable miniscule probability of error.”</em>, Michael Rabin, 1977</p>
</blockquote>
<p>In early computer systems, much effort was taken to drive <em>out</em> randomness and noise. Hardware components were prone to non-deterministic behavior from a number of causes, whether it was vacuum tubes overheating or actual physical bugs causing short circuits (see <a href='#bugfig'>Figure 18.1</a>). This motivated John von Neumann, one of the early computing pioneers, to write a paper on how to <em>error correct</em> computation, introducing the notion of <em>redundancy</em>.</p>
<figure>
<img src="../figure/bug.jpg" alt="18.1: A 1947 entry in the log book of the Harvard MARK II computer containing an actual bug that caused a hardware malfunction. By Courtesy of the Naval Surface Warfare Center." id="bugfig" class="margin" /><figcaption>18.1: A 1947 entry in the <a href="http://americanhistory.si.edu/collections/search/object/nmah_334663">log book</a> of the Harvard MARK II computer containing an actual bug that caused a hardware malfunction. By Courtesy of the Naval Surface Warfare Center.</figcaption>
</figure>
<p>So it is quite surprising that randomness turned out not just a hindrance but also a <em>resource</em> for computation, enabling us to achieve tasks much more efficiently than previously known. One of the first applications involved the very same John von Neumann. While he was sick in bed and playing cards, Stan Ulam came up with the observation that calculating statistics of a system could be done much faster by running several randomized simulations. He mentioned this idea to von Neumann, who became very excited about it; indeed, it turned out to be crucial for the neutron transport calculations that were needed for development of the Atom bomb and later on the hydrogen bomb. Because this project was highly classified, Ulam, von Neumann and their collaborators came up with the codeword “Monte Carlo” for this approach (based on the famous casinos where Ulam’s uncle gambled). The name stuck, and randomized algorithms are known as Monte Carlo algorithms to this day.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
<p>In this chapter, we will see some examples of randomized algorithms that use randomness to compute a quantity in a faster or simpler way than was known otherwise. We will describe the algorithms in an informal / “pseudo-code” way, rather than as NAND-TM, NAND-RAM programs or Turing macines. In <a href='lec_17_model_rand.html#chapmodelrand'>Chapter 19</a> we will discuss how to augment the computational models we say before to incorporate the ability to “toss coins”.</p>
<h2 id="finding-approximately-good-maximum-cuts." data-number="18.1">Finding approximately good maximum cuts.</h2>
<p>We start with the following example. Recall the <em>maximum cut problem</em> of finding, given a graph <span><span class="math inline">\(G=(V,E)\)</span></span>, the cut that maximizes the number of edges. This problem is <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard, which means that we do not know of any efficient algorithm that can solve it, but randomization enables a simple algorithm that can cut at least half of the edges:</p>
<div id="maxcutthm" class="theorem" title="Approximating max cut" name="Theorem 18.1 (Approximating max cut) ">
<p>There is an efficient probabilistic algorithm that on input an <span><span class="math inline">\(n\)</span></span>-vertex <span><span class="math inline">\(m\)</span></span>-edge graph <span><span class="math inline">\(G\)</span></span>, outputs a cut <span><span class="math inline">\((S,\overline{S})\)</span></span> that cuts at least <span><span class="math inline">\(m/2\)</span></span> of the edges of <span><span class="math inline">\(G\)</span></span> in expectation.</p>
</div>
<div id="section-1" class="proofidea" data-ref="maxcutthm" name="Proofidea">
<p>We simply choose a <em>random cut</em>: we choose a subset <span><span class="math inline">\(S\)</span></span> of vertices by choosing every vertex <span><span class="math inline">\(v\)</span></span> to be a member of <span><span class="math inline">\(S\)</span></span> with probability <span><span class="math inline">\(1/2\)</span></span> independently. It’s not hard to see that each edge is cut with probability <span><span class="math inline">\(1/2\)</span></span> and so the expected number of cut edges is <span><span class="math inline">\(m/2\)</span></span>.</p>
</div>
<div class="proof" data-ref="maxcutthm" name="Proof 18.1">
<p>The algorithm is extremely simple:</p>
<blockquote>
<div class="quote" name="Quote 18.1">
<p><strong>Algorithm Random Cut:</strong></p>
<p><strong>Input:</strong> Graph <span><span class="math inline">\(G=(V,E)\)</span></span> with <span><span class="math inline">\(n\)</span></span> vertices and <span><span class="math inline">\(m\)</span></span> edges. Denote <span><span class="math inline">\(V = \{ v_0,v_1,\ldots, v_{n-1}\}\)</span></span>.</p>
<p><strong>Operation:</strong></p>
<ol type="1">
<li><p>Pick <span><span class="math inline">\(x\)</span></span> uniformly at random in <span><span class="math inline">\(\{0,1\}^n\)</span></span>.</p></li>
<li><p>Let <span><span class="math inline">\(S \subseteq V\)</span></span> be the set <span><span class="math inline">\(\{ v_i \;:\; x_i = 1 \;,\; i\in [n] \}\)</span></span> that includes all vertices corresponding to coordinates of <span><span class="math inline">\(x\)</span></span> where <span><span class="math inline">\(x_i=1\)</span></span>.</p></li>
<li><p>Output the cut <span><span class="math inline">\((S,\overline{S})\)</span></span>.</p></li>
</ol>
</div>
</blockquote>
<p>We claim that the expected number of edges cut by the algorithm is <span><span class="math inline">\(m/2\)</span></span>. Indeed, for every edge <span><span class="math inline">\(e \in E\)</span></span>, let <span><span class="math inline">\(X_e\)</span></span> be the random variable such that <span><span class="math inline">\(X_e(x)=1\)</span></span> if the edge <span><span class="math inline">\(e\)</span></span> is cut by <span><span class="math inline">\(x\)</span></span>, and <span><span class="math inline">\(X_e(x)=0\)</span></span> otherwise. For every such edge <span><span class="math inline">\(e =\{ i,j \}\)</span></span>, <span><span class="math inline">\(X_e(x)=1\)</span></span> if and only if <span><span class="math inline">\(x_i \neq x_j\)</span></span>. Since the pair <span><span class="math inline">\((x_i,x_j)\)</span></span> obtains each of the values <span><span class="math inline">\(00,01,10,11\)</span></span> with probability <span><span class="math inline">\(1/4\)</span></span>, the probability that <span><span class="math inline">\(x_i \neq x_j\)</span></span> is <span><span class="math inline">\(1/2\)</span></span> and hence <span><span class="math inline">\(\E[X_e]=1/2\)</span></span>. If we let <span><span class="math inline">\(X\)</span></span> be the random variable corresponding to the total number of edges cut by <span><span class="math inline">\(S\)</span></span>, then <span><span class="math inline">\(X = \sum_{e\in E} X_e\)</span></span> and hence by linearity of expectation</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\E[X] = \sum_{e\in E} \E[X_e] = m(1/2) = m/2 \;.\]</span></div></span></p>
</div>
<p><strong>Randomized algorithms work in the worst case.</strong> It is tempting of a randomized algorithm such as the one of <a href='#maxcutthm'>Theorem 18.1</a> as an algorithm that works for a “random input graph” but it is actually much better than that. The expectation in this theorem is <em>not</em> taken over the choice of the graph, but rather only over the <em>random choices of the algorithm</em>. In particular, <em>for every graph <span><span class="math inline">\(G\)</span></span></em>, the algorithm is guaranteed to cut half of the edges of the input graph in expectation. That is,</p>
<div id="randomworstcaseidea" class="bigidea" name="Bigidea 23">
<p>A randomized algorithm outputs the correct value with good probability on <em>every possible input</em>.</p>
</div>
<p>We will define more formally what “good probability” means in <a href='lec_17_model_rand.html#chapmodelrand'>Chapter 19</a> but the crucial point is that this probability is always only taken over the random choices of the algorithm, while the input is <em>not</em> chosen at random.</p>
<h3 id="amplifying-the-success-of-randomized-algorithms" data-number="18.1.1">Amplifying the success of randomized algorithms</h3>
<p><a href='#maxcutthm'>Theorem 18.1</a> gives us an algorithm that cuts <span><span class="math inline">\(m/2\)</span></span> edges in <em>expectation</em>. But, as we saw before, expectation does not immediately imply concentration, and so a priori, it may be the case that when we run the algorithm, most of the time we don’t get a cut matching the expectation. Luckily, we can <em>amplify</em> the probability of success by repeating the process several times and outputting the best cut we find. We start by arguing that the probability the algorithm above succeeds in cutting at least <span><span class="math inline">\(m/2\)</span></span> edges is not <em>too</em> tiny.</p>
<div id="cutprob" class="lemma" name="Lemma 18.2">
<p>The probability that a random cut in an <span><span class="math inline">\(m\)</span></span> edge graph cuts at least <span><span class="math inline">\(m/2\)</span></span> edges is at least <span><span class="math inline">\(1/(2m)\)</span></span>.</p>
</div>
<div id="section-2" class="proofidea" data-ref="cutprob" name="Proofidea">
<p>To see the idea behind the proof, think of the case that <span><span class="math inline">\(m=1000\)</span></span>. In this case one can show that we will cut at least <span><span class="math inline">\(500\)</span></span> edges with probability at least <span><span class="math inline">\(0.001\)</span></span> (and so in particular larger than <span><span class="math inline">\(1/(2m)=1/2000\)</span></span>). Specifically, if we assume otherwise, then this means that with probability more than <span><span class="math inline">\(0.999\)</span></span> the algorithm cuts <span><span class="math inline">\(499\)</span></span> or fewer edges. But since we can never cut more than the total of <span><span class="math inline">\(1000\)</span></span> edges, given this assumption, the highest value the expected number of edges cut is if we cut exactly <span><span class="math inline">\(499\)</span></span> edges with probability <span><span class="math inline">\(0.999\)</span></span> and cut <span><span class="math inline">\(1000\)</span></span> edges with probability <span><span class="math inline">\(0.001\)</span></span>. Yet even in this case the expected number of edges will be <span><span class="math inline">\(0.999 \cdot 499 + 0.001 \cdot 1000 &lt; 500\)</span></span>, which contradicts the fact that we’ve calculated the expectation to be at least <span><span class="math inline">\(500\)</span></span> in <a href='#maxcutthm'>Theorem 18.1</a>.</p>
</div>
<div class="proof" data-ref="cutprob" name="Proof 18.1.1">
<p>Let <span><span class="math inline">\(p\)</span></span> be the probability that we cut at least <span><span class="math inline">\(m/2\)</span></span> edges and suppose, towards a contradiction, that <span><span class="math inline">\(p&lt;1/(2m)\)</span></span>. Since the number of edges cut is an integer, and <span><span class="math inline">\(m/2\)</span></span> is a multiple of <span><span class="math inline">\(0.5\)</span></span>, by definition of <span><span class="math inline">\(p\)</span></span>, with probability <span><span class="math inline">\(1-p\)</span></span> we cut at most <span><span class="math inline">\(m/2 - 0.5\)</span></span> edges. Moreover, since we can never cut more than <span><span class="math inline">\(m\)</span></span> edges, under our assumption that <span><span class="math inline">\(p&lt;m/2\)</span></span>, we can bound the expected number of edges cut by</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
pm + (1-p)(m/2-0.5)  \leq pm + m/2-0.5
\]</span></div></span> But if <span><span class="math inline">\(p&lt;1/(2m)\)</span></span> then <span><span class="math inline">\(pm&lt;0.5\)</span></span> and so the righthand side is smaller than <span><span class="math inline">\(m/2\)</span></span>, which contradicts the fact that (as proven in <a href='#maxcutthm'>Theorem 18.1</a>) the expected number of edges cut is at least <span><span class="math inline">\(m/2\)</span></span>.</p>
</div>
<h3 id="success-amplification" data-number="18.1.2">Success amplification</h3>
<p><a href='#cutprob'>Lemma 18.2</a> shows that our algorithm succeeds at least <em>some</em> of the time, but we’d like to succeed almost <em>all</em> of the time. The approach to do that is to simply <em>repeat</em> our algorithm many times, with fresh randomness each time, and output the best cut we get in one of these repetitions. It turns out that with extremely high probability we will get a cut of size at least <span><span class="math inline">\(m/2\)</span></span>. For example, if we repeat this experiment <span><span class="math inline">\(2000m\)</span></span> times, then (using the inequality <span><span class="math inline">\((1-1/k)^k \leq 1/e \leq 1/2\)</span></span>) we can show that the probability that we will never cut at least <span><span class="math inline">\(m/2\)</span></span> edges is at most</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
(1-1/(2m))^{2000 m} \leq 2^{-1000} \;.
\]</span></div></span></p>
<p>More generally, the same calculations can be used to show the following lemma:</p>
<div id="cutalgorithmamplificationlem" class="lemma" name="Lemma 18.3">
<p>There is an algorithm that on input a graph <span><span class="math inline">\(G=(V,E)\)</span></span> and a number <span><span class="math inline">\(k\)</span></span>, runs in time polynomial in <span><span class="math inline">\(|V|\)</span></span> and <span><span class="math inline">\(k\)</span></span> and outputs a cut <span><span class="math inline">\((S,\overline{S})\)</span></span> such that <span>
<div class='myequationbox'><span class="math display">\[
\Pr[ \text{number of edges cut by $(S,\overline{S})$ } \geq |E|/2 ] \geq 1- 2^{-k} \;.
\]</span></div></span></p>
</div>
<div class="proof" data-ref="cutalgorithmamplificationlem" name="Proof 18.1.2">
<p>The algorithm will work as follows:</p>
<blockquote>
<div class="quote" name="Quote 18.1.2">
<p><strong>Algorithm AMPLIFY RANDOM CUT:</strong></p>
<p><strong>Input:</strong> Graph <span><span class="math inline">\(G=(V,E)\)</span></span> with <span><span class="math inline">\(n\)</span></span> vertices and <span><span class="math inline">\(m\)</span></span> edges. Denote <span><span class="math inline">\(V = \{ v_0,v_1,\ldots, v_{n-1}\}\)</span></span>. Number <span><span class="math inline">\(k&gt;0\)</span></span>.</p>
<p><strong>Operation:</strong></p>
<ol type="1">
<li><p>Repeat the following <span><span class="math inline">\(200km\)</span></span> times:</p>
<ol type="a">
<li><p>Pick <span><span class="math inline">\(x\)</span></span> uniformly at random in <span><span class="math inline">\(\{0,1\}^n\)</span></span>.</p></li>
<li><p>Let <span><span class="math inline">\(S \subseteq V\)</span></span> be the set <span><span class="math inline">\(\{ v_i \;:\; x_i = 1 \;,\; i\in [n] \}\)</span></span> that includes all vertices corresponding to coordinates of <span><span class="math inline">\(x\)</span></span> where <span><span class="math inline">\(x_i=1\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\((S,\overline{S})\)</span></span> cuts at least <span><span class="math inline">\(m/2\)</span></span> then halt and output <span><span class="math inline">\((S,\overline{S})\)</span></span>.</p></li>
</ol></li>
<li><p>Output “failed”</p></li>
</ol>
</div>
</blockquote>
<p>We leave completing the analysis as an exercise to the reader (see <a href='#cutalgorithmamplificationlemex'>Exercise 18.1</a>).</p>
</div>
<h3 id="two-sided-amplification" data-number="18.1.3">Two-sided amplification</h3>
<p>The analysis above relied on the fact that the maximum cut has <em>one sided error</em>. By this we mean that if we get a cut of size at least <span><span class="math inline">\(m/2\)</span></span> then we know we have succeeded. This is common for randomized algorithms, but is not the only case. In particular, consider the task of computing some Boolean function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>. A randomized algorithm <span><span class="math inline">\(A\)</span></span> for computing <span><span class="math inline">\(F\)</span></span>, given input <span><span class="math inline">\(x\)</span></span>, might toss coins and succeed in outputting <span><span class="math inline">\(F(x)\)</span></span> with probability, say, <span><span class="math inline">\(0.9\)</span></span>. We say that <span><span class="math inline">\(A\)</span></span> has <em>two sided errors</em> if there is positive probability that <span><span class="math inline">\(A(x)\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> when <span><span class="math inline">\(F(x)=0\)</span></span>, and positive probability that <span><span class="math inline">\(A(x)\)</span></span> outputs <span><span class="math inline">\(0\)</span></span> when <span><span class="math inline">\(F(x)=1\)</span></span>. In such a case, to simplify <span><span class="math inline">\(A\)</span></span>’s success, we cannot simply repeat it <span><span class="math inline">\(k\)</span></span> times and output <span><span class="math inline">\(1\)</span></span> if a single one of those repetitions resulted in <span><span class="math inline">\(1\)</span></span>, nor can we output <span><span class="math inline">\(0\)</span></span> if a single one of the repetitions resulted in <span><span class="math inline">\(0\)</span></span>. But we can output the <em>majority value</em> of these repetitions. By the Chernoff bound (<a href='lec_15_probability.html#chernoffthm'>Theorem 17.12</a>), with probability <em>exponentially close</em> to <span><span class="math inline">\(1\)</span></span> (i.e., <span><span class="math inline">\(1-2^{\Omega(k)}\)</span></span>), the fraction of the repetitions where <span><span class="math inline">\(A\)</span></span> will output <span><span class="math inline">\(F(x)\)</span></span> will be at least, say <span><span class="math inline">\(0.89\)</span></span>, and in such cases we will of course output the correct answer.</p>
<p>The above translates into the following theorem</p>
<div id="amplifyalg" class="theorem" title="Two-sided amplification" name="Theorem 18.4 (Two-sided amplification) ">
<p>If <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is a function such that there is a polynomial-time algorithm <span><span class="math inline">\(A\)</span></span> satisfying <span>
<div class='myequationbox'><span class="math display">\[
\Pr[A(x) = F(x)] \geq 0.51
\]</span></div></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, then there is a polynomial time algorithm <span><span class="math inline">\(B\)</span></span> satisfying <span>
<div class='myequationbox'><span class="math display">\[
\Pr[ B(x) = F(x) ] \geq 1 - 2^{-|x|}
\]</span></div></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>.</p>
</div>
<p>We omit the proof of <a href='#amplifyalg'>Theorem 18.4</a>, since we will prove a more general result later on in <a href='lec_17_model_rand.html#amplificationthm'>Theorem 19.5</a>.</p>
<h3 id="what-does-this-mean" data-number="18.1.4">What does this mean?</h3>
<p>We have shown a probabilistic algorithm that on any <span><span class="math inline">\(m\)</span></span> edge graph <span><span class="math inline">\(G\)</span></span>, will output a cut of at least <span><span class="math inline">\(m/2\)</span></span> edges with probability at least <span><span class="math inline">\(1-2^{-1000}\)</span></span>. Does it mean that we can consider this problem as “easy”? Should we be somewhat wary of using a probabilistic algorithm, since it can sometimes fail?</p>
<p>First of all, it is important to emphasize that this is still a <em>worst case</em> guarantee. That is, we are not assuming anything about the <em>input graph</em>: the probability is only due to the <em>internal randomness of the algorithm</em>. While a probabilistic algorithm might not seem as nice as a deterministic algorithm that is <em>guaranteed</em> to give an output, to get a sense of what a failure probability of <span><span class="math inline">\(2^{-1000}\)</span></span> means, note that:</p>
<ul>
<li><p>The chance of winning the Massachusetts Mega Million lottery is one over <span><span class="math inline">\((75)^5\cdot 15\)</span></span> which is roughly <span><span class="math inline">\(2^{-35}\)</span></span>. So <span><span class="math inline">\(2^{-1000}\)</span></span> corresponds to winning the lottery about <span><span class="math inline">\(300\)</span></span> times in a row, at which point you might not care so much about your algorithm failing.</p></li>
<li><p>The chance for a U.S. resident to be struck by lightning is about <span><span class="math inline">\(1/700000\)</span></span>, which corresponds to about <span><span class="math inline">\(2^{-45}\)</span></span> chance that you’ll be struck by lightning the very second that you’re reading this sentence (after which again you might not care so much about the algorithm’s performance).</p></li>
<li><p>Since the earth is about 5 billion years old, we can estimate the chance that an asteroid of the magnitude that caused the dinosaurs’ extinction will hit us this very second to be about <span><span class="math inline">\(2^{-60}\)</span></span>. It is quite likely that even a deterministic algorithm will fail if this happens.</p></li>
</ul>
<p>So, in practical terms, a probabilistic algorithm is just as good as a deterministic one. But it is still a theoretically fascinating question whether randomized algorithms actually yield more power, or whether is it the case that for any computational problem that can be solved by probabilistic algorithm, there is a deterministic algorithm with nearly the same performance.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> For example, we will see in <a href='#maxcutex'>Exercise 18.2</a> that there is in fact a deterministic algorithm that can cut at least <span><span class="math inline">\(m/2\)</span></span> edges in an <span><span class="math inline">\(m\)</span></span>-edge graph. We will discuss this question in generality in <a href='lec_17_model_rand.html#chapmodelrand'>Chapter 19</a>. For now, let us see a couple of examples where randomization leads to algorithms that are better in some sense than the known deterministic algorithms.</p>
<h3 id="solving-sat-through-randomization" data-number="18.1.5">Solving SAT through randomization</h3>
<p>The 3SAT problem is <span><span class="math inline">\(\mathbf{NP}\)</span></span> hard, and so it is unlikely that it has a polynomial (or even subexponential) time algorithm. But this does not mean that we can’t do at least somewhat better than the trivial <span><span class="math inline">\(2^n\)</span></span> algorithm for <span><span class="math inline">\(n\)</span></span>-variable 3SAT. The best known worst-case algorithms for 3SAT are randomized, and are related to the following simple algorithm, variants of which are also used in practice:</p>
<blockquote>
<div class="quote" name="Quote 18.1.5">
<p><strong>Algorithm WalkSAT:</strong></p>
<p><strong>Input:</strong> An <span><span class="math inline">\(n\)</span></span> variable 3CNF formula <span><span class="math inline">\(\varphi\)</span></span>.</p>
<p><strong>Parameters:</strong> <span><span class="math inline">\(T,S \in \N\)</span></span></p>
<p><strong>Operation:</strong></p>
<ol type="1">
<li><p>Repeat the following <span><span class="math inline">\(T\)</span></span> steps:</p>
<ol type="a">
<li><p>Choose a random assignment <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> and repeat the following for <span><span class="math inline">\(S\)</span></span> steps:</p>
<ol type="1">
<li><p>If <span><span class="math inline">\(x\)</span></span> satisfies <span><span class="math inline">\(\varphi\)</span></span> then output <span><span class="math inline">\(x\)</span></span>.</p></li>
<li><p>Otherwise, choose a random clause <span><span class="math inline">\((\ell_i \vee \ell_j \vee \ell_k)\)</span></span> that <span><span class="math inline">\(x\)</span></span> does not satisfy, choose a random literal in <span><span class="math inline">\(\ell_i,\ell_j,\ell_k\)</span></span> and modify <span><span class="math inline">\(x\)</span></span> to satisfy this literal.</p></li>
</ol></li>
</ol></li>
<li><p>If all the <span><span class="math inline">\(T\cdot S\)</span></span> repetitions above did not result in a satisfying assignment then output <code>Unsatisfiable</code></p></li>
</ol>
</div>
</blockquote>
<p>The running time of this algorithm is <span><span class="math inline">\(S\cdot T \cdot poly(n)\)</span></span>, and so the key question is how small we can make <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span> so that the probability that WalkSAT outputs <code>Unsatisfiable</code> on a satisfiable formula <span><span class="math inline">\(\varphi\)</span></span> is small. It is known that we can do so with <span><span class="math inline">\(\ensuremath{\mathit{ST}} = \tilde{O}((4/3)^n) = \tilde{O}(1.333\ldots^n)\)</span></span> (see <a href='#walksatex'>Exercise 18.4</a> for a weaker result), but we’ll show below a simpler analysis yielding <span><span class="math inline">\(\ensuremath{\mathit{ST}}= \tilde{O}(\sqrt{3}^n) = \tilde{O}(1.74^n)\)</span></span>, which is still much better than the trivial <span><span class="math inline">\(2^n\)</span></span> bound.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>
<div id="walksatthm" class="theorem" title="WalkSAT simple analysis" name="Theorem 18.5 (WalkSAT simple analysis) ">
<p>If we set <span><span class="math inline">\(T=100\cdot \sqrt{3}^{n}\)</span></span> and <span><span class="math inline">\(S= n/2\)</span></span>, then the probability we output <code>Unsatisfiable</code> for a satisfiable <span><span class="math inline">\(\varphi\)</span></span> is at most <span><span class="math inline">\(1/2\)</span></span>.</p>
</div>
<div class="proof" data-ref="walksatthm" name="Proof 18.1.5">
<p>Suppose that <span><span class="math inline">\(\varphi\)</span></span> is a satisfiable formula and let <span><span class="math inline">\(x^*\)</span></span> be a satisfying assignment for it. For every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, denote by <span><span class="math inline">\(\Delta(x,x^*)\)</span></span> the number of coordinates that differ between <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(x^*\)</span></span>. The heart of the proof is the following claim:</p>
<p><strong>Claim I:</strong> For every <span><span class="math inline">\(x,x^*\)</span></span> as above, in every local improvement step, the value <span><span class="math inline">\(\Delta(x,x^*)\)</span></span> is decreased by one with probability at least <span><span class="math inline">\(1/3\)</span></span>.</p>
<p><strong>Proof of Claim I:</strong> Since <span><span class="math inline">\(x^*\)</span></span> is a <em>satisfying</em> assignment, if <span><span class="math inline">\(C\)</span></span> is a clause that <span><span class="math inline">\(x\)</span></span> does <em>not</em> satisfy, then at least one of the variables involve in <span><span class="math inline">\(C\)</span></span> must get different values in <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(x^*\)</span></span>. Thus when we change <span><span class="math inline">\(x\)</span></span> by one of the three literals in the clause, we have probability at least <span><span class="math inline">\(1/3\)</span></span> of decreasing the distance.</p>
<p>The second claim is that our starting point is not that bad:</p>
<p><strong>Claim 2:</strong> With probability at least <span><span class="math inline">\(1/2\)</span></span> over a random <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, <span><span class="math inline">\(\Delta(x,x^*) \leq n/2\)</span></span>.</p>
<p><strong>Proof of Claim II:</strong> Consider the map <span><span class="math inline">\(\ensuremath{\mathit{FLIP}}:\{0,1\}^n \rightarrow \{0,1\}^n\)</span></span> that simply “flips” all the bits of its input from <span><span class="math inline">\(0\)</span></span> to <span><span class="math inline">\(1\)</span></span> and vice versa. That is, <span><span class="math inline">\(\ensuremath{\mathit{FLIP}}(x_0,\ldots,x_{n-1}) = (1-x_0,\ldots,1-x_{n-1})\)</span></span>. Clearly <span><span class="math inline">\(\ensuremath{\mathit{FLIP}}\)</span></span> is one to one. Moreover, if <span><span class="math inline">\(x\)</span></span> is of distance <span><span class="math inline">\(k\)</span></span> to <span><span class="math inline">\(x^*\)</span></span>, then <span><span class="math inline">\(\ensuremath{\mathit{FLIP}}(x)\)</span></span> is distance <span><span class="math inline">\(n-k\)</span></span> to <span><span class="math inline">\(x^*\)</span></span>. Now let <span><span class="math inline">\(B\)</span></span> be the “bad event” in which <span><span class="math inline">\(x\)</span></span> is of distance <span><span class="math inline">\(&gt;n/2\)</span></span> from <span><span class="math inline">\(x^*\)</span></span>. Then the set <span><span class="math inline">\(A = \ensuremath{\mathit{FLIP}}(B) = \{ \ensuremath{\mathit{FLIP}}(x) \;:\; x\in \{0,1\}^n \}\)</span></span> satisfies <span><span class="math inline">\(|A|=|B|\)</span></span> and that if <span><span class="math inline">\(x\in A\)</span></span> then <span><span class="math inline">\(x\)</span></span> is of distance <span><span class="math inline">\(&lt;n/2\)</span></span> from <span><span class="math inline">\(x^*\)</span></span>. Since <span><span class="math inline">\(A\)</span></span> and <span><span class="math inline">\(B\)</span></span> are disjoint events, <span><span class="math inline">\(\Pr[A] + \Pr[B] \leq 1\)</span></span>. Since they have the same cardinality, they have the same probability and so we get that <span><span class="math inline">\(2\Pr[B] \leq 1\)</span></span> or <span><span class="math inline">\(\Pr[B] \leq 1/2\)</span></span>. (See also <a href='#flipaanalysisfig'>Figure 18.2</a>).</p>
<p>Claims I and II imply that each of the <span><span class="math inline">\(T\)</span></span> iterations of the outer loop succeeds with probability at least <span><span class="math inline">\(1/2\cdot\sqrt{3}^{-n}\)</span></span>. Indeed, by Claim II, the original guess <span><span class="math inline">\(x\)</span></span> will satisfy <span><span class="math inline">\(\Delta(x,x^*)\leq n/2\)</span></span> with probability <span><span class="math inline">\(\Pr[\Delta(x,x^*)\leq n/2]\geq 1/2\)</span></span>. By Claim I, even conditioned on all the history so far, for each of the <span><span class="math inline">\(S = n/2\)</span></span> steps of the inner loop we have probability at least <span><span class="math inline">\(\geq 1/3\)</span></span> of being “lucky” and decreasing the distance (i.e. the output of <span><span class="math inline">\(\Delta\)</span></span>) by one. The chance we will be lucky in all <span><span class="math inline">\(n/2\)</span></span> steps is hence at least <span><span class="math inline">\((1/3)^{n/2} = \sqrt{3}^{-n}\)</span></span>.</p>
<p>Since any single iteration of the outer loop succeeds with probability at least <span><span class="math inline">\(\tfrac{1}{2} \cdot \sqrt{3}^{-n}\)</span></span>, the probability that we never do so in <span><span class="math inline">\(T=100 \sqrt{3}^{n}\)</span></span> repetitions is at most <span><span class="math inline">\((1-\tfrac{1}{2\sqrt{3}^{n}})^{100\cdot \sqrt{3}^n} \leq (1/e)^{50}\)</span></span>.</p>
</div>
<figure>
<img src="../figure/flipaanalysis.png" alt="18.2: For every x^* \in \{0,1\}^n, we can sort all strings in \{0,1\}^n according to their distance from x^* (top to bottom in the above figure), where we let A = \{ x\in \{0,1\}^n \;|\; dist(x,x^* \leq n/2 \} be the “top half” of strings. If we define \ensuremath{\mathit{FLIP}}:\{0,1\}^n \rightarrow \{0,1\} to be the map that “flips” the bits of a given string x then it maps every x\in \overline{A} to an output \ensuremath{\mathit{FLIP}}(x)\in A in a one-to-one way, and so it demonstrates that |\overline{A}| \leq |A| which implies that \Pr[A] \geq \Pr[\overline{A}] and hence \Pr[A] \geq 1/2." id="flipaanalysisfig" class="margin" /><figcaption>18.2: For every <span><span class="math inline">\(x^* \in \{0,1\}^n\)</span></span>, we can sort all strings in <span><span class="math inline">\(\{0,1\}^n\)</span></span> according to their distance from <span><span class="math inline">\(x^*\)</span></span> (top to bottom in the above figure), where we let <span><span class="math inline">\(A = \{ x\in \{0,1\}^n \;|\; dist(x,x^* \leq n/2 \}\)</span></span> be the “top half” of strings. If we define <span><span class="math inline">\(\ensuremath{\mathit{FLIP}}:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> to be the map that “flips” the bits of a given string <span><span class="math inline">\(x\)</span></span> then it maps every <span><span class="math inline">\(x\in \overline{A}\)</span></span> to an output <span><span class="math inline">\(\ensuremath{\mathit{FLIP}}(x)\in A\)</span></span> in a one-to-one way, and so it demonstrates that <span><span class="math inline">\(|\overline{A}| \leq |A|\)</span></span> which implies that <span><span class="math inline">\(\Pr[A] \geq \Pr[\overline{A}]\)</span></span> and hence <span><span class="math inline">\(\Pr[A] \geq 1/2\)</span></span>.</figcaption>
</figure>
<h3 id="bipartite-matching." data-number="18.1.6">Bipartite matching.</h3>
<p>The <em>matching</em> problem is one of the canonical optimization problems, arising in all kinds of applications: matching residents with hospitals, kidney donors with patients, flights with crews, and many others. One prototypical variant is <em>bipartite perfect matching</em>. In this problem, we are given a bipartite graph <span><span class="math inline">\(G = (L\cup R,E)\)</span></span> which has <span><span class="math inline">\(2n\)</span></span> vertices partitioned into <span><span class="math inline">\(n\)</span></span>-sized sets <span><span class="math inline">\(L\)</span></span> and <span><span class="math inline">\(R\)</span></span>, where all edges have one endpoint in <span><span class="math inline">\(L\)</span></span> and the other in <span><span class="math inline">\(R\)</span></span>. The goal is to determine whether there is a <em>perfect matching</em>, a subset <span><span class="math inline">\(M \subseteq E\)</span></span> of <span><span class="math inline">\(n\)</span></span> disjoint edges. That is, <span><span class="math inline">\(M\)</span></span> matches every vertex in <span><span class="math inline">\(L\)</span></span> to a unique vertex in <span><span class="math inline">\(R\)</span></span>.</p>
<figure>
<img src="../figure/matchingfig.png" alt="18.3: The bipartite matching problem in the graph G=(L\cup R,E) can be reduced to the minimum s,t cut problem in the graph G&#39; obtained by adding vertices s,t to G, connecting s with L and connecting t with R." id="matchingfig" class="margin" /><figcaption>18.3: The bipartite matching problem in the graph <span><span class="math inline">\(G=(L\cup R,E)\)</span></span> can be reduced to the minimum <span><span class="math inline">\(s,t\)</span></span> cut problem in the graph <span><span class="math inline">\(G&#39;\)</span></span> obtained by adding vertices <span><span class="math inline">\(s,t\)</span></span> to <span><span class="math inline">\(G\)</span></span>, connecting <span><span class="math inline">\(s\)</span></span> with <span><span class="math inline">\(L\)</span></span> and connecting <span><span class="math inline">\(t\)</span></span> with <span><span class="math inline">\(R\)</span></span>.</figcaption>
</figure>
<p>The bipartite matching problem turns out to have a polynomial-time algorithm, since we can reduce finding a matching in <span><span class="math inline">\(G\)</span></span> to finding a maximum flow (or equivalently, minimum cut) in a related graph <span><span class="math inline">\(G&#39;\)</span></span> (see <a href='#matchingfig'>Figure 18.3</a>). However, we will see a different probabilistic algorithm to determine whether a graph contains such a matching.</p>
<p>Let us label <span><span class="math inline">\(G\)</span></span>’s vertices as <span><span class="math inline">\(L = \{ \ell_0,\ldots,\ell_{n-1} \}\)</span></span> and <span><span class="math inline">\(R = \{ r_0, \ldots, r_{n-1} \}\)</span></span>. A matching <span><span class="math inline">\(M\)</span></span> corresponds to a <em>permutation</em> <span><span class="math inline">\(\pi \in S_n\)</span></span> (i.e., one-to-one and onto function <span><span class="math inline">\(\pi: [n] \rightarrow [n]\)</span></span>) where for every <span><span class="math inline">\(i\in [n]\)</span></span>, we define <span><span class="math inline">\(\pi(i)\)</span></span> to be the unique <span><span class="math inline">\(j\)</span></span> such that <span><span class="math inline">\(M\)</span></span> contains the edge <span><span class="math inline">\(\{ \ell_i ,r_j \}\)</span></span>. Define an <span><span class="math inline">\(n\times n\)</span></span> matrix <span><span class="math inline">\(A=A(G)\)</span></span> where <span><span class="math inline">\(A_{i,j}=1\)</span></span> if and only if the edge <span><span class="math inline">\(\{\ell_i,r_j\}\)</span></span> is present and <span><span class="math inline">\(A_{i,j}=0\)</span></span> otherwise. The correspondence between matchings and permutations implies the following claim:</p>
<div id="matchpolylem" class="lemma" title="Matching polynomial" name="Lemma 18.6 (Matching polynomial) ">
<p>Define <span><span class="math inline">\(P=P(G)\)</span></span> to be the polynomial mapping <span><span class="math inline">\(\R^{n^2}\)</span></span> to <span><span class="math inline">\(\R\)</span></span> where <span>
<div class='myequationbox'><span class="math display">\[
P(x_{0,0},\ldots,x_{n-1,n-1}) = \sum_{\pi \in S_n} \left( \prod_{i=0}^{n-1} sign(\pi)A_{i,\pi(i)} \right) \prod_{i=0}^{n-1} x_{i,\pi(i)} \;\;(18.7)
\]</span><a id='matchpolyeq'></a></div></span> Then <span><span class="math inline">\(G\)</span></span> has a perfect matching if and only if <span><span class="math inline">\(P\)</span></span> is not identically zero. That is, <span><span class="math inline">\(G\)</span></span> has a perfect matching if and only if there exists some assignment <span><span class="math inline">\(x=(x_{i,j})_{i,j\in [n]} \in \R^{n^2}\)</span></span> such that <span><span class="math inline">\(P(x) \neq 0\)</span></span>.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></p>
</div>
<div id="section-3" class="proof" data-ref="matchpolylem" name="Proof">
<p>If <span><span class="math inline">\(G\)</span></span> has a perfect matching <span><span class="math inline">\(M^*\)</span></span>, then let <span><span class="math inline">\(\pi^*\)</span></span> be the permutation corresponding to <span><span class="math inline">\(M\)</span></span> and let <span><span class="math inline">\(x^* \in \Z^{n^2}\)</span></span> defined as follows: <span><span class="math inline">\(x_{i,j}=1\)</span></span> if <span><span class="math inline">\(j=\pi(i)\)</span></span> and <span><span class="math inline">\(x_{i,j}=0\)</span></span>. Note that for every <span><span class="math inline">\(\pi \neq \pi^*\)</span></span>, <span><span class="math inline">\(\prod_{i=0}^{n-1} x_{i,\pi(i)}=0\)</span></span> but <span><span class="math inline">\(\prod_{i=0}^{n-1} x^*_{i,\pi^*(i)}=1\)</span></span>. Hence <span><span class="math inline">\(P(x^*)\)</span></span> will equal <span><span class="math inline">\(\prod_{i=0}^{n-1} A_{i,\pi^*(i)}\)</span></span>. But since <span><span class="math inline">\(M^*\)</span></span> is a perfect matching in <span><span class="math inline">\(G\)</span></span>, <span><span class="math inline">\(\prod_{i=0}^{n-1} A_{i,\pi^*(i)} = 1\)</span></span>.</p>
<p>On the other hand, suppose that <span><span class="math inline">\(P\)</span></span> is not identically zero. By <a href='#matchpolyeq'>Equation 18.7</a>, this means that at least one of the terms <span><span class="math inline">\(\prod_{i=0}^{n-1}A_{i,\pi(i)}\)</span></span> is not equal to zero. But then this permutation <span><span class="math inline">\(\pi\)</span></span> must be a perfect matching in <span><span class="math inline">\(G\)</span></span>.</p>
</div>
<p>As we’ve seen before, for every <span><span class="math inline">\(x \in \R^{n^2}\)</span></span>, we can compute <span><span class="math inline">\(P(x)\)</span></span> by simply computing the <em>determinant</em> of the matrix <span><span class="math inline">\(A(x)\)</span></span>, which is obtained by replacing <span><span class="math inline">\(A_{i,j}\)</span></span> with <span><span class="math inline">\(A_{i,j}x_{i,j}\)</span></span>. This reduces testing perfect matching to the <em>zero testing</em> problem for polynomials: given some polynomial <span><span class="math inline">\(P(\cdot)\)</span></span>, test whether <span><span class="math inline">\(P\)</span></span> is identically zero or not. The intuition behind our randomized algorithm for zero testing is the following:</p>
<blockquote>
<p><em>If a polynomial is not identically zero, then it can’t have “too many” roots.</em></p>
</blockquote>
<figure>
<img src="../figure/curves.png" alt="18.4: A degree d curve in one variable can have at most d roots. In higher dimensions, a n-variate degree-d polynomial can have an infinite number roots though the set of roots will be an n-1 dimensional surface. Over a finite field \mathbb{F}, an n-variate degree d polynomial has at most d|\mathbb{F}|^{n-1} roots." id="curvesfig" class="margin" /><figcaption>18.4: A degree <span><span class="math inline">\(d\)</span></span> curve in one variable can have at most <span><span class="math inline">\(d\)</span></span> roots. In higher dimensions, a <span><span class="math inline">\(n\)</span></span>-variate degree-<span><span class="math inline">\(d\)</span></span> polynomial can have an infinite number roots though the set of roots will be an <span><span class="math inline">\(n-1\)</span></span> dimensional surface. Over a finite field <span><span class="math inline">\(\mathbb{F}\)</span></span>, an <span><span class="math inline">\(n\)</span></span>-variate degree <span><span class="math inline">\(d\)</span></span> polynomial has at most <span><span class="math inline">\(d|\mathbb{F}|^{n-1}\)</span></span> roots.</figcaption>
</figure>
<p>This intuition sort of makes sense. For one variable polynomials, we know that a nonzero linear function has at most one root, a quadratic function (e.g., a parabola) has at most two roots, and generally a degree <span><span class="math inline">\(d\)</span></span> equation has at most <span><span class="math inline">\(d\)</span></span> roots. While in more than one variable there can be an infinite number of roots (e.g., the polynomial <span><span class="math inline">\(x_0+y_0\)</span></span> vanishes on the line <span><span class="math inline">\(y=-x\)</span></span>) it is still the case that the set of roots is very “small” compared to the set of all inputs. For example, the root of a bivariate polynomial form a curve, the roots of a three-variable polynomial form a surface, and more generally the roots of an <span><span class="math inline">\(n\)</span></span>-variable polynomial are a space of dimension <span><span class="math inline">\(n-1\)</span></span>.</p>
<p>This intuition leads to the following simple randomized algorithm:</p>
<blockquote>
<p><em>To decide if <span><span class="math inline">\(P\)</span></span> is identically zero, choose a “random” input <span><span class="math inline">\(x\)</span></span> and check if <span><span class="math inline">\(P(x)\neq 0\)</span></span>.</em></p>
</blockquote>
<p>This makes sense: if there are only “few” roots, then we expect that with high probability the random input <span><span class="math inline">\(x\)</span></span> is not going to be one of those roots. However, to transform this into an actual algorithm, we need to make both the intuition and the notion of a “random” input precise. Choosing a random real number is quite problematic, especially when you have only a finite number of coins at your disposal, and so we start by reducing the task to a finite setting. We will use the following result</p>
<div id="szlem" class="theorem" title="Schwartz–Zippel lemma" name="Theorem 18.7 (Schwartz–Zippel lemma) ">
<p>For every integer <span><span class="math inline">\(q\)</span></span>, and polynomial <span><span class="math inline">\(P:\R^n \rightarrow \R\)</span></span> with integer coefficients. If <span><span class="math inline">\(P\)</span></span> has degree at most <span><span class="math inline">\(d\)</span></span> and is not identically zero, then it has at most <span><span class="math inline">\(dq^{n-1}\)</span></span> roots in the set <span><span class="math inline">\([q]^n = \{ (x_0,\ldots,x_{n-1}) : x_i \in \{0,\ldots,q-1\} \}\)</span></span>.</p>
</div>
<p>We omit the (not too complicated) proof of <a href='#szlem'>Theorem 18.7</a>. We remark that it holds not just over the real numbers but over any field as well. Since the matching polynomial <span><span class="math inline">\(P\)</span></span> of <a href='#matchpolylem'>Lemma 18.6</a> has degree at most <span><span class="math inline">\(n\)</span></span>, <a href='#szlem'>Theorem 18.7</a> leads directly to a simple algorithm for testing if it is nonzero:</p>
<blockquote>
<div class="quote" name="Quote 18.1.6">
<p><strong>Algorithm Perfect-Matching:</strong></p>
<p><strong>Input:</strong> Bipartite graph <span><span class="math inline">\(G\)</span></span> on <span><span class="math inline">\(2n\)</span></span> vertices <span><span class="math inline">\(\{ \ell_0,\ldots,\ell_{n-1} , r_0,\ldots,r_{n-1} \}\)</span></span>.</p>
<p><strong>Operation:</strong></p>
<ol type="1">
<li><p>For every <span><span class="math inline">\(i,j \in [n]\)</span></span>, choose <span><span class="math inline">\(x_{i,j}\)</span></span> independently at random from <span><span class="math inline">\([2n]=\{0,\ldots 2n-1\}\)</span></span>.</p></li>
<li><p>Compute the determinant of the matrix <span><span class="math inline">\(A(x)\)</span></span> whose <span><span class="math inline">\((i,j)^{th}\)</span></span> entry equals <span><span class="math inline">\(x_{i,j}\)</span></span> if the edge <span><span class="math inline">\(\{\ell_i,r_j\}\)</span></span> is present and <span><span class="math inline">\(0\)</span></span> otherwise.</p></li>
<li><p>Output <code>no perfect matching</code> if this determinant is zero, and output <code>perfect matching</code> otherwise.</p></li>
</ol>
</div>
</blockquote>
<p>This algorithm can be improved further (e.g., see <a href='#matchingmodex'>Exercise 18.5</a>). While it is not necessarily faster than the cut-based algorithms for perfect matching, it does have some advantages. In particular, it is more amenable for parallelization. (However, it also has the significant disadvantage that it does not produce a matching but only states that one exists.) The Schwartz–Zippel Lemma, and the associated zero testing algorithm for polynomials, is widely used across computer science, including in several settings where we have no known deterministic algorithm matching their performance.</p>
<div class="recap" name="Recap 18.1.6">
<ul>
<li><p>Using concentration results, we can <em>amplify</em> in polynomial time the success probability of a probabilistic algorithm from a mere <span><span class="math inline">\(1/p(n)\)</span></span> to <span><span class="math inline">\(1-2^{-q(n)}\)</span></span> for every polynomials <span><span class="math inline">\(p\)</span></span> and <span><span class="math inline">\(q\)</span></span>.</p></li>
<li><p>There are several randomized algorithms that are better in various senses (e.g., simpler, faster, or other advantages) than the best known deterministic algorithm for the same problem.</p></li>
</ul>
</div>
<h2 id="exercises" data-number="18.2">Exercises</h2>
<div id="cutalgorithmamplificationlemex" class="exercise" title="Amplification for max cut" name="Exercise 18.1 (Amplification for max cut) ">
<p>Prove <a href='#cutalgorithmamplificationlem'>Lemma 18.3</a></p>
</div>
<div id="maxcutex" class="exercise" title="Deterministic max cut algorithm" name="Exercise 18.2 (Deterministic max cut algorithm) ">
<p><sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup></p>
</div>
<div id="coindistex" class="exercise" title="Simulating distributions using coins" name="Exercise 18.3 (Simulating distributions using coins) ">
<p>Our model for probability involves tossing <span><span class="math inline">\(n\)</span></span> coins, but sometimes algorithm require sampling from other distributions, such as selecting a uniform number in <span><span class="math inline">\(\{0,\ldots,M-1\}\)</span></span> for some <span><span class="math inline">\(M\)</span></span>. Fortunately, we can simulate this with an exponentially small probability of error: prove that for every <span><span class="math inline">\(M\)</span></span>, if <span><span class="math inline">\(n&gt;k\lceil \log M \rceil\)</span></span>, then there is a function <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,\ldots,M-1\} \cup \{ \bot \}\)</span></span> such that <strong>(1)</strong> The probability that <span><span class="math inline">\(F(x)=\bot\)</span></span> is at most <span><span class="math inline">\(2^{-k}\)</span></span> and <strong>(2)</strong> the distribution of <span><span class="math inline">\(F(x)\)</span></span> conditioned on <span><span class="math inline">\(F(x) \neq \bot\)</span></span> is equal to the uniform distribution over <span><span class="math inline">\(\{0,\ldots,M-1\}\)</span></span>.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup></p>
</div>
<div id="walksatex" class="exercise" title="Better walksat analysis" name="Exercise 18.4 (Better walksat analysis) ">
<ol type="1">
<li>Prove that for every <span><span class="math inline">\(\epsilon&gt;0\)</span></span>, if <span><span class="math inline">\(n\)</span></span> is large enough then for every <span><span class="math inline">\(x^*\in \{0,1\}^n\)</span></span> <span><span class="math inline">\(\Pr_{x \sim \{0,1\}^n}[ \Delta(x,x^*) \leq n/3 ] \leq 2^{-(1-H(1/3)-\epsilon)n}\)</span></span> where <span><span class="math inline">\(H(p)=p\log(1/p) + (1-p)\log(1/(1-p))\)</span></span> is the same function as in <a href='lec_15_probability.html#entropybinomex'>Exercise 17.9</a>.<br />
</li>
<li>Prove that <span><span class="math inline">\(2^{1-H(1/4)+(1/4) \log 3}=(3/2)\)</span></span>.</li>
<li>Use the above to prove that for every <span><span class="math inline">\(\delta&gt;0\)</span></span> and large enough <span><span class="math inline">\(n\)</span></span>, if we set <span><span class="math inline">\(T=1000\cdot (3/2+\delta)^n\)</span></span> and <span><span class="math inline">\(S=n/4\)</span></span> in the WalkSAT algorithm then for every satisfiable 3CNF <span><span class="math inline">\(\varphi\)</span></span>, the probability that we output <code>unsatisfiable</code> is at most <span><span class="math inline">\(1/2\)</span></span>.<br />
</li>
</ol>
</div>
<div id="matchingmodex" class="exercise" title="Faster bipartite matching (challenge)" name="Exercise 18.5 (Faster bipartite matching (challenge)) ">
<p>(to be completed: improve the matching algorithm by working modulo a prime)</p>
</div>
<h2 id="bibliographical-notes" data-number="18.3">Bibliographical notes</h2>
<p>The books of Motwani and Raghavan  (<a href="https://scholar.google.com/scholar?hl=en&q=Motwani,+Raghavan+Randomized+algorithms" target="_blank">Motwani, Raghavan, 1995</a>)  and Mitzenmacher and Upfal  (<a href="https://scholar.google.com/scholar?hl=en&q=Mitzenmacher,+Upfal+Probability+and+computing:+randomization+and+probabilistic+techniques+in+algorithms+and+data+analysis" target="_blank">Mitzenmacher, Upfal, 2017</a>)  are two excellent resources for randomized algorithms. Some of the history of the discovery of Monte Carlo algorithm is covered <a href="http://permalink.lanl.gov/object/tr?what=info:lanl-repo/lareport/LA-UR-88-9068">here</a>.</p>
<h2 id="acknowledgements" data-number="18.4">Acknowledgements</h2>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>Some texts also talk about “Las Vegas algorithms” that always return the right answer but whose running time is only polynomial on the average. Since this Monte Carlo vs Las Vegas terminology is confusing, we will not use these terms anymore, and simply talk about randomized algorithms.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>This question does have some significance to practice, since hardware that generates high quality randomness at speed is nontrivial to construct.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>At the time of this writing, the best known <a href="https://arxiv.org/pdf/1103.2165.pdf">randomized</a> algorithms for 3SAT run in time roughly <span><span class="math inline">\(O(1.308^n)\)</span></span>, and the best known <a href="https://arxiv.org/pdf/1102.3766v1.pdf">deterministic</a> algorithms run in time <span><span class="math inline">\(O(1.3303^n)\)</span></span> in the worst case.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>The <a href="https://goo.gl/ELnXhq">sign</a> of a permutation <span><span class="math inline">\(\pi:[n] \rightarrow [n]\)</span></span>, denoted by <span><span class="math inline">\(sign(\pi)\)</span></span>, can be defined in several equivalent ways, one of which is that <span><span class="math inline">\(sign(\pi)=(-1)^{INV(\pi)}\)</span></span> where <span><span class="math inline">\(\ensuremath{\mathit{INV}}(pi)=|\{(x,y) \in [n] \;|\; x&lt;y \; \wedge \; \pi(x)&gt;\pi(y)\}\)</span></span> (i.e., <span><span class="math inline">\(\ensuremath{\mathit{INV}}(\pi)\)</span></span> is the number of pairs of elements that are <em>inverted</em> by <span><span class="math inline">\(\pi\)</span></span>). The importance of the term <span><span class="math inline">\(sign(\pi)\)</span></span> is that it makes <span><span class="math inline">\(P\)</span></span> equal to the <em>determinant</em> of the matrix <span><span class="math inline">\((x_{i,j})\)</span></span> and hence efficiently computable.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>TODO: add exercise to give a deterministic max cut algorithm that gives <span><span class="math inline">\(m/2\)</span></span> edges. Talk about greedy approach.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p><strong>Hint:</strong> Think of <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> as choosing <span><span class="math inline">\(k\)</span></span> numbers <span><span class="math inline">\(y_1,\ldots,y_k \in \{0,\ldots, 2^{\lceil \log M \rceil}-1 \}\)</span></span>. Output the first such number that is in <span><span class="math inline">\(\{0,\ldots,M-1\}\)</span></span>. </p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 21:39:59</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_16_randomized_alg.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
