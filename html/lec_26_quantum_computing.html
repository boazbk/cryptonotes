<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Quantum computing</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Quantum computing" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#lecture-summary"><i class="fa fa-check"></i><b>16.1</b> Lecture summary</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.2</b> Exercises</a></li><li class="chapter" data-level="16.3" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.3</b> Bibliographical notes</a></li><li class="chapter" data-level="16.4" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#further-explorations"><i class="fa fa-check"></i><b>16.4</b> Further explorations</a></li><li class="chapter" data-level="16.5" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#acknowledgements"><i class="fa fa-check"></i><b>16.5</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantum computing</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_26_quantum_computing.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="quantumchap" data-number="22">Quantum computing</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>See main aspects in which quantum mechanics differs from local deterministic theories.<br />
</li>
<li>Model of quantum circuits, or equivalently QNAND-CIRC programs<br />
</li>
<li>The complexity class <span><span class="math inline">\(\mathbf{BQP}\)</span></span> and what we know about its relation to other classes<br />
</li>
<li>Ideas behind Shor’s Algorithm and the Quantum Fourier Transform</li>
</ul>
</div>
<blockquote>
<p><em>“We always have had (secret, secret, close the doors!) … a great deal of difficulty in understanding the world view that quantum mechanics represents … It has not yet become obvious to me that there’s no real problem. … Can I learn anything from asking this question about computers–about this may or may not be mystery as to what the world view of quantum mechanics is?”</em> , Richard Feynman, 1981</p>
</blockquote>
<blockquote>
<p><em>“The only difference between a probabilistic classical world and the equations of the quantum world is that somehow or other it appears as if the probabilities would have to go negative”</em>, Richard Feynman, 1981</p>
</blockquote>
<p>There were two schools of natural philosophy in ancient Greece. <em>Aristotle</em> believed that objects have an <em>essence</em> that explains their behavior, and a theory of the natural world has to refer to the <em>reasons</em> (or “final cause” to use Aristotle’s language) as to why they exhibit certain phenomena. <em>Democritus</em> believed in a purely mechanistic explanation of the world. In his view, the universe was ultimately composed of elementary particles (or <em>Atoms</em>) and our observed phenomena arise from the interactions between these particles according to some local rules. Modern science (arguably starting with Newton) has embraced Democritus’ point of view, of a mechanistic or “clockwork” universe of particles and forces acting upon them.</p>
<p>While the classification of particles and forces evolved with time, to a large extent the “big picture” has not changed from Newton till Einstein. In particular it was held as an axiom that if we knew fully the current <em>state</em> of the universe (i.e., the particles and their properties such as location and velocity) then we could predict its future state at any point in time. In computational language, in all these theories the state of a system with <span><span class="math inline">\(n\)</span></span> particles could be stored in an array of <span><span class="math inline">\(O(n)\)</span></span> numbers, and predicting the evolution of the system can be done by running some efficient (e.g., <span><span class="math inline">\(poly(n)\)</span></span> time) deterministic computation on this array.</p>
<h2 id="the-double-slit-experiment" data-number="22.1">The double slit experiment</h2>
<p>Alas, in the beginning of the 20th century, several experimental results were calling into question this “clockwork” or “billiard ball” theory of the world. One such experiment is the famous <a href="https://en.wikipedia.org/wiki/Double-slit_experiment">double slit experiment</a>. Here is one way to describe it. Suppose that we buy one of those baseball pitching machines, and aim it at a soft plastic wall, but put a <em>metal barrier with a single slit</em> between the machine and the plastic wall (see <a href='#doublebaseballfig'>Figure 22.1</a>). If we shoot baseballs at the plastic wall, then some of the baseballs would bounce off the metal barrier, while some would make it through the slit and dent the wall. If we now carve out an additional slit in the metal barrier then more balls would get through, and so the plastic wall would be <em>even more dented</em>.</p>
<figure>
<img src="../figure/double_baseball2.png" alt="22.1: In the “double baseball experiment” we shoot baseballs from a gun at a soft wall through a hard barrier that has one or two slits open in it. There is only “constructive interference” in the sense that the dent in each position in the wall when both slits are open is the sum of the dents when each slit is open on its own." id="doublebaseballfig" class="margin" /><figcaption>22.1: In the “double baseball experiment” we shoot baseballs from a gun at a soft wall through a hard barrier that has one or two slits open in it. There is only “constructive interference” in the sense that the dent in each position in the wall when both slits are open is the sum of the dents when each slit is open on its own.</figcaption>
</figure>
<p>So far this is pure common sense, and it is indeed (to my knowledge) an accurate description of what happens when we shoot baseballs at a plastic wall. However, this is not the same when we shoot <em>photons</em>. Amazingly, if we shoot with a “photon gun” (i.e., a laser) at a wall equipped with photon detectors through some barrier, then (as shown in <a href='#doubleslitfig'>Figure 22.2</a>) in some positions of the wall we will see <em>fewer</em> hits when the two slits are open than when only one of them is!. In particular there are positions in the wall that are hit when the first slit is open, hit when the second gun is open, but are <em>not hit at all when both slits are open!</em>.</p>
<figure>
<img src="../figure/double-slit-setup.PNG" alt="22.2: The setup of the double slit experiment in the case of photon or electron guns. We see also destructive interference in the sense that there are some positions on the wall that get fewer hits when both slits are open than they get when only one of the slits is open. See also this video." id="doubleslitfig" class="margin" /><figcaption>22.2: The setup of the double slit experiment in the case of photon or electron guns. We see also <em>destructive</em> interference in the sense that there are some positions on the wall that get <em>fewer</em> hits when both slits are open than they get when only one of the slits is open. See also <a href="https://www.youtube.com/watch?v=DfPeprQ7oGc">this video</a>.</figcaption>
</figure>
<p>It seems as if each photon coming out of the gun is aware of the global setup of the experiment, and behaves differently if two slits are open than if only one is. If we try to “catch the photon in the act” and place a detector right next to each slit so we can see exactly the path each photon takes then something even more bizarre happens. The mere fact that we <em>measure</em> the path changes the photon’s behavior, and now this “destructive interference” pattern is gone and the number of times a position is hit when two slits are open is the sum of the number of times it is hit when each slit is open.</p>
<div id="section-1" class="pause" name="Pause">
<p>You should read the paragraphs above more than once and make sure you appreciate how truly mind boggling these results are.</p>
</div>
<h2 id="quantum-amplitudes" data-number="22.2">Quantum amplitudes</h2>
<p>The double slit and other experiments ultimately forced scientists to accept a very counterintuitive picture of the world. It is not merely about nature being randomized, but rather it is about the probabilities in some sense “going negative” and cancelling each other!</p>
<p>To see what we mean by this, let us go back to the baseball experiment. Suppose that the probability a ball passes through the left slit is <span><span class="math inline">\(p_L\)</span></span> and the probability that it passes through the right slit is <span><span class="math inline">\(p_R\)</span></span>. Then, if we shoot <span><span class="math inline">\(N\)</span></span> balls out of each gun, we expect the wall will be hit <span><span class="math inline">\((p_L+p_R)N\)</span></span> times. In contrast, in the quantum world of photons instead of baseballs, it can sometimes be the case that in both the first and second case the wall is hit with positive probabilities <span><span class="math inline">\(p_L\)</span></span> and <span><span class="math inline">\(p_R\)</span></span> respectively but somehow when both slits are open the wall (or a particular position in it) is not hit at all. It’s almost as if the probabilities can “cancel each other out”.</p>
<p>To understand the way we model this in quantum mechanics, it is helpful to think of a “lazy evaluation” approach to probability. We can think of a probabilistic experiment such as shooting a baseball through two slits in two different ways:</p>
<ul>
<li><p>When a ball is shot, “nature” tosses a coin and decides if it will go through the left slit (which happens with probability <span><span class="math inline">\(p_L\)</span></span>), right slit (which happens with probability <span><span class="math inline">\(p_R\)</span></span>), or bounce back. If it passes through one of the slits then it will hit the wall. Later we can look at the wall and find out whether or not this event happened, but the fact that the event happened or not is determined independently of whether or not we look at the wall.</p></li>
<li><p>The other viewpoint is that when a ball is shot, “nature” computes the probabilities <span><span class="math inline">\(p_L\)</span></span> and <span><span class="math inline">\(p_R\)</span></span> as before, but does <em>not</em> yet “toss the coin” and determines what happened. Only when we actually look at the wall, nature tosses a coin and with probability <span><span class="math inline">\(p_L+p_R\)</span></span> ensures we see a dent. That is, nature uses “lazy evaluation”, and only determines the result of a probabilistic experiment when we decide to <em>measure</em> it.</p></li>
</ul>
<p>While the first scenario seems much more natural, the end result in both is the same (the wall is hit with probability <span><span class="math inline">\(p_L+p_R\)</span></span>) and so the question of whether we should model nature as following the first scenario or second one seems like asking about the proverbial tree that falls in the forest with no one hearing about it.</p>
<p>However, when we want to describe the double slit experiment with photons rather than baseballs, it is the second scenario that lends itself better to a quantum generalization. Quantum mechanics associates a number <span><span class="math inline">\(\alpha\)</span></span> known as an <em>amplitude</em> with each probabilistic experiment. This number <span><span class="math inline">\(\alpha\)</span></span> can be <em>negative</em>, and in fact even <em>complex</em>. We never observe the amplitudes directly, since whenever we <em>measure</em> an event with amplitude <span><span class="math inline">\(\alpha\)</span></span>, nature tosses a coin and determines that the event happens with probability <span><span class="math inline">\(|\alpha|^2\)</span></span>. However, the sign (or in the complex case, phase) of the amplitudes can affect whether two different events have <em>constructive</em> or <em>destructive</em> interference.</p>
<p>Specifically, consider an event that can either occur or not (e.g. “detector number 17 was hit by a photon”). In classical probability, we model this by a probability distribution over the two outcomes: a pair of non-negative numbers <span><span class="math inline">\(p\)</span></span> and <span><span class="math inline">\(q\)</span></span> such that <span><span class="math inline">\(p+q=1\)</span></span>, where <span><span class="math inline">\(p\)</span></span> corresponds to the probability that the event occurs and <span><span class="math inline">\(q\)</span></span> corresponds to the probability that the event does not occur. In quantum mechanics, we model this also by pair of numbers, which we call <em>amplitudes</em>. This is a pair of (potentially negative or even complex) numbers <span><span class="math inline">\(\alpha\)</span></span> and <span><span class="math inline">\(\beta\)</span></span> such that <span><span class="math inline">\(|\alpha|^2 + |\beta|^2 =1\)</span></span>. The probability that the event occurs is <span><span class="math inline">\(|\alpha|^2\)</span></span> and the probability that it does not occur is <span><span class="math inline">\(|\beta|^2\)</span></span>. In isolation, these negative or complex numbers don’t matter much, since we anyway square them to obtain probabilities. But the interaction of positive and negative amplitudes can result in surprising <em>cancellations</em> where somehow combining two scenarios where an event happens with positive probability results in a scenario where it never does.</p>
<div class="pause" name="Pause 22.2">
<p>If you don’t find the above description confusing and unintuitive, you probably didn’t get it. Please make sure to re-read the above paragraphs until you are thoroughly confused.</p>
</div>
<p>Quantum mechanics is a mathematical theory that allows us to calculate and predict the results of the double-slit and many other experiments. If you think of quantum mechanics as an explanation as to what “really” goes on in the world, it can be rather confusing. However, if you simply “shut up and calculate” then it works amazingly well at predicting experimental results. In particular, in the double slit experiment, for any position in the wall, we can compute numbers <span><span class="math inline">\(\alpha\)</span></span> and <span><span class="math inline">\(\beta\)</span></span> such that photons from the first and second slit hit that position with probabilities <span><span class="math inline">\(|\alpha|^2\)</span></span> and <span><span class="math inline">\(|\beta|^2\)</span></span> respectively. When we open both slits, the probability that the position will be hit is proportional to <span><span class="math inline">\(|\alpha+\beta|^2\)</span></span>, and so in particular, if <span><span class="math inline">\(\alpha=-\beta\)</span></span> then it will be the case that, despite being hit when <em>either</em> slit one or slit two are open, the position is <em>not hit at all</em> when they both are. If you are confused by quantum mechanics, you are not alone: for decades people have been trying to come up with <a href="https://en.wikipedia.org/wiki/Interpretations_of_quantum_mechanics">explanations</a> for “the underlying reality” behind quantum mechanics, including <a href="https://en.wikipedia.org/wiki/De_Broglie%E2%80%93Bohm_theory">Bohmian Mechanics</a>, <a href="https://en.wikipedia.org/wiki/Many-worlds_interpretation">Many Worlds</a> and others. However, none of these interpretations have gained universal acceptance and all of those (by design) yield the same experimental predictions. Thus at this point many scientists prefer to just ignore the question of what is the “true reality” and go back to simply “shutting up and calculating”.</p>
<div id="complexrem" class="remark" title="Complex vs real, other simplifications" name="Remark 22.1 (Complex vs real, other simplifications) ">
<p>If (like the author) you are a bit intimidated by complex numbers, don’t worry: you can think of all amplitudes as <em>real</em> (though potentially <em>negative</em>) numbers without loss of understanding. All the “magic” of quantum computing already arises in this case, and so we will often restrict attention to real amplitudes in this chapter.</p>
<p>We will also only discuss so-called <em>pure</em> quantum states, and not the more general notion of <em>mixed</em> states. Pure states turn out to be sufficient for understanding the algorithmic aspects of quantum computing.</p>
<p>More generally, this chapter is not meant to be a complete description of quantum mechanics, quantum information theory, or quantum computing, but rather illustrate the main points where these differ from classical computing.</p>
</div>
<h3 id="linear-algebra-quick-review" data-number="22.2.1">Linear algebra quick review</h3>
<p><em>Linear algebra</em> underlies much of quantum mechanics, and so you would do well to review some of the basic notions such as vectors, matrices, and linear subspaces. The operations in quantum mechanics can be represented as linear functions over the <em>complex</em> numbers, but we stick to the real numbers in this chapter. This does not cause much loss in understanding but does allow us to simplify our notation and eliminate the use of the complex conjugate.</p>
<p>The main notions we use are:</p>
<ul>
<li><p>A function <span><span class="math inline">\(F:\R^N \rightarrow \R^N\)</span></span> is <em>linear</em> if <span><span class="math inline">\(F(\alpha u + \beta v) = \alpha F(u) + \beta F(v)\)</span></span> for every <span><span class="math inline">\(\alpha,\beta \in \R\)</span></span> and <span><span class="math inline">\(u,v \in \R^N\)</span></span>.</p></li>
<li><p>The <em>inner product</em> of two vectors <span><span class="math inline">\(u,v \in \R^N\)</span></span> can be defined as <span><span class="math inline">\(\langle u,v \rangle = \sum_{i\in [N]} u_iv_i\)</span></span>. (There can be different inner products but we stick to this one.) The <em>norm</em> of a vector <span><span class="math inline">\(u \in \R^N\)</span></span> is defined as <span><span class="math inline">\(\|u\| = \sqrt{\langle u,u \rangle} = \sqrt{\sum_{i\in [N]}u_i^2}\)</span></span>. We say that <span><span class="math inline">\(u\)</span></span> is a <em>unit vector</em> if <span><span class="math inline">\(\|u\|=1\)</span></span>.</p></li>
<li><p>Two vectors <span><span class="math inline">\(u,v \in \R^N\)</span></span> are <em>orthogonal</em> if <span><span class="math inline">\(\langle u,v\rangle = 0\)</span></span>. An <em>orthonormal basis</em> for <span><span class="math inline">\(\R^N\)</span></span> is a set of <span><span class="math inline">\(N\)</span></span> vectors <span><span class="math inline">\(v_0,v_1,\ldots, v_{N-1}\)</span></span> such that <span><span class="math inline">\(\| v_i \|=1\)</span></span> for every <span><span class="math inline">\(i\in [N]\)</span></span> and <span><span class="math inline">\(\langle v_i,v_j \rangle=0\)</span></span> for every <span><span class="math inline">\(i\neq j\)</span></span>. A canoncial example is the <em>standard basis</em> <span><span class="math inline">\(e_0,\ldots,e_{N-1}\)</span></span>, where <span><span class="math inline">\(e_i\)</span></span> is the vector that has zeroes in all cooordinates except the <span><span class="math inline">\(i\)</span></span>-th coordinate in which its value is <span><span class="math inline">\(1\)</span></span>. A quirk of the quantum mechanics literature is that <span><span class="math inline">\(e_i\)</span></span> is often denoted by <span><span class="math inline">\(|i \rangle\)</span></span>. We often consider the case <span><span class="math inline">\(N=2^n\)</span></span>, in which case we identify <span><span class="math inline">\([N]\)</span></span> with <span><span class="math inline">\(\{0,1\}^n\)</span></span> and for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, we denote the standard basis element corresponding to the <span><span class="math inline">\(x\)</span></span>-th coordinate by <span><span class="math inline">\(|x \rangle\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(u\)</span></span> is a vector in <span><span class="math inline">\(\R^n\)</span></span> and <span><span class="math inline">\(v_0,\ldots,v_{N-1}\)</span></span> is an orthonormal basis for <span><span class="math inline">\(\R^N\)</span></span>, then there are coefficients <span><span class="math inline">\(\alpha_0,\ldots,\alpha_{N-1}\)</span></span> such that <span><span class="math inline">\(u = \alpha_0v_0 + \cdots + \alpha_{N-1}v_{N-1}\)</span></span>. Consequently, the value <span><span class="math inline">\(F(u)\)</span></span> is determined by the values <span><span class="math inline">\(F(v_0)\)</span></span>, <span><span class="math inline">\(\ldots\)</span></span>, <span><span class="math inline">\(F(v_{N-1})\)</span></span>. Moreover, <span><span class="math inline">\(\|u\| = \sqrt{\sum_{i\in [N]} \alpha_i^2}\)</span></span>.</p></li>
<li><p>We can represent a linear function <span><span class="math inline">\(F:\R^N \rightarrow \R^N\)</span></span> as an <span><span class="math inline">\(N\times N\)</span></span> <em>matrix</em> <span><span class="math inline">\(M(F)\)</span></span> where the coordinate in the <span><span class="math inline">\(i\)</span></span>-th row and <span><span class="math inline">\(j\)</span></span>-th column of <span><span class="math inline">\(M(F)\)</span></span> (that is <span><span class="math inline">\(M(F)_{i,j}\)</span></span>) is equal to <span><span class="math inline">\(\langle e_i , F(e_j) \rangle\)</span></span> or equivalently the <span><span class="math inline">\(i\)</span></span>-th coordinate of <span><span class="math inline">\(F(e_j)\)</span></span>.</p></li>
<li><p>A linear function <span><span class="math inline">\(F:\R^N \rightarrow \R^N\)</span></span> such that <span><span class="math inline">\(\| F(u) \| = \|u \|\)</span></span> for every <span><span class="math inline">\(u\)</span></span> is called <em>unitary</em>. It can be shown that a function <span><span class="math inline">\(F\)</span></span> is unitary if and only if <span><span class="math inline">\(M(F) M(F)^\top = I\)</span></span> where <span><span class="math inline">\(\top\)</span></span> is the <em>transpose</em> operator (in the complex case the conjugate transpose) and <span><span class="math inline">\(I\)</span></span> is the <span><span class="math inline">\(N\times N\)</span></span> identity matrix that has <span><span class="math inline">\(1\)</span></span>’s on the diagonal and zeroes everywhere else. (For every two matrices <span><span class="math inline">\(A,B\)</span></span>, we use <span><span class="math inline">\(A B\)</span></span> to denote the <em>matrix product</em> of <span><span class="math inline">\(A\)</span></span> and <span><span class="math inline">\(B\)</span></span>.) Another equivalent characterization of this condition is that <span><span class="math inline">\(M(F)^\top = M(F)^{-1}\)</span></span> and yet another is that both the rows and columns of <span><span class="math inline">\(M(F)\)</span></span> form an orthonormal basis.</p></li>
</ul>
<h2 id="bellineqsec" data-number="22.3">Bell’s Inequality</h2>
<p>There is something weird about quantum mechanics. In 1935 <a href="http://plato.stanford.edu/entries/qt-epr/">Einstein, Podolsky and Rosen (EPR)</a> tried to pinpoint this issue by highlighting a previously unrealized corollary of this theory. They showed that the idea that nature does not determine the results of an experiment until it is measured results in so called “spooky action at a distance”. Namely, making a measurement of one object may instantaneously effect the state (i.e., the vector of amplitudes) of another object in the other end of the universe.</p>
<p>Since the vector of amplitudes is just a mathematical abstraction, the EPR paper was considered to be merely a thought experiment for philosophers to be concerned about, without bearing on experiments. This changed when in 1965 John Bell showed an actual experiment to test the predictions of EPR and hence pit intuitive common sense against quantum mechanics. Quantum mechanics won: it turns out that it <em>is</em> in fact possible to use measurements to create correlations between the states of objects far removed from one another that cannot be explained by any prior theory. Nonetheless, since the results of these experiments are so obviously wrong to anyone that has ever sat in an armchair, that there are still a number of <a href="http://www.scottaaronson.com/blog/?p=2464">Bell denialists</a> arguing that this can’t be true and quantum mechanics is wrong.</p>
<p>So, what is this Bell’s Inequality? Suppose that Alice and Bob try to convince you they have telepathic ability, and they aim to prove it via the following experiment. Alice and Bob will be in separate closed rooms.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> You will interrogate Alice and your associate will interrogate Bob. You choose a random bit <span><span class="math inline">\(x\in\{0,1\}\)</span></span> and your associate chooses a random <span><span class="math inline">\(y\in\{0,1\}\)</span></span>. We let <span><span class="math inline">\(a\)</span></span> be Alice’s response and <span><span class="math inline">\(b\)</span></span> be Bob’s response. We say that Alice and Bob win this experiment if <span><span class="math inline">\(a \oplus b = x \wedge y\)</span></span>. In other words, Alice and Bob need to output two bits that <em>disagree</em> if <span><span class="math inline">\(x=y=1\)</span></span> and <em>agree</em> otherwise.</p>
<p>Now if Alice and Bob are not telepathic, then they need to agree in advance on some strategy. It’s not hard for Alice and Bob to succeed with probability <span><span class="math inline">\(3/4\)</span></span>: just always output the same bit. Moreover, by doing some case analysis, we can show that no matter what strategy they use, Alice and Bob cannot succeed with higher probability than that:</p>
<div id="bellthm" class="theorem" title="Bell&#39;s Inequality" name="Theorem 22.2 (Bell&#39;s Inequality) ">
<p>For every two functions <span><span class="math inline">\(f,g:\{0,1\}\rightarrow\{0,1\}\)</span></span>, <span><span class="math inline">\(\Pr_{x,y \in \{0,1\}}[ f(x) \oplus g(y) = x \wedge y] \leq 3/4\)</span></span>.</p>
</div>
<div class="proof" data-ref="bellthm" name="Proof 22.3">
<p>Since the probability is taken over all four choices of <span><span class="math inline">\(x,y \in \{0,1\}\)</span></span>, the only way the theorem can be violated if if there exist two functions <span><span class="math inline">\(f,g\)</span></span> that satisfy</p>
<p><span>
<div class='myequationbox'><span class="math display">\[f(x) \oplus g(y) = x \wedge y\]</span></div></span></p>
<p>for all the four choices of <span><span class="math inline">\(x,y \in \{0,1\}^2\)</span></span>. Let’s plug in all these four choices and see what we get (below we use the equalities <span><span class="math inline">\(z \oplus 0 = z\)</span></span>, <span><span class="math inline">\(z \wedge 0=0\)</span></span> and <span><span class="math inline">\(z \wedge 1 = z\)</span></span>):</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\begin{aligned}
f(0) &amp;\oplus g(0) &amp;= 0\;\;\;\; &amp;(\text{plugging in } x=0,y=0) \\
f(0) &amp;\oplus g(1) &amp;= 0\;\;\;\; &amp;(\text{plugging in } x=0,y=1) \\
f(1) &amp;\oplus g(0) &amp;= 0\;\;\;\; &amp;(\text{plugging in } x=1,y=0) \\
f(1) &amp;\oplus g(1) &amp;= 1\;\;\;\; &amp;(\text{plugging in } x=1,y=1)
\end{aligned}
\]</span></div></span></p>
<p>If we XOR together the first and second equalities we get <span><span class="math inline">\(g(0) \oplus g(1) = 0\)</span></span> while if we XOR together the third and fourth equalities we get <span><span class="math inline">\(g(0) \oplus g(1) = 1\)</span></span>, thus obtaining a contradiction.</p>
</div>
<div id="randomizedstrategies" class="remark" title="Randomized strategies" name="Remark 22.3 (Randomized strategies) ">
<p><a href='#bellthm'>Theorem 22.2</a> above assumes that Alice and Bob use <em>deterministic</em> strategies <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> respectively. More generally, Alice and Bob could use a <em>randomized</em> strategy, or equivalently, each could choose <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> from some <em>distributions</em> <span><span class="math inline">\(\mathcal{F}\)</span></span> and <span><span class="math inline">\(\mathcal{G}\)</span></span> respectively. However the <em>averaging principle</em> (<a href='lec_15_probability.html#averagingprinciplerem'>Lemma 17.10</a>) implies that if all possible deterministic strategies succeed with probability at most <span><span class="math inline">\(3/4\)</span></span>, then the same is true for all randomized strategies.</p>
</div>
<p>An amazing <a href="http://arxiv.org/abs/1508.05949">experimentally verified</a> fact is that quantum mechanics allows for “telepathy”.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> Specifically, it has been shown that using the weirdness of quantum mechanics, there is in fact a strategy for Alice and Bob to succeed in this game with probability larger than <span><span class="math inline">\(3/4\)</span></span> (in fact, they can succeed with probability about <span><span class="math inline">\(0.85\)</span></span>, see <a href='#bellstrategy'>Lemma 22.5</a>).</p>
<h2 id="quantum-weirdness" data-number="22.4">Quantum weirdness</h2>
<p>Some of the counterintuitive properties that arise from quantum mechanics include:</p>
<ul>
<li><p><strong>Interference</strong> - As we’ve seen, quantum amplitudes can “cancel each other out”.</p></li>
<li><p><strong>Measurement</strong> - The idea that amplitudes are negative as long as “no one is looking” and “collapse” (by squaring them) to positive probabilities when they are <em>measured</em> is deeply disturbing. Indeed, as shown by EPR and Bell, this leads to various strange outcomes such as “spooky actions at a distance”, where we can create correlations between the results of measurements in places far removed. Unfortunately (or fortunately?) these strange outcomes have been confirmed experimentally.</p></li>
<li><p><strong>Entanglement</strong> - The notion that two parts of the system could be connected in this weird way where measuring one will affect the other is known as <em>quantum entanglement</em>.</p></li>
</ul>
<p>As counter-intuitive as these concepts are, they have been experimentally confirmed, so we just have to live with them.</p>
<p>The discussion in this chapter of quantum mechanics in general and quantum computing in particular is quite brief and superficial, the “bibliographical notes” section (<a href='#quantumbibnotessec'>Section 22.13</a>) contains references and links to many other resources that cover this material in more depth.</p>
<h2 id="quantum-computing-and-computation---an-executive-summary." data-number="22.5">Quantum computing and computation - an executive summary.</h2>
<p>One of the strange aspects of the quantum-mechanical picture of the world is that unlike in the billiard ball example, there is no obvious algorithm to simulate the evolution of <span><span class="math inline">\(n\)</span></span> particles over <span><span class="math inline">\(t\)</span></span> time periods in <span><span class="math inline">\(poly(n,t)\)</span></span> steps. In fact, the natural way to simulate <span><span class="math inline">\(n\)</span></span> quantum particles will require a number of steps that is <em>exponential</em> in <span><span class="math inline">\(n\)</span></span>. This is a huge headache for scientists that actually need to do these calculations in practice.</p>
<p>In the 1981, physicist Richard Feynman proposed to “turn this lemon to lemonade” by making the following almost tautological observation:</p>
<blockquote>
<p>If a physical system cannot be simulated by a computer in <span><span class="math inline">\(T\)</span></span> steps, the system can be considered as performing a computation that would take more than <span><span class="math inline">\(T\)</span></span> steps.</p>
</blockquote>
<p>So, he asked whether one could design a quantum system such that its outcome <span><span class="math inline">\(y\)</span></span> based on the initial condition <span><span class="math inline">\(x\)</span></span> would be some function <span><span class="math inline">\(y=f(x)\)</span></span> such that <strong>(a)</strong> we don’t know how to efficiently compute in any other way, and <strong>(b)</strong> is actually useful for something.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> In 1985, David Deutsch formally suggested the notion of a quantum Turing machine, and the model has been since refined in works of Deutsch, Josza, Bernstein and Vazirani. Such a system is now known as a <em>quantum computer</em>.</p>
<p>For a while these hypothetical quantum computers seemed useful for one of two things. First, to provide a general-purpose mechanism to simulate a variety of the real quantum systems that people care about, such as various interactions inside molecules in quantum chemistry. Second, as a challenge to the <em>Physical Extended Church Turing Thesis</em> which says that every physically realizable computation device can be modeled (up to polynomial overhead) by Turing machines (or equivalently, NAND-TM / NAND-RAM programs).</p>
<p>Quantum chemistry is important (and in particular understanding it can be a bottleneck for designing new materials, drugs, and more), but it is still a rather niche area within the broader context of computing (and even scientific computing) applications. Hence for a while most researchers (to the extent they were aware of it), thought of quantum computers as a theoretical curiosity that has little bearing to practice, given that this theoretical “extra power” of quantum computer seemed to offer little advantage in the majority of the problems people want to solve in areas such as combinatorial optimization, machine learning, data structures, etc..</p>
<p>To some extent this is still true today. As far as we know, quantum computers, if built, will <em>not</em> provide exponential speed ups for 95% of the applications of computing.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> In particular, as far as we know, quantum computers will <em>not</em> help us solve <span><span class="math inline">\(\mathbf{NP}\)</span></span> complete problems in polynomial or even sub-exponential time, though <em>Grover’s algorithm</em> ( <a href='#quantumnp'>Remark 22.4</a>) does yield a quadratic advantage in many cases.</p>
<p>However, there is one cryptography-sized exception: In 1994 Peter Shor showed that quantum computers can solve the integer factoring and discrete logarithm in polynomial time. This result has captured the imagination of a great many people, and completely energized research into quantum computing. This is both because the hardness of these particular problems provides the foundations for securing such a huge part of our communications (and these days, our economy), as well as it was a powerful demonstration that quantum computers could turn out to be useful for problems that a-priori seemed to have nothing to do with quantum physics.</p>
<p>As we’ll discuss later, at the moment there are several intensive efforts to construct large scale quantum computers. It seems safe to say that, as far as we know, in the next five years or so there will not be a quantum computer large enough to factor, say, a <span><span class="math inline">\(1024\)</span></span> bit number. On the other hand, it does seem quite likely that in the very near future there will be quantum computers which achieve <em>some</em> task exponentially faster than the best-known way to achieve the same task with a classical computer. When and if a quantum computer is built that is strong enough to break reasonable parameters of Diffie Hellman, RSA and elliptic curve cryptography is anybody’s guess. It could also be a “self destroying prophecy” whereby the existence of a small-scale quantum computer would cause everyone to shift away to lattice-based crypto which in turn will diminish the motivation to invest the huge resources needed to build a large scale quantum computer.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup></p>
<div id="quantumnp" class="remark" title="Quantum computing and $\mathbf{NP}$" name="Remark 22.4 (Quantum computing and $\mathbf{NP}$) ">
<p>Despite popular accounts of quantum computers as having variables that can take “zero and one at the same time” and therefore can “explore an exponential number of possibilities simultaneously”, their true power is much more subtle and nuanced. In particular, as far as we know, quantum computers do <em>not</em> enable us to solve <span><span class="math inline">\(\mathbf{NP}\)</span></span> complete problems such as 3SAT in polynomial or even sub-exponential time. However, <a href="https://goo.gl/NQVLLF">Grover’s search algorithm</a> does give a more modest advantage (namely, quadratic) for quantum computers over classical ones for problems in <span><span class="math inline">\(\mathbf{NP}\)</span></span>. In particular, due to Grover’s search algorithm, we know that the <span><span class="math inline">\(k\)</span></span>-SAT problem for <span><span class="math inline">\(n\)</span></span> variables can be solved in time <span><span class="math inline">\(O(2^{n/2}poly(n))\)</span></span> on a quantum computer for every <span><span class="math inline">\(k\)</span></span>. In contrast, the best known algorithms for <span><span class="math inline">\(k\)</span></span>-SAT on a classical computer take roughly <span><span class="math inline">\(2^{(1-\tfrac{1}{k})n}\)</span></span> steps.</p>
</div>
<div id="quantumcomp" class="bigidea" name="Bigidea 27">
<p>Quantum computers are not a panacea and are unlikely to solve <span><span class="math inline">\(\mathbf{NP}\)</span></span> complete problems, but they can provide exponential speedups to certain <em>structured</em> problems.</p>
</div>
<h2 id="quantum-systems" data-number="22.6">Quantum systems</h2>
<p>Before we talk about <em>quantum</em> computing, let us recall how we physically realize “vanilla” or <em>classical</em> computing. We model a <em>logical bit</em> that can equal <span><span class="math inline">\(0\)</span></span> or a <span><span class="math inline">\(1\)</span></span> by some physical system that can be in one of two states. For example, it might be a wire with high or low voltage, charged or uncharged capacitor, or even (as we saw) a pipe with or without a flow of water, or the presence or absence of a soldier crab. A <em>classical</em> system of <span><span class="math inline">\(n\)</span></span> bits is composed of <span><span class="math inline">\(n\)</span></span> such “basic systems”, each of which can be in either a “zero” or “one” state. We can model the state of such a system by a string <span><span class="math inline">\(s \in \{0,1\}^n\)</span></span>. If we perform an operation such as writing to the 17-th bit the NAND of the 3rd and 5th bits, this corresponds to applying a <em>local</em> function to <span><span class="math inline">\(s\)</span></span> such as setting <span><span class="math inline">\(s_{17} = 1 - s_3\cdot s_5\)</span></span>.</p>
<p>In the <em>probabilistic</em> setting, we would model the state of the system by a <em>distribution</em>. For an individual bit, we could model it by a pair of non-negative numbers <span><span class="math inline">\(\alpha,\beta\)</span></span> such that <span><span class="math inline">\(\alpha+\beta=1\)</span></span>, where <span><span class="math inline">\(\alpha\)</span></span> is the probability that the bit is zero and <span><span class="math inline">\(\beta\)</span></span> is the probability that the bit is one. For example, applying the <em>negation</em> (i.e., NOT) operation to this bit corresponds to mapping the pair <span><span class="math inline">\((\alpha,\beta)\)</span></span> to <span><span class="math inline">\((\beta,\alpha)\)</span></span> since the probability that <span><span class="math inline">\(\ensuremath{\mathit{NOT}}(\sigma)\)</span></span> is equal to <span><span class="math inline">\(1\)</span></span> is the same as the probability that <span><span class="math inline">\(\sigma\)</span></span> is equal to <span><span class="math inline">\(0\)</span></span>. This means that we can think of the NOT function as the linear map <span><span class="math inline">\(N:\R^2 \rightarrow \R^2\)</span></span> such that <span><span class="math inline">\(N \begin{pmatrix} \alpha \\ \beta \end{pmatrix} = \begin{pmatrix} \beta \\ \alpha \end{pmatrix}\)</span></span> or equivalently as the matrix <span><span class="math inline">\(\begin{pmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{pmatrix}\)</span></span>.</p>
<p>If we think of the <span><span class="math inline">\(n\)</span></span>-bit system as a whole, then since the <span><span class="math inline">\(n\)</span></span> bits can take one of <span><span class="math inline">\(2^n\)</span></span> possible values, we model the state of the system as a vector <span><span class="math inline">\(p\)</span></span> of <span><span class="math inline">\(2^n\)</span></span> probabilities. For every <span><span class="math inline">\(s\in \{0,1\}^n\)</span></span>, we denote by <span><span class="math inline">\(e_s\)</span></span> the <span><span class="math inline">\(2^n\)</span></span> dimensional vector that has <span><span class="math inline">\(1\)</span></span> in the coordinate corresponding to <span><span class="math inline">\(s\)</span></span> (identifying it with a number in <span><span class="math inline">\([2^n]\)</span></span>), and so can write <span><span class="math inline">\(p\)</span></span> as <span><span class="math inline">\(\sum_{s\in \{0,1\}^n} p_s e_s\)</span></span> where <span><span class="math inline">\(p_s\)</span></span> is the probability that the system is in the state <span><span class="math inline">\(s\)</span></span>.</p>
<p>Applying the operation above of setting the <span><span class="math inline">\(17\)</span></span>-th bit to the NAND of the 3rd and 5th bits, corresponds to transforming the vector <span><span class="math inline">\(p\)</span></span> to the vector <span><span class="math inline">\(Fp\)</span></span> where <span><span class="math inline">\(F:\R^{2^n} \rightarrow \R^{2^n}\)</span></span> is the linear map that maps <span><span class="math inline">\(e_s\)</span></span> to <span><span class="math inline">\(e_{s_0\cdots s_{16}(1-s_3\cdot s_5)s_{18}\cdots s_{n-1}}\)</span></span>. (Since <span><span class="math inline">\(\{ e_s \}_{s\in \{0,1\}^n}\)</span></span> is a <em>basis</em> for <span><span class="math inline">\(R^{2^n}\)</span></span>, it suffices to define the map <span><span class="math inline">\(F\)</span></span> on vectors of this form.)</p>
<div class="pause" name="Pause 22.6">
<p>Please make sure you understand why performing the operation will take a system in state <span><span class="math inline">\(p\)</span></span> to a system in the state <span><span class="math inline">\(Fp\)</span></span>. Understanding the evolution of probabilistic systems is a prerequisite to understanding the evolution of quantum systems.</p>
<p>If your linear algebra is a bit rusty, now would be a good time to review it, and in particular make sure you are comfortable with the notions of <em>matrices</em>, <em>vectors</em>, (orthogonal and orthonormal) <em>bases</em>, and <em>norms</em>.</p>
</div>
<h3 id="quantum-amplitudes-1" data-number="22.6.1">Quantum amplitudes</h3>
<p>In the quantum setting, the state of an individual bit (or “qubit”, to use quantum parlance) is modeled by a pair of numbers <span><span class="math inline">\((\alpha,\beta)\)</span></span> such that <span><span class="math inline">\(|\alpha|^2 + |\beta|^2 = 1\)</span></span>. While in general these numbers can be <em>complex</em>, for the rest of this chapter, we will often assume they are <em>real</em> (though potentially negative), and hence often drop the absolute value operator. (This turns out not to make much of a difference in explanatory power.) As before, we think of <span><span class="math inline">\(\alpha^2\)</span></span> as the probability that the bit equals <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(\beta^2\)</span></span> as the probability that the bit equals <span><span class="math inline">\(1\)</span></span>. As we did before, we can model the NOT operation by the map <span><span class="math inline">\(N:\R^2 \rightarrow \R^2\)</span></span> where <span><span class="math inline">\(N(\alpha,\beta)=(\beta,\alpha)\)</span></span>.</p>
<p>Following quantum tradition, instead of using <span><span class="math inline">\(e_0\)</span></span> and <span><span class="math inline">\(e_1\)</span></span> as we did above, from now on we will denote the vector <span><span class="math inline">\((1,0)\)</span></span> by <span><span class="math inline">\(|0\rangle\)</span></span> and the vector <span><span class="math inline">\((0,1)\)</span></span> by <span><span class="math inline">\(|1\rangle\)</span></span> (and moreover, think of these as column vectors). This is known as the Dirac “ket” notation. This means that NOT is the unique linear map <span><span class="math inline">\(N:\R^2 \rightarrow \R^2\)</span></span> that satisfies <span><span class="math inline">\(N |0\rangle=|1\rangle\)</span></span> and <span><span class="math inline">\(N |1\rangle =|0\rangle\)</span></span>. In other words, in the quantum case, as in the probabilistic case, NOT corresponds to the matrix <span>
<div class='myequationbox'><span class="math display">\[
N = \begin{pmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{pmatrix} \;.
\]</span></div></span></p>
<p>In classical computation, we typically think that there are only two operations that we can do on a single bit: keep it the same or negate it. In the quantum setting, a single bit operation corresponds to any linear map <span><span class="math inline">\(\ensuremath{\mathit{OP}}:\R^2 \rightarrow \R^2\)</span></span> that is <em>norm preserving</em> in the sense that for every <span><span class="math inline">\(\alpha,\beta\)</span></span>, if we apply <span><span class="math inline">\(\ensuremath{\mathit{OP}}\)</span></span> to the vector <span><span class="math inline">\(\begin{pmatrix} \alpha \\ \beta \end{pmatrix}\)</span></span> then we obtain a vector <span><span class="math inline">\(\begin{pmatrix} \alpha&#39; \\ \beta&#39; \end{pmatrix}\)</span></span> such that <span><span class="math inline">\(\alpha&#39;^2 + \beta&#39;^2 = \alpha^2 + \beta^2\)</span></span>. Such a linear map <span><span class="math inline">\(\ensuremath{\mathit{OP}}\)</span></span> corresponds to a <a href="https://en.wikipedia.org/wiki/Unitary_matrix">unitary</a> two by two matrix. (As we mentioned, quantum mechanics actually models states as vectors with <em>complex</em> coordinates; however, this does not make any qualitative difference to our discussion.) Keeping the bit the same corresponds to the matrix <span><span class="math inline">\(I = \begin{pmatrix} 1&amp;0\\ 0&amp;1 \end{pmatrix}\)</span></span> and (as we’ve seen) the NOT operations corresponds to the matrix <span><span class="math inline">\(N = \begin{pmatrix} 0&amp;1\\ 1&amp;0 \end{pmatrix}\)</span></span>. But there are other operations we can use as well. One such useful operation is the <em>Hadamard</em> operation, which corresponds to the matrix <span>
<div class='myequationbox'><span class="math display">\[H = \tfrac{1}{\sqrt{2}} \begin{pmatrix} +1 &amp; +1\\ +1 &amp; -1 \end{pmatrix} \;. \]</span></div></span></p>
<p>In fact it turns out that Hadamard is all that we need to add to a classical universal basis to achieve the full power of quantum computing.</p>
<h3 id="quantum-systems-an-executive-summary" data-number="22.6.2">Quantum systems: an executive summary</h3>
<p>If you ignore the physics and philosophy, for the purposes of understanding the model of quantum computers, all you need to know about quantum systems is the following. The <em>state</em> of a <em>quantum system</em> of <span><span class="math inline">\(n\)</span></span> qubits is modeled by an <span><span class="math inline">\(2^n\)</span></span> dimensional vector <span><span class="math inline">\(\psi\)</span></span> of unit norm (i.e., squares of all coordinates sums up to <span><span class="math inline">\(1\)</span></span>), which we write as <span><span class="math inline">\(\psi=\sum_{x\in \{0,1\}^n} \psi_x |x \rangle\)</span></span> where <span><span class="math inline">\(|x\rangle\)</span></span> is the column vector that has <span><span class="math inline">\(0\)</span></span> in all coordinates except the one corresponding to <span><span class="math inline">\(x\)</span></span> (identifying <span><span class="math inline">\(\{0,1\}^n\)</span></span> with the numbers <span><span class="math inline">\(\{0,\ldots,2^n-1\}\)</span></span>). We use the convention that if <span><span class="math inline">\(a,b\)</span></span> are strings of lengths <span><span class="math inline">\(k\)</span></span> and <span><span class="math inline">\(\ell\)</span></span> respectively then we can write the <span><span class="math inline">\(2^{k+\ell}\)</span></span> dimensional vector with <span><span class="math inline">\(1\)</span></span> in the <span><span class="math inline">\(ab\)</span></span>-th coordinate and zero elsewhere not just as <span><span class="math inline">\(|ab\rangle\)</span></span> but also as <span><span class="math inline">\(|a\rangle |b \rangle\)</span></span>. In particular, for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, we can write the vector <span><span class="math inline">\(|x\rangle\)</span></span> also as <span><span class="math inline">\(|x_0\rangle |x_1\rangle \cdots |x_{n-1} \rangle\)</span></span>. This notation satisfies certain nice distributive laws such as <span><span class="math inline">\(|a\rangle(|b\rangle + |b&#39;\rangle)|c \rangle = |abc \rangle + |ab&#39;c\rangle\)</span></span>.</p>
<p>A <em>quantum operation</em> on such a system is modeled by a <span><span class="math inline">\(2^n \times 2^n\)</span></span> <em>unitary matrix</em> <span><span class="math inline">\(U\)</span></span> (one that satisfies <span><span class="math inline">\(\ensuremath{\mathit{UU}}^\top = I\)</span></span> where <span><span class="math inline">\(U^\top\)</span></span> is the <em>transpose</em> operation, or conjugate transpose for complex matrices). If the system is in state <span><span class="math inline">\(\psi\)</span></span> and we apply to it the operation <span><span class="math inline">\(U\)</span></span>, then the new state of the system is <span><span class="math inline">\(U\psi\)</span></span>.</p>
<p>When we <em>measure</em> an <span><span class="math inline">\(n\)</span></span>-qubit system in a state <span><span class="math inline">\(\psi= \sum_{x\in \{0,1\}^n} \psi_x |x \rangle\)</span></span>, then we observe the value <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> with probability <span><span class="math inline">\(|\psi_x|^2\)</span></span>. In this case, the system <em>collapses</em> to the state <span><span class="math inline">\(|x \rangle\)</span></span>.</p>
<h2 id="analysis-of-bells-inequality-optional" data-number="22.7">Analysis of Bell’s Inequality (optional)</h2>
<p>Now that we have the notation in place, we can show a strategy for Alice and Bob to display “quantum telepathy” in Bell’s Game. Recall that in the classical case, Alice and Bob can succeed in the “Bell Game” with probability at most <span><span class="math inline">\(3/4 = 0.75\)</span></span>. We now show that quantum mechanics allows them to succeed with probability at least <span><span class="math inline">\(0.8\)</span></span>. (The strategy we show is not the best one. Alice and Bob can in fact succeed with probability <span><span class="math inline">\(\cos^2(\pi/8) \sim 0.854\)</span></span>.)</p>
<div id="bellstrategy" class="lemma" name="Lemma 22.5">
<p>There is a 2-qubit quantum state <span><span class="math inline">\(\psi\in \mathbb{C}^4\)</span></span> so that if Alice has access to the first qubit of <span><span class="math inline">\(\psi\)</span></span>, can manipulate and measure it and output <span><span class="math inline">\(a\in \{0,1\}\)</span></span> and Bob has access to the second qubit of <span><span class="math inline">\(\psi\)</span></span> and can manipulate and measure it and output <span><span class="math inline">\(b\in \{0,1\}\)</span></span> then <span><span class="math inline">\(\Pr[ a \oplus b = x \wedge y ] \geq 0.8\)</span></span>.</p>
</div>
<div class="proof" data-ref="bellstrategy" name="Proof 22.7">
<p>Alice and Bob will start by preparing a 2-qubit quantum system in the state</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\psi = \tfrac{1}{\sqrt{2}}|00\rangle + \tfrac{1}{\sqrt{2}}|11\rangle\]</span></div></span></p>
<p>(this state is known as an <a href="https://en.wikipedia.org/wiki/EPR_paradox">EPR pair</a>). Alice takes the first qubit of the system to her room, and Bob takes the second qubit to his room. Now, when Alice receives <span><span class="math inline">\(x\)</span></span> if <span><span class="math inline">\(x=0\)</span></span> she does nothing and if <span><span class="math inline">\(x=1\)</span></span> she applies the unitary map <span><span class="math inline">\(R_{-\pi/8}\)</span></span> to her qubit where <span><span class="math inline">\(R_\theta = \begin{pmatrix} cos \theta &amp; -\sin \theta \\ \sin \theta &amp; \cos \theta \end{pmatrix}\)</span></span> is the unitary operation corresponding to rotation in the plane with angle <span><span class="math inline">\(\theta\)</span></span>. When Bob receives <span><span class="math inline">\(y\)</span></span>, if <span><span class="math inline">\(y=0\)</span></span> he does nothing and if <span><span class="math inline">\(y=1\)</span></span> he applies the unitary map <span><span class="math inline">\(R_{\pi/8}\)</span></span> to his qubit. Then each one of them measures their qubit and sends this as their response.</p>
<p>Recall that to win the game Bob and Alice want their outputs to be more likely to differ if <span><span class="math inline">\(x=y=1\)</span></span> and to be more likely to agree otherwise. We will split the analysis in one case for each of the four possible values of <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(y\)</span></span>.</p>
<p><strong>Case 1: <span><span class="math inline">\(x=0\)</span></span> and <span><span class="math inline">\(y=0\)</span></span>.</strong> If <span><span class="math inline">\(x=y=0\)</span></span> then the state does not change. Because the state <span><span class="math inline">\(\psi\)</span></span> is proportional to <span><span class="math inline">\(|00\rangle + |11\rangle\)</span></span>, the measurements of Bob and Alice will always agree (if Alice measures <span><span class="math inline">\(0\)</span></span> then the state collapses to <span><span class="math inline">\(|00 \rangle\)</span></span> and so Bob measures <span><span class="math inline">\(0\)</span></span> as well, and similarly for <span><span class="math inline">\(1\)</span></span>). Hence in the case <span><span class="math inline">\(x=y=1\)</span></span>, Alice and Bob always win.</p>
<p><strong>Case 2: <span><span class="math inline">\(x=0\)</span></span> and <span><span class="math inline">\(y=1\)</span></span>.</strong> If <span><span class="math inline">\(x=0\)</span></span> and <span><span class="math inline">\(y=1\)</span></span> then after Alice measures her bit, if she gets <span><span class="math inline">\(0\)</span></span> then the system collapses to the state <span><span class="math inline">\(|00 \rangle\)</span></span>, in which case after Bob performs his rotation, his qubit is in the state <span><span class="math inline">\(\cos (\pi/8)|0\rangle+\sin(\pi/8)|1\rangle\)</span></span>. Thus, when Bob measures his qubit, he will get <span><span class="math inline">\(0\)</span></span> (and hence agree with Alice) with probability <span><span class="math inline">\(\cos^2 (\pi/8) \geq 0.85\)</span></span>. Similarly, if Alice gets <span><span class="math inline">\(1\)</span></span> then the system collapses to <span><span class="math inline">\(|11 \rangle\)</span></span>, in which case after rotation Bob’s qubit will be in the state <span><span class="math inline">\(-\sin (\pi/8)|0\rangle+\cos(\pi/8)|1\rangle\)</span></span> and so once again he will agree with Alice with probability <span><span class="math inline">\(\cos^2(\pi/8)\)</span></span>.</p>
<p>The analysis for <strong>Case 3</strong>, where <span><span class="math inline">\(x=1\)</span></span> and <span><span class="math inline">\(y=0\)</span></span>, is completely analogous to Case 2. Hence Alice and Bob will agree with probability <span><span class="math inline">\(\cos^2(\pi/8)\)</span></span> in this case as well. (To show this we use the observation that the result of this experiment is the same regardless of the order in which Alice and Bob apply their rotations and measurements; this requires a proof but is not very hard to show.)</p>
<p><strong>Case 4: <span><span class="math inline">\(x=1\)</span></span> and <span><span class="math inline">\(y=1\)</span></span>.</strong> For the case that <span><span class="math inline">\(x=1\)</span></span> and <span><span class="math inline">\(y=1\)</span></span>, after both Alice and Bob perform their rotations, the state will be proportional to</p>
<p><span>
<div class='myequationbox'><span class="math display">\[R_{-\pi/8}|0\rangle R_{\pi/8}|0 \rangle + R_{-\pi/8}|1\rangle R_{\pi/8}|1 \rangle \;. \;\;(22.6)\]</span><a id='quantumbellcasefoureq'></a></div></span></p>
<p>Intuitively, since we rotate one state by 45 degrees and the other state by -45 degrees, they will become orthogonal to each other, and the measurements will behave like independent coin tosses that agree with probability 1/2. However, for the sake of completeness, we now show the full calculation.</p>
<p>Opening up the coefficients and using <span><span class="math inline">\(\cos(-x)=\cos(x)\)</span></span> and <span><span class="math inline">\(\sin(-x)=-\sin(x)\)</span></span>, we can see that <a href='#quantumbellcasefoureq'>Equation 22.6</a> is proportional to</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\begin{aligned}
\cos^2(\pi/8)|00 \rangle &amp;+ \cos(\pi/8)\sin(\pi/8)|01 \rangle \\
- \sin(\pi/8)\cos(\pi/8)|10\rangle  &amp;+ \sin^2(\pi/8)|11 \rangle \\
-  \sin^2(\pi/8)|00 \rangle &amp;+ \sin(\pi/8)\cos(\pi/8)|01 \rangle \\
-  \cos(\pi/8)\sin(\pi/8)|10\rangle  &amp;+ \cos^2(\pi/8)|11 \rangle \;.
\end{aligned}
\]</span></div></span></p>
<p>Using the trigonometric identities <span><span class="math inline">\(2\sin(\alpha)\cos(\alpha)= \sin(2\alpha)\)</span></span> and <span><span class="math inline">\(\cos^2(\alpha) - \sin^2(\alpha) = \cos(2\alpha)\)</span></span>, we see that the probability of getting any one of <span><span class="math inline">\(|00\rangle,|10\rangle,|01\rangle,|11\rangle\)</span></span> is proportional to <span><span class="math inline">\(\cos(\pi/4)=\sin(\pi/4)=\tfrac{1}{\sqrt{2}}\)</span></span>. Hence all four options for <span><span class="math inline">\((a,b)\)</span></span> are equally likely, which mean that in this case <span><span class="math inline">\(a=b\)</span></span> with probability <span><span class="math inline">\(0.5\)</span></span>.</p>
<p>Taking all the four cases together, the overall probability of winning the game is <span><span class="math inline">\(\tfrac{1}{4}\cdot 1 + \tfrac{1}{2}\cdot 0.85 + \tfrac{1}{4} \cdot 0.5 =0.8\)</span></span>.</p>
</div>
<div id="quantumprob" class="remark" title="Quantum vs probabilistic strategies" name="Remark 22.6 (Quantum vs probabilistic strategies) ">
<p>It is instructive to understand what is it about quantum mechanics that enabled this gain in Bell’s Inequality. For this, consider the following analogous probabilistic strategy for Alice and Bob. They agree that each one of them output <span><span class="math inline">\(0\)</span></span> if he or she get <span><span class="math inline">\(0\)</span></span> as input and outputs <span><span class="math inline">\(1\)</span></span> with probability <span><span class="math inline">\(p\)</span></span> if they get <span><span class="math inline">\(1\)</span></span> as input. In this case one can see that their success probability would be <span><span class="math inline">\(\tfrac{1}{4}\cdot 1 + \tfrac{1}{2}(1-p)+\tfrac{1}{4}[2p(1-p)]=0.75 -0.5p^2 \leq 0.75\)</span></span>. The quantum strategy we described above can be thought of as a variant of the probabilistic strategy for parameter <span><span class="math inline">\(p\)</span></span> set to <span><span class="math inline">\(\sin^2 (\pi/8)=0.15\)</span></span>. But in the case <span><span class="math inline">\(x=y=1\)</span></span>, instead of disagreeing only with probability <span><span class="math inline">\(2p(1-p)=1/4\)</span></span>, the existence of the so called ``negative probabilities’’ in the quantum world allowed us to rotate the state in <em>opposing directions</em> to achieve <em>destructive interference</em> and hence a higher probability of disagreement, namely <span><span class="math inline">\(\sin^2 (\pi/4)=0.5\)</span></span>.</p>
</div>
<h2 id="quantum-computation" data-number="22.8">Quantum computation</h2>
<p>Recall that in the classical setting, we modeled computation as obtained by a sequence of <em>basic operations</em>. We had two types of computational models:</p>
<ul>
<li><p><em>Non uniform models of computation</em> such as Boolean circuits and NAND-CIRC programs, where a finite function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> is computable in size <span><span class="math inline">\(T\)</span></span> if it can be expressed as a combination of <span><span class="math inline">\(T\)</span></span> basic operations (gates in a circuit or lines in a NAND-CIRC program)</p></li>
<li><p><em>Uniform models of computation</em> such as Turing machines and NAND-TM programs, where an infinite function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is computable in time <span><span class="math inline">\(T(n)\)</span></span> if there is a single algorithm that on input <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> evaluates <span><span class="math inline">\(F(x)\)</span></span> using at most <span><span class="math inline">\(T(n)\)</span></span> basic steps.</p></li>
</ul>
<p>When considering <em>efficient computation</em>, we defined the class <span><span class="math inline">\(\mathbf{P}\)</span></span> to consist of all infinite functions <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> that can be computed by a Turing machine or NAND-TM program in time <span><span class="math inline">\(p(n)\)</span></span> for some polynomial <span><span class="math inline">\(p(\cdot)\)</span></span>. We defined the class <span><span class="math inline">\(\mathbf{P_{/poly}}\)</span></span> to consists of all infinite functions <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> such that for every <span><span class="math inline">\(n\)</span></span>, the restriction <span><span class="math inline">\(F_{\upharpoonright n}\)</span></span> of <span><span class="math inline">\(F\)</span></span> to <span><span class="math inline">\(\{0,1\}^n\)</span></span> can be computed by a Boolean circuit or NAND-CIRC program of size at most <span><span class="math inline">\(p(n)\)</span></span> for some polynomial <span><span class="math inline">\(p(\cdot)\)</span></span>.</p>
<p>We will do the same for <em>quantum computation</em>, focusing mostly on the <em>non uniform</em> setting of quantum circuits, since that is simpler, and already illustrates the important differences with classical computing.</p>
<h3 id="quantum-circuits" data-number="22.8.1">Quantum circuits</h3>
<p>A <em>quantum circuit</em> is analogous to a Boolean circuit, and can be described as a directed acyclic graph. One crucial difference that the <em>out degree</em> of every vertex in a quantum circuit is at most one. This is because we cannot “reuse” quantum states without <em>measuring</em> them (which collapses their “probabilities”). Therefore, we cannot use the same qubit as input for two different gates. (This is known as the <a href="https://goo.gl/jCVtEY">No Cloning Theorem</a>.) Another more technical difference is that to express our operations as unitary matrices, we will need to make sure all our gates are <em>reversible</em>. This is not hard to ensure. For example, in the quantum context, instead of thinking of <span><span class="math inline">\(\ensuremath{\mathit{NAND}}\)</span></span> as a (non reversible) map from <span><span class="math inline">\(\{0,1\}^2\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span>, we will think of it as the reversible map on <em>three</em> qubits that maps <span><span class="math inline">\(a,b,c\)</span></span> to <span><span class="math inline">\(a,b,c\oplus \ensuremath{\mathit{NAND}}(a,b)\)</span></span> (i.e., flip the last bit if <span><span class="math inline">\(\ensuremath{\mathit{NAND}}\)</span></span> of the first two bits is <span><span class="math inline">\(1\)</span></span>). Equivalently, the NAND operation corresponds to the <span><span class="math inline">\(8\times 8\)</span></span> unitary matrix <span><span class="math inline">\(U_{NAND}\)</span></span> such that (identifying <span><span class="math inline">\(\{0,1\}^3\)</span></span> with <span><span class="math inline">\([8]\)</span></span>) for every <span><span class="math inline">\(a,b,c \in \{0,1\}\)</span></span>, if <span><span class="math inline">\(|abc\rangle\)</span></span> is the basis element with <span><span class="math inline">\(1\)</span></span> in the <span><span class="math inline">\(abc\)</span></span>-th coordinate and zero elsewhere, then <span><span class="math inline">\(U_{NAND} |abc\rangle =|ab(c \oplus \ensuremath{\mathit{NAND}}(a,b))\rangle\)</span></span>.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup> If we order the rows and columns as <span><span class="math inline">\(000,001,010,\ldots,111\)</span></span>, then <span><span class="math inline">\(U_{NAND}\)</span></span> can be written as the following matrix:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
U_{NAND}  = \begin{pmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
                            1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
                            0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
                            0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
                            0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
                            0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
                            0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
                            0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix}
\]</span></div></span></p>
<p>If we have an <span><span class="math inline">\(n\)</span></span> qubit system, then for <span><span class="math inline">\(i,j,k \in [n]\)</span></span>, we will denote by <span><span class="math inline">\(U_{NAND}^{i,j,k}\)</span></span> as the <span><span class="math inline">\(2^n \times 2^n\)</span></span> unitary matrix that corresponds to applying <span><span class="math inline">\(U_{NAND}\)</span></span> to the <span><span class="math inline">\(i\)</span></span>-th, <span><span class="math inline">\(j\)</span></span>-th, and <span><span class="math inline">\(k\)</span></span>-th bits, leaving the others intact. That is, for every <span><span class="math inline">\(v = \sum_{x\in \{0,1\}^n} v_x |x \rangle\)</span></span>, <span><span class="math inline">\(U_{NAND}^{i,j,k}v = \sum_{x\in \{0,1\}^n}v_x |x_0 \cdots x_{k-1}(x_k \oplus \ensuremath{\mathit{NAND}}(x_i,x_j))x_{k+1} \cdots x_{n-1} \rangle\)</span></span>.</p>
<p>As mentioned above, we will also use the <em>Hadamard</em> or <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> operation, A <em>quantum circuit</em> is obtained by applying a sequence of <span><span class="math inline">\(U_{NAND}\)</span></span> and <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> gates, where a <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> gates corresponding to applying the matrix <span>
<div class='myequationbox'><span class="math display">\[H = \tfrac{1}{\sqrt{2}} \begin{pmatrix} +1 &amp; +1\\ +1 &amp; -1 \end{pmatrix} \;. \]</span></div></span> Another way to write define <span><span class="math inline">\(H\)</span></span> is that for <span><span class="math inline">\(b \in \{0,1\}\)</span></span>, <span><span class="math inline">\(H |b\rangle = \tfrac{1}{\sqrt{2}}|0\rangle + \tfrac{1}{\sqrt{2}} (-1)^b |1\rangle\)</span></span>. We define <span><span class="math inline">\(\ensuremath{\mathit{HAD}}^i\)</span></span> to be the <span><span class="math inline">\(2^n \times 2^n\)</span></span> unitary matrix that applies <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> to the <span><span class="math inline">\(i\)</span></span>-th qubit and leaves the others intact. Using the ket notation, we can write this as <span>
<div class='myequationbox'><span class="math display">\[
\ensuremath{\mathit{HAD}}^i \; \sum_{x\in \{0,1\}^n} v_x |x \rangle  \;=\; \tfrac{1}{\sqrt{2}}\sum_{x\in \{0,1\}^n}|x_0 \cdots x_{i-1}\rangle \left(|0\rangle + (-1)^{x_i}|1\rangle\right)|x_i \cdots x_{n-1} \rangle \;.
\]</span></div></span></p>
<p>A <em>quantum circuit</em> is obtained by composing these basic operations on some <span><span class="math inline">\(m\)</span></span> qubits. If <span><span class="math inline">\(m \geq n\)</span></span>, we use a circuit to compute a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span>:</p>
<ul>
<li><p>On input <span><span class="math inline">\(x\)</span></span>, we initialize the system to hold <span><span class="math inline">\(x_0,\ldots,x_{n-1}\)</span></span> in the first <span><span class="math inline">\(n\)</span></span> qubits, and initialize all remaining <span><span class="math inline">\(m-n\)</span></span> qubits to zero.</p></li>
<li><p>We execute each elementary operation one by one: at every step we apply to the current state either an operation of the form <span><span class="math inline">\(U_{NAND}^{i,j,k}\)</span></span> or an operation of the form <span><span class="math inline">\(\ensuremath{\mathit{HAD}}^i\)</span></span> for <span><span class="math inline">\(i,j,k\in [m]\)</span></span>.</p></li>
<li><p>At the end of the computation, we <em>measure</em> the system, and output the result of the last qubit (i.e. the qubit in location <span><span class="math inline">\(m-1\)</span></span>). (For simplicity we restrict attention to functions with a single bit of output, though the definition of quantum circuits naturally extends to circuits with multiple outputs.)</p></li>
<li><p>We say that the circuit <em>computes</em> the function <span><span class="math inline">\(f\)</span></span> if the probability that this output equals <span><span class="math inline">\(f(x)\)</span></span> is at least <span><span class="math inline">\(2/3\)</span></span>. Note that this probability is obtained by summing up the squares of the amplitudes of all coordinates in the final state of the system corresponding to vectors <span><span class="math inline">\(|y \rangle\)</span></span> where <span><span class="math inline">\(y_{m-1}=f(x)\)</span></span>.</p></li>
</ul>
<p>Formally we define quantum circuits as follows:</p>
<div id="quantumcircuitdef" class="definition" title="Quantum circuit" name="Definition 22.7 (Quantum circuit) ">
<p>Let <span><span class="math inline">\(s \geq m \geq n\)</span></span>. A <em>quantum circuit of <span><span class="math inline">\(n\)</span></span> inputs, <span><span class="math inline">\(m-n\)</span></span> auxiliary bits, and <span><span class="math inline">\(s\)</span></span> gates</em> over the <span><span class="math inline">\(\{ U_{NAND}, \ensuremath{\mathit{HAD}} \}\)</span></span> basis is a sequence of <span><span class="math inline">\(s\)</span></span> unitary <span><span class="math inline">\(2^m \times 2^m\)</span></span> matrices <span><span class="math inline">\(U_0,\ldots,U_{s-1}\)</span></span> such that each matrix <span><span class="math inline">\(U_\ell\)</span></span> is either of the form <span><span class="math inline">\(\ensuremath{\mathit{NAND}}^{i,j,k}\)</span></span> for <span><span class="math inline">\(i,j,k\in [m]\)</span></span> or <span><span class="math inline">\(\ensuremath{\mathit{HAD}}^i\)</span></span> for <span><span class="math inline">\(i\in [m]\)</span></span>.</p>
<p>A quantum circuit <em>computes</em> a function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> if the following is true for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>:</p>
<p>Let <span><span class="math inline">\(v\)</span></span> be the vector <span>
<div class='myequationbox'><span class="math display">\[v \;=\; U_{s-1}U_{s-2}\cdots U_1 U_0 |x0^{m-n} \rangle\]</span></div></span> and write <span><span class="math inline">\(v\)</span></span> as <span><span class="math inline">\(\sum_{y\in \{0,1\}^m} v_y |y \rangle\)</span></span>. Then <span>
<div class='myequationbox'><span class="math display">\[
\sum_{y \in \{0,1\}^m \text{ s.t. } y_{m-1}=f(x)} |v_y|^2 \geq \frac{2}{3} \;.
\]</span></div></span></p>
</div>
<div class="pause" name="Pause 22.8.1">
<p>Please stop here and see that this definition makes sense to you.</p>
</div>
<div id="quantumdefine" class="bigidea" name="Bigidea 28">
<p>Just as we did with classical computation, we can define mathematical models for quantum computation, and represent quantum algorithms as binary strings.</p>
</div>
<p>Once we have the notion of quantum circuits, we can define the quantum analog of <span><span class="math inline">\(\mathbf{P_{/poly}}\)</span></span> (i.e., the class of functions computable by <em>polynomial size quantum circuits</em>) as follows:</p>
<div id="QBPpoly" class="definition" title="$\mathbf{BQP_{/poly}}$" name="Definition 22.8 ($\mathbf{BQP_{/poly}}$) ">
<p>Let <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>. We say that <span><span class="math inline">\(F\in \mathbf{BQP_{/poly}}\)</span></span> if there exists some polynomial <span><span class="math inline">\(p:\N \rightarrow \N\)</span></span> such that for every <span><span class="math inline">\(n\in \N\)</span></span>, if <span><span class="math inline">\(F_{\upharpoonright n}\)</span></span> is the restriction of <span><span class="math inline">\(F\)</span></span> to inputs of length <span><span class="math inline">\(n\)</span></span>, then there is a quantum circuit of size at most <span><span class="math inline">\(p(n)\)</span></span> that computes <span><span class="math inline">\(F_{\upharpoonright n}\)</span></span>.</p>
</div>
<div id="exponential" class="remark" title="The obviously exponential fallacy" name="Remark 22.9 (The obviously exponential fallacy) ">
<p>A priori it might seem “obvious” that quantum computing is exponentially powerful, since to perform a quantum computation on <span><span class="math inline">\(n\)</span></span> bits we need to maintain the <span><span class="math inline">\(2^n\)</span></span> dimensional state vector and apply <span><span class="math inline">\(2^n\times 2^n\)</span></span> matrices to it. Indeed popular descriptions of quantum computing (too) often say something along the lines that the difference between quantum and classical computer is that a classical bit can either be zero or one while a qubit can be in both states at once, and so in many qubits a quantum computer can perform exponentially many computations at once.</p>
<p>Depending on how you interpret it, this description is either false or would apply equally well to <em>probabilistic computation</em>, even though we’ve already seen that every randomized algorithm can be simulated by a similar-sized circuit, and in fact we conjecture that <span><span class="math inline">\(\mathbf{BPP}=\mathbf{P}\)</span></span>.</p>
<p>Moreover, this “obvious” approach for simulating a quantum computation will take not just exponential time but <em>exponential space</em> as well, while can be shown that using a simple recursive formula one can calculate the final quantum state using <em>polynomial space</em> (in physics this is known as “Feynman path integrals”). So, the exponentially long vector description by itself does not imply that quantum computers are exponentially powerful. Indeed, we cannot <em>prove</em> that they are (i.e., we have not been able to rule out the possibility that every QNAND-CIRC program could be simulated by a NAND-CIRC program/ Boolean circuit with polynomial overhead), but we do have some problems (integer factoring most prominently) for which they do provide exponential speedup over the currently best <em>known</em> classical (deterministic or probabilistic) algorithms.</p>
</div>
<h3 id="qnand-circ-programs-optional" data-number="22.8.2">QNAND-CIRC programs (optional)</h3>
<p>Just like in the classical case, there is an equivalence between circuits and straight-line programs, and so we can define the programming language QNAND-CIRC that is the quantum analog of our NAND-CIRC programming language. To do so, we only add a single operation: <code>HAD(foo)</code> which applies the single-bit operation <span><span class="math inline">\(H\)</span></span> to the variable <code>foo</code>. We also use the following interpretation to make <code>NAND</code> reversible: <code>foo = NAND(bar,blah)</code> means that we modify <code>foo</code> to be the XOR of its original value and the NAND of <code>bar</code> and <code>blah</code>. (In other words, apply the <span><span class="math inline">\(8\)</span></span> by <span><span class="math inline">\(8\)</span></span> unitary transformation <span><span class="math inline">\(U_{NAND}\)</span></span> defined above to the three qubits corresponding to <code>foo</code>, <code>bar</code> and <code>blah</code>.) If <code>foo</code> is initialized to zero then this makes no difference.</p>
<p>If <span><span class="math inline">\(P\)</span></span> is a QNAND-CIRC program with <span><span class="math inline">\(n\)</span></span> input variables, <span><span class="math inline">\(\ell\)</span></span> workspace variables, and <span><span class="math inline">\(m\)</span></span> output variables, then running it on the input <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> corresponds to setting up a system with <span><span class="math inline">\(n+m+\ell\)</span></span> qubits and performing the following process:</p>
<ol type="1">
<li><p>We initialize the input variables <code>X[</code><span><span class="math inline">\(0\)</span></span><code>]</code> <span><span class="math inline">\(\ldots\)</span></span> <code>X[</code><span><span class="math inline">\(n-1\)</span></span><code>]</code> to <span><span class="math inline">\(x_0,\ldots,x_{n-1}\)</span></span> and all other variables to <span><span class="math inline">\(0\)</span></span>.</p></li>
<li><p>We execute the program line by line, applying the corresponding physical operation <span><span class="math inline">\(H\)</span></span> or <span><span class="math inline">\(U_{NAND}\)</span></span> to the qubits that are referred to by the line.</p></li>
<li><p>We <em>measure</em> the output variables <code>Y[</code><span><span class="math inline">\(0\)</span></span><code>]</code>, <span><span class="math inline">\(\ldots\)</span></span>, <code>Y[</code><span><span class="math inline">\(m-1\)</span></span><code>]</code> and output the result (if there is more than one output then we measure more variables).</p></li>
</ol>
<h3 id="uniform-computation" data-number="22.8.3">Uniform computation</h3>
<p>Just as in the classical case, we can define <em>uniform</em> computational models for quantum computing as well. We will let <span><span class="math inline">\(\mathbf{BQP}\)</span></span> be the quantum analog to <span><span class="math inline">\(\mathbf{P}\)</span></span> and <span><span class="math inline">\(\mathbf{BPP}\)</span></span>: the class of all Boolean functions <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> that can be computed by quantum algorithms in polynomial time. There are several equivalent ways to define <span><span class="math inline">\(\mathbf{BQP}\)</span></span>. For example, there is a computational model of <a href="https://en.wikipedia.org/wiki/Quantum_Turing_machine">Quantum Turing Machines</a> that can be used to define <span><span class="math inline">\(\mathbf{BQP}\)</span></span> just as standard Turing machines are used to define <span><span class="math inline">\(\mathbf{P}\)</span></span>. Another alternative is to define the <em>QNAND-TM programming language</em> to be QNAND-CIRC augmented with loops and arrays just like NAND-TM is obtained from NAND-CIRC. Once again, we can define <span><span class="math inline">\(\mathbf{BQP}\)</span></span> using QNAND-TM programs analogously to the way <span><span class="math inline">\(\mathbf{P}\)</span></span> can be defined using NAND-TM programs. However, we use the following equivalent definition (which is also the one most popular in the literature):</p>
<div id="BQPdef" class="definition" title="The class $\mathbf{BQP}$" name="Definition 22.10 (The class $\mathbf{BQP}$) ">
<p>Let <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>. We say that <span><span class="math inline">\(F\in \mathbf{BQP}\)</span></span> if there exists a polynomial time NAND-TM program <span><span class="math inline">\(P\)</span></span> such that for every <span><span class="math inline">\(n\)</span></span>, <span><span class="math inline">\(P(1^n)\)</span></span> is the description of a quantum circuit <span><span class="math inline">\(C_n\)</span></span> that computes the restriction of <span><span class="math inline">\(F\)</span></span> to <span><span class="math inline">\(\{0,1\}^n\)</span></span>.</p>
</div>
<div id="section-2" class="pause" name="Pause">
<p><a href='#BQPdef'>Definition 22.10</a> is the quantum analog of the alternative characterization of <span><span class="math inline">\(\mathbf{P}\)</span></span> that appears in <a href='#Palternativeex'>?? ??</a>. One way to verify that you’ve understood <a href='#BQPdef'>Definition 22.10</a> it to see that you can prove <strong>(1)</strong> <span><span class="math inline">\(\mathbf{P} \subseteq \mathbf{BQP}\)</span></span> and in fact the stronger statement <span><span class="math inline">\(\mathbf{BPP} \subseteq \mathbf{BQP}\)</span></span>, <strong>(2)</strong> <span><span class="math inline">\(\mathbf{BQP} \subseteq \mathbf{EXP}\)</span></span>, and <strong>(3)</strong> For every <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete function <span><span class="math inline">\(F\)</span></span>, if <span><span class="math inline">\(F\in \mathbf{BQP}\)</span></span> then <span><span class="math inline">\(\mathbf{NP} \subseteq \mathbf{BQP}\)</span></span>. <a href='#BQPcontainements'>Exercise 22.1</a> asks you to work these out.</p>
</div>
<p>The relation between <span><span class="math inline">\(\mathbf{NP}\)</span></span> and <span><span class="math inline">\(\mathbf{BQP}\)</span></span> is not known (see also <a href='#quantumnp'>Remark 22.4</a>). It is widely believed that <span><span class="math inline">\(\mathbf{NP} \nsubseteq \mathbf{BQP}\)</span></span>, but there is no consensus whether or not <span><span class="math inline">\(\mathbf{BQP} \subseteq \mathbf{NP}\)</span></span>. It is <a href="https://eccc.weizmann.ac.il/report/2018/107/">quite possible</a> that these two classes are <em>incomparable</em>, in the sense that <span><span class="math inline">\(\mathbf{NP} \nsubseteq \mathbf{BQP}\)</span></span> (and in particular no <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete function belongs to <span><span class="math inline">\(\mathbf{BQP}\)</span></span>) but also <span><span class="math inline">\(\mathbf{BQP} \nsubseteq \mathbf{NP}\)</span></span> (and there are some interesting candidates for such problems).</p>
<p>It can be shown that <span><span class="math inline">\(\ensuremath{\mathit{QNANDEVAL}}\)</span></span> (evaluating a quantum circuit on an input) is computable by a polynomial size QNAND-CIRC program, and moreover this program can even be generated <em>uniformly</em> and hence <span><span class="math inline">\(\ensuremath{\mathit{QNANDEVAL}}\)</span></span> is in <span><span class="math inline">\(\mathbf{BQP}\)</span></span>. This allows us to “port” many of the results of classical computational complexity into the quantum realm, including the notions of a universal quantum Turing machine, as well as all of the uncomputability results. There is even a quantum analog of the <a href="https://arxiv.org/abs/1401.3916">Cook-Levin Theorem</a>.</p>
<div id="quantumnonuniformrem" class="remark" title="Restricting attention to circuits" name="Remark 22.11 (Restricting attention to circuits) ">
<p>Because the non uniform model is a little cleaner to work with, in the rest of this chapter we mostly restrict attention to this model, though all the algorithms we discuss can be implemented using uniform algorithms as well.</p>
</div>
<h2 id="physically-realizing-quantum-computation" data-number="22.9">Physically realizing quantum computation</h2>
<p>To realize quantum computation one needs to create a system with <span><span class="math inline">\(n\)</span></span> independent binary states (i.e., “qubits”), and be able to manipulate small subsets of two or three of these qubits to change their state. While by the way we defined operations above it might seem that one needs to be able to perform arbitrary unitary operations on these two or three qubits, it turns out that there are several choices for <em>universal sets</em> - a small constant number of gates that generate all others. The biggest challenge is how to keep the system from being measured and <em>collapsing</em> to a single classical combination of states. This is sometimes known as the <em>coherence time</em> of the system. The <a href="https://courses.cs.washington.edu/courses/cse599d/06wi/lecturenotes19.pdf">threshold theorem</a> says that there is some absolute constant level of errors <span><span class="math inline">\(\tau\)</span></span> so that if errors are created at every gate at rate smaller than <span><span class="math inline">\(\tau\)</span></span> then we can recover from those and perform arbitrary long computations. (Of course there are different ways to model the errors and so there are actually several threshold <em>theorems</em> corresponding to various noise models).</p>
<figure>
<img src="../figure/googlequantum.jpg" alt="22.3: Superconducting quantum computer prototype at Google. Image credit: Google / MIT Technology Review." id="googlequantumfig" class="margin" /><figcaption>22.3: Superconducting quantum computer prototype at Google. Image credit: Google / MIT Technology Review.</figcaption>
</figure>
<p>There have been several proposals to build quantum computers:</p>
<ul>
<li><p><a href="https://en.wikipedia.org/wiki/Superconducting_quantum_computing">Superconducting quantum computers</a> use superconducting electric circuits to do quantum computation. This is the direction where <a href="https://arxiv.org/abs/1709.06678">there has been most recent progress</a> towards “beating” classical computers.</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Trapped_ion_quantum_computer">Trapped ion quantum computers</a> Use the states of an ion to simulate a qubit. People have made some <a href="http://iontrap.umd.edu/wp-content/uploads/2016/02/1602.02840v1.pdf">recent advances</a> on these computers too. While it’s not at all clear that’s the right measuring yard, the <a href="http://arxiv.org/abs/1507.08852">current best implementation</a> of Shor’s algorithm (for factoring 15) is done using an ion-trap computer.</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Topological_quantum_computer">Topological quantum computers</a> use a different technology. Topological qubits are more stable by design and hence error correction is less of an issue, but constructing them is extremely challenging.</p></li>
</ul>
<p>These approaches are not mutually exclusive and it could be that ultimately quantum computers are built by combining all of them together. In the near future, it seems that we will not be able to achieve full fledged large scale universal quantum computers, but rather more restricted machines, sometimes called “Noisy Intermediate-Scale Quantum Computers” or “NISQ”. See <a href="https://arxiv.org/abs/1801.00862">this article by John Preskil</a> for some of the progress and applications of such more restricted devices.</p>
<h2 id="shors-algorithm-hearing-the-shape-of-prime-factors" data-number="22.10">Shor’s Algorithm: Hearing the shape of prime factors</h2>
<p>Bell’s Inequality is a powerful demonstration that there is something very strange going on with quantum mechanics. But could this “strangeness” be of any use to solve computational problems not directly related to quantum systems? A priori, one could guess the answer is <em>no</em>. In 1994 Peter Shor showed that one would be wrong:</p>
<div id="shorthm" class="theorem" title="Shor&#39;s Algorithm" name="Theorem 22.12 (Shor&#39;s Algorithm) ">
<p>There is a polynomial-time quantum algorithm that on input an integer <span><span class="math inline">\(M\)</span></span> (represented in base two), outputs the prime factorization of <span><span class="math inline">\(M\)</span></span>.</p>
</div>
<p>Another way to state <a href='#shorthm'>Theorem 22.12</a> is that if we define <span><span class="math inline">\(\ensuremath{\mathit{FACTORING}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> to be the function that on input a pair of numbers <span><span class="math inline">\((M,X)\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(M\)</span></span> has a factor <span><span class="math inline">\(P\)</span></span> such that <span><span class="math inline">\(2 \leq P \leq X\)</span></span>, then <span><span class="math inline">\(\ensuremath{\mathit{FACTORING}}\)</span></span> is in <span><span class="math inline">\(\mathbf{BQP}\)</span></span>. This is an exponential improvement over the best known classical algorithms, which take roughly <span><span class="math inline">\(2^{\tilde{O}(n^{1/3})}\)</span></span> time, where the <span><span class="math inline">\(\tilde{O}\)</span></span> notation hides factors that are polylogarithmic in <span><span class="math inline">\(n\)</span></span>. While we will not prove <a href='#shorthm'>Theorem 22.12</a> in this chapter, we will sketch some of the ideas behind the proof.</p>
<h3 id="period-finding" data-number="22.10.1">Period finding</h3>
<p>At the heart of Shor’s Theorem is an efficient quantum algorithm for finding <em>periods</em> of a given function. For example, a function <span><span class="math inline">\(f:\R \rightarrow \R\)</span></span> is <em>periodic</em> if there is some <span><span class="math inline">\(h&gt;0\)</span></span> such that <span><span class="math inline">\(f(x+h)=f(x)\)</span></span> for every <span><span class="math inline">\(x\)</span></span> (e.g., see <a href='#periodicfig'>Figure 22.4</a>).</p>
<figure>
<img src="../figure/periodic_vs_aperiodic.png" alt="22.4: Top: A periodic function. Bottom: An a-periodic function." id="periodicfig" class="margin" /><figcaption>22.4: Top: A periodic function. Bottom: An a-periodic function.</figcaption>
</figure>
<p><em>Musical notes</em> yield one type of periodic function. When you pull on a string on a musical instrument, it vibrates in a repeating pattern. Hence, if we plot the speed of the string (and so also the speed of the air around it) as a function of time, it will correspond to some <em>periodic</em> function. The length of the period is known as the <em>wave length</em> of the note. The <em>frequency</em> is the number of times the function repeats itself within a unit of time. For example, the “Middle C” note has a frequency of <span><span class="math inline">\(261.63\)</span></span> Hertz, which means its period is <span><span class="math inline">\(1/(261.63)\)</span></span> seconds.</p>
<p>If we play a <em>chord</em> by playing several notes at once, we get a more complex periodic function obtained by combining the functions of the individual notes (see <a href='#timefreqfig'>Figure 22.5</a>). The human ear contains many small hairs, each of which is sensitive to a narrow band of frequencies. Hence when we hear the sound corresponding to a chord, the hairs in our ears actually separate it out to the components corresponding to each frequency.</p>
<figure>
<img src="../figure/timefreq.png" alt="22.5: Left: The air-pressure when playing a “C Major” chord as a function of time. Right: The coefficients of the Fourier transform of the same function, we can see that it is the sum of three frequencies corresponding to the C, E and G notes (261.63, 329.63 and 392 Hertz respectively). Credit: Bjarke Mønsted’s Quora answer." id="timefreqfig" class="margin" /><figcaption>22.5: Left: The air-pressure when playing a “C Major” chord as a function of time. Right: The coefficients of the Fourier transform of the same function, we can see that it is the sum of three frequencies corresponding to the C, E and G notes (261.63, 329.63 and 392 Hertz respectively). Credit: Bjarke Mønsted’s <a href="https://www.quora.com/What-is-the-meaning-of-frequency-domain">Quora answer</a>.</figcaption>
</figure>
<p>It turns out that (essentially) <em>every</em> periodic function <span><span class="math inline">\(f:\R \rightarrow \R\)</span></span> can be decomposed into a sum of simple <em>wave</em> functions (namely functions of the form <span><span class="math inline">\(x \mapsto \sin(\theta x)\)</span></span> or <span><span class="math inline">\(x \mapsto \cos(\theta x)\)</span></span>). This is known as the <a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier Transform</a> (see <a href='#qfourierfig'>Figure 22.6</a>). The Fourier transform makes it easy to compute the period of a given function: it will simply be the least common multiple of the periods of the constituent waves.</p>
<figure>
<img src="../figure/quantum_fourier.jpg" alt="22.6: If f is a periodic function then when we represent it in the Fourier transform, we expect the coefficients corresponding to wavelengths that do not evenly divide the period to be very small, as they would tend to “cancel out”." id="qfourierfig" class="margin" /><figcaption>22.6: If <span><span class="math inline">\(f\)</span></span> is a periodic function then when we represent it in the Fourier transform, we expect the coefficients corresponding to wavelengths that do not evenly divide the period to be very small, as they would tend to “cancel out”.</figcaption>
</figure>
<h3 id="shors-algorithm-a-birds-eye-view" data-number="22.10.2">Shor’s Algorithm: A bird’s eye view</h3>
<p>On input an integer <span><span class="math inline">\(M\)</span></span>, Shor’s algorithm outputs the prime factorization of <span><span class="math inline">\(M\)</span></span> in time that is polynomial in <span><span class="math inline">\(\log M\)</span></span>. The main steps in the algorithm are the following:</p>
<p><strong>Step 1: Reduce to period finding.</strong> The first step in the algorithm is to pick a random <span><span class="math inline">\(A\in \{0,1\ldots,M-1\}\)</span></span> and define the function <span><span class="math inline">\(F_A:\{0,1\}^m \rightarrow \{0,1\}^m\)</span></span> as <span><span class="math inline">\(F_A(x)= A^x (\mod M)\)</span></span> where we identify the string <span><span class="math inline">\(x \in \{0,1\}^m\)</span></span> with an integer using the binary representation, and similarly represent the integer <span><span class="math inline">\(A^x (\mod M)\)</span></span> as a string. (We will choose <span><span class="math inline">\(m\)</span></span> to be some polynomial in <span><span class="math inline">\(\log M\)</span></span> and so in particular <span><span class="math inline">\(\{0,1\}^m\)</span></span> is a large enough set to represent all the numbers in <span><span class="math inline">\(\{0,1,\ldots, M-1 \}\)</span></span>).</p>
<p>Some not-too-hard (though somewhat technical) calculations show that: <strong>(1)</strong> The function <span><span class="math inline">\(F_A\)</span></span> is <em>periodic</em> (i.e., there is some integer <span><span class="math inline">\(p_A\)</span></span> such that <span><span class="math inline">\(F_A(x+p_A)=F_A(x)\)</span></span> for “almost” every <span><span class="math inline">\(x\)</span></span>) and more importantly <strong>(2)</strong> If we can recover the period <span><span class="math inline">\(p_A\)</span></span> of <span><span class="math inline">\(F_A\)</span></span> for several randomly chosen <span><span class="math inline">\(A\)</span></span>’s, then we can recover the factorization of <span><span class="math inline">\(M\)</span></span>. (We’ll ignore the “almost” qualifier in the discussion below; it causes some annoying, yet ultimately manageable, technical issues in the full-fledged algorithm.) Hence, factoring <span><span class="math inline">\(M\)</span></span> reduces to finding out the period of the function <span><span class="math inline">\(F_A\)</span></span>. <a href='#dlogfromorder'>Exercise 22.2</a> asks you to work out this for the related task of computing the <em>discrete logarithm</em> (which underlies the security of the Diffie-Hellman key exchange and elliptic curve cryptography).</p>
<p><strong>Step 2: Period finding via the Quantum Fourier Transform.</strong> Using a simple trick known as “repeated squaring”, it is possible to compute the map <span><span class="math inline">\(x \mapsto F_A(x)\)</span></span> in time polynomial in <span><span class="math inline">\(m\)</span></span>, which means we can also compute this map using a polynomial number of NAND gates,and so in particular we can generate in polynomial quantum time a quantum state <span><span class="math inline">\(\rho\)</span></span> that is (up to normalization) equal to</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\sum_{x\in \{0,1\}^m} |x\rangle |F_A(x) \rangle \;\;.
\]</span></div></span></p>
<p>In particular, if we were to <em>measure</em> the state <span><span class="math inline">\(\rho\)</span></span>, we would get a random pair of the form <span><span class="math inline">\((x,y)\)</span></span> where <span><span class="math inline">\(y= F_A(x)\)</span></span>. So far, this is not at all impressive. After all, we did not need the power of quantum computing to generate such pairs: we could simply generate a random <span><span class="math inline">\(x\)</span></span> and then compute <span><span class="math inline">\(F_A(x)\)</span></span>.</p>
<p>Another way to describe the state <span><span class="math inline">\(\rho\)</span></span> is that the coefficient of <span><span class="math inline">\(|x \rangle |y \rangle\)</span></span> in <span><span class="math inline">\(\rho\)</span></span> is proportional to <span><span class="math inline">\(f_{A,y}(x)\)</span></span> where <span><span class="math inline">\(f_{A,y} : \{0,1\}^m \rightarrow \R\)</span></span> is the function such that <span>
<div class='myequationbox'><span class="math display">\[f_{A,y}(x) = \begin{cases} 1 &amp; y = A^x (\mod M) \\ 0 &amp; \text{otherwise} \end{cases} \;.\]</span></div></span></p>
<p>The magic of Shor’s algorithm comes from a procedure known as the <a href="https://en.wikipedia.org/wiki/Quantum_Fourier_transform"><em>Quantum Fourier Transform</em></a>. It allows to change the state <span><span class="math inline">\(\rho\)</span></span> into the state <span><span class="math inline">\(\hat{\rho}\)</span></span> where the coefficient of <span><span class="math inline">\(|x\rangle|y \rangle\)</span></span> is now proportional to the <em><span><span class="math inline">\(x\)</span></span>-th Fourier coefficient</em> of <span><span class="math inline">\(f_{A,y}\)</span></span>. In other words, if we measure the state <span><span class="math inline">\(\hat{\rho}\)</span></span>, we will obtain a pair <span><span class="math inline">\((x,y)\)</span></span> such that the probability of choosing <span><span class="math inline">\(x\)</span></span> is proportional to the square of the weight of the <em>frequency</em> <span><span class="math inline">\(x\)</span></span> in the representation of the function <span><span class="math inline">\(f_{A,y}\)</span></span>. Since for every <span><span class="math inline">\(y\)</span></span>, the function <span><span class="math inline">\(f_{A,y}\)</span></span> has the period <span><span class="math inline">\(p_A\)</span></span>, it can be shown that the frequency <span><span class="math inline">\(x\)</span></span> will be (almost) a multiple of <span><span class="math inline">\(p_A\)</span></span>. If we make several such samples <span><span class="math inline">\(y_0,\ldots,y_k\)</span></span> and obtain the frequencies <span><span class="math inline">\(x_1,\ldots,x_k\)</span></span>, then the true period <span><span class="math inline">\(p_A\)</span></span> divides all of them, and it can be shown that it is going to be in fact the <em>greatest common divisor</em> (g.c.d.) of all these frequencies: a value which can be computed in polynomial time.</p>
<p>As mentioned above, we can recover the factorization of <span><span class="math inline">\(M\)</span></span> from the periods of <span><span class="math inline">\(F_{A_0},\ldots,F_{A_t}\)</span></span> for some randomly chosen <span><span class="math inline">\(A_0,\ldots,A_t\)</span></span> in <span><span class="math inline">\(\{0,\ldots, M-1\}\)</span></span> and <span><span class="math inline">\(t\)</span></span> which is polynomial in <span><span class="math inline">\(\log M\)</span></span>.</p>
<p>The resulting algorithm can be described in a high (and somewhat inaccurate) level as follows:</p>
<blockquote>
<div class="quote" name="Quote 22.10.2">
<p><strong>Shor’s Algorithm:</strong> <em>(sketch)</em></p>
<p><strong>Input:</strong> Number <span><span class="math inline">\(M\in \N\)</span></span>.</p>
<p><strong>Output:</strong> Prime factorization of <span><span class="math inline">\(M\)</span></span>.</p>
<p><strong>Operations:</strong></p>
<ol type="1">
<li><p>Repeat the following <span><span class="math inline">\(k=poly(\log M)\)</span></span> number of times:</p>
<ol type="a">
<li><p>Choose <span><span class="math inline">\(A \in \{0,\ldots,M-1\}\)</span></span> at random, and let <span><span class="math inline">\(f_A:\Z_M \rightarrow \Z_M\)</span></span> be the map <span><span class="math inline">\(x \mapsto A^x \mod M\)</span></span>.</p></li>
<li><p>For <span><span class="math inline">\(t=poly(\log M)\)</span></span>, repeat <span><span class="math inline">\(t\)</span></span> times the following step: <em>Quantum Fourier Transform</em> to create a quantum state <span><span class="math inline">\(| \psi \rangle\)</span></span> over <span><span class="math inline">\(poly(\log(m))\)</span></span> qubits, such that if we measure <span><span class="math inline">\(| \psi \rangle\)</span></span> we obtain a pair of strings <span><span class="math inline">\((j,y)\)</span></span> with probability proportional to the square of the coefficient corresponding to the wave function <span><span class="math inline">\(x \mapsto \cos(x \pi j/M)\)</span></span> or <span><span class="math inline">\(x \mapsto \sin(x \pi j/M)\)</span></span> in the Fourier transform of the function <span><span class="math inline">\(f_{A,y}:\Z_m \rightarrow \{0,1\}\)</span></span> defined as <span><span class="math inline">\(f_{A,y}(x)=1\)</span></span> iff <span><span class="math inline">\(f_A(x)=y\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(j_1,\ldots,j_t\)</span></span> are the coefficients we obtained in the previous step, then the least common multiple of <span><span class="math inline">\(M/j_1,\ldots,M/j_t\)</span></span> is likely to be the <em>period</em> of the function <span><span class="math inline">\(f_A\)</span></span>.</p></li>
</ol></li>
<li><p>If we let <span><span class="math inline">\(A_0,\ldots,A_{k-1}\)</span></span> and <span><span class="math inline">\(p_0,\ldots,p_{k-1}\)</span></span> be the numbers we chose in the previous step and the corresponding periods of the functions <span><span class="math inline">\(f_{A_0},\ldots,f_{A_{k-1}}\)</span></span> then we can use classical results in number theory to obtain from these a non-trivial prime factor <span><span class="math inline">\(Q\)</span></span> of <span><span class="math inline">\(M\)</span></span> (if such exists). We can now run the algorithm again with the (smaller) input <span><span class="math inline">\(M/Q\)</span></span> to obtain all other factors.</p></li>
</ol>
</div>
</blockquote>
<p>Reducing factoring to order finding is cumbersome, but can be done in polynomial time using a classical computer. The key quantum ingredient in Shor’s algorithm is the <em>quantum fourier transform</em>.</p>
<div id="QFT" class="remark" title="Quantum Fourier Transform" name="Remark 22.13 (Quantum Fourier Transform) ">
<p>Despite its name, the Quantum Fourier Transform does <em>not</em> actually give a way to compute the Fourier Transform of a function <span><span class="math inline">\(f:\{0,1\}^m \rightarrow \R\)</span></span>. This would be impossible to do in time polynomial in <span><span class="math inline">\(m\)</span></span>, as simply writing down the Fourier Transform would require <span><span class="math inline">\(2^m\)</span></span> coefficients. Rather the Quantum Fourier Transform gives a <em>quantum state</em> where the amplitude corresponding to an element (think: frequency) <span><span class="math inline">\(h\)</span></span> is equal to the corresponding Fourier coefficient. This allows to sample from a distribution where <span><span class="math inline">\(h\)</span></span> is drawn with probability proportional to the square of its Fourier coefficient. This is not the same as computing the Fourier transform, but is good enough for recovering the period.</p>
</div>
<h2 id="quantum-fourier-transform-advanced-optional" data-number="22.11">Quantum Fourier Transform (advanced, optional)</h2>
<p>The above description of Shor’s algorithm skipped over the implementation of the main quantum ingredient: the <em>Quantum Fourier Transform</em> algorithm. In this section we discuss the ideas behind this algorithm. We will be rather brief and imprecise. <a href='#quantumbibnotessec'>Section 22.13</a> contain references to sources of more information about this topic.</p>
<p>To understand the Quantum Fourier Transform, we need to better understand the Fourier Transform itself. In particular, we will need to understand how it applies not just to functions whose input is a real number but to functions whose domain can be any arbitrary commutative <em>group</em>. Therefore we now take a short detour to (very basic) <em>group theory</em>, and define the notion of periodic functions over groups.</p>
<div id="grouptheorem" class="remark" title="Group theory" name="Remark 22.14 (Group theory) ">
<p>While we define the concepts we use, some background in group or number theory will be very helpful for fully understanding this section. In particular we will use the notion of <em>finite commutative (a.k.a. Abelian) groups</em>. These are defined as follows.</p>
<ul>
<li><p>A finite <em>group</em> <span><span class="math inline">\(\mathbb{G}\)</span></span> is a pair <span><span class="math inline">\((G,\star)\)</span></span> where <span><span class="math inline">\(G\)</span></span> is a finite set of elements and <span><span class="math inline">\(\star\)</span></span> is a <em>binary operation</em> mapping a pair <span><span class="math inline">\(g,h\)</span></span> of elements in <span><span class="math inline">\(G\)</span></span> to the element <span><span class="math inline">\(g \star h\)</span></span> in <span><span class="math inline">\(G\)</span></span>. We often identify <span><span class="math inline">\(\mathbb{G}\)</span></span> with the set <span><span class="math inline">\(G\)</span></span> of its elements, and so use notation such as <span><span class="math inline">\(g\in \mathbb{G}\)</span></span> to indicate that <span><span class="math inline">\(g\)</span></span> is an element of <span><span class="math inline">\(\mathbb{G}\)</span></span> and <span><span class="math inline">\(|\mathbb{G}|\)</span></span> to denote the number of elements in <span><span class="math inline">\(\mathbb{G}\)</span></span>.</p></li>
<li><p>The operation <span><span class="math inline">\(\star\)</span></span> satisfies the sort of properties that a product operation does, namely, it is <em>associative</em> (i.e., <span><span class="math inline">\((g \star h)\star f = g \star (h \star f)\)</span></span>) and there is some element <span><span class="math inline">\(1\)</span></span> such that <span><span class="math inline">\(g \star 1 = g\)</span></span> for all <span><span class="math inline">\(g\)</span></span>, and for every <span><span class="math inline">\(g\in \mathbb{G}\)</span></span> there exists an element <span><span class="math inline">\(g^{-1}\)</span></span> such that <span><span class="math inline">\(g \star g^{-1} = 1\)</span></span>.</p></li>
<li><p>A group is called <em>commutative</em> (also known as <em>Abelian</em>) if <span><span class="math inline">\(g \star h = h \star g\)</span></span> for all <span><span class="math inline">\(g,h \in \mathbb{G}\)</span></span>.</p></li>
</ul>
</div>
<p>The Fourier transform is a deep and vast topic, on which we will barely touch upon here. Over the real numbers, the Fourier transform of a function <span><span class="math inline">\(f\)</span></span> is obtained by expressing <span><span class="math inline">\(f\)</span></span> in the form <span><span class="math inline">\(\sum \hat{f}(\alpha)\chi_\alpha\)</span></span> where the <span><span class="math inline">\(\chi_\alpha\)</span></span>’s are “wave functions” (e.g. sines and cosines). However, it turns out that the same notion exists for <em>every</em> Abelian group <span><span class="math inline">\(\mathbb{G}\)</span></span>. Specifically, for every such group <span><span class="math inline">\(\mathbb{G}\)</span></span>, if <span><span class="math inline">\(f\)</span></span> is a function mapping <span><span class="math inline">\(\mathbb{G}\)</span></span> to <span><span class="math inline">\(\mathbb{C}\)</span></span>, then we can write <span><span class="math inline">\(f\)</span></span> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[f = \sum_{g \in \mathbb{G}} \hat{f}(g)\chi_g \;\;, \;\;(22.15)\]</span><a id='fourierexpansion'></a></div></span></p>
<p>where the <span><span class="math inline">\(\chi_g\)</span></span>’s are functions mapping <span><span class="math inline">\(\mathbb{G}\)</span></span> to <span><span class="math inline">\(\mathbb{C}\)</span></span> that are analogs of the “wave functions” for the group <span><span class="math inline">\(\mathbb{G}\)</span></span> and for every <span><span class="math inline">\(g\in \mathbb{G}\)</span></span>, <span><span class="math inline">\(\hat{f}(g)\)</span></span> is a complex number known as the <em>Fourier coefficient of <span><span class="math inline">\(f\)</span></span> corresponding to <span><span class="math inline">\(g\)</span></span></em>. Specifically, the equation <a href='#fourierexpansion'>Equation 22.15</a> means that if we think of <span><span class="math inline">\(f\)</span></span> as a <span><span class="math inline">\(|\mathbb{G}|\)</span></span> dimensional vector over the complex numbers, then we can write this vector as a sum (with certain coefficients) of the vectors <span><span class="math inline">\(\{ \chi_g \}_{g\in \mathbb{G}}\)</span></span>. The representation <a href='#fourierexpansion'>Equation 22.15</a> is known as the <em>Fourier expansion</em> or <em>Fourier transform</em> of <span><span class="math inline">\(f\)</span></span>, the numbers <span><span class="math inline">\(( \hat{f}(g) )_{g\in\mathbb{G}}\)</span></span> are known as the <em>Fourier coefficients</em> of <span><span class="math inline">\(f\)</span></span> and the functions <span><span class="math inline">\(( \chi_g )_{g\in\mathbb{G}}\)</span></span> are known as the <em>Fourier characters</em>. The central property of the Fourier characters is that they are <em>homomorphisms</em> of the group into the complex numbers, in the sense that for every <span><span class="math inline">\(x,x&#39; \in \mathbb{G}\)</span></span>, <span><span class="math inline">\(\chi_g(x \star x&#39;)=\chi_g(x)\chi_g(x&#39;)\)</span></span>, where <span><span class="math inline">\(\star\)</span></span> is the group operation. One corollary of this property is that if <span><span class="math inline">\(\chi_g(h)=1\)</span></span> then <span><span class="math inline">\(\chi_g\)</span></span> is <em><span><span class="math inline">\(h\)</span></span> periodic</em> in the sense that <span><span class="math inline">\(\chi_g(x \star h)=\chi_g(x)\)</span></span> for every <span><span class="math inline">\(x\)</span></span>. It turns out that if <span><span class="math inline">\(f\)</span></span> is periodic with minimal period <span><span class="math inline">\(h\)</span></span>, then the only Fourier characters that have non zero coefficients in the expression <a href='#fourierexpansion'>Equation 22.15</a> are those that are <span><span class="math inline">\(h\)</span></span> periodic as well. This can be used to recover the period of <span><span class="math inline">\(f\)</span></span> from its Fourier expansion.</p>
<h3 id="quantum-fourier-transform-over-the-boolean-cube-simons-algorithm" data-number="22.11.1">Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</h3>
<p>We now describe the simplest setting of the Quantum Fourier Transform: the group <span><span class="math inline">\(\{0,1\}^n\)</span></span> with the XOR operation, which we’ll denote by <span><span class="math inline">\((\{0,1\}^n,\oplus)\)</span></span>. (Since <span><span class="math inline">\(\ensuremath{\mathit{XOR}}\)</span></span> is equal to addition modulo two, this group is also often denoted as <span><span class="math inline">\((\Z_2)^n\)</span></span>.) It can be shown that the Fourier transform over <span><span class="math inline">\((\{0,1\}^n,\oplus)\)</span></span> corresponds to expressing <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \mathbb{C}\)</span></span> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
f = \sum_{y\in \{0,1\}} \hat{f}(y) \chi_y
\]</span></div></span></p>
<p>where <span><span class="math inline">\(\chi_y:\{0,1\}^n \rightarrow \mathbb{C}\)</span></span> is defined as <span><span class="math inline">\(\chi_y(x) = (-1)^{\sum_i y_i x_i}\)</span></span> and <span><span class="math inline">\(\hat{f}(y) = \tfrac{1}{\sqrt{2^n}}\sum_{x\in \{0,1\}^n} f(x)(-1)^{\sum_i y_i x_i}\)</span></span>.</p>
<p>The Quantum Fourier Transform over <span><span class="math inline">\((\{0,1\}^n,\oplus)\)</span></span> is actually quite simple:</p>
<div id="QFTcube" class="theorem" title="QFT Over the Boolean Cube" name="Theorem 22.15 (QFT Over the Boolean Cube) ">
<p>Let <span><span class="math inline">\(\rho = \sum_{x\in \{0,1\}^n} f(x)|x\rangle\)</span></span> be a quantum state where <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \mathbb{C}\)</span></span> is some function satisfying <span><span class="math inline">\(\sum_{x\in \{0,1\}^n} |f(x)|^2 = 1\)</span></span>. Then we can use <span><span class="math inline">\(n\)</span></span> gates to transform <span><span class="math inline">\(\rho\)</span></span> to the state</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\sum_{y\in \{0,1\}^n} \hat{f}(y) |y \rangle\]</span></div></span></p>
<p>where <span><span class="math inline">\(f = \sum_{y} \hat{f}(y)\chi_y\)</span></span> and <span><span class="math inline">\(\chi_y:\{0,1\}^n \rightarrow \mathbb{C}\)</span></span> is the function <span><span class="math inline">\(\chi_y(x) = -1^{\sum x_iy_i}\)</span></span>.</p>
</div>
<div id="section-3" class="proofidea" data-ref="QFTcube" name="Proofidea">
<p>The idea behind the proof is that the <em>Hadamard</em> operation corresponds to the <em>Fourier transform</em> over the group <span><span class="math inline">\(\{0,1\}^n\)</span></span> (with the XOR operations). To show this, we just need to do the calculations.</p>
</div>
<div class="proof" data-ref="QFTcube" name="Proof 22.11.1">
<p>We can express the Hadamard operation <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> as follows:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[ \ensuremath{\mathit{HAD}}|a\rangle = \tfrac{1}{\sqrt{2}}(|0\rangle+(-1)^a|1\rangle) \;.\]</span></div></span></p>
<p>We are given the state <span>
<div class='myequationbox'><span class="math display">\[\rho = \sum_{x\in\{0,1\}^n} f(x)|x\rangle \;.\]</span></div></span></p>
<p>Now suppose that we apply the <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> operation to each of the <span><span class="math inline">\(n\)</span></span> qubits. We can see that we get the state</p>
<p><span>
<div class='myequationbox'><span class="math display">\[2^{-n/2}\sum_{x\in\{0,1\}^n}f(x)\prod_{i=0}^{n-1}(|0\rangle+(-1)^{x_i}|1\rangle) \;.
\]</span></div></span></p>
<p>We can now use the distributive law and open up a term of the form</p>
<p><span>
<div class='myequationbox'><span class="math display">\[f(x)\bigl(|0\rangle + (-1)^{x_0}|1\rangle\bigr) \cdots  \bigl(|0\rangle + (-1)^{x_{n-1}}|1\rangle\bigr)\]</span></div></span></p>
<p>to the following sum over <span><span class="math inline">\(2^n\)</span></span> terms: <span>
<div class='myequationbox'><span class="math display">\[
f(x) \sum_{y \in \{0,1\}^n} (-1)^{\sum y_ix_i}|y \rangle \;.
\]</span></div></span></p>
<p>(If you find the above confusing, try to work out explicitly this calculation for <span><span class="math inline">\(n=3\)</span></span>; namely show that <span><span class="math inline">\(\bigl(|0\rangle + (-1)^{x_0}|1 \rangle\bigr) \bigl(|0\rangle + (-1)^{x_1}|1 \rangle \bigr) \bigl(|0\rangle + (-1)^{x_2}|1 \rangle \bigr)\)</span></span> is the same as the sum over <span><span class="math inline">\(2^3\)</span></span> terms <span><span class="math inline">\(|000\rangle + (-1)^{x_2}|001\rangle + \cdots +(-1)^{x_0+x_1+x_2}|111\rangle\)</span></span>.)</p>
<p>By changing the order of summations, we see that the final state is</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\sum_{y \in \{0,1\}^n} 2^{-n/2}\bigl(\sum_{x\in \{0,1\}^n} f(x) (-1)^{\sum x_i y_i} \bigr) | y \rangle
\]</span></div></span></p>
<p>which exactly corresponds to <span><span class="math inline">\(\hat{\rho}\)</span></span>.</p>
</div>
<h3 id="from-fourier-to-period-finding-simons-algorithm-advanced-optional" data-number="22.11.2">From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</h3>
<p>Using <a href='#QFTcube'>Theorem 22.15</a> it is not hard to get an algorithm that can recover a string <span><span class="math inline">\(h^* \in \{0,1\}^n\)</span></span> given a circuit that computes a function <span><span class="math inline">\(F:\{0,1\}^n \rightarrow \{0,1\}^*\)</span></span> that is <em><span><span class="math inline">\(h^*\)</span></span> periodic</em> in the sense that <span><span class="math inline">\(F(x)=F(x&#39;)\)</span></span> for distinct <span><span class="math inline">\(x,x&#39;\)</span></span> if and only if <span><span class="math inline">\(x&#39; = x \oplus h^*\)</span></span>. The key observation is that if we compute the state <span><span class="math inline">\(\sum_{x\in \{0,1\}^n} |x \rangle |F(x) \rangle\)</span></span>, and perform the Quantum Fourier transform on the first <span><span class="math inline">\(n\)</span></span> qubits, then we would get a state such that the only basis elements with nonzero coefficients would be of the form <span><span class="math inline">\(|y \rangle\)</span></span> where</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\sum y_i h^*_i = 0 (\mod 2) \;\;(22.24)
\]</span><a id='eq:periodbooleanqft'></a></div></span></p>
<p>So, by measuring the state, we can obtain a sample of a random <span><span class="math inline">\(y\)</span></span> satisfying <a href='#eq:periodbooleanqft'>Equation 22.24</a>. But since <a href='#eq:periodbooleanqft'>Equation 22.24</a> is a <em>linear</em> equation modulo <span><span class="math inline">\(2\)</span></span> about the unknown <span><span class="math inline">\(n\)</span></span> variables <span><span class="math inline">\(h^*_0,\ldots,h^*_{n-1}\)</span></span>, if we repeat this procedure to get <span><span class="math inline">\(n\)</span></span> such equations, we will have at least as many equations as variables and (it can be shown that) this will suffice to recover <span><span class="math inline">\(h^*\)</span></span>.</p>
<p>This result is known as <a href="https://en.wikipedia.org/wiki/Simon%27s_problem">Simon’s Algorithm</a>, and it preceded and inspired Shor’s algorithm.</p>
<h3 id="from-simon-to-shor-advanced-optional" data-number="22.11.3">From Simon to Shor (advanced, optional)</h3>
<p><a href='#QFTcube'>Theorem 22.15</a> seemed to really use the special bit-wise structure of the group <span><span class="math inline">\(\{0,1\}^n\)</span></span>, and so one could wonder if it can be extended to other groups. However, it turns out that we can in fact achieve such a generalization.</p>
<p>The key step in Shor’s algorithm is to implement the Fourier transform for the group <span><span class="math inline">\(\Z_L\)</span></span> which is the set of numbers <span><span class="math inline">\(\{0,\ldots,L-1\}\)</span></span> with the operation being addition modulo <span><span class="math inline">\(L\)</span></span>. In this case it turns out that the Fourier characters are the functions <span><span class="math inline">\(\chi_y(x) = \omega^{yx}\)</span></span> where <span><span class="math inline">\(\omega = e^{2\pi i/L}\)</span></span> (<span><span class="math inline">\(i\)</span></span> here denotes the complex number <span><span class="math inline">\(\sqrt{-1}\)</span></span>). The <span><span class="math inline">\(y\)</span></span>-th Fourier coefficient of a function <span><span class="math inline">\(f:\Z_L \rightarrow \mathbb{C}\)</span></span> is</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\hat{f}(y) = \tfrac{1}{\sqrt{L}}\sum_{x\in \Z_L} f(x)\omega^{xy} \;. \;\;(22.25)\]</span><a id='fouriercoeffmodular'></a></div></span></p>
<p>The key to implementing the Quantum Fourier Transform for such groups is to use the same recursive equations that enable the classical <a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">Fast Fourier Transform (FFT)</a> algorithm. Specifically, consider the case that <span><span class="math inline">\(L=2^\ell\)</span></span>. We can separate the sum over <span><span class="math inline">\(x\)</span></span> in <a href='#fouriercoeffmodular'>Equation 22.25</a> to the terms corresponding to even <span><span class="math inline">\(x\)</span></span>’s (of the form <span><span class="math inline">\(x=2z\)</span></span>) and odd <span><span class="math inline">\(x\)</span></span>’s (of the form <span><span class="math inline">\(x=2z+1\)</span></span>) to obtain</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\hat{f}(y) = \tfrac{1}{\sqrt{L}}\sum_{z \in Z_{L/2}} f(2z)(\omega^2)^{yz} + \tfrac{\omega^y}{\sqrt{L}}\sum_{z\in \Z_{L/2}}f(2z+1)(\omega^2)^{yz} \;\;(22.26)
\]</span><a id='eqfftrecurse'></a></div></span></p>
<p>which reduces computing the Fourier transform of <span><span class="math inline">\(f\)</span></span> over the group <span><span class="math inline">\(\Z_{2^\ell}\)</span></span> to computing the Fourier transform of the functions <span><span class="math inline">\(f_{even}\)</span></span> and <span><span class="math inline">\(f_{odd}\)</span></span> (corresponding to the applying <span><span class="math inline">\(f\)</span></span> to only the even and odd <span><span class="math inline">\(x\)</span></span>’s respectively) which have <span><span class="math inline">\(2^{\ell-1}\)</span></span> inputs that we can identify with the group <span><span class="math inline">\(\Z_{2^{\ell-1}}=\Z_{L/2}\)</span></span>.</p>
<p>Specifically, the Fourier characters of the group <span><span class="math inline">\(\Z_{L/2}\)</span></span> are the functions <span><span class="math inline">\(\chi_y(x) = e^{2\pi i/(L/2) yx} = (\omega^2)^{yx}\)</span></span> for every <span><span class="math inline">\(x,y \in \Z_{L/2}\)</span></span>. Moreover, since <span><span class="math inline">\(\omega^L = 1\)</span></span>, <span><span class="math inline">\((\omega^2)^y = (\omega^2)^{y \mod L/2}\)</span></span> for every <span><span class="math inline">\(y\in \N\)</span></span>. Thus <a href='#eqfftrecurse'>Equation 22.26</a> translates into <span>
<div class='myequationbox'><span class="math display">\[\hat{f}(y) = \hat{f}_{even}(y \mod L/2) + \omega^y \hat{f}_{odd}(y \mod L/2) \;.
\]</span></div></span></p>
<p>This observation is usually used to obtain a fast (e.g. <span><span class="math inline">\(O(L \log L)\)</span></span>) time to compute the Fourier transform in a classical setting, but it can be used to obtain a quantum circuit of <span><span class="math inline">\(poly(\log L)\)</span></span> gates to transform a state of the form <span><span class="math inline">\(\sum_{x\in \Z_L} f(x)|x\rangle\)</span></span> to a state of the form <span><span class="math inline">\(\sum_{y\in \Z_L} \hat{f}(y)|y \rangle\)</span></span>.</p>
<p>The case that <span><span class="math inline">\(L\)</span></span> is not an exact power of two causes some complications in both the classical case of the Fast Fourier Transform and the quantum setting of Shor’s algorithm. However, it is possible to handle these. The idea is that we can embed <span><span class="math inline">\(Z_L\)</span></span> in the group <span><span class="math inline">\(\Z_{A\cdot L}\)</span></span> for any integer <span><span class="math inline">\(A\)</span></span>, and we can find an integer <span><span class="math inline">\(A\)</span></span> such that <span><span class="math inline">\(A\cdot L\)</span></span> will be close enough to a power of <span><span class="math inline">\(2\)</span></span> (i.e., a number of the form <span><span class="math inline">\(2^m\)</span></span> for some <span><span class="math inline">\(m\)</span></span>), so that if we do the Fourier transform over the group <span><span class="math inline">\(\Z_{2^m}\)</span></span> then we will not introduce too many errors.</p>
<figure>
<img src="../figure/quantumscenarios.png" alt="22.7: Conjectured status of \mathbf{BQP} with respect to other complexity classes. We know that \mathbf{P} \subseteq \mathbf{BPP} \subseteq \mathbf{BQP} and \mathbf{BQP} \subseteq \mathbf{PSPACE} \subseteq \mathbf{EXP}. It is not known if any of these inclusions are strict though it is believed that they are. The relation between \mathbf{BQP} and \mathbf{NP} is unknown but they are believed to be incomparable, and that \mathbf{NP}-complete problems can not be solved in polynomial time by quantum computers. However, it is possible that \mathbf{BQP} contains \mathbf{NP} and even \mathbf{PSPACE}, and it is also possible that quantum computers offer no super-polynomial speedups and that \mathbf{P}=\mathbf{BQP}. The class “\mathbf{NISQ}” above is not a well defined complexity class, but rather captures the current status of quantum devices, which seem to be able to solve a set of computational tasks that is incomparable with the set of tasks solvable by classical computers. The diagram is also inaccurate in the sense that at the moment the “quantum supremacy” tasks on which such devices seem to offer exponential speedups do not correspond to Boolean functions/ decision problems." id="quantumoptionsfig" /><figcaption>22.7: Conjectured status of <span><span class="math inline">\(\mathbf{BQP}\)</span></span> with respect to other complexity classes. We know that <span><span class="math inline">\(\mathbf{P} \subseteq \mathbf{BPP} \subseteq \mathbf{BQP}\)</span></span> and <span><span class="math inline">\(\mathbf{BQP} \subseteq \mathbf{PSPACE} \subseteq \mathbf{EXP}\)</span></span>. It is not known if any of these inclusions are strict though it is believed that they are. The relation between <span><span class="math inline">\(\mathbf{BQP}\)</span></span> and <span><span class="math inline">\(\mathbf{NP}\)</span></span> is unknown but they are believed to be incomparable, and that <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete problems <em>can not</em> be solved in polynomial time by quantum computers. However, it is possible that <span><span class="math inline">\(\mathbf{BQP}\)</span></span> contains <span><span class="math inline">\(\mathbf{NP}\)</span></span> and even <span><span class="math inline">\(\mathbf{PSPACE}\)</span></span>, and it is also possible that quantum computers offer no super-polynomial speedups and that <span><span class="math inline">\(\mathbf{P}=\mathbf{BQP}\)</span></span>. The class “<span><span class="math inline">\(\mathbf{NISQ}\)</span></span>” above is not a well defined complexity class, but rather captures the current status of quantum devices, which seem to be able to solve a set of computational tasks that is incomparable with the set of tasks solvable by classical computers. The diagram is also inaccurate in the sense that at the moment the “quantum supremacy” tasks on which such devices seem to offer exponential speedups do <em>not</em> correspond to Boolean functions/ decision problems.</figcaption>
</figure>
<div id="section-4" class="recap" name="Recap">
<ul>
<li>The state of an <span><span class="math inline">\(n\)</span></span>-qubit quantum system can be modeled as a <span><span class="math inline">\(2^n\)</span></span> dimensional vector</li>
<li>An operation on the state corresponds to applying a unitary matrix to this vector.</li>
<li>Quantum circuits are obtained by composing basic operations such as <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> and <span><span class="math inline">\(U_{NAND}\)</span></span>.</li>
<li>We can use quantum circuits to define the classes <span><span class="math inline">\(\mathbf{BQP_{/poly}}\)</span></span> and <span><span class="math inline">\(\mathbf{BQP}\)</span></span> which are the quantum analogs of <span><span class="math inline">\(\mathbf{P_{/poly}}\)</span></span> and <span><span class="math inline">\(\mathbf{BPP}\)</span></span> respectively.</li>
<li>There are some problems for which the best known quantum algorithm is <em>exponentially faster</em> than the best known, but quantum computing is not a panacea. In particular, as far as we know, quantum computers could still require exponential time to solve <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete problems such as <span><span class="math inline">\(\ensuremath{\mathit{SAT}}\)</span></span>.</li>
</ul>
</div>
<h2 id="exercises" data-number="22.12">Exercises</h2>
<div id="BQPcontainements" class="exercise" title="Quantum and classical complexity class relations" name="Exercise 22.1 (Quantum and classical complexity class relations) ">
<p>Prove the following relations between quantum complexity classes and classical ones:</p>
<ol type="1">
<li><p><span><span class="math inline">\(\mathbf{P_{/poly}} \subseteq \mathbf{BQP_{/poly}}\)</span></span>. See footnote for hint.<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup></p></li>
<li><p><span><span class="math inline">\(\mathbf{P} \subseteq \mathbf{BQP}\)</span></span>. See footnote for hint.<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup></p></li>
<li><p><span><span class="math inline">\(\mathbf{BPP} \subseteq \mathbf{BQP}\)</span></span>. See footnote for hint.<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup></p></li>
<li><p><span><span class="math inline">\(\mathbf{BQP} \subseteq \mathbf{EXP}\)</span></span>. See footnote for hint.<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup></p></li>
<li><p>If <span><span class="math inline">\(\ensuremath{\mathit{SAT}} \in \mathbf{BQP}\)</span></span> then <span><span class="math inline">\(\mathbf{NP} \subseteq \mathbf{BQP}\)</span></span>. See footnote for hint.<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup></p></li>
</ol>
</div>
<div id="dlogfromorder" class="exercise" title="Discrete logarithm from order finding" name="Exercise 22.2 (Discrete logarithm from order finding) ">
<p>Show a probabilistic polynomial time classical algorithm that given an Abelian finite group <span><span class="math inline">\(\mathbb{G}\)</span></span> (in the form of an algorithm that computes the group operation), a <em>generator</em> <span><span class="math inline">\(g\)</span></span> for the group, and an element <span><span class="math inline">\(h \in \mathbb{G}\)</span></span>, as well as access to a black box that on input <span><span class="math inline">\(f\in \mathbb{G}\)</span></span> outputs the <em>order</em> of <span><span class="math inline">\(f\)</span></span> (the smallest <span><span class="math inline">\(a\)</span></span> such that <span><span class="math inline">\(f^a =1\)</span></span>), computes the <em>discrete logarithm</em> of <span><span class="math inline">\(h\)</span></span> with respect to <span><span class="math inline">\(g\)</span></span>. That is the algorithm should output a number <span><span class="math inline">\(x\)</span></span> such that <span><span class="math inline">\(g^x = h\)</span></span>. See footnote for hint.<sup id="fnref:12"><a href="#fn:12" rel="footnote">12</a></sup></p>
</div>
<h2 id="quantumbibnotessec" data-number="22.13">Bibliographical notes</h2>
<p>An excellent gentle introduction to quantum computation is given in Mermin’s book  (<a href="https://scholar.google.com/scholar?hl=en&q=Mermin+Quantum+computer+science:+an+introduction" target="_blank">Mermin, 2007</a>) . In particular the first 100 pages (Chapter 1 to 4) of  (<a href="https://scholar.google.com/scholar?hl=en&q=Mermin+Quantum+computer+science:+an+introduction" target="_blank">Mermin, 2007</a>)  cover all the material of this chapter in a much more comprehensive way. This material is also covered in the first 5 chapters of <a href="https://arxiv.org/abs/1907.09415">De-Wolf’s online lecture notes</a>. For a more condensed exposition, the chapter on quantum computation in my <a href="http://theory.cs.princeton.edu/complexity/">book with Arora</a> (see <a href="http://theory.cs.princeton.edu/complexity/ab_quantumchap.pdf">draft here</a>) is one relatively short source that contains full descriptions of Grover’s, Simon’s and Shor’s algorithms. This <a href="http://www.scottaaronson.com/blog/?p=208">blog post of Aaronson</a> contains a high level explanation of Shor’s algorithm which ends with links to several more detailed expositions. Chapters 9 and 10 in Aaronson’s book  (<a href="https://scholar.google.com/scholar?hl=en&q=Aaronson+Quantum+computing+since+Democritus" target="_blank">Aaronson, 2013</a>)  give an informal but highly informative introduction to the topics of this chapter and much more. Chapter 10 in <a href="https://www.math.ias.edu/avi/book">Avi Wigderson’s book</a> also provides a high level overview of quantum computing. Other recommended resources include Andrew Childs’ <a href="http://www.cs.umd.edu/~amchilds/qa/qa.pdf">lecture notes on quantum algorithms</a>, as well as the lecture notes of <a href="https://inst.eecs.berkeley.edu/~cs191/">Umesh Vazirani</a>, <a href="http://www.theory.caltech.edu/people/preskill/ph229/">John Preskill</a>, and <a href="https://cs.uwaterloo.ca/~watrous/LectureNotes.html">John Watrous</a>.</p>
<p>There are many excellent videos available online covering some of these materials. The videos of <a href="https://www.youtube.com/playlist?list=PLDAjb_zu5aoFazE31_8yT0OfzsTcmvAVg">Umesh Vazirani’z EdX course</a> are an accessible and recommended introduction to quantum computing. Regarding quantum mechanics in general, this <a href="https://www.youtube.com/watch?v=DfPeprQ7oGc">video</a> illustrates the double slit experiment, this <a href="https://www.youtube.com/watch?v=xM3GOXaci7w">Scientific American video</a> is a nice exposition of Bell’s Theorem. This <a href="https://youtu.be/GdqC2bVLesQ?t=2m51s">talk and panel</a> moderated by Brian Greene discusses some of the philosophical and technical issues around quantum mechanics and its so called “measurement problem”. The <a href="http://www.feynmanlectures.caltech.edu/I_50.html">Feynmann lecture on the Fourier Transform</a> and <a href="http://www.feynmanlectures.caltech.edu/III_toc.html">quantum mechanics in general</a> are very much worth reading. The Fourier transform is covered in these videos of <a href="https://youtu.be/EYRmB1aNh9I?t=19s">Dr. Chris Geoscience</a>, <a href="https://www.youtube.com/watch?v=Y9pYHDSxc7g">Clare Zhang</a> and <a href="https://www.youtube.com/watch?v=i_0DXxNeaQ0">Vi Hart</a>. See also <a href="https://www.youtube.com/watch?v=wUwZZaI5u0c">Kelsey Houston-Edwards’s video on Shor’s Algorithm</a>.</p>
<p>The form of Bell’s game we discuss in <a href='#bellineqsec'>Section 22.3</a> was given by <a href="https://goo.gl/wvJGZU">Clauser, Horne, Shimony, and Holt</a>.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">Fast Fourier Transform</a>, used as a component in Shor’s algorithm, is one of the most widely used algorithms invented. The stories of its discovery by Gauss in trying to calculate asteroid orbits and rediscovery by Tukey during the cold war are fascinating as well.</p>
<p>The image in <a href='#doubleslitfig'>Figure 22.2</a> is taken from Wikipedia.</p>
<p>Thanks to Scott Aaronson for many helpful comments about this chapter.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>If you are extremely paranoid about Alice and Bob communicating with one another, you can coordinate with your assistant to perform the experiment exactly at the same time, and make sure that the rooms are sufficiently far apart (e.g., are on two different continents, or maybe even one is on the moon and another is on earth) so that Alice and Bob couldn’t communicate to each other in time the results of their respective coins even if they do so at the speed of light.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>More accurately, one either has to give up on a “billiard ball type” theory of the universe or believe in telepathy (believe it or not, some scientists went for the <a href="https://en.wikipedia.org/wiki/Superdeterminism">latter option</a>).</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>As its title suggests, Feynman’s <a href="https://www.cs.berkeley.edu/~christos/classics/Feynman.pdf">lecture</a> was actually focused on the other side of simulating physics with a computer. However, he mentioned that as a “side remark” one could wonder if it’s possible to simulate physics with a new kind of computer - a “quantum computer” which would “not [be] a Turing machine, but a machine of a different kind”. As far as I know, Feynman did not suggest that such a computer could be useful for computations completely outside the domain of quantum simulation. Indeed, he was more interested in the question of whether quantum mechanics could be simulated by a classical computer.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>This “95 percent” is a figure of speech, but not completely so. At the time of this writing, cryptocurrency mining electricity consumption is estimated to use up at least <a href="https://digiconomist.net/bitcoin-energy-consumption">70Twh or 0.3 percent of the world’s production</a>, which is about <a href="http://www.mdpi.com/2078-1547/6/1/117/html">2 to 5 percent</a> of the total energy usage for the computing industry. All the current cryptocurrencies will be broken by quantum computers. Also, for many web servers the TLS protocol (which is based on the current non-lattice based systems would be completely broken by quantum computing) is responsible <a href="https://goo.gl/mHpYpm">for about 1 percent of the CPU usage</a>.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>Of course, given that <a href="http://blog.cryptographyengineering.com/2016/03/attack-of-week-drown.html">we’re still hearing</a> of attacks exploiting “export grade” cryptography that was supposed to disappear in 1990’s, I imagine that we’ll still have products running 1024 bit RSA when everyone has a quantum laptop.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p>Readers familiar with quantum computing should note that <span><span class="math inline">\(U_{NAND}\)</span></span> is a close variant of the so called <a href="https://goo.gl/BE7aVG">Toffoli gate</a> and so QNAND-CIRC programs correspond to quantum circuits with the Hadamard and Toffoli gates.</p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:7"><p>
<div>
<p>You can use <span><span class="math inline">\(U_{NAND}\)</span></span> to simulate NAND gates.</p>
</div>
<a href="#fnref:7" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:8"><p>
<div>
<p>Use the alternative characterization of <span><span class="math inline">\(\mathbf{P}\)</span></span> as in <a href='#Palternativeex'>?? ??</a>.</p>
</div>
<a href="#fnref:8" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:9"><p>
<div>
<p>You can use the <span><span class="math inline">\(\ensuremath{\mathit{HAD}}\)</span></span> gate to simulate a coin toss.</p>
</div>
<a href="#fnref:9" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:10"><p>
<div>
<p>In exponential time simulating quantum computation boils down to matrix multiplication.</p>
</div>
<a href="#fnref:10" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:11"><p>
<div>
<p>If a reduction can be implemented in <span><span class="math inline">\(\mathbf{P}\)</span></span> it can be implemented in <span><span class="math inline">\(\mathbf{BQP}\)</span></span> as well.</p>
</div>
<a href="#fnref:11" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:12"><p>
<div>
<p>We are given <span><span class="math inline">\(h=g^x\)</span></span> and need to recover <span><span class="math inline">\(x\)</span></span>. To do so we can compute the order of various elements of the form <span><span class="math inline">\(h^ag^b\)</span></span>. The order of such an element is a number <span><span class="math inline">\(c\)</span></span> satisfying <span><span class="math inline">\(c(xa+b) = 0 \pmod{|\mathbb{G}|}\)</span></span>. With a few random examples we will get a non trivial equation on <span><span class="math inline">\(x\)</span></span> (where <span><span class="math inline">\(c\)</span></span> is not zero modulo <span><span class="math inline">\(|\mathbb{G}|\)</span></span>) and then we can use our knowledge of <span><span class="math inline">\(a,b,c\)</span></span> to recover <span><span class="math inline">\(x\)</span></span>.</p>
</div>
<a href="#fnref:12" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 21:38:34</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_26_quantum_computing.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
