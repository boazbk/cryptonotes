<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Loops and infinity</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Loops and infinity" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#lecture-summary"><i class="fa fa-check"></i><b>16.1</b> Lecture summary</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.2</b> Exercises</a></li><li class="chapter" data-level="16.3" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.3</b> Bibliographical notes</a></li><li class="chapter" data-level="16.4" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#further-explorations"><i class="fa fa-check"></i><b>16.4</b> Further explorations</a></li><li class="chapter" data-level="16.5" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#acknowledgements"><i class="fa fa-check"></i><b>16.5</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loops and infinity</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_06_loops.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="chaploops" data-number="6">Loops and infinity</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>Learn the model of <em>Turing machines</em>, which can compute functions of <em>arbitrary input lengths</em>.</li>
<li>See a programming-language description of Turing machines, using NAND-TM programs, which add <em>loops</em> and <em>arrays</em> to NAND-CIRC.</li>
<li>See some basic syntactic sugar and equivalence of variants of Turing machines and NAND-TM programs.</li>
</ul>
</div>
<blockquote>
<p><em>“An algorithm is a finite answer to an infinite number of questions.”</em>, Attributed to Stephen Kleene.</p>
</blockquote>
<blockquote>
<p><em>“The bounds of arithmetic were however outstepped the moment the idea of applying the [punched] cards had occurred; and the Analytical Engine does not occupy common ground with mere”calculating machines."" … In enabling mechanism to combine together general symbols, in successions of unlimited variety and extent, a uniting link is established between the operations of matter and the abstract mental processes of the most abstract branch of mathematical science. "</em>, Ada Augusta, countess of Lovelace, 1843</p>
</blockquote>
<p>The model of Boolean circuits (or equivalently, the NAND-CIRC programming language) has one very significant drawback: a Boolean circuit can only compute a <em>finite</em> function <span><span class="math inline">\(f\)</span></span>, and in particular since every gate has two inputs, a size <span><span class="math inline">\(s\)</span></span> circuit can compute on an input of length at most <span><span class="math inline">\(2s\)</span></span>. This does not capture our intuitive notion of an algorithm as a <em>single recipe</em> to compute a potentially infinite function. For example, the standard elementary school multiplication algorithm is a <em>single</em> algorithm that multiplies numbers of all lengths, but yet we cannot express this algorithm as a single circuit, but rather need a different circuit (or equivalently, a NAND-CIRC program) for every input length (see <a href='#multschoolfig'>Figure 6.1</a>).</p>
<figure>
<img src="../figure/multiplicationschool.png" alt="6.1: Once you know how to multiply multi-digit numbers, you can do so for every number n of digits, but if you had to describe multiplication using NAND-CIRC programs or Boolean circuits, you would need a different program/circuit for every length n of the input." id="multschoolfig" class="margin" /><figcaption>6.1: Once you know how to multiply multi-digit numbers, you can do so for every number <span><span class="math inline">\(n\)</span></span> of digits, but if you had to describe multiplication using NAND-CIRC programs or Boolean circuits, you would need a different program/circuit for every length <span><span class="math inline">\(n\)</span></span> of the input.</figcaption>
</figure>
<p>Let us consider the case of the simple <em>parity</em> or <em>XOR</em> function <span><span class="math inline">\(\ensuremath{\mathit{XOR}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>, where <span><span class="math inline">\(\ensuremath{\mathit{XOR}}(x)\)</span></span> equals <span><span class="math inline">\(1\)</span></span> iff the number of <span><span class="math inline">\(1\)</span></span>’s in <span><span class="math inline">\(x\)</span></span> is odd. (In other words, <span><span class="math inline">\(\ensuremath{\mathit{XOR}}(x) = \sum_{i=0}^{|x|-1} x_i \mod 2\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>.) As simple as it is, the <span><span class="math inline">\(\ensuremath{\mathit{XOR}}\)</span></span> function cannot be computed by a NAND-CIRC program. Rather, for every <span><span class="math inline">\(n\)</span></span>, we can compute <span><span class="math inline">\(\ensuremath{\mathit{XOR}}_n\)</span></span> (the restriction of <span><span class="math inline">\(\ensuremath{\mathit{XOR}}\)</span></span> to <span><span class="math inline">\(\{0,1\}^n\)</span></span>) using a different NAND-CIRC program. For example, <a href='#XOR5fig'>Figure 6.2</a> presents the NAND-CIRC program (or equivalently the circuit) to compute <span><span class="math inline">\(\ensuremath{\mathit{XOR}}_5\)</span></span>.</p>
<figure>
<img src="../figure/xor5circprog.png" alt="6.2: The NAND circuit and NAND-CIRC program for computing the XOR of 5 bits. Note how the circuit for \ensuremath{\mathit{XOR}}_5 merely repeats four times the circuit to compute the XOR of 2 bits." id="XOR5fig" class="margin" /><figcaption>6.2: The NAND circuit and NAND-CIRC program for computing the XOR of <span><span class="math inline">\(5\)</span></span> bits. Note how the circuit for <span><span class="math inline">\(\ensuremath{\mathit{XOR}}_5\)</span></span> merely repeats four times the circuit to compute the XOR of <span><span class="math inline">\(2\)</span></span> bits.</figcaption>
</figure>
<p>This code for computing <span><span class="math inline">\(\ensuremath{\mathit{XOR}}_5\)</span></span> is rather repetitive, and more importantly, does not capture the fact that there is a <em>single</em> algorithm to compute the parity on all inputs. Typical programming language use the notion of <em>loops</em> to express such an algorithm, along the lines of:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1"><span class="co"># s is the &quot;running parity&quot;, initialized to 0</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="cf">while</span> i<span class="op">&lt;</span><span class="bu">len</span>(X):</a>
<a class="sourceLine" id="cb1-3" title="3">    u <span class="op">=</span> NAND(s,X[i])</a>
<a class="sourceLine" id="cb1-4" title="4">    v <span class="op">=</span> NAND(s,u)</a>
<a class="sourceLine" id="cb1-5" title="5">    w <span class="op">=</span> NAND(X[i],u)</a>
<a class="sourceLine" id="cb1-6" title="6">    s <span class="op">=</span> NAND(v,w)</a>
<a class="sourceLine" id="cb1-7" title="7">    i<span class="op">+=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb1-8" title="8">Y[<span class="dv">0</span>] <span class="op">=</span> s</a></code></pre></div>
<figure>
<img src="../figure/algcomponents.png" alt="6.3: An algorithm is a finite recipe to compute on arbitrarily long inputs. The components of an algorithm include the instructions to be performed, finite state or “local variables”, the memory to store the input and intermediate computations, as well as mechanisms to decide which part of the memory to access, and when to repeat instructions and when to halt." id="algcomponentfig" class="margin" /><figcaption>6.3: An algorithm is a finite recipe to compute on arbitrarily long inputs. The components of an algorithm include the instructions to be performed, finite state or “local variables”, the memory to store the input and intermediate computations, as well as mechanisms to decide which part of the memory to access, and when to repeat instructions and when to halt.</figcaption>
</figure>
<p>Generally an algorithm is, as we quote above, “a finite answer to an infinite number of questions”. To express an algorithm we need to write down a finite set of instructions that will enable us to compute on arbitrarily long inputs. To describe and execute an algorithm we need the following components (see <a href='#algcomponentfig'>Figure 6.3</a>):</p>
<ul>
<li><p>The finite set of instructions to be performed.</p></li>
<li><p>Some “local variables” or finite state used in the execution.</p></li>
<li><p>A potentially unbounded working memory to store the input as well as any other values we may require later.</p></li>
<li><p>While the memory is unbounded, at every single step we can only read and write to a finite part of it, and we need a way to <em>address</em> which are the parts we want to read from and write to.</p></li>
<li><p>If we only have a finite set of instructions but our input can be arbitrarily long, we will need to <em>repeat</em> instructions (i.e., <em>loop</em> back). We need a mechanism to decide when we will loop and when we will halt.</p></li>
</ul>
<p>In this chapter we will show how we can extend the model of Boolean circuits / straight-line programs so that it can capture these kinds of constructs. We will see two ways to do so:</p>
<ul>
<li><p><em>Turing machines</em>, invented by Alan Turing in 1936, are an hypothetical abstract device that yields a finite description of an algorithm that can handle arbitrarily long inputs.</p></li>
<li><p>The <em>NAND-TM Programming language</em> extends NAND-CIRC with the notion of <em>loops</em> and <em>arrays</em> to obtain finite programs that can compute a function with arbitrarily long inputs.</p></li>
</ul>
<p>It turns out that these two models are <em>equivalent</em>, and in fact they are equivalent to a great many other computational models including programming languages you may be familiar with such as C, Lisp, Python, JavaScript, etc. This notion, known as <em>Turing equivalence</em> or <em>Turing completeness</em>, will be discussed in <a href='lec_07_other_models.html#chapequivalentmodels'>Chapter 7</a>. See <a href='#chaploopoverviewfig'>Figure 6.4</a> for an overview of the models presented in this chapter and <a href='lec_07_other_models.html#chapequivalentmodels'>Chapter 7</a>.</p>
<figure>
<img src="../figure/chaploopoverview.png" alt="6.4: Overview of our models for finite and unbounded computation. In the previous chapters we study the computation of finite functions, which are functions f:\{0,1\}^n \rightarrow \{0,1\}^m for some fixed n,m, and modeled computing these functions using circuits or straightline programs. In this chapter we study computing unbounded functions of the form F:\{0,1\}^* \rightarrow \{0,1\}^m or F:\{0,1\}^* \rightarrow \{0,1\}^*. We model computing these functions using Turing Machines or (equivalently) NAND-TM programs which add the notion of loops to the NAND-CIRC programming language. In  we will show that these models are equivalent to many other models, including RAM machines, the \lambda calculus, and all the common programming languages including C, Python, Java, JavaScript, etc." id="chaploopoverviewfig" /><figcaption>6.4: Overview of our models for finite and unbounded computation. In the previous chapters we study the computation of <em>finite functions</em>, which are functions <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> for some fixed <span><span class="math inline">\(n,m\)</span></span>, and modeled computing these functions using circuits or straightline programs. In this chapter we study computing <em>unbounded</em> functions of the form <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^m\)</span></span> or <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>. We model computing these functions using <em>Turing Machines</em> or (equivalently) NAND-TM programs which add the notion of <em>loops</em> to the NAND-CIRC programming language. In <a href='lec_07_other_models.html#chapequivalentmodels'>Chapter 7</a> we will show that these models are equivalent to many other models, including RAM machines, the <span><span class="math inline">\(\lambda\)</span></span> calculus, and all the common programming languages including C, Python, Java, JavaScript, etc.</figcaption>
</figure>
<div id="infinite" class="remark" title="Finite vs infinite computation" name="Remark 6.1 (Finite vs infinite computation) ">
<p>Previously in this book we studied the computation of <em>finite</em> functions <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span>. Such a function <span><span class="math inline">\(f\)</span></span> can always be described by listing all the <span><span class="math inline">\(2^n\)</span></span> values it takes on inputs <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>.</p>
<p>In this chapter we consider functions that take inputs of <em>unbounded</em> size, such as the function <span><span class="math inline">\(\ensuremath{\mathit{XOR}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> that maps <span><span class="math inline">\(x\)</span></span> to <span><span class="math inline">\(\sum_{i=0}^{|x|-1} x_i \mod 2\)</span></span>. While we can describe <span><span class="math inline">\(\ensuremath{\mathit{XOR}}\)</span></span> using a finite number of symbols (in fact we just did so in the previous sentence), it takes infinitely many possible inputs and so we cannot just write down all of its values. The same is true for many other functions capturing important computational tasks including addition, multiplication, sorting, finding paths in graphs, fitting curves to points, and so on and so forth.</p>
<p>To contrast with the finite case, we will sometimes call a function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> (or <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>) <em>infinite</em> but we emphasize that the functions we are interested in always take an input which is a finite string. It’s just that, unlike the finite case, this string can be arbitrarily long and is not fixed to some particular length <span><span class="math inline">\(n\)</span></span>.</p>
<p>Some texts present the task of computing a function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> as the task of deciding membership in the <em>language</em> <span><span class="math inline">\(L \subseteq \{0,1\}^*\)</span></span> defined as <span><span class="math inline">\(L = \{ x\in \{0,1\}^* \;|\; F(x) = 1 \}\)</span></span>. These two views are equivalent, see <a href='#decidablelanguagesrem'>Remark 6.5</a>.</p>
</div>
<h2 id="turing-machines" data-number="6.1">Turing Machines</h2>
<blockquote>
<p><em>“Computing is normally done by writing certain symbols on paper. We may suppose that this paper is divided into squares like a child’s arithmetic book.. The behavior of the [human] computer at any moment is determined by the symbols which he is observing, and of his ‘state of mind’ at that moment… We may suppose that in a simple operation not more than one symbol is altered.”</em>,<br />
<em>“We compare a man in the process of computing … to a machine which is only capable of a finite number of configurations… The machine is supplied with a ‘tape’ (the analogue of paper) … divided into sections (called ‘squares’) each capable of bearing a ‘symbol’”</em>, Alan Turing, 1936</p>
</blockquote>
<blockquote>
<p><em>“What is the difference between a Turing machine and the modern computer? It’s the same as that between Hillary’s ascent of Everest and the establishment of a Hilton hotel on its peak.”</em> , Alan Perlis, 1982.</p>
</blockquote>
<figure>
<img src="../figure/alan-turing-running.jpg" alt="6.5: Aside from his many other achievements, Alan Turing was an excellent long distance runner who just fell shy of making England’s olympic team. A fellow runner once asked him why he punished himself so much in training. Alan said “I have such a stressful job that the only way I can get it out of my mind is by running hard; it’s the only way I can get some release.”" id="turingrunning" class="margin" /><figcaption>6.5: Aside from his many other achievements, Alan Turing was an excellent long distance runner who just fell shy of making England’s olympic team. A fellow runner once asked him why he punished himself so much in training. Alan said “I have such a stressful job that the only way I can get it out of my mind is by running hard; it’s the only way I can get some release.”</figcaption>
</figure>
<p>The “granddaddy” of all models of computation is the <em>Turing Machine</em>. Turing machines were defined in 1936 by Alan Turing in an attempt to formally capture all the functions that can be computed by human “computers” (see <a href='#humancomputersfig'>Figure 6.6</a>) that follow a well-defined set of rules, such as the standard algorithms for addition or multiplication.</p>
<figure>
<img src="../figure/HumanComputers.jpg" alt="6.6: Until the advent of electronic computers, the word “computer” was used to describe a person that performed calculations. Most of these “human computers” were women, and they were absolutely essential to many achievements including mapping the stars, breaking the Enigma cipher, and the NASA space mission; see also the bibliographical notes. Photo from National Photo Company Collection; see also ." id="humancomputersfig" class="margin" /><figcaption>6.6: Until the advent of electronic computers, the word “computer” was used to describe a person that performed calculations. Most of these “human computers” were women, and they were absolutely essential to many achievements including mapping the stars, breaking the Enigma cipher, and the NASA space mission; see also the bibliographical notes. Photo from <a href="https://www.loc.gov/pictures/item/2016838906/">National Photo Company Collection</a>; see also  (<a href="https://scholar.google.com/scholar?hl=en&q=Sobel+The+Glass+Universe+:+How+the+Ladies+of+the+Harvard+Observatory+Took+the+Measure+of+the+Stars" target="_blank">Sobel, 2017</a>) .</figcaption>
</figure>
<p>Turing thought of such a person as having access to as much “scratch paper” as they need. For simplicity we can think of this scratch paper as a one dimensional piece of graph paper (or <em>tape</em>, as it is commonly referred to), which is divided to “cells”, where each “cell” can hold a single symbol (e.g., one digit or letter, and more generally some element of a finite <em>alphabet</em>). At any point in time, the person can read from and write to a single cell of the paper, and based on the contents can update his/her finite mental state, and/or move to the cell immediately to the left or right of the current one.</p>
<figure>
<img src="../figure/SPTM.jpg" alt="6.7: Steam-powered Turing Machine mural, painted by CSE grad students at the University of Washington on the night before spring qualifying examinations, 1987. Image from https://www.cs.washington.edu/building/art/SPTM." id="steamturingmachine" class="margin" /><figcaption>6.7: Steam-powered Turing Machine mural, painted by CSE grad students at the University of Washington on the night before spring qualifying examinations, 1987. Image from <a href="https://www.cs.washington.edu/building/art/SPTM">https://www.cs.washington.edu/building/art/SPTM</a>.</figcaption>
</figure>
<p>Turing modeled such a computation by a “machine” that maintains one of <span><span class="math inline">\(k\)</span></span> states. At each point in time the machine reads from its “work tape” a single symbol from a finite alphabet <span><span class="math inline">\(\Sigma\)</span></span> and uses that to update its state, write to tape, and possibly move to an adjacent cell (see <a href='#turing-machine-fig'>Figure 6.9</a>). To compute a function <span><span class="math inline">\(F\)</span></span> using this machine, we initialize the tape with the input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> and our goal is to ensure that the tape will contain the value <span><span class="math inline">\(F(x)\)</span></span> at the end of the computation. Specifically, a computation of a Turing Machine <span><span class="math inline">\(M\)</span></span> with <span><span class="math inline">\(k\)</span></span> states and alphabet <span><span class="math inline">\(\Sigma\)</span></span> on input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> proceeds as follows:</p>
<ul>
<li><p>Initially the machine is at state <span><span class="math inline">\(0\)</span></span> (known as the “starting state”) and the tape is initialized to <span><span class="math inline">\(\triangleright,x_0,\ldots,x_{n-1},\varnothing,\varnothing,\ldots\)</span></span>. We use the symbol <span><span class="math inline">\(\triangleright\)</span></span> to denote the beginning of the tape, and the symbol <span><span class="math inline">\(\varnothing\)</span></span> to denote an empty cell. We will always assume that the alphabet <span><span class="math inline">\(\Sigma\)</span></span> is a (potentially strict) superset of <span><span class="math inline">\(\{ \triangleright, \varnothing , 0 , 1 \}\)</span></span>.</p></li>
<li><p>The location <span><span class="math inline">\(i\)</span></span> to which the machine points to is set to <span><span class="math inline">\(0\)</span></span>.</p></li>
<li><p>At each step, the machine reads the symbol <span><span class="math inline">\(\sigma = T[i]\)</span></span> that is in the <span><span class="math inline">\(i^{th}\)</span></span> location of the tape, and based on this symbol and its state <span><span class="math inline">\(s\)</span></span> decides on:</p>
<ul>
<li>What symbol <span><span class="math inline">\(\sigma&#39;\)</span></span> to write on the tape<br />
</li>
<li>Whether to move <strong>L</strong>eft (i.e., <span><span class="math inline">\(i \leftarrow i-1\)</span></span>), <strong>R</strong>ight (i.e., <span><span class="math inline">\(i \leftarrow i+1\)</span></span>), <strong>S</strong>tay in place, or <strong>H</strong>alt the computation.</li>
<li>What is going to be the new state <span><span class="math inline">\(s \in [k]\)</span></span></li>
</ul></li>
<li><p>The set of rules the Turing machine follows is known as its <em>transition function</em>.</p></li>
<li><p>When the machine halts then its output is the binary string obtained by reading the tape from the beginning until the head position, dropping all symbolssuch as <span><span class="math inline">\(\triangleright\)</span></span>, <span><span class="math inline">\(\varnothing\)</span></span>, etc. that are not either <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span>.</p></li>
</ul>
<figure>
<img src="../figure/turingmachinecomponents.png" alt="6.8: The components of a Turing Machine. Note how they correspond to the general components of algorithms as described in ." id="turingmachinecomponentsfig" class="margin" /><figcaption>6.8: The components of a Turing Machine. Note how they correspond to the general components of algorithms as described in <a href='#algcomponentfig'>Figure 6.3</a>.</figcaption>
</figure>
<h3 id="turingmachinepalindrome" data-number="6.1.1">Extended example: A Turing machine for palindromes</h3>
<p>Let <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span> (for <em>palindromes</em>) be the function that on input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(x\)</span></span> is an (even length) <em>palindrome</em>, in the sense that <span><span class="math inline">\(x = w_0 \cdots w_{n-1}w_{n-1}w_{n-2}\cdots w_0\)</span></span> for some <span><span class="math inline">\(n\in \N\)</span></span> and <span><span class="math inline">\(w\in \{0,1\}^n\)</span></span>.</p>
<p>We now show a Turing Machine <span><span class="math inline">\(M\)</span></span> that computes <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span>. To specify <span><span class="math inline">\(M\)</span></span> we need to specify <strong>(i)</strong> <span><span class="math inline">\(M\)</span></span>’s tape alphabet <span><span class="math inline">\(\Sigma\)</span></span> which should contain at least the symbols <span><span class="math inline">\(0\)</span></span>,<span><span class="math inline">\(1\)</span></span>, <span><span class="math inline">\(\triangleright\)</span></span> and <span><span class="math inline">\(\varnothing\)</span></span>, and <strong>(ii)</strong> <span><span class="math inline">\(M\)</span></span>’s <em>transition function</em> which determines what action <span><span class="math inline">\(M\)</span></span> takes when it reads a given symbol while it is in a particular state.</p>
<p>In our case, <span><span class="math inline">\(M\)</span></span> will use the alphabet <span><span class="math inline">\(\{ 0,1,\triangleright, \varnothing, \times \}\)</span></span> and will have <span><span class="math inline">\(k=14\)</span></span> states. Though the states are simply numbers between <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(k-1\)</span></span>, for convenience we will give them the following labels:</p>
<table>
<colgroup>
<col style="width: 29%" />
<col style="width: 70%" />
</colgroup>
<thead>
<tr class="header">
<th><p>State</p></th>
<th><p>Label</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>0</p></td>
<td><p><code>START</code></p></td>
</tr>
<tr class="even">
<td><p>1</p></td>
<td><p><code>RIGHT_0</code></p></td>
</tr>
<tr class="odd">
<td><p>2</p></td>
<td><p><code>RIGHT_1</code></p></td>
</tr>
<tr class="even">
<td><p>3</p></td>
<td><p><code>LOOK_FOR_0</code></p></td>
</tr>
<tr class="odd">
<td><p>4</p></td>
<td><p><code>LOOK_FOR_1</code></p></td>
</tr>
<tr class="even">
<td><p>5</p></td>
<td><p><code>RETURN</code></p></td>
</tr>
<tr class="odd">
<td><p>6</p></td>
<td><p><code>REJECT</code></p></td>
</tr>
<tr class="even">
<td><p>7</p></td>
<td><p><code>ACCEPT</code></p></td>
</tr>
<tr class="odd">
<td><p>8</p></td>
<td><p><code>OUTPUT_0</code></p></td>
</tr>
<tr class="even">
<td><p>9</p></td>
<td><p><code>OUTPUT_1</code></p></td>
</tr>
<tr class="odd">
<td><p>10</p></td>
<td><p><code>0_AND_BLANK</code></p></td>
</tr>
<tr class="even">
<td><p>11</p></td>
<td><p><code>1_AND_BLANK</code></p></td>
</tr>
<tr class="odd">
<td><p>12</p></td>
<td><p><code>BLANK_AND_STOP</code></p></td>
</tr>
</tbody>
</table>
<p>We describe the operation of our Turing Machine <span><span class="math inline">\(M\)</span></span> in words:</p>
<ul>
<li><p><span><span class="math inline">\(M\)</span></span> starts in state <code>START</code> and will go right, looking for the first symbol that is <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span>. If we find <span><span class="math inline">\(\varnothing\)</span></span> before we hit such a symbol then we will move to the <code>OUTPUT_1</code> state that we describe below.</p></li>
<li><p>Once <span><span class="math inline">\(M\)</span></span> finds such a symbol <span><span class="math inline">\(b \in \{0,1\}\)</span></span>, <span><span class="math inline">\(M\)</span></span> deletes <span><span class="math inline">\(b\)</span></span> from the tape by writing the <span><span class="math inline">\(\times\)</span></span> symbol, it enters either the <code>RIGHT_0</code> or <code>RIGHT_1</code> mode according to the value of <span><span class="math inline">\(b\)</span></span> and starts moving rightwards until it hits the first <span><span class="math inline">\(\varnothing\)</span></span> or <span><span class="math inline">\(\times\)</span></span> symbol.</p></li>
<li><p>Once we find this symbol we go into the state <code>LOOK_FOR_0</code> or <code>LOOK_FOR_1</code> depending on whether we were in the state <code>RIGHT_0</code> or <code>RIGHT_1</code> and make one left move.</p></li>
<li><p>In the state <code>LOOK_FOR_</code><span><span class="math inline">\(b\)</span></span>, we check whether the value on the tape is <span><span class="math inline">\(b\)</span></span>. If it is, then we delete it by changing its value to <span><span class="math inline">\(\times\)</span></span>, and move to the state <code>RETURN</code>. Otherwise, we change to the <code>OUTPUT_0</code> state.</p></li>
<li><p>The <code>RETURN</code> state means we go back to the beginning. Specifically, we move leftward until we hit the first symbol that is not <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span>, in which case we change our state to <code>START</code>.</p></li>
<li><p>The <code>OUTPUT_</code><span><span class="math inline">\(b\)</span></span> states mean that we are going to output the value <span><span class="math inline">\(b\)</span></span>. In both these states we go left until we hit <span><span class="math inline">\(\triangleright\)</span></span>. Once we do so, we make a right step, and change to the <code>1_AND_BLANK</code> or <code>0_AND_BLANK</code> states respectively. In the latter states, we write the corresponding value, and then move right and change to the <code>BLANK_AND_STOP</code> state, in which we write <span><span class="math inline">\(\varnothing\)</span></span> to the tape and halt.</p></li>
</ul>
<p>The above description can be turned into a table describing for each one of the <span><span class="math inline">\(13\cdot 5\)</span></span> combination of state and symbol, what the Turing machine will do when it is in that state and it reads that symbol. This table is known as the <em>transition function</em> of the Turing machine.</p>
<h3 id="turing-machines-a-formal-definition" data-number="6.1.2">Turing machines: a formal definition</h3>
<figure>
<img src="../figure/turingmachine.png" alt="6.9: A Turing machine has access to a tape of unbounded length. At each point in the execution, the machine can read a single symbol of the tape, and based on that and its current state, write a new symbol, update the tape, decide whether to move left, right, stay, or halt." id="turing-machine-fig" /><figcaption>6.9: A Turing machine has access to a <em>tape</em> of unbounded length. At each point in the execution, the machine can read a single symbol of the tape, and based on that and its current state, write a new symbol, update the tape, decide whether to move left, right, stay, or halt.</figcaption>
</figure>
<p>The formal definition of Turing machines is as follows:</p>
<div id="TM-def" class="definition" title="Turing Machine" name="Definition 6.2 (Turing Machine) ">
<p>A (one tape) <em>Turing machine</em> with <span><span class="math inline">\(k\)</span></span> states and alphabet <span><span class="math inline">\(\Sigma \supseteq \{0,1, \triangleright, \varnothing \}\)</span></span> is represented by a <em>transition function</em> <span><span class="math inline">\(\delta_M:[k]\times \Sigma \rightarrow [k] \times \Sigma \times \{\mathsf{L},\mathsf{R}, \mathsf{S}, \mathsf{H} \}\)</span></span>.</p>
<p>For every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, the <em>output</em> of <span><span class="math inline">\(M\)</span></span> on input <span><span class="math inline">\(x\)</span></span>, denoted by <span><span class="math inline">\(M(x)\)</span></span>, is the result of the following process:</p>
<ul>
<li><p>We initialize <span><span class="math inline">\(T\)</span></span> to be the sequence <span><span class="math inline">\(\triangleright,x_0,x_1,\ldots,x_{n-1},\varnothing,\varnothing,\ldots\)</span></span>, where <span><span class="math inline">\(n=|x|\)</span></span>. (That is, <span><span class="math inline">\(T[0]=\triangleright\)</span></span>, <span><span class="math inline">\(T[i+1]=x_{i}\)</span></span> for <span><span class="math inline">\(i\in [n]\)</span></span>, and <span><span class="math inline">\(T[i]=\varnothing\)</span></span> for <span><span class="math inline">\(i&gt;n\)</span></span>.)</p></li>
<li><p>We also initialize <span><span class="math inline">\(i=0\)</span></span> and <span><span class="math inline">\(s=0\)</span></span>.</p></li>
<li><p>We then repeat the following process:</p>
<ol type="1">
<li>Let <span><span class="math inline">\((s&#39;,\sigma&#39;,D) = \delta_M(s,T[i])\)</span></span>.</li>
<li>Set <span><span class="math inline">\(s \rightarrow s&#39;\)</span></span>, <span><span class="math inline">\(T[i] \rightarrow \sigma&#39;\)</span></span>.</li>
<li>If <span><span class="math inline">\(D=\mathsf{R}\)</span></span> then set <span><span class="math inline">\(i \rightarrow i+1\)</span></span>, if <span><span class="math inline">\(D=\mathsf{L}\)</span></span> then set <span><span class="math inline">\(i \rightarrow \max\{i-1,0\}\)</span></span>. (If <span><span class="math inline">\(D = \mathsf{S}\)</span></span> then we keep <span><span class="math inline">\(i\)</span></span> the same.)</li>
<li>If <span><span class="math inline">\(D=\mathsf{H}\)</span></span> then halt.</li>
</ol></li>
<li><p>If the process above halts, then <span><span class="math inline">\(M\)</span></span>’s output, denoted by <span><span class="math inline">\(M(x)\)</span></span>, is the string <span><span class="math inline">\(y\in \{0,1\}^*\)</span></span> obtained by concatenating all the symbols in <span><span class="math inline">\(\{0,1\}\)</span></span> in positions <span><span class="math inline">\(T[0],\ldots, T[i]\)</span></span> where <span><span class="math inline">\(i\)</span></span> is the final head position.</p></li>
<li><p>If The Turing machine does not halt then we denote <span><span class="math inline">\(M(x)=\bot\)</span></span>.</p></li>
</ul>
</div>
<div class="pause" name="Pause 6.1.2">
<p>You should make sure you see why this formal definition corresponds to our informal description of a Turing Machine. To get more intuition on Turing Machines, you can explore some of the online available simulators such as <a href="https://turingmachinesimulator.com/">Martin Ugarte’s</a>, <a href="http://morphett.info/turing/turing.html">Anthony Morphett’s</a>, or <a href="http://rendell-attic.org/gol/TMapplet/index.htm">Paul Rendell’s</a>.</p>
</div>
<p>One should not confuse the <em>transition function</em> <span><span class="math inline">\(\delta_M\)</span></span> of a Turing machine <span><span class="math inline">\(M\)</span></span> with the function that the machine computes. The transition function <span><span class="math inline">\(\delta_M\)</span></span> is a <em>finite</em> function, with <span><span class="math inline">\(k|\Sigma|\)</span></span> inputs and <span><span class="math inline">\(4k|\Sigma|\)</span></span> outputs. (Can you see why?) The machine can compute an <em>infinite</em> function <span><span class="math inline">\(F\)</span></span> that takes as input a string <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> of arbitrary length and might also produce an arbitrary length string as output.</p>
<p>In our formal definition, we identified the machine <span><span class="math inline">\(M\)</span></span> with its transition function <span><span class="math inline">\(\delta_M\)</span></span> since the transition function tells us everything we need to know about the Turing machine, and hence serves as a good mathematical representation of it. This choice of representation is somewhat arbitrary, and is based on our convention that the state space is always the numbers <span><span class="math inline">\(\{0,\ldots,k-1\}\)</span></span> with <span><span class="math inline">\(0\)</span></span> as the starting state. Other texts use different conventions and so their mathematical definition of a Turing machine might look superficially different, but these definitions describe the same computational process and has the same computational powers. See <a href='#chaploopnotes'>Section 6.7</a> for a comparison between <a href='#TM-def'>Definition 6.2</a> and the way Turing Machines are defined in texts such as Sipser  (<a href="https://scholar.google.com/scholar?hl=en&q=Sipser+Introduction+to+the+theory+of+computation" target="_blank">Sipser, 1997</a>) . These definitions are equivalent despite their superficial differences.</p>
<h3 id="computable-functions" data-number="6.1.3">Computable functions</h3>
<p>We now turn to making one of the most important definitions in this book, that of <em>computable functions</em>.</p>
<div id="computablefuncdef" class="definition" title="Computable functions" name="Definition 6.3 (Computable functions) ">
<p>Let <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span> be a (total) function and let <span><span class="math inline">\(M\)</span></span> be a Turing machine. We say that <span><span class="math inline">\(M\)</span></span> <em>computes</em> <span><span class="math inline">\(F\)</span></span> if for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(M(x)=F(x)\)</span></span>.</p>
<p>We say that a function <span><span class="math inline">\(F\)</span></span> is <em>computable</em> if there exists a Turing machine <span><span class="math inline">\(M\)</span></span> that computes it.</p>
</div>
<p>Defining a function “computable” if and only if it can be computed by a Turing machine might seem “reckless” but, as we’ll see in <a href='lec_07_other_models.html#chapequivalentmodels'>Chapter 7</a>, it turns out that being computable in the sense of <a href='#computablefuncdef'>Definition 6.3</a> is equivalent to being computable in essentially any reasonable model of computation. This is known as the <em>Church Turing Thesis</em>. (Unlike the <em>extended</em> Church Turing Thesis which we discussed in <a href='lec_04_code_and_data.html#PECTTsec'>Section 5.6</a>, the Church-Turing thesis itself is widely believed and there are no candidate devices that attack it.)</p>
<div id="definecompidea" class="bigidea" name="Bigidea 8">
<p>We can precisely define what it means for a function to be computable by <em>any possible algorithm</em>.</p>
</div>
<p>This is a good point to remind the reader that <em>functions</em> are <em>not</em> the same as <em>programs</em>:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[ \text{Functions} \;\neq\; \text{Programs} \;.\]</span></div></span></p>
<p>A Turing machine (or program) <span><span class="math inline">\(M\)</span></span> can <em>compute</em> some function <span><span class="math inline">\(F\)</span></span>, but it is not the same as <span><span class="math inline">\(F\)</span></span>. In particular there can be more than one program to compute the same function. Being computable is a property of <em>functions</em>, not of machines.</p>
<p>We will often pay special attention to functions <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> that have a single bit of output. Hence we give a special name for the set of functions of this form that are computable.</p>
<div id="classRdef" class="definition" title="The class $\mathbf{R}$" name="Definition 6.4 (The class $\mathbf{R}$) ">
<p>We define <span><span class="math inline">\(\mathbf{R}\)</span></span> be the set of all <em>computable</em> functions <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span>.</p>
</div>
<div id="decidablelanguagesrem" class="remark" title="Functions vs. languages" name="Remark 6.5 (Functions vs. languages) ">
<p>Many texts use the terminology of “languages” rather than functions to refer to computational tasks. The name “language” has its roots in <em>formal language theory</em> as pursued by linguists such as Noam Chomsky. A <em>formal language</em> is a subset <span><span class="math inline">\(L \subseteq \{0,1\}^*\)</span></span> (or more generally <span><span class="math inline">\(L \subseteq \Sigma^*\)</span></span> for some finite alphabet <span><span class="math inline">\(\Sigma\)</span></span>). The <em>membership</em> or <em>decision</em> problem for a language <span><span class="math inline">\(L\)</span></span>, is the task of determining, given <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, whether or not <span><span class="math inline">\(x\in L\)</span></span>. A Turing machine <span><span class="math inline">\(M\)</span></span> <em>decides</em> a language <span><span class="math inline">\(L\)</span></span> if for every input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(M(x)\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(x\in L\)</span></span>. This is equivalent to computing the Boolean function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> defined as <span><span class="math inline">\(F(x)=1\)</span></span> iff <span><span class="math inline">\(x\in L\)</span></span>. A language <span><span class="math inline">\(L\)</span></span> is <em>decidable</em> if there is a Turing machine <span><span class="math inline">\(M\)</span></span> that decides it. For historical reasons, some texts also call such a language <em>recursive</em> (which is the reason that the letter <span><span class="math inline">\(\mathbf{R}\)</span></span> is often used to denote the set of computable Boolean functions / decidable languages defined in <a href='#classRdef'>Definition 6.4</a>).</p>
<p>In this book we stick to the terminology of <em>functions</em> rather than languages, but all definitions and results can be easily translated back and forth by using the equivalence between the function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> and the language <span><span class="math inline">\(L = \{ x\in \{0,1\}^* \;|\; F(x) = 1 \}\)</span></span>.</p>
</div>
<h3 id="infinite-loops-and-partial-functions" data-number="6.1.4">Infinite loops and partial functions</h3>
<p>One crucial difference between circuits/straight-line programs and Turing machines is the following. Looking at a NAND-CIRC program <span><span class="math inline">\(P\)</span></span>, we can always tell how many inputs and how many outputs it has (by simply looking at the <code>X</code> and <code>Y</code> variables). Furthermore, we are guaranteed that if we invoke <span><span class="math inline">\(P\)</span></span> on any input then <em>some</em> output will be produced.</p>
<p>In contrast, given any Turing machine <span><span class="math inline">\(M\)</span></span>, we cannot determine a priori the length of the output. In fact, we don’t even know if an output would be produced at all! For example, it is very easy to come up with a Turing machine whose transition function never outputs <span><span class="math inline">\(\mathsf{H}\)</span></span> and hence never halts.</p>
<p>If a machine <span><span class="math inline">\(M\)</span></span> fails to stop and produce an output on some an input <span><span class="math inline">\(x\)</span></span>, then it cannot compute any total function <span><span class="math inline">\(F\)</span></span>, since clearly on input <span><span class="math inline">\(x\)</span></span>, <span><span class="math inline">\(M\)</span></span> will fail to output <span><span class="math inline">\(F(x)\)</span></span>. However, <span><span class="math inline">\(P\)</span></span> can still compute a <em>partial function</em>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
<p>For example, consider the partial function <span><span class="math inline">\(\ensuremath{\mathit{DIV}}\)</span></span> that on input a pair <span><span class="math inline">\((a,b)\)</span></span> of natural numbers, outputs <span><span class="math inline">\(\ceil{a/b}\)</span></span> if <span><span class="math inline">\(b &gt; 0\)</span></span>, and is undefined otherwise. We can define a Turing machine <span><span class="math inline">\(M\)</span></span> that computes <span><span class="math inline">\(\ensuremath{\mathit{DIV}}\)</span></span> on input <span><span class="math inline">\(a,b\)</span></span> by outputting the first <span><span class="math inline">\(c=0,1,2,\ldots\)</span></span> such that <span><span class="math inline">\(cb \geq a\)</span></span>. If <span><span class="math inline">\(a&gt;0\)</span></span> and <span><span class="math inline">\(b=0\)</span></span> then the machine <span><span class="math inline">\(M\)</span></span> will never halt, but this is OK, since <span><span class="math inline">\(\ensuremath{\mathit{DIV}}\)</span></span> is undefined on such inputs. If <span><span class="math inline">\(a=0\)</span></span> and <span><span class="math inline">\(b=0\)</span></span>, the machine <span><span class="math inline">\(M\)</span></span> will output <span><span class="math inline">\(0\)</span></span>, which is also OK, since we don’t care about what the program outputs on inputs on which <span><span class="math inline">\(\ensuremath{\mathit{DIV}}\)</span></span> is undefined. Formally, we define computability of partial functions as follows:</p>
<div id="computablepartialfuncdef" class="definition" title="Computable (partial or total) functions" name="Definition 6.6 (Computable (partial or total) functions) ">
<p>Let <span><span class="math inline">\(F\)</span></span> be either a total or partial function mapping <span><span class="math inline">\(\{0,1\}^*\)</span></span> to <span><span class="math inline">\(\{0,1\}^*\)</span></span> and let <span><span class="math inline">\(M\)</span></span> be a Turing machine. We say that <span><span class="math inline">\(M\)</span></span> <em>computes</em> <span><span class="math inline">\(F\)</span></span> if for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> on which <span><span class="math inline">\(F\)</span></span> is defined, <span><span class="math inline">\(M(x)=F(x)\)</span></span>. We say that a (partial or total) function <span><span class="math inline">\(F\)</span></span> is <em>computable</em> if there is a Turing machine that computes it.</p>
</div>
<p>Note that if <span><span class="math inline">\(F\)</span></span> is a total function, then it is defined on every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> and hence in this case, <a href='#computablepartialfuncdef'>Definition 6.6</a> is identical to <a href='#computablefuncdef'>Definition 6.3</a>.</p>
<div id="botsymbol" class="remark" title="Bot symbol" name="Remark 6.7 (Bot symbol) ">
<p>We often use <span><span class="math inline">\(\bot\)</span></span> as our special “failure symbol”. If a Turing machine <span><span class="math inline">\(M\)</span></span> fails to halt on some input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> then we denote this by <span><span class="math inline">\(M(x) = \bot\)</span></span>. This <em>does not</em> mean that <span><span class="math inline">\(M\)</span></span> outputs some encoding of the symbol <span><span class="math inline">\(\bot\)</span></span> but rather that <span><span class="math inline">\(M\)</span></span> enters into an infinite loop when given <span><span class="math inline">\(x\)</span></span> as input.</p>
<p>If a partial function <span><span class="math inline">\(F\)</span></span> is undefined on <span><span class="math inline">\(x\)</span></span> then we can also write <span><span class="math inline">\(F(x) = \bot\)</span></span>. Therefore one might think that <a href='#computablepartialfuncdef'>Definition 6.6</a> can be simplified to requiring that <span><span class="math inline">\(M(x) = F(x)\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, which would imply that for every <span><span class="math inline">\(x\)</span></span>, <span><span class="math inline">\(M\)</span></span> halts on <span><span class="math inline">\(x\)</span></span> if and only if <span><span class="math inline">\(F\)</span></span> is defined on <span><span class="math inline">\(x\)</span></span>. However this is not the case: for a Turing Machine <span><span class="math inline">\(M\)</span></span> to compute a partial function <span><span class="math inline">\(F\)</span></span> it is not <em>necessary</em> for <span><span class="math inline">\(M\)</span></span> to enter an infinite loop on inputs <span><span class="math inline">\(x\)</span></span> on which <span><span class="math inline">\(F\)</span></span> is not defined. All that is needed is for <span><span class="math inline">\(M\)</span></span> to output <span><span class="math inline">\(F(x)\)</span></span> on <span><span class="math inline">\(x\)</span></span>’s on which <span><span class="math inline">\(F\)</span></span> is defined: on other inputs it is OK for <span><span class="math inline">\(M\)</span></span> to output an arbitrary value such as <span><span class="math inline">\(0\)</span></span>, <span><span class="math inline">\(1\)</span></span>, or anything else, or not to halt at all. To borrow a term from the <code>C</code> programming language, on inputs <span><span class="math inline">\(x\)</span></span> on which <span><span class="math inline">\(F\)</span></span> is not defined, what <span><span class="math inline">\(M\)</span></span> does is “undefined behavior”.</p>
</div>
<h2 id="turing-machines-as-programming-languages" data-number="6.2">Turing machines as programming languages</h2>
<p>The name “Turing machine”, with its “tape” and “head” evokes a physical object, while in contrast we think of a <em>program</em> as a piece of text. But we can think of a Turing machine as a program as well. For example, consider the Turing Machine <span><span class="math inline">\(M\)</span></span> of <a href='#turingmachinepalindrome'>Subsection 6.1.1</a> that computes the function <span><span class="math inline">\(\ensuremath{\mathit{PAL}}\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{PAL}}(x)=1\)</span></span> iff <span><span class="math inline">\(x\)</span></span> is a palindrome. We can also describe this machine as a <em>program</em> using the Python-like pseudocode of the form below</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># Gets an array Tape initialized to</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="co"># [&quot;&gt;&quot;, x_0 , x_1 , .... , x_(n-1), &quot;∅&quot;, &quot;∅&quot;, ...]</span></a>
<a class="sourceLine" id="cb2-3" title="3"><span class="co"># At the end of the execution, Tape[1] is equal to 1</span></a>
<a class="sourceLine" id="cb2-4" title="4"><span class="co"># if x is a palindrome and is equal to 0 otherwise</span></a>
<a class="sourceLine" id="cb2-5" title="5"><span class="kw">def</span> PAL(Tape):</a>
<a class="sourceLine" id="cb2-6" title="6">    head <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb2-7" title="7">    state <span class="op">=</span> <span class="dv">0</span> <span class="co"># START</span></a>
<a class="sourceLine" id="cb2-8" title="8">    <span class="cf">while</span> (state <span class="op">!=</span> <span class="dv">12</span>):</a>
<a class="sourceLine" id="cb2-9" title="9">        <span class="cf">if</span> (state <span class="op">==</span> <span class="dv">0</span> <span class="op">&amp;&amp;</span> Tape[head]<span class="op">==</span><span class="st">&#39;0&#39;</span>):</a>
<a class="sourceLine" id="cb2-10" title="10">            state <span class="op">=</span> <span class="dv">3</span> <span class="co"># LOOK_FOR_0</span></a>
<a class="sourceLine" id="cb2-11" title="11">            Tape[head] <span class="op">=</span> <span class="st">&#39;x&#39;</span></a>
<a class="sourceLine" id="cb2-12" title="12">            head <span class="op">+=</span> <span class="dv">1</span> <span class="co"># move right</span></a>
<a class="sourceLine" id="cb2-13" title="13">        <span class="cf">if</span> (state<span class="op">==</span><span class="dv">0</span> <span class="op">&amp;&amp;</span> Tape[head]<span class="op">==</span><span class="st">&#39;1&#39;</span>)</a>
<a class="sourceLine" id="cb2-14" title="14">            state <span class="op">=</span> <span class="dv">4</span> <span class="co"># LOOK_FOR_1</span></a>
<a class="sourceLine" id="cb2-15" title="15">            Tape[head] <span class="op">=</span> <span class="st">&#39;x&#39;</span></a>
<a class="sourceLine" id="cb2-16" title="16">            head <span class="op">+=</span> <span class="dv">1</span> <span class="co"># move right</span></a>
<a class="sourceLine" id="cb2-17" title="17">        ... <span class="co"># more if statements here</span></a></code></pre></div>
<p>The particular details of this program are not important. What matters is that we can describe Turing machines as <em>programs</em>. Moreover, note that when translating a Turing machine into a program, the <em>tape</em> becomes a <em>list</em> or <em>array</em> that can hold values from the finite set <span><span class="math inline">\(\Sigma\)</span></span>.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> The <em>head position</em> can be thought of as an integer valued variable that can hold integers of unbounded size. The <em>state</em> is a <em>local register</em> that can hold one of a fixed number of values in <span><span class="math inline">\([k]\)</span></span>.</p>
<p>More generally we can think of every Turing Machine <span><span class="math inline">\(M\)</span></span> as equivalent to a program similar to the following:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"><span class="co"># Gets an array Tape initialized to</span></a>
<a class="sourceLine" id="cb3-2" title="2"><span class="co"># [&quot;&gt;&quot;, x_0 , x_1 , .... , x_(n-1), &quot;∅&quot;, &quot;∅&quot;, ...]</span></a>
<a class="sourceLine" id="cb3-3" title="3"><span class="kw">def</span> M(Tape):</a>
<a class="sourceLine" id="cb3-4" title="4">    state <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb3-5" title="5">    i     <span class="op">=</span> <span class="dv">0</span> <span class="co"># holds head location</span></a>
<a class="sourceLine" id="cb3-6" title="6">    <span class="cf">while</span> (<span class="va">True</span>):</a>
<a class="sourceLine" id="cb3-7" title="7">        <span class="co"># Move head, modify state, write to tape</span></a>
<a class="sourceLine" id="cb3-8" title="8">        <span class="co"># based on current state and cell at head</span></a>
<a class="sourceLine" id="cb3-9" title="9">        <span class="co"># below are just examples for how program looks for a particular transition function</span></a>
<a class="sourceLine" id="cb3-10" title="10">        <span class="cf">if</span> Tape[i]<span class="op">==</span><span class="st">&quot;0&quot;</span> <span class="kw">and</span> state<span class="op">==</span><span class="dv">7</span>: <span class="co"># δ_M(7,&quot;0&quot;)=(19,&quot;1&quot;,&quot;R&quot;)</span></a>
<a class="sourceLine" id="cb3-11" title="11">            i <span class="op">+=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb3-12" title="12">            Tape[i]<span class="op">=</span><span class="st">&quot;1&quot;</span></a>
<a class="sourceLine" id="cb3-13" title="13">            state <span class="op">=</span> <span class="dv">19</span></a>
<a class="sourceLine" id="cb3-14" title="14">        <span class="cf">elif</span> Tape[i]<span class="op">==</span><span class="st">&quot;&gt;&quot;</span> <span class="kw">and</span> state <span class="op">==</span> <span class="dv">13</span>: <span class="co"># δ_M(13,&quot;&gt;&quot;)=(15,&quot;0&quot;,&quot;S&quot;)</span></a>
<a class="sourceLine" id="cb3-15" title="15">            Tape[i]<span class="op">=</span><span class="st">&quot;0&quot;</span></a>
<a class="sourceLine" id="cb3-16" title="16">            state <span class="op">=</span> <span class="dv">15</span></a>
<a class="sourceLine" id="cb3-17" title="17">        <span class="cf">elif</span> ...</a>
<a class="sourceLine" id="cb3-18" title="18">        ...</a>
<a class="sourceLine" id="cb3-19" title="19">        <span class="cf">elif</span> Tape[i]<span class="op">==</span><span class="st">&quot;&gt;&quot;</span> <span class="kw">and</span> state <span class="op">==</span> <span class="dv">29</span>: <span class="co"># δ_M(29,&quot;&gt;&quot;)=(.,.,&quot;H&quot;)</span></a>
<a class="sourceLine" id="cb3-20" title="20">            <span class="cf">break</span> <span class="co"># Halt</span></a></code></pre></div>
<p>If we wanted to use only <em>Boolean</em> (i.e., <span><span class="math inline">\(0\)</span></span>/<span><span class="math inline">\(1\)</span></span>-valued) variables then we can encode the <code>state</code> variables using <span><span class="math inline">\(\ceil{\log k}\)</span></span> bits. Similarly, we can represent each element of the alphabet <span><span class="math inline">\(\Sigma\)</span></span> using <span><span class="math inline">\(\ell=\ceil{\log |\Sigma|}\)</span></span> bits and hence we can replace the <span><span class="math inline">\(\Sigma\)</span></span>-valued array <code>Tape[]</code> with <span><span class="math inline">\(\ell\)</span></span> Boolean-valued arrays <code>Tape0[]</code>,<span><span class="math inline">\(\ldots\)</span></span>, <code>Tape</code><span><span class="math inline">\(\ell\)</span></span><code>[]</code>.</p>
<h3 id="the-nand-tm-programming-language" data-number="6.2.1">The NAND-TM Programming language</h3>
<p>We now introduce the <em>NAND-TM programming language</em>, which aims to capture the power of a Turing machine in a programming language formalism. Just like the difference between Boolean circuits and Turing Machines, the main difference between NAND-TM and NAND-CIRC is that NAND-TM models a <em>single uniform algorithm</em> that can compute a function that takes inputs of <em>arbitrary lengths</em>. To do so, we extend the NAND-CIRC programming language with two constructs:</p>
<ul>
<li><p><em>Loops</em>: NAND-CIRC is a <em>straight-line</em> programming language- a NAND-CIRC program of <span><span class="math inline">\(s\)</span></span> lines takes exactly <span><span class="math inline">\(s\)</span></span> steps of computation and hence in particular cannot even touch more than <span><span class="math inline">\(3s\)</span></span> variables. <em>Loops</em> allow us to capture in a short program the instructions for a computation that can take an arbitrary amount of time.</p></li>
<li><p><em>Arrays</em>: A NAND-CIRC program of <span><span class="math inline">\(s\)</span></span> lines touches at most <span><span class="math inline">\(3s\)</span></span> variables. While we can use variables with names such as <code>Foo_17</code> or <code>Bar[22]</code>, they are not true arrays, since the number in the identifier is a constant that is “hardwired” into the program.</p></li>
</ul>
<figure>
<img src="../figure/nandtmprog.png" alt="6.10: A NAND-TM program has scalar variables that can take a Boolean value, array variables that hold a sequence of Boolean values, and a special index variable i that can be used to index the array variables. We refer to the i-th value of the array variable Spam using Spam[i]. At each iteration of the program the index variable can be incremented or decremented by one step using the MODANDJMP operation." id="nandtmfig" /><figcaption>6.10: A NAND-TM program has <em>scalar</em> variables that can take a Boolean value, <em>array</em> variables that hold a sequence of Boolean values, and a special <em>index</em> variable <code>i</code> that can be used to index the array variables. We refer to the <code>i</code>-th value of the array variable <code>Spam</code> using <code>Spam[i]</code>. At each iteration of the program the index variable can be incremented or decremented by one step using the <code>MODANDJMP</code> operation.</figcaption>
</figure>
<p>Thus a good way to remember NAND-TM is using the following informal equation:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\text{NAND-TM} \;=\; \text{NAND-CIRC} \;+\; \text{loops} \;+\; \text{arrays} \;\;(6.2)
\]</span><a id='eqnandloops'></a></div></span></p>
<div id="otherpl" class="remark" title="NAND-CIRC + loops + arrays = everything." name="Remark 6.8 (NAND-CIRC + loops + arrays = everything.) ">
<p>As we will see, adding loops and arrays to NAND-CIRC is enough to capture the full power of all programming languages! Hence we could replace “NAND-TM” with any of <em>Python</em>, <em>C</em>, <em>Javascript</em>, <em>OCaml</em>, etc. in the lefthand side of <a href='#eqnandloops'>Equation 6.2</a>. But we’re getting ahead of ourselves: this issue will be discussed in <a href='lec_07_other_models.html#chapequivalentmodels'>Chapter 7</a>.</p>
</div>
<p>Concretely, the NAND-TM programming language adds the following features on top of NANC-CIRC (see <a href='#nandtmfig'>Figure 6.10</a>)):</p>
<ul>
<li><p>We add a special <em>integer valued</em> variable <code>i</code>. All other variables in NAND-TM are <em>Boolean valued</em> (as in NAND-CIRC).</p></li>
<li><p>Apart from <code>i</code> NAND-TM has two kinds of variables: <em>scalars</em> and <em>arrays</em>. <em>Scalar</em> variables hold one bit (just as in NAND-CIRC). <em>Array</em> variables hold an unbounded number of bits. At any point in the computation we can access the array variables at the location indexed by <code>i</code> using <code>Foo[i]</code>. We cannot access the arrays at locations other the one pointed to by <code>i</code>.</p></li>
<li><p>We use the convention that <em>arrays</em> always start with a capital letter, and <em>scalar variables</em> (which are never indexed with <code>i</code>) start with lowercase letters. Hence <code>Foo</code> is an array and <code>bar</code> is a scalar variable.</p></li>
<li><p>The input and output <code>X</code> and <code>Y</code> are now considered <em>arrays</em> with values of zeroes and ones. (There are also two other special arrays <code>X_nonblank</code> and <code>Y_nonblank</code>, see below.)</p></li>
<li><p>We add a special <code>MODANDJUMP</code> instruction that takes two boolean variables <span><span class="math inline">\(a,b\)</span></span> as input and does the following:</p>
<ul>
<li>If <span><span class="math inline">\(a=1\)</span></span> and <span><span class="math inline">\(b=1\)</span></span> then <code>MODANDJUMP(</code><span><span class="math inline">\(a,b\)</span></span><code>)</code> increments <code>i</code> by one and jumps to the first line of the program.</li>
<li>If <span><span class="math inline">\(a=0\)</span></span> and <span><span class="math inline">\(b=1\)</span></span> then <code>MODANDJUMP(</code><span><span class="math inline">\(a,b\)</span></span><code>)</code> decrements <code>i</code> by one and jumps to the first line of the program. (If <code>i</code> is already equal to <span><span class="math inline">\(0\)</span></span> then it stays at <span><span class="math inline">\(0\)</span></span>.)</li>
<li>If <span><span class="math inline">\(a=1\)</span></span> and <span><span class="math inline">\(b=0\)</span></span> then <code>MODANDJUMP(</code><span><span class="math inline">\(a,b\)</span></span><code>)</code> jumps to the first line of the program without modifying <code>i</code>.</li>
<li>If <span><span class="math inline">\(a=b=0\)</span></span> then <code>MODANDJUMP(</code><span><span class="math inline">\(a,b\)</span></span><code>)</code> halts execution of the program.</li>
</ul></li>
<li><p>The<code>MODANDJUMP</code> instruction always appears in the last line of a NAND-TM program and nowhere else.</p></li>
</ul>
<p><strong>Default values.</strong> We need one more convention to handle “default values”. Turing machines have the special symbol <span><span class="math inline">\(\varnothing\)</span></span> to indicate that tape location is “blank” or “uninitialized”. In NAND-TM there is no such symbol, and all variables are <em>Boolean</em>, containing either <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span>. All variables and locations of arrays are default to <span><span class="math inline">\(0\)</span></span> if they have not been initialized to another value. To keep track of whether a <span><span class="math inline">\(0\)</span></span> in an array corresponds to a true zero or to an uninitialized cell, a programmer can always add to an array <code>Foo</code> a “companion array” <code>Foo_nonblank</code> and set <code>Foo_nonblank[i]</code> to <span><span class="math inline">\(1\)</span></span> whenever the <code>i</code>’th location is initialized. In particular we will use this convention for the input and output arrays <code>X</code> and <code>Y</code>. A NAND-TM program has <em>four</em> special arrays <code>X</code>, <code>X_nonblank</code>, <code>Y</code>, and <code>Y_nonblank</code>. When a NAND-TM program is executed on input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> of length <span><span class="math inline">\(n\)</span></span>, the first <span><span class="math inline">\(n\)</span></span> cells of the array <code>X</code> are initialized to <span><span class="math inline">\(x_0,\ldots,x_{n-1}\)</span></span> and the first <span><span class="math inline">\(n\)</span></span> cells of the array <code>X_nonblank</code> are initialized to <span><span class="math inline">\(1\)</span></span>. (All uninitialized cells default to <span><span class="math inline">\(0\)</span></span>.) The output of a NAND-TM program is the string <code>Y[</code><span><span class="math inline">\(0\)</span></span><code>]</code>, <span><span class="math inline">\(\ldots\)</span></span>, <code>Y[</code><span><span class="math inline">\(m-1\)</span></span><code>]</code> where <span><span class="math inline">\(m\)</span></span> is the smallest integer such that <code>Y_nonblank[</code><span><span class="math inline">\(m\)</span></span><code>]</code><span><span class="math inline">\(=0\)</span></span>. A NAND-TM program gets called with <code>X</code> and <code>X_nonblank</code> initialized to contain the input, and writes to <code>Y</code> and <code>Y_nonblank</code> to produce the output.</p>
<p>Formally, NAND-TM programs are defined as follows:</p>
<div id="NANDTM" class="definition" title="NAND-TM programs" name="Definition 6.9 (NAND-TM programs) ">
<p>A <em>NAND-TM program</em> consists of a sequence of lines of the form <code>foo = NAND(bar,blah)</code> ending with a line of the form <code>MODANDJMP(foo,bar)</code>, where <code>foo</code>,<code>bar</code>,<code>blah</code> are either <em>scalar variables</em> (sequences of letters, digits, and underscores) or <em>array variables</em> of the form <code>Foo[i]</code> (starting with capital letter and indexed by <code>i</code>). The program has the array variables <code>X</code>, <code>X_nonblank</code>, <code>Y</code>, <code>Y_nonblank</code> and the index variable <code>i</code> built in, and can use additional array and scalar variables.</p>
<p>If <span><span class="math inline">\(P\)</span></span> is a NAND-TM program and <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> is an input then an execution of <span><span class="math inline">\(P\)</span></span> on <span><span class="math inline">\(x\)</span></span> is the following process:</p>
<ol type="1">
<li><p>The arrays <code>X</code> and <code>X_nonblank</code> are initialized by <code>X[</code><span><span class="math inline">\(i\)</span></span><code>]</code><span><span class="math inline">\(=x_i\)</span></span> and <code>X_nonblank[</code><span><span class="math inline">\(i\)</span></span><code>]</code><span><span class="math inline">\(=1\)</span></span> for all <span><span class="math inline">\(i\in [|x|]\)</span></span>. All other variables and cells are initialized to <span><span class="math inline">\(0\)</span></span>. The index variable <code>i</code> is also initialized to <span><span class="math inline">\(0\)</span></span>.</p></li>
<li><p>The program is executed line by line, when the last line <code>MODANDJMP(foo,bar)</code> is executed then we do as follows:</p>
<ol type="a">
<li><p>If <code>foo</code><span><span class="math inline">\(=1\)</span></span> and <code>bar</code><span><span class="math inline">\(=0\)</span></span> then jump to the first line without modifying the value of <code>i</code>.</p></li>
<li><p>If <code>foo</code><span><span class="math inline">\(=1\)</span></span> and <code>bar</code><span><span class="math inline">\(=1\)</span></span> then increment <code>i</code> by one and jump to the first line.</p></li>
<li><p>If <code>foo</code><span><span class="math inline">\(=0\)</span></span> and <code>bar</code><span><span class="math inline">\(=1\)</span></span> then decrement <code>i</code> by one (unless it is already zero) and jump to the first line.</p></li>
<li><p>If <code>foo</code><span><span class="math inline">\(=0\)</span></span> and <code>bar</code><span><span class="math inline">\(=0\)</span></span> then halt and output <code>Y[</code><span><span class="math inline">\(0\)</span></span><code>]</code>, <span><span class="math inline">\(\ldots\)</span></span>, <code>Y[</code><span><span class="math inline">\(m-1\)</span></span><code>]</code> where <span><span class="math inline">\(m\)</span></span> is the smallest integer such that <code>Y_nonblank[</code><span><span class="math inline">\(m\)</span></span><code>]</code><span><span class="math inline">\(=0\)</span></span>.</p></li>
</ol></li>
</ol>
</div>
<h3 id="sneak-peak-nand-tm-vs-turing-machines" data-number="6.2.2">Sneak peak: NAND-TM vs Turing machines</h3>
<p>As the name implies, NAND-TM programs are a direct implementation of Turing machines in programming language form. We will show the equivalence below but you can already see how the components of Turing machines and NAND-TM programs correspond to one another:</p>
<p><a name="TMvsNANDTMtable"></a></p>
<table>
<caption>Turing Machine and NAND-TM analogs</caption>
<colgroup>
<col style="width: 43%" />
<col style="width: 56%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><p><strong>Turing Machine</strong></p></th>
<th style="text-align: left;"><p><strong>NAND-TM program</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><p><em>State:</em> single register that takes values in <span class="math inline">\([k]\)</span></p></td>
<td style="text-align: left;"><p><em>Scalar variables:</em> Several variables such as <code>foo</code>, <code>bar</code> etc.. each taking values in <span class="math inline">\(\{0,1\}\)</span>.</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><em>Tape:</em> One tape containing values in a finite set <span class="math inline">\(\Sigma\)</span>. Potentially infinite but <span class="math inline">\(T[t]\)</span> defaults to <span class="math inline">\(\varnothing\)</span> for all locations <span class="math inline">\(t\)</span> that have not been accessed.</p></td>
<td style="text-align: left;"><p><em>Arrays:</em> Several arrays such as <code>Foo</code>, <code>Bar</code> etc.. for each such array <code>Arr</code> and index <span class="math inline">\(j\)</span>, the value of <code>Arr</code> at position <span class="math inline">\(j\)</span> is either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. The value defaults to <span class="math inline">\(0\)</span> for position that have not been written to.</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><em>Head location:</em> A number <span class="math inline">\(i\in \mathbb{N}\)</span> that encodes the position of the head.</p></td>
<td style="text-align: left;"><p><em>Index variable:</em> The variable <code>i</code> that can be used to access the arrays.</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><em>Accessing memory:</em> At every step the Turing machine has access to its local state, but can only access the tape at the position of the current head location.</p></td>
<td style="text-align: left;"><p><em>Accessing memory:</em> At every step a NAND-TM program has access to all the scalar variables, but can only access the arrays at the location <code>i</code> of the index variable</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><em>Control of location:</em> In each step the machine can move the head location by at most one position.</p></td>
<td style="text-align: left;"><p><em>Control of index variable:</em> In each iteration of its main loop the program can modify the index <code>i</code> by at most one.</p></td>
</tr>
</tbody>
</table>
<h3 id="examples" data-number="6.2.3">Examples</h3>
<p>We now present some examples of NAND-TM programs</p>
<div id="XORENANDPP" class="example" title="XOR in NAND-TM" name="Example 6.10 (XOR in NAND-TM) ">
<p>The following is a NAND-TM program to compute the XOR function on inputs of arbitrary length. That is <span><span class="math inline">\(\ensuremath{\mathit{XOR}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{XOR}}(x) = \sum_{i=0}^{|x|-1} x_i \mod 2\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">temp_0 <span class="op">=</span> NAND(X[<span class="dv">0</span>],X[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb4-2" title="2">Y_nonblank[<span class="dv">0</span>] <span class="op">=</span> NAND(X[<span class="dv">0</span>],temp_0)</a>
<a class="sourceLine" id="cb4-3" title="3">temp_2 <span class="op">=</span> NAND(X[i],Y[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb4-4" title="4">temp_3 <span class="op">=</span> NAND(X[i],temp_2)</a>
<a class="sourceLine" id="cb4-5" title="5">temp_4 <span class="op">=</span> NAND(Y[<span class="dv">0</span>],temp_2)</a>
<a class="sourceLine" id="cb4-6" title="6">Y[<span class="dv">0</span>] <span class="op">=</span> NAND(temp_3,temp_4)</a>
<a class="sourceLine" id="cb4-7" title="7">MODANDJUMP(X_nonblank[i],X_nonblank[i])</a></code></pre></div>
</div>
<div id="INCENANDPP" class="example" title="Increment in NAND-TM" name="Example 6.11 (Increment in NAND-TM) ">
<p>We now present NAND-TM program to compute the <em>increment function</em>. That is, <span><span class="math inline">\(\ensuremath{\mathit{INC}}:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span> such that for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{INC}}(x)\)</span></span> is the <span><span class="math inline">\(n+1\)</span></span> bit long string <span><span class="math inline">\(y\)</span></span> such that if <span><span class="math inline">\(X = \sum_{i=0}^{n-1}x_i \cdot 2^i\)</span></span> is the number represented by <span><span class="math inline">\(x\)</span></span>, then <span><span class="math inline">\(y\)</span></span> is the (least-significant digit first) binary representation of the number <span><span class="math inline">\(X+1\)</span></span>.</p>
<p>We start by showing the program using the “syntactic sugar” we’ve seen before of using shorthand for some NAND-CIRC programs we have seen before to compute simple functions such as <code>IF</code>, <code>XOR</code> and <code>AND</code> (as well as the constant <code>one</code> function as well as the function <code>COPY</code> that just maps a bit to itself).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1">carry <span class="op">=</span> IF(started,carry,one(started))</a>
<a class="sourceLine" id="cb5-2" title="2">started <span class="op">=</span> one(started)</a>
<a class="sourceLine" id="cb5-3" title="3">Y[i] <span class="op">=</span> XOR(X[i],carry)</a>
<a class="sourceLine" id="cb5-4" title="4">carry <span class="op">=</span> AND(X[i],carry)</a>
<a class="sourceLine" id="cb5-5" title="5">Y_nonblank[i] <span class="op">=</span> one(started)</a>
<a class="sourceLine" id="cb5-6" title="6">MODANDJUMP(X_nonblank[i],X_nonblank[i])</a></code></pre></div>
<p>The above is not, strictly speaking, a valid NAND-TM program. If we “open up” all of the syntactic sugar, we get the following valid program to compute this syntactic sugar.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" title="1">temp_0 <span class="op">=</span> NAND(started,started)</a>
<a class="sourceLine" id="cb6-2" title="2">temp_1 <span class="op">=</span> NAND(started,temp_0)</a>
<a class="sourceLine" id="cb6-3" title="3">temp_2 <span class="op">=</span> NAND(started,started)</a>
<a class="sourceLine" id="cb6-4" title="4">temp_3 <span class="op">=</span> NAND(temp_1,temp_2)</a>
<a class="sourceLine" id="cb6-5" title="5">temp_4 <span class="op">=</span> NAND(carry,started)</a>
<a class="sourceLine" id="cb6-6" title="6">carry <span class="op">=</span> NAND(temp_3,temp_4)</a>
<a class="sourceLine" id="cb6-7" title="7">temp_6 <span class="op">=</span> NAND(started,started)</a>
<a class="sourceLine" id="cb6-8" title="8">started <span class="op">=</span> NAND(started,temp_6)</a>
<a class="sourceLine" id="cb6-9" title="9">temp_8 <span class="op">=</span> NAND(X[i],carry)</a>
<a class="sourceLine" id="cb6-10" title="10">temp_9 <span class="op">=</span> NAND(X[i],temp_8)</a>
<a class="sourceLine" id="cb6-11" title="11">temp_10 <span class="op">=</span> NAND(carry,temp_8)</a>
<a class="sourceLine" id="cb6-12" title="12">Y[i] <span class="op">=</span> NAND(temp_9,temp_10)</a>
<a class="sourceLine" id="cb6-13" title="13">temp_12 <span class="op">=</span> NAND(X[i],carry)</a>
<a class="sourceLine" id="cb6-14" title="14">carry <span class="op">=</span> NAND(temp_12,temp_12)</a>
<a class="sourceLine" id="cb6-15" title="15">temp_14 <span class="op">=</span> NAND(started,started)</a>
<a class="sourceLine" id="cb6-16" title="16">Y_nonblank[i] <span class="op">=</span> NAND(started,temp_14)</a>
<a class="sourceLine" id="cb6-17" title="17">MODANDJUMP(X_nonblank[i],X_nonblank[i])</a></code></pre></div>
</div>
<div class="pause" name="Pause 6.2.3">
<p>Working out the above two examples can go a long way towards understanding the NAND-TM language. See the <a href="http://tiny.cc/introtcsappendix">appendix</a> and our <a href="https://github.com/boazbk/tcscode">GitHub repository</a> for a full specification of the NAND-TM language.</p>
</div>
<h2 id="equivalence-of-turing-machines-and-nand-tm-programs" data-number="6.3">Equivalence of Turing machines and NAND-TM programs</h2>
<p>Given the above discussion, it might not be surprising that Turing machines turn out to be equivalent to NAND-TM programs. Indeed, we designed the NAND-TM language to have this property. Nevertheless, this is an important result, and the first of many other such equivalence results we will see in this book.</p>
<div id="TM-equiv-thm" class="theorem" title="Turing machines and NAND-TM programs are equivalent" name="Theorem 6.12 (Turing machines and NAND-TM programs are equivalent) ">
<p>For every <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F\)</span></span> is computable by a NAND-TM program <span><span class="math inline">\(P\)</span></span> if and only if there is a Turing Machine <span><span class="math inline">\(M\)</span></span> that computes <span><span class="math inline">\(F\)</span></span>.</p>
</div>
<div class="proofidea" data-ref="TM-equiv-thm" name="Proofidea 6.3">
<p>To prove such an equivalence theorem, we need to show two directions. We need to be able to <strong>(1)</strong> transform a Turing machine <span><span class="math inline">\(M\)</span></span> to a NAND-TM program <span><span class="math inline">\(P\)</span></span> that computes the same function as <span><span class="math inline">\(M\)</span></span> and <strong>(2)</strong> transform a NAND-TM program <span><span class="math inline">\(P\)</span></span> into a Turing machine <span><span class="math inline">\(M\)</span></span> that computes the same function as <span><span class="math inline">\(P\)</span></span>.</p>
<p>The idea of the proof is illustrated in <a href='#tmvsnandppfig'>Figure 6.11</a>. To show <strong>(1)</strong>, given a Turing machine <span><span class="math inline">\(M\)</span></span>, we will create a NAND-TM program <span><span class="math inline">\(P\)</span></span> that will have an array <code>Tape</code> for the tape of <span><span class="math inline">\(M\)</span></span> and scalar (i.e., non array) variable(s) <code>state</code> for the state of <span><span class="math inline">\(M\)</span></span>. Specifically, since the state of a Turing machine is not in <span><span class="math inline">\(\{0,1\}\)</span></span> but rather in a larger set <span><span class="math inline">\([k]\)</span></span>, we will use <span><span class="math inline">\(\ceil{\log k}\)</span></span> variables <code>state_</code><span><span class="math inline">\(0\)</span></span> , <span><span class="math inline">\(\ldots\)</span></span>, <code>state_</code><span><span class="math inline">\(\ceil{\log k}-1\)</span></span> variables to store the representation of the state. Similarly, to encode the larger alphabet <span><span class="math inline">\(\Sigma\)</span></span> of the tape, we will use <span><span class="math inline">\(\ceil{\log |\Sigma|}\)</span></span> arrays <code>Tape_</code><span><span class="math inline">\(0\)</span></span> , <span><span class="math inline">\(\ldots\)</span></span>, <code>Tape_</code><span><span class="math inline">\(\ceil{\log |\Sigma|}-1\)</span></span>, such that the <span><span class="math inline">\(i^{th}\)</span></span> location of these arrays encodes the <span><span class="math inline">\(i^{th}\)</span></span> symbol in the tape for every tape. Using the fact that <em>every</em> function can be computed by a NAND-CIRC program, we will be able to compute the transition function of <span><span class="math inline">\(M\)</span></span>, replacing moving left and right by decrementing and incrementing <code>i</code> respectively.</p>
<p>We show <strong>(2)</strong> using very similar ideas. Given a program <span><span class="math inline">\(P\)</span></span> that uses <span><span class="math inline">\(a\)</span></span> array variables and <span><span class="math inline">\(b\)</span></span> scalar variables, we will create a Turing machine with about <span><span class="math inline">\(2^b\)</span></span> states to encode the values of scalar variables, and an alphabet of about <span><span class="math inline">\(2^a\)</span></span> so we can encode the arrays using our tape. (The reason the sizes are only “about” <span><span class="math inline">\(2^a\)</span></span> and <span><span class="math inline">\(2^b\)</span></span> is that we will need to add some symbols and steps for bookkeeping purposes.) The Turing Machine <span><span class="math inline">\(M\)</span></span> will simulate each iteration of the program <span><span class="math inline">\(P\)</span></span> by updating its state and tape accordingly.</p>
</div>
<figure>
<img src="../figure/turingmachinevsnandtm.png" alt="6.11: Comparing a Turing Machine to a NAND-TM program. Both have an unbounded memory component (the tape for a Turing machine, and the arrays for a NAND-TM program), as well as a constant local memory (state for a Turing machine, and scalar variables for a NAND-TM program). Both can only access at each step one location of the unbounded memory, this is the “head” location for a Turing machine, and the value of the index variable i for a NAND-TM program." id="tmvsnandppfig" /><figcaption>6.11: Comparing a Turing Machine to a NAND-TM program. Both have an unbounded memory component (the <em>tape</em> for a Turing machine, and the <em>arrays</em> for a NAND-TM program), as well as a constant local memory (<em>state</em> for a Turing machine, and <em>scalar variables</em> for a NAND-TM program). Both can only access at each step one location of the unbounded memory, this is the “head” location for a Turing machine, and the value of the index variable <code>i</code> for a NAND-TM program.</figcaption>
</figure>
<div class="proof" data-ref="TM-equiv-thm" name="Proof 6.3">
<p>We start by proving the “if” direction of <a href='#TM-equiv-thm'>Theorem 6.12</a>. Namely we show that given a Turing machine <span><span class="math inline">\(M\)</span></span>, we can find a NAND-TM program <span><span class="math inline">\(P_M\)</span></span> such that for every input <span><span class="math inline">\(x\)</span></span>, if <span><span class="math inline">\(M\)</span></span> halts on input <span><span class="math inline">\(x\)</span></span> with output <span><span class="math inline">\(y\)</span></span> then <span><span class="math inline">\(P_M(x)=y\)</span></span>. Since our goal is just to show such a program <span><span class="math inline">\(P_M\)</span></span> <em>exists</em>, we don’t need to write out the full code of <span><span class="math inline">\(P_M\)</span></span> line by line, and can take advantage of our various “syntactic sugar” in describing it.</p>
<p>The key observation is that by <a href='lec_03a_computing_every_function.html#NAND-univ-thm'>Theorem 4.12</a> we can compute <em>every</em> finite function using a NAND-CIRC program. In particular, consider the transition function <span><span class="math inline">\(\delta_M:[k]\times \Sigma \rightarrow [k] \times \Sigma \times \{\mathsf{L},\mathsf{R} \}\)</span></span> of our Turing Machine. We can encode the its components as follows:</p>
<ul>
<li><p>We encode <span><span class="math inline">\([k]\)</span></span> using <span><span class="math inline">\(\{0,1\}^\ell\)</span></span> and <span><span class="math inline">\(\Sigma\)</span></span> using <span><span class="math inline">\(\{0,1\}^{\ell&#39;}\)</span></span>, where <span><span class="math inline">\(\ell = \ceil{\log k}\)</span></span> and <span><span class="math inline">\(\ell&#39; = \ceil{\log |\Sigma|}\)</span></span>.</p></li>
<li><p>We encode the set <span><span class="math inline">\(\{\mathsf{L},\mathsf{R}, \mathsf{S},\mathsf{H} \}\)</span></span> using <span><span class="math inline">\(\{0,1\}^2\)</span></span>. We will choose the encode <span><span class="math inline">\(\mathsf{L} \mapsto 01\)</span></span>, <span><span class="math inline">\(\mathsf{R} \mapsto 11\)</span></span>, <span><span class="math inline">\(\mathsf{S} \mapsto 10\)</span></span>, <span><span class="math inline">\(\mathsf{H} \mapsto 00\)</span></span>. (This conveniently corresponds to the semantics of the <code>MODANDJUMP</code> operation.)</p></li>
</ul>
<p>Hence we can identify <span><span class="math inline">\(\delta_M\)</span></span> with a function <span><span class="math inline">\(\overline{M}:\{0,1\}^{\ell+\ell&#39;} \rightarrow \{0,1\}^{\ell+\ell&#39;+2}\)</span></span>, mapping strings of length <span><span class="math inline">\(\ell+\ell&#39;\)</span></span> to strings of length <span><span class="math inline">\(\ell+\ell&#39;+2\)</span></span>. By <a href='lec_03a_computing_every_function.html#NAND-univ-thm'>Theorem 4.12</a> there exists a finite length NAND-CIRC program <code>ComputeM</code> that computes this function <span><span class="math inline">\(\overline{M}\)</span></span>. The NAND-TM program to simulate <span><span class="math inline">\(M\)</span></span> will essentially be the following:</p>
<div  class="pseudocodeoutput">
<div class="ps-root">
<div class="ps-algorithm with-caption" id = simMwithNANDTMarg>
<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;">
<span class="ps-keyword">Algorithm 13 </span>NAND-TM program to simulate TM $M$</p>
<div class="ps-algorithmic"><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">Input:</span>  \(x\in \{0,1\}^*\)<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">Output:</span>  \(M(x)\) if \(M\) halts on \(x\). Otherwise go into infinite loop<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> <span class="ps-comment"><i>#  We use variables \texttt{state\_</i></span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> <span class="ps-comment"><i>#  We use arrays \texttt{Tape\_</i></span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> <span class="ps-comment"><i>#  We omit the initial and final "book keeping" to copy <span class="ps-keyword">Input:</span> to \texttt{Tape</i></span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> <span class="ps-comment"><i>#  Use the fact that transition is finite and computable by NAND-CIRC program:</i></span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \texttt{state\_}\(0\) \(\ldots\) \texttt{state\_}\(\ell-1\), \texttt{Tape\_}\(0\)\texttt{[i]}\(\ldots\) \texttt{Tape\_}\(\ell'-1\)\texttt{[i]}, \texttt{dir0},\texttt{dir1} \(\leftarrow\) \texttt{TRANSITION(} \texttt{state\_}\(0\) \(\ldots\) \texttt{state\_}\(\ell-1\), \texttt{Tape\_}\(0\)\texttt{[i]}\(\ldots\) \texttt{Tape\_}\(\ell'-1\)\texttt{[i]}, \texttt{dir0},\texttt{dir1} \texttt{)}<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> \texttt{MODANDJMP(dir0,dir1)}<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"></div>
</div>
</div>
</div>
<p>Every step of the main loop of the above program perfectly mimics the computation of the Turing Machine <span><span class="math inline">\(M\)</span></span> and so the program carries out exactly the definition of computation by a Turing Machine as per <a href='#TM-def'>Definition 6.2</a>.</p>
<p>For the other direction, suppose that <span><span class="math inline">\(P\)</span></span> is a NAND-TM program with <span><span class="math inline">\(s\)</span></span> lines, <span><span class="math inline">\(\ell\)</span></span> scalar variables, and <span><span class="math inline">\(\ell&#39;\)</span></span> array variables. We will show that there exists a Turing machine <span><span class="math inline">\(M_P\)</span></span> with <span><span class="math inline">\(2^\ell+C\)</span></span> states and alphabet <span><span class="math inline">\(\Sigma\)</span></span> of size <span><span class="math inline">\(C&#39; + 2^{\ell&#39;}\)</span></span> that computes the same functions as <span><span class="math inline">\(P\)</span></span> (where <span><span class="math inline">\(C\)</span></span>, <span><span class="math inline">\(C&#39;\)</span></span> are some constants to be determined later).</p>
<p>Specifically, consider the function <span><span class="math inline">\(\overline{P}:\{0,1\}^\ell \times \{0,1\}^{\ell&#39;} \rightarrow \{0,1\}^\ell \times \{0,1\}^{\ell&#39;}\)</span></span> that on input the contents of <span><span class="math inline">\(P\)</span></span>’s scalar variables and the contents of the array variables at location <code>i</code> in the beginning of an iteration, outputs all the new values of these variables at the last line of the iteration, right before the <code>MODANDJUMP</code> instruction is executed.</p>
<p>If <code>foo</code> and <code>bar</code> are the two variables that are used as input to the <code>MODANDJUMP</code> instruction, then this means that based on the values of these variables we can compute whether <code>i</code> will increase, decrease or stay the same, and whether the program will halt or jump back to the beginning. Hence a Turing machine can simulate an execution of <span><span class="math inline">\(P\)</span></span> in one iteration using a finite function applied to its alphabet. The overall operation of the Turing machine will be as follows:</p>
<ol type="1">
<li><p>The machine <span><span class="math inline">\(M_P\)</span></span> encodes the contents of the array variables of <span><span class="math inline">\(P\)</span></span> in its tape, and the contents of the scalar variables in (part of) its state. Specifically, if <span><span class="math inline">\(P\)</span></span> has <span><span class="math inline">\(\ell\)</span></span> local variables and <span><span class="math inline">\(t\)</span></span> arrays, then the state space of <span><span class="math inline">\(M\)</span></span> will be large enough to encode all <span><span class="math inline">\(2^\ell\)</span></span> assignments to the local variables and the alphabet <span><span class="math inline">\(\Sigma\)</span></span> of <span><span class="math inline">\(M\)</span></span> will be large enough to encode all <span><span class="math inline">\(2^t\)</span></span> assignments for the array variables at each location. The head location corresponds to the index variable <code>i</code>.</p></li>
<li><p>Recall that every line of the program <span><span class="math inline">\(P\)</span></span> corresponds to reading and writing either a scalar variable, or an array variable at the location <code>i</code>. In one iteration of <span><span class="math inline">\(P\)</span></span> the value of <code>i</code> remains fixed, and so the machine <span><span class="math inline">\(M\)</span></span> can simulate this iteration by reading the values of all array variables at <code>i</code> (which are encoded by the single symbol in the alphabet <span><span class="math inline">\(\Sigma\)</span></span> located at the <code>i</code>-th cell of the tape) , reading the values of all scalar variables (which are encoded by the state), and updating both. The transition function of <span><span class="math inline">\(M\)</span></span> can output <span><span class="math inline">\(\mathsf{L},\mathsf{S},\mathsf{R}\)</span></span> depending on whether the values given to the <code>MODANDJMP</code> operation are <span><span class="math inline">\(01\)</span></span>, <span><span class="math inline">\(10\)</span></span> or <span><span class="math inline">\(11\)</span></span> respectively.</p></li>
<li><p>When the program halts (i.e., <code>MODANDJMP</code> gets <span><span class="math inline">\(00\)</span></span>) then the Turing machine will enter into a special loop to copy the results of the <code>Y</code> array into the output and then halt. We can achieve this by adding a few more states.</p></li>
</ol>
<p>The above is not a full formal description of a Turing Machine, but our goal is just to show that such a machine exists. One can see that <span><span class="math inline">\(M_P\)</span></span> simulates every step of <span><span class="math inline">\(P\)</span></span>, and hence computes the same function as <span><span class="math inline">\(P\)</span></span>.</p>
</div>
<div id="polyequivrem" class="remark" title="Running time equivalence (optional)" name="Remark 6.14 (Running time equivalence (optional)) ">
<p>If we examine the proof of <a href='#TM-equiv-thm'>Theorem 6.12</a> then we can see that every iteration of the loop of a NAND-TM program corresponds to one step in the execution of the Turing machine. We will come back to this question of measuring number of computation steps later in this course. For now the main take away point is that NAND-TM programs and Turing Machines are essentially equivalent in power even when taking running time into account.</p>
</div>
<h3 id="specification-vs-implementation-again" data-number="6.3.1">Specification vs implementation (again)</h3>
<p>Once you understand the definitions of both NAND-TM programs and Turing Machines, <a href='#TM-equiv-thm'>Theorem 6.12</a> is fairly straightforward. Indeed, NAND-TM programs are not as much a different model from Turing Machines as they are simply a reformulation of the same model using programming language notation. You can think of the difference between a Turing machine and a NAND-TM program as the difference between representing a number using decimal or binary notation. In contrast, the difference between a <em>function</em> <span><span class="math inline">\(F\)</span></span> and a Turing machine that computes <span><span class="math inline">\(F\)</span></span> is much more profound: it is like the difference between the equation <span><span class="math inline">\(x^2 + x = 12\)</span></span> and the number <span><span class="math inline">\(3\)</span></span> that is a solution for this equation. For this reason, while we take special care in distinguishing <em>functions</em> from <em>programs</em> or <em>machines</em>, we will often identify the two latter concepts. We will move freely between describing an algorithm as a Turing machine or as a NAND-TM program (as well as some of the other equivalent computational models we will see in <a href='lec_07_other_models.html#chapequivalentmodels'>Chapter 7</a> and beyond).</p>
<p><a name="specvsimp"></a></p>
<table>
<caption>Specification vs Implementation formalisms</caption>
<colgroup>
<col style="width: 17%" />
<col style="width: 46%" />
<col style="width: 35%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><p><em>Setting</em></p></th>
<th style="text-align: left;"><p><em>Specification</em></p></th>
<th><p><em>Implementation</em></p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><p><em>Finite computation</em></p></td>
<td style="text-align: left;"><p><strong>Functions</strong> mapping <span class="math inline">\(\{0,1\}^n\)</span> to <span class="math inline">\(\{0,1\}^m\)</span></p></td>
<td><p><strong>Circuits</strong>, <strong>Straightline programs</strong></p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><em>Infinite computation</em></p></td>
<td style="text-align: left;"><p><strong>Functions</strong> mapping <span class="math inline">\(\{0,1\}^*\)</span> to <span class="math inline">\(\{0,1\}\)</span> or to <span class="math inline">\(\{0,1\}^*\)</span>.</p></td>
<td><p><strong>Algorithms</strong>, <strong>Turing Machines</strong>, <strong>Programs</strong></p></td>
</tr>
</tbody>
</table>
<h2 id="nand-tm-syntactic-sugar" data-number="6.4">NAND-TM syntactic sugar</h2>
<p>Just like we did with NAND-CIRC in <a href='lec_03a_computing_every_function.html#finiteuniversalchap'>Chapter 4</a>, we can use “syntactic sugar” to make NAND-TM programs easier to write. For starters, we can use all of the syntactic sugar of NAND-CIRC, and so have access to macro definitions and conditionals (i.e., if/then). But we can go beyond this and achieve for example:</p>
<ul>
<li><p>Inner loops such as the <code>while</code> and <code>for</code> operations common to many programming language.s</p></li>
<li><p>Multiple index variables (e.g., not just <code>i</code> but we can add <code>j</code>, <code>k</code>, etc.).</p></li>
<li><p>Arrays with more than one dimension (e.g., <code>Foo[i][j]</code>, <code>Bar[i][j][k]</code> etc.)</p></li>
</ul>
<p>In all of these cases (and many others) we can implement the new feature as mere “syntactic sugar” on top of standard NAND-TM, which means that the set of functions computable by NAND-TM with this feature is the same as the set of functions computable by standard NAND-TM. Similarly, we can show that the set of functions computable by Turing Machines that have more than one tape, or tapes of more dimensions than one, is the same as the set of functions computable by standard Turing machines.</p>
<h3 id="nandtminnerloopssec" data-number="6.4.1">“GOTO” and inner loops</h3>
<p>We can implement more advanced <em>looping constructs</em> than the simple <code>MODANDJUMP</code>. For example, we can implement <code>GOTO</code>. A <code>GOTO</code> statement corresponds to jumping to a certain line in the execution. For example, if we have code of the form</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" title="1"><span class="co">&quot;start&quot;</span>:  do foo</a>
<a class="sourceLine" id="cb7-2" title="2">   GOTO(<span class="st">&quot;end&quot;</span>)</a>
<a class="sourceLine" id="cb7-3" title="3"><span class="co">&quot;skip&quot;</span>: do bar</a>
<a class="sourceLine" id="cb7-4" title="4"><span class="co">&quot;end&quot;</span>: do blah</a></code></pre></div>
<p>then the program will only do <code>foo</code> and <code>blah</code> as when it reaches the line <code>GOTO("end")</code> it will jump to the line labeled with <code>"end"</code>. We can achieve the effect of <code>GOTO</code> in NAND-TM using conditionals. In the code below, we assume that we have a variable <code>pc</code> that can take strings of some constant length. This can be encoded using a finite number of Boolean variables <code>pc_0</code>, <code>pc_1</code>, <span><span class="math inline">\(\ldots\)</span></span>, <code>pc_</code><span><span class="math inline">\(k-1\)</span></span>, and so when we write below <code>pc = "label"</code> what we mean is something like <code>pc_0 = 0</code>,<code>pc_1 = 1</code>, <span><span class="math inline">\(\ldots\)</span></span> (where the bits <span><span class="math inline">\(0,1,\ldots\)</span></span> correspond to the encoding of the finite string <code>"label"</code> as a string of length <span><span class="math inline">\(k\)</span></span>). We also assume that we have access to conditional (i.e., <code>if</code> statements), which we can emulate using syntactic sugar in the same way as we did in NAND-CIRC.</p>
<p>To emulate a GOTO statement, we will first modify a program P of the form</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" title="1">do foo</a>
<a class="sourceLine" id="cb8-2" title="2">do bar</a>
<a class="sourceLine" id="cb8-3" title="3">do blah</a></code></pre></div>
<p>to have the following form (using syntactic sugar for <code>if</code>):</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" title="1">pc <span class="op">=</span> <span class="st">&quot;line1&quot;</span></a>
<a class="sourceLine" id="cb9-2" title="2"><span class="cf">if</span> (pc<span class="op">==</span><span class="st">&quot;line1&quot;</span>):</a>
<a class="sourceLine" id="cb9-3" title="3">    do foo</a>
<a class="sourceLine" id="cb9-4" title="4">    pc <span class="op">=</span> <span class="st">&quot;line2&quot;</span></a>
<a class="sourceLine" id="cb9-5" title="5"><span class="cf">if</span> (pc<span class="op">==</span><span class="st">&quot;line2&quot;</span>):</a>
<a class="sourceLine" id="cb9-6" title="6">    do bar</a>
<a class="sourceLine" id="cb9-7" title="7">    pc <span class="op">=</span> <span class="st">&quot;line3&quot;</span></a>
<a class="sourceLine" id="cb9-8" title="8"><span class="cf">if</span> (pc<span class="op">==</span><span class="st">&quot;line3&quot;</span>):</a>
<a class="sourceLine" id="cb9-9" title="9">    do blah</a></code></pre></div>
<p>These two programs do the same thing. The variable <code>pc</code> corresponds to the “program counter” and tells the program which line to execute next. We can see that if we wanted to emulate a <code>GOTO("line3")</code> then we could simply modify the instruction <code>pc = "line2"</code> to be <code>pc = "line3"</code>.</p>
<p>In NAND-CIRC we could only have <code>GOTO</code>s that go forward in the code, but since in NAND-TM everything is encompassed within a large outer loop, we can use the same ideas to implement <code>GOTO</code>’s that can go backwards, as well as conditional loops.</p>
<p><strong>Other loops.</strong> Once we have <code>GOTO</code>, we can emulate all the standard loop constructs such as <code>while</code>, <code>do .. until</code> or <code>for</code> in NAND-TM as well. For example, we can replace the code</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb10-1" title="1"><span class="cf">while</span> foo:</a>
<a class="sourceLine" id="cb10-2" title="2">    do blah</a>
<a class="sourceLine" id="cb10-3" title="3">do bar</a></code></pre></div>
<p>with</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb11-1" title="1"><span class="co">&quot;loop&quot;</span>:</a>
<a class="sourceLine" id="cb11-2" title="2">    <span class="cf">if</span> NOT(foo): GOTO(<span class="st">&quot;next&quot;</span>)</a>
<a class="sourceLine" id="cb11-3" title="3">    do blah</a>
<a class="sourceLine" id="cb11-4" title="4">    GOTO(<span class="st">&quot;loop&quot;</span>)</a>
<a class="sourceLine" id="cb11-5" title="5"><span class="co">&quot;next&quot;</span>:</a>
<a class="sourceLine" id="cb11-6" title="6">    do bar</a></code></pre></div>
<div id="gotorem" class="remark" title="GOTO&#39;s in programming languages" name="Remark 6.15 (GOTO&#39;s in programming languages) ">
<p>The <code>GOTO</code> statement was a staple of most early programming languages, but has largely fallen out of favor and is not included in many modern languages such as <em>Python</em>, <em>Java</em>, <em>Javascript</em>. In 1968, Edsger Dijsktra wrote a famous letter titled “<a href="https://goo.gl/bnNsjo">Go to statement considered harmful.</a>” (see also <a href='#xkcdgotofig'>Figure 6.12</a>). The main trouble with <code>GOTO</code> is that it makes analysis of programs more difficult by making it harder to argue about <em>invariants</em> of the program.</p>
<p>When a program contains a loop of the form:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb12-1" title="1"><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</a>
<a class="sourceLine" id="cb12-2" title="2">    do something</a>
<a class="sourceLine" id="cb12-3" title="3"></a>
<a class="sourceLine" id="cb12-4" title="4">do blah</a></code></pre></div>
<p>you know that the line of code <code>do blah</code> can only be reached if the loop ended, in which case you know that <code>j</code> is equal to <span><span class="math inline">\(100\)</span></span>, and might also be able to argue other properties of the state of the program. In contrast, if the program might jump to <code>do blah</code> from any other point in the code, then it’s very hard for you as the programmer to know what you can rely upon in this code. As Dijkstra said, such invariants are important because <em>“our intellectual powers are rather geared to master static relations and .. our powers to visualize processes evolving in time are relatively poorly developed”</em> and so <em>“we should … do …our utmost best to shorten the conceptual gap between the static program and the dynamic process.”</em></p>
<p>That said, <code>GOTO</code> is still a major part of lower level languages where it is used to implement higher level looping constructs such as <code>while</code> and <code>for</code> loops. For example, even though <em>Java</em> doesn’t have a <code>GOTO</code> statement, the Java Bytecode (which is a lower level representation of Java) does have such a statement. Similarly, Python bytecode has instructions such as <code>POP_JUMP_IF_TRUE</code> that implement the <code>GOTO</code> functionality, and similar instructions are included in many assembly languages. The way we use <code>GOTO</code> to implement a higher level functionality in NAND-TM is reminiscent of the way these various jump instructions are used to implement higher level looping constructs.</p>
</div>
<figure>
<img src="../figure/xkcdgoto.png" alt="6.12: XKCD’s take on the GOTO statement." id="xkcdgotofig" class="margin" /><figcaption>6.12: XKCD’s take on the <code>GOTO</code> statement.</figcaption>
</figure>
<h2 id="uniformity-and-nand-vs-nand-tm-discussion" data-number="6.5">Uniformity, and NAND vs NAND-TM (discussion)</h2>
<p>While NAND-TM adds extra operations over NAND-CIRC, it is not exactly accurate to say that NAND-TM programs or Turing machines are “more powerful” than NAND-CIRC programs or Boolean circuits. NAND-CIRC programs, having no loops, are simply not applicable for computing functions with an unbounded number of inputs. Thus, to compute a function <span><span class="math inline">\(F:\{0,1\}^* :\rightarrow \{0,1\}^*\)</span></span> using NAND-CIRC (or equivalently, Boolean circuits) we need a <em>collection</em> of programs/circuits: one for every input length.</p>
<p>The key difference between NAND-CIRC and NAND-TM is that NAND-TM allows us to express the fact that the algorithm for computing parities of length-<span><span class="math inline">\(100\)</span></span> strings is really the same one as the algorithm for computing parities of length-<span><span class="math inline">\(5\)</span></span> strings (or similarly the fact that the algorithm for adding <span><span class="math inline">\(n\)</span></span>-bit numbers is the same for every <span><span class="math inline">\(n\)</span></span>, etc.). That is, one can think of the NAND-TM program for general parity as the “seed” out of which we can grow NAND-CIRC programs for length <span><span class="math inline">\(10\)</span></span>, length <span><span class="math inline">\(100\)</span></span>, or length <span><span class="math inline">\(1000\)</span></span> parities as needed.</p>
<p>This notion of a single algorithm that can compute functions of all input lengths is known as <em>uniformity</em> of computation and hence we think of Turing machines / NAND-TM as <em>uniform</em> model of computation, as opposed to Boolean circuits or NAND-CIRC which is a <em>nonuniform</em> model, where we have to specify a different program for every input length.</p>
<p>Looking ahead, we will see that this uniformity leads to another crucial difference between Turing machines and circuits. Turing machines can have inputs and outputs that are longer than the description of the machine as a string and in particular there exists a Turing machine that can “self replicate” in the sense that it can print its own code. This notion of “self replication”, and the related notion of “self reference” is crucial to many aspects of computation, as well of course to life itself, whether in the form of digital or biological programs.</p>
<p>For now, what you ought to remember is the following differences between <em>uniform</em> and <em>non uniform</em> computational models:</p>
<ul>
<li><p><strong>Non uniform computational models:</strong> Examples are <em>NAND-CIRC programs</em> and <em>Boolean circuits</em>. These are models where each individual program/circuit can compute a <em>finite</em> function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span>. We have seen that <em>every</em> finite function can be computed by <em>some</em> program/circuit. To discuss computation of an <em>infinite</em> function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span> we need to allow a <em>sequence</em> <span><span class="math inline">\(\{ P_n \}_{n\in \N}\)</span></span> of programs/circuits (one for every input length), but this does not capture the notion of a <em>single algorithm</em> to compute the function <span><span class="math inline">\(F\)</span></span>.</p></li>
<li><p><strong>Uniform computational models:</strong> Examples are <em>Turing machines</em> and <em>NAND-TM programs</em>. These are model where a single program/machine can take inputs of <em>arbitrary length</em> and hence compute an <em>infinite</em> function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>. The number of steps that a program/machine takes on some input is not a priori bounded in advance and in particular there is a chance that it will enter into an <em>infinite loop</em>. Unlike the nonuniform case, we have <em>not</em> shown that every infinite function can be computed by some NAND-TM program/Turing Machine. We will come back to this point in <a href='lec_08_uncomputability.html#chapcomputable'>Chapter 8</a>.</p></li>
</ul>
<div id="section-1" class="recap" name="Recap">
<ul>
<li><em>Turing machines</em> capture the notion of a single algorithm that can evaluate functions of every input length.</li>
<li>They are equivalent to <em>NAND-TM programs</em>, which add loops and arrays to NAND-CIRC.</li>
<li>Unlike NAND-CIRC or Boolean circuits, the number of steps that a Turing machine takes on a given input is not fixed in advance. In fact, a Turing machine or a NAND-TM program can enter into an <em>infinite loop</em> on certain inputs, and not halt at all.</li>
</ul>
</div>
<h2 id="exercises" data-number="6.6">Exercises</h2>
<div id="majoritynandtm" class="exercise" title="Explicit NAND TM programming" name="Exercise 6.1 (Explicit NAND TM programming) ">
<p>Produce the code of a (syntactic-sugar free) NAND-TM program <span><span class="math inline">\(P\)</span></span> that computes the (unbounded input length) <em>Majority</em> function <span><span class="math inline">\(Maj:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> where for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(Maj(x)=1\)</span></span> if and only if <span><span class="math inline">\(\sum_{i=0}^{|x|} x_i &gt; |x|/2\)</span></span>. We say “produce” rather than “write” because you do not have to write the code of <span><span class="math inline">\(P\)</span></span> by hand, but rather can use the programming language of your choice to compute this code.</p>
</div>
<div id="computable" class="exercise" title="Computable functions examples" name="Exercise 6.2 (Computable functions examples) ">
<p>Prove that the following functions are computable. For all of these functions, you do not have to fully specify the Turing Machine or the NAND-TM program that computes the function, but rather only prove that such a machine or program exists:</p>
<ol type="1">
<li><p><span><span class="math inline">\(\ensuremath{\mathit{INC}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> which takes as input a representation of a natural number <span><span class="math inline">\(n\)</span></span> and outputs the representation of <span><span class="math inline">\(n+1\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(\ensuremath{\mathit{ADD}}:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> which takes as input a representation of a pair of natural numbers <span><span class="math inline">\((n,m)\)</span></span> and outputs the representation of <span><span class="math inline">\(n+m\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(\ensuremath{\mathit{MULT}}:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, which takes a representation of a pair of natural numbers <span><span class="math inline">\((n,m)\)</span></span> and outputs the representation of <span><span class="math inline">\(n\dot m\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(\ensuremath{\mathit{SORT}}:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span> which takes as input the representation of a list of natural numbers <span><span class="math inline">\((a_0,\ldots,a_{n-1})\)</span></span> and returns its sorted version <span><span class="math inline">\((b_0,\ldots,b_{n-1})\)</span></span> such that for every <span><span class="math inline">\(i\in [n]\)</span></span> there is some <span><span class="math inline">\(j \in [n]\)</span></span> with <span><span class="math inline">\(b_i=a_j\)</span></span> and <span><span class="math inline">\(b_0 \leq b_1 \leq \cdots \leq b_{n-1}\)</span></span>.</p></li>
</ol>
</div>
<div id="twoindexex" class="exercise" title="Two index NAND-TM" name="Exercise 6.3 (Two index NAND-TM) ">
<p>Define NAND-TM’ to be the variant of NAND-TM where there are <em>two</em> index variables <code>i</code> and <code>j</code>. Arrays can be indexed by either <code>i</code> or <code>j</code>. The operation <code>MODANDJMP</code> takes four variables <span><span class="math inline">\(a,b,c,d\)</span></span> and uses the values of <span><span class="math inline">\(c,d\)</span></span> to decide whether to increment <code>j</code>, decrement <code>j</code> or keep it in the same value (corresponding to <span><span class="math inline">\(01\)</span></span>, <span><span class="math inline">\(10\)</span></span>, and <span><span class="math inline">\(00\)</span></span> respectively). Prove that for every function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F\)</span></span> is computable by a NAND-TM program if and only if <span><span class="math inline">\(F\)</span></span> is computable by a NAND-TM’ program.</p>
</div>
<div id="twotapeex" class="exercise" title="Two tape Turing machines" name="Exercise 6.4 (Two tape Turing machines) ">
<p>Define a <em>two tape Turing machine</em> to be a Turing machine which has two separate tapes and two separate heads. At every step, the transition function gets as input the location of the cells in the two tapes, and can decide whether to move each head independently. Prove that for every function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F\)</span></span> is computable by a standard Turing Machine if and only if <span><span class="math inline">\(F\)</span></span> is computable by a two-tape Turing machine.</p>
</div>
<div id="twodimnandtmex" class="exercise" title="Two dimensional arrays" name="Exercise 6.5 (Two dimensional arrays) ">
<p>Define NAND-TM’’ to be the variant of NAND-TM where just like NAND-TM’ defined in <a href='#twoindexex'>Exercise 6.3</a> there are two index variables <code>i</code> and <code>j</code>, but now the arrays are <em>two dimensional</em> and so we index an array <code>Foo</code> by <code>Foo[i][j]</code>. Prove that for every function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F\)</span></span> is computable by a NAND-TM program if and only if <span><span class="math inline">\(F\)</span></span> is computable by a NAND-TM’’ program.</p>
</div>
<div id="twodimtapeex" class="exercise" title="Two dimensional Turing machines" name="Exercise 6.6 (Two dimensional Turing machines) ">
<p>Define a <em>two-dimensional Turing machine</em> to be a Turing machine in which the tape is <em>two dimensional</em>. At every step the machine can move <span><span class="math inline">\(\mathsf{U}\)</span></span>p, <span><span class="math inline">\(\mathsf{D}\)</span></span>own, <span><span class="math inline">\(\mathsf{L}\)</span></span>eft, <span><span class="math inline">\(\mathsf{R}\)</span></span>ight, or <span><span class="math inline">\(\mathsf{S}\)</span></span>tay. Prove that for every function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, <span><span class="math inline">\(F\)</span></span> is computable by a standard Turing Machine if and only if <span><span class="math inline">\(F\)</span></span> is computable by a two-dimensional Turing machine.</p>
</div>
<div class="exercise" name="Exercise 6.7">
<p>Prove the following closure properties of the set <span><span class="math inline">\(\mathbf{R}\)</span></span> defined in <a href='#classRdef'>Definition 6.4</a>:</p>
<ol type="1">
<li><p>If <span><span class="math inline">\(F \in \mathbf{R}\)</span></span> then the function <span><span class="math inline">\(G(x) = 1 - F(x)\)</span></span> is in <span><span class="math inline">\(\mathbf{R}\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(F,G \in \mathbf{R}\)</span></span> then the function <span><span class="math inline">\(H(x) = F(x) \vee G(x)\)</span></span> is in <span><span class="math inline">\(\mathbf{R}\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(F \in \mathbf{R}\)</span></span> then the function <span><span class="math inline">\(F^*\)</span></span> in in <span><span class="math inline">\(\mathbf{R}\)</span></span> where <span><span class="math inline">\(F^*\)</span></span> is defined as follows: <span><span class="math inline">\(F^*(x)=1\)</span></span> iff there exist some strings <span><span class="math inline">\(w_0,\ldots,w_{k-1}\)</span></span> such that <span><span class="math inline">\(x = w_0 w_1 \cdots w_{k-1}\)</span></span> and <span><span class="math inline">\(F(w_i)=1\)</span></span> for every <span><span class="math inline">\(i\in [k]\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(F \in \mathbf{R}\)</span></span> then the function <span>
<div class='myequationbox'><span class="math display">\[
G(x) = \begin{cases}  \exists_{y \in \{0,1\}^{|x|}} F(xy) = 1 \\
0 &amp; \text{otherwise}
\end{cases}
\]</span></div></span> is in <span><span class="math inline">\(\mathbf{R}\)</span></span>.</p></li>
</ol>
</div>
<div id="obliviousTMex" class="exercise" title="Oblivious Turing Machines (challenging)" name="Exercise 6.8 (Oblivious Turing Machines (challenging)) ">
<p>Define a Turing Machine <span><span class="math inline">\(M\)</span></span> to be <em>oblivious</em> if its head movements are independent of its input. That is, we say that <span><span class="math inline">\(M\)</span></span> is oblivious if there exists an infinite sequence <span><span class="math inline">\(\ensuremath{\mathit{MOVE}} \in \{\mathsf{L},\mathsf{R}, \mathsf{S} \}^\infty\)</span></span> such that for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, the movements of <span><span class="math inline">\(M\)</span></span> when given input <span><span class="math inline">\(x\)</span></span> (up until the point it halts, if such point exists) are given by <span><span class="math inline">\(\ensuremath{\mathit{MOVE}}_0,\ensuremath{\mathit{MOVE}}_1,\ensuremath{\mathit{MOVE}}_2,\ldots\)</span></span>.</p>
<p>Prove that for every function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, if <span><span class="math inline">\(F\)</span></span> is computable then it is computable by an oblivious Turing machine. See footnote for hint.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>
</div>
<div id="singlebit-ex" class="exercise" title="Single vs multiple bit" name="Exercise 6.9 (Single vs multiple bit) ">
<p>Prove that for every <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span>, the function <span><span class="math inline">\(F\)</span></span> is computable if and only if the following function <span><span class="math inline">\(G:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is computable, where <span><span class="math inline">\(G\)</span></span> is defined as follows: <span><span class="math inline">\(G(x,i,\sigma) = \begin{cases} F(x)_i &amp; i &lt; |F(x)|, \sigma =0 \\ 1 &amp; i &lt; |F(x)|, \sigma = 1 \\ 0 &amp; i \geq |F(x)| \end{cases}\)</span></span></p>
</div>
<div id="uncomputabilityviacountingex" class="exercise" title="Uncomputability via counting" name="Exercise 6.10 (Uncomputability via counting) ">
<p>Recall that <span><span class="math inline">\(\mathbf{R}\)</span></span> is the set of all total functions from <span><span class="math inline">\(\{0,1\}^*\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span> that are computable by a Turing machine (see <a href='#classRdef'>Definition 6.4</a>). Prove that <span><span class="math inline">\(\mathbf{R}\)</span></span> is <em>countable</em>. That is, prove that there exists a one-to-one map <span><span class="math inline">\(DtN:\mathbf{R} \rightarrow \mathbb{N}\)</span></span>. You can use the equivalence between Turing machines and NAND-TM programs.</p>
</div>
<div id="uncountablefuncex" class="exercise" title="Not every function is computable" name="Exercise 6.11 (Not every function is computable) ">
<p>Prove that the set of <em>all</em> total functions from <span><span class="math inline">\(\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is <em>not</em> countable. You can use the results of <a href='lec_02_representation.html#cantorsec'>Subsection 2.3.1</a>. (We will see an <em>explicit</em> uncomputable function in <a href='lec_08_uncomputability.html#chapcomputable'>Chapter 8</a>.)</p>
</div>
<h2 id="chaploopnotes" data-number="6.7">Bibliographical notes</h2>
<p>Augusta Ada Byron, countess of Lovelace (1815-1852) lived a short but turbulent life, though is today most well known for her collaboration with Charles Babbage (see  (<a href="https://scholar.google.com/scholar?hl=en&q=Stein+Ada+:+a+life+and+a+legacy" target="_blank">Stein, 1987</a>)  for a biography). Ada took an immense interest in Babbage’s <em>analytical engine</em>, which we mentioned in <a href='lec_03_computation.html#compchap'>Chapter 3</a>. In 1842-3, she translated from Italian a paper of Menabrea on the engine, adding copious notes (longer than the paper itself). The quote in the chapter’s beginning is taken from Nota A in this text. Lovelace’s notes contain several examples of <em>programs</em> for the analytical engine, and because of this she has been called “the world’s first computer programmer” though it is not clear whether they were written by Lovelace or Babbage himself  (<a href="https://scholar.google.com/scholar?hl=en&q=Holt+The+Ada+perplex:+how+Byronâ€™s+daughter+came+to+be+celebrated+as+a+cybervisionary" target="_blank">Holt, 2001</a>) . Regardless, Ada was clearly one of very few people (perhaps the only one outside of Babbage himself) to fully appreciate how significant and revolutionary the idea of mechanizing computation truly is.</p>
<p>The books of Shetterly  (<a href="https://scholar.google.com/scholar?hl=en&q=Shetterly+Hidden+figures+:+the+American+dream+and+the+untold+story+of+the+Black+women+mathematicians+who+helped+win+the+space+race" target="_blank">Shetterly, 2016</a>)  and Sobel  (<a href="https://scholar.google.com/scholar?hl=en&q=Sobel+The+Glass+Universe+:+How+the+Ladies+of+the+Harvard+Observatory+Took+the+Measure+of+the+Stars" target="_blank">Sobel, 2017</a>)  discuss the history of human computers (who were female, more often than not) and their important contributions to scientific discoveries in astronomy and space exploration.</p>
<p>Alan Turing was one of the intellectual giants of the 20th century. He was not only the first person to define the notion of computation, but also invented and used some of the world’s earliest computational devices as part of the effort to break the <em>Enigma</em> cipher during World War II, saving <a href="https://goo.gl/KY1bJN">millions of lives</a>. Tragically, Turing committed suicide in 1954, following his conviction in 1952 for homosexual acts and a court-mandated hormonal treatment. In 2009, British prime minister Gordon Brown made an official public apology to Turing, and in 2013 Queen Elizabeth II granted Turing a posthumous pardon. Turing’s life is the subject of a <a href="https://goo.gl/3GdFdp">great book</a> and a <a href="https://goo.gl/EtQvSu">mediocre movie</a>.</p>
<p>Sipser’s text  (<a href="https://scholar.google.com/scholar?hl=en&q=Sipser+Introduction+to+the+theory+of+computation" target="_blank">Sipser, 1997</a>)  defines a Turing machine as a <em>seven tuple</em> consisting of the state space, input alphabet, tape alphabet, transition function, starting state, accepting state, and rejecting state. Superficially this looks like a very different definition than <a href='#TM-def'>Definition 6.2</a> but it is simply a different representation of the same concept, just as a graph can be represented in either adjacency list or adjacency matrix form.</p>
<p>One difference is that Sipser considers a general set of states <span><span class="math inline">\(Q\)</span></span> that is not necessarily of the form <span><span class="math inline">\(Q=\{0,1,2,\ldots, k-1\}\)</span></span> for some natural number <span><span class="math inline">\(k&gt;0\)</span></span>. Sipser also restricts his attention to Turing machines that output only a single bit and therefore designates two special <em>halting states</em>: the “<span><span class="math inline">\(0\)</span></span> halting state” (often known as the <em>rejecting state</em>) and the other as the “<span><span class="math inline">\(1\)</span></span> halting state” (often known as the <em>accepting state</em>). Thus instead of writing <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span> on an output tape, the machine will enter into one of these states and halt. This again makes no difference to the computational power, though we prefer to consider the more general model of multi-bit outputs. (Sipser presents the basic task of a Turing machine as that of <em>deciding a language</em> as opposed to computing a function, but these are equivalent, see <a href='#decidablelanguagesrem'>Remark 6.5</a>.)</p>
<p>Sipser considers also functions with input in <span><span class="math inline">\(\Sigma^*\)</span></span> for an arbitrary alphabet <span><span class="math inline">\(\Sigma\)</span></span> (and hence distinguishes between the <em>input alphabet</em> which he denotes as <span><span class="math inline">\(\Sigma\)</span></span> and the <em>tape alphabet</em> which he denotes as <span><span class="math inline">\(\Gamma\)</span></span>), while we restrict attention to functions with binary strings as input. Again this is not a major issue, since we can always encode an element of <span><span class="math inline">\(\Sigma\)</span></span> using a binary string of length <span><span class="math inline">\(\log \ceil{|\Sigma|}\)</span></span>. Finally (and this is a very minor point) Sipser requires the machine to either move left or right in every step, without the <span><span class="math inline">\(\mathsf{S}\)</span></span>tay operation, though staying in place is very easy to emulate by simply moving right and then back left.</p>
<p>Another definition used in the literature is that a Turing machine <span><span class="math inline">\(M\)</span></span> <em>recognizes</em> a language <span><span class="math inline">\(L\)</span></span> if for every <span><span class="math inline">\(x\in L\)</span></span>, <span><span class="math inline">\(M(x)=1\)</span></span> and for every <span><span class="math inline">\(x\not\in L\)</span></span>, <span><span class="math inline">\(M(x) \in \{0,\bot \}\)</span></span>. A language <span><span class="math inline">\(L\)</span></span> is <em>recursively enumerable</em> if there exists a Turing machine <span><span class="math inline">\(M\)</span></span> that recognizes it, and the set of all recursively enumerable languages is often denoted by <span><span class="math inline">\(\mathbf{RE}\)</span></span>. We will not use this terminology in this book.</p>
<p>One of the first programming-language formulations of Turing machines was given by Wang  (<a href="https://scholar.google.com/scholar?hl=en&q=Wang+A+variant+to+Turing's+theory+of+computing+machines" target="_blank">Wang, 1957</a>) . Our formulation of NAND-TM is aimed at making the connection with circuits more direct, with the eventual goal of using it for the Cook-Levin Theorem, as well as results such as <span><span class="math inline">\(\mathbf{P} \subseteq \mathbf{P_{/poly}}\)</span></span> and <span><span class="math inline">\(\mathbf{BPP} \subseteq \mathbf{P_{/poly}}\)</span></span>. The website <a href="https://esolangs.org">esolangs.org</a> features a large variety of esoteric Turing-complete programming languages. One of the most famous of them is <a href="https://esolangs.org/wiki/Brainfuck">Brainf*ck</a>.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>A <em>partial function</em> <span><span class="math inline">\(F\)</span></span> from a set <span><span class="math inline">\(A\)</span></span> to a set <span><span class="math inline">\(B\)</span></span> is a function that is only defined on a <em>subset</em> of <span><span class="math inline">\(A\)</span></span>, (see <a href='lec_00_1_math_background.html#functionsec'>Subsection 1.4.3</a>). We can also think of such a function as mapping <span><span class="math inline">\(A\)</span></span> to <span><span class="math inline">\(B \cup \{ \bot \}\)</span></span> where <span><span class="math inline">\(\bot\)</span></span> is a special “failure” symbol such that <span><span class="math inline">\(F(a)=\bot\)</span></span> indicates the function <span><span class="math inline">\(F\)</span></span> is not defined on <span><span class="math inline">\(a\)</span></span>.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>Most programming languages use arrays of fixed size, while a Turing machine’s tape is unbounded. But of course there is no need to store an infinite number of <span><span class="math inline">\(\varnothing\)</span></span> symbols. If you want, you can think of the tape as a list that starts off just long enough to store the input, but is dynamically grown in size as the Turing machine’s head explores new positions.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>You can use the sequence <span><span class="math inline">\(\mathsf{R}\)</span></span>, <span><span class="math inline">\(\mathsf{L}\)</span></span>,<span><span class="math inline">\(\mathsf{R}\)</span></span>, <span><span class="math inline">\(\mathsf{R}\)</span></span>, <span><span class="math inline">\(\mathsf{L}\)</span></span>, <span><span class="math inline">\(\mathsf{L}\)</span></span>, <span><span class="math inline">\(\mathsf{R}\)</span></span>,<span><span class="math inline">\(\mathsf{R}\)</span></span>,<span><span class="math inline">\(\mathsf{R}\)</span></span>, <span><span class="math inline">\(\mathsf{L}\)</span></span>, <span><span class="math inline">\(\mathsf{L}\)</span></span>, <span><span class="math inline">\(\mathsf{L}\)</span></span>, <span><span class="math inline">\(\ldots\)</span></span>.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 21:38:05</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_06_loops.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
