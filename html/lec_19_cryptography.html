<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Cryptography</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Cryptography" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.1</b> Exercises</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cryptography</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_19_cryptography.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="chapcryptography" data-number="20">Cryptography</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>Definition of perfect secrecy<br />
</li>
<li>The one-time pad encryption scheme<br />
</li>
<li>Necessity of long keys for perfect secrecy<br />
</li>
<li>Computational secrecy and the derandomized one-time pad.<br />
</li>
<li>Public key encryption<br />
</li>
<li>A taste of advanced topics<br />
</li>
</ul>
</div>
<blockquote>
<p><em>“Human ingenuity cannot concoct a cipher which human ingenuity cannot resolve.”</em>, Edgar Allen Poe, 1841</p>
</blockquote>
<blockquote>
<p><em>“A good disguise should not reveal the person’s height”</em>, Shafi Goldwasser and Silvio Micali, 1982</p>
</blockquote>
<blockquote>
<p><em>““Perfect Secrecy” is defined by requiring of a system that after a cryptogram is intercepted by the enemy the a posteriori probabilities of this cryptogram representing various messages be identically the same as the a priori probabilities of the same messages before the interception. It is shown that perfect secrecy is possible but requires, if the number of messages is finite, the same number of possible keys."</em>, Claude Shannon, 1945</p>
</blockquote>
<blockquote>
<p><em>“We stand today on the brink of a revolution in cryptography.”</em>, Whitfeld Diffie and Martin Hellman, 1976</p>
</blockquote>
<p>Cryptography - the art or science of “secret writing” - has been around for several millennia, and for almost all of that time Edgar Allan Poe’s quote above held true. Indeed, the history of cryptography is littered with the figurative corpses of cryptosystems believed secure and then broken, and sometimes with the actual corpses of those who have mistakenly placed their faith in these cryptosystems.</p>
<p>Yet, something changed in the last few decades, which is the “revolution” alluded to (and to a large extent initiated by) Diffie and Hellman’s 1976 paper quoted above. New cryptosystems have been found that have not been broken despite being subjected to immense efforts involving both human ingenuity and computational power on a scale that completely dwarves the “code breakers” of Poe’s time. Even more amazingly, these cryptosystem are not only seemingly unbreakable, but they also achieve this under much harsher conditions. Not only do today’s attackers have more computational power but they also have more data to work with. In Poe’s age, an attacker would be lucky if they got access to more than a few encryptions of known messages. These days attackers might have massive amounts of data- terabytes or more - at their disposal. In fact, with <em>public key</em> encryption, an attacker can generate as many ciphertexts as they wish.</p>
<p>The key to this success has been a clearer understanding of both how to <em>define</em> security for cryptographic tools and how to relate this security to <em>concrete computational problems</em>. Cryptography is a vast and continuously changing topic, but we will touch on some of these issues in this chapter.</p>
<h2 id="classical-cryptosystems" data-number="20.1">Classical cryptosystems</h2>
<p>A great many cryptosystems have been devised and broken throughout the ages. Let us recount just some of these stories. In 1587, Mary the queen of Scots, and the heir to the throne of England, wanted to arrange the assassination of her cousin, queen Elisabeth I of England, so that she could ascend to the throne and finally escape the house arrest under which she had been for the last 18 years. As part of this complicated plot, she sent a coded letter to Sir Anthony Babington.</p>
<figure>
<img src="../figure/encrypted_letter.jpg" alt="20.1: Snippet from encrypted communication between queen Mary and Sir Babington" id="maryscottletterfig" class="margin" /><figcaption>20.1: Snippet from encrypted communication between queen Mary and Sir Babington</figcaption>
</figure>
<p>Mary used what’s known as a <em>substitution cipher</em> where each letter is transformed into a different obscure symbol (see <a href='#maryscottletterfig'>Figure 20.1</a>). At a first look, such a letter might seem rather inscrutable- a meaningless sequence of strange symbols. However, after some thought, one might recognize that these symbols <em>repeat</em> several times and moreover that different symbols repeat with different frequencies. Now it doesn’t take a large leap of faith to assume that perhaps each symbol corresponds to a different letter and the more frequent symbols correspond to letters that occur in the alphabet with higher frequency. From this observation, there is a short gap to completely breaking the cipher, which was in fact done by queen Elisabeth’s spies who used the decoded letters to learn of all the co-conspirators and to convict queen Mary of treason, a crime for which she was executed. Trusting in superficial security measures (such as using “inscrutable” symbols) is a trap that users of cryptography have been falling into again and again over the years. (As in many things, this is the subject of a great XKCD cartoon, see <a href='#XKCDnavajofig'>Figure 20.2</a>.)</p>
<figure>
<img src="../figure/code_talkers.png" alt="20.2: XKCD’s take on the added security of using uncommon symbols" id="XKCDnavajofig" class="margin" /><figcaption>20.2: XKCD’s take on the added security of using uncommon symbols</figcaption>
</figure>
<p>The <a href="https://en.wikipedia.org/wiki/Vigen%C3%A8re_cipher">Vigenère cipher</a> is named after Blaise de Vigenère who described it in a book in 1586 (though it was invented earlier by Bellaso). The idea is to use a collection of substitution cyphers - if there are <span><span class="math inline">\(n\)</span></span> different ciphers then the first letter of the plaintext is encoded with the first cipher, the second with the second cipher, the <span><span class="math inline">\(n^{th}\)</span></span> with the <span><span class="math inline">\(n^{th}\)</span></span> cipher, and then the <span><span class="math inline">\(n+1^{st}\)</span></span> letter is again encoded with the first cipher. The key is usually a word or a phrase of <span><span class="math inline">\(n\)</span></span> letters, and the <span><span class="math inline">\(i^{th}\)</span></span> substitution cipher is obtained by shifting each letter <span><span class="math inline">\(k_i\)</span></span> positions in the alphabet. This “flattens” the frequencies and makes it much harder to do frequency analysis, which is why this cipher was considered “unbreakable” for 300+ years and got the nickname “le chiffre indéchiffrable” (“the unbreakable cipher”). Nevertheless, Charles Babbage cracked the Vigenère cipher in 1854 (though he did not publish it). In 1863 Friedrich Kasiski broke the cipher and published the result. The idea is that once you guess the length of the cipher, you can reduce the task to breaking a simple substitution cipher which can be done via frequency analysis (can you see why?). Confederate generals used Vigenère regularly during the civil war, and their messages were routinely cryptanalzed by Union officers.</p>
<figure>
<img src="../figure/confederate_cipher_disk.jpg" alt="20.4: Confederate Cipher Disk for implementing the Vigenère cipher" id="tmplabelfig" class="margin" /><figcaption>20.4: Confederate Cipher Disk for implementing the Vigenère cipher</figcaption>
</figure>
<figure>
<img src="../figure/confederate_message.jpg" alt="20.4: Confederate encryption of the message “Gen’l Pemberton: You can expect no help from this side of the river. Let Gen’l Johnston know, if possible, when you can attack the same point on the enemy’s lines. Inform me also and I will endeavor to make a diversion. I have sent some caps. I subjoin a despatch from General Johnston.”" id="tmplabelfig" class="margin" /><figcaption>20.4: Confederate encryption of the message “Gen’l Pemberton: You can expect no help from this side of the river. Let Gen’l Johnston know, if possible, when you can attack the same point on the enemy’s lines. Inform me also and I will endeavor to make a diversion. I have sent some caps. I subjoin a despatch from General Johnston.”</figcaption>
</figure>
<p>The <em>Enigma</em> cipher was a mechanical cipher (looking like a typewriter, see <a href='#enigmafig'>Figure 20.5</a>) where each letter typed would get mapped into a different letter depending on the (rather complicated) key and current state of the machine which had several rotors that rotated at different paces. An identically wired machine at the other end could be used to decrypt. Just as many ciphers in history, this has also been believed by the Germans to be “impossible to break” and even quite late in the war they refused to believe it was broken despite mounting evidence to that effect. (In fact, some German generals refused to believe it was broken even <em>after</em> the war.) Breaking Enigma was an heroic effort which was initiated by the Poles and then completed by the British at Bletchley Park, with Alan Turing (of the Turing machines) playing a key role. As part of this effort the Brits built arguably the world’s first large scale mechanical computation devices (though they looked more similar to washing machines than to iPhones). They were also helped along the way by some quirks and errors of the German operators. For example, the fact that their messages ended with “Heil Hitler” turned out to be quite useful.</p>
<figure>
<img src="../figure/enigma.jpg" alt="20.5: In the Enigma mechanical cipher the secret key would be the settings of the rotors and internal wires. As the operator types up their message, the encrypted version appeared in the display area above, and the internal state of the cipher was updated (and so typing the same letter twice would generally result in two different letters output). Decrypting follows the same process: if the sender and receiver are using the same key then typing the ciphertext would result in the plaintext appearing in the display." id="enigmafig" class="margin" /><figcaption>20.5: In the <em>Enigma</em> mechanical cipher the secret key would be the settings of the rotors and internal wires. As the operator types up their message, the encrypted version appeared in the display area above, and the internal state of the cipher was updated (and so typing the same letter twice would generally result in two different letters output). Decrypting follows the same process: if the sender and receiver are using the same key then typing the ciphertext would result in the plaintext appearing in the display.</figcaption>
</figure>
<p>Here is one entertaining anecdote: the Enigma machine would never map a letter to itself. In March 1941, Mavis Batey, a cryptanalyst at Bletchley Park received a very long message that she tried to decrypt. She then noticed a curious property— the message did <em>not</em> contain the letter “L”.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> She realized that the probability that no “L”’s appeared in the message is too small for this to happen by chance. Hence she surmised that the original message must have been composed <em>only</em> of L’s. That is, it must have been the case that the operator, perhaps to test the machine, have simply sent out a message where he repeatedly pressed the letter “L”. This observation helped her decode the next message, which helped inform of a planned Italian attack and secure a resounding British victory in what became known as “the Battle of Cape Matapan”. Mavis also helped break another Enigma machine. Using the information she provided, the Brits were able to feed the Germans with the false information that the main allied invasion would take place in Pas de Calais rather than on Normandy.</p>
<p>In the words of General Eisenhower, the intelligence from Bletchley park was of “priceless value”. It made a huge difference for the Allied war effort, thereby shortening World War II and saving millions of lives. See also <a href="http://www.cix.co.uk/~klockstone/hinsley.htm">this interview with Sir Harry Hinsley</a>.</p>
<h2 id="defining-encryption" data-number="20.2">Defining encryption</h2>
<p>Many of the troubles that cryptosystem designers faced over history (and still face!) can be attributed to not properly defining or understanding what are the goals they want to achieve in the first place. Let us focus on the setting of <em>private key encryption</em>. (This is also known as “symmetric encryption”; for thousands of years, “private key encryption” was synonymous with encryption and only in the 1970’s was the concept of <em>public key encryption</em> invented, see <a href='#publickeyencdef'>Definition 20.11</a>.) A <em>sender</em> (traditionally called “Alice”) wants to send a message (known also as a <em>plaintext</em>) <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> to a <em>receiver</em> (traditionally called “Bob”). They would like their message to be kept secret from an <em>adversary</em> who listens in or “eavesdrops” on the communication channel (and is traditionally called “Eve”).</p>
<p>Alice and Bob share a <em>secret key</em> <span><span class="math inline">\(k \in \{0,1\}^*\)</span></span>. (While the letter <span><span class="math inline">\(k\)</span></span> is often used elsewhere in the book to denote a natural number, in this chapter we use it to denote the string corresponding to a secret key.) Alice uses the key <span><span class="math inline">\(k\)</span></span> to “scramble” or <em>encrypt</em> the plaintext <span><span class="math inline">\(x\)</span></span> into a <em>ciphertext</em> <span><span class="math inline">\(y\)</span></span>, and Bob uses the key <span><span class="math inline">\(k\)</span></span> to “unscramble” or <em>decrypt</em> the ciphertext <span><span class="math inline">\(y\)</span></span> back into the plaintext <span><span class="math inline">\(x\)</span></span>. This motivates the following definition which attempts to capture what it means for an encryption scheme to be <em>valid</em> or “make sense”, regardless of whether or not it is <em>secure</em>:</p>
<div id="encryptiondef" class="definition" title="Valid encryption scheme" name="Definition 20.1 (Valid encryption scheme) ">
<p>Let <span><span class="math inline">\(L:\N \rightarrow \N\)</span></span> and <span><span class="math inline">\(C:\N \rightarrow \N\)</span></span> be two functions mapping natural numbers to natural numbers. A pair of polynomial-time computable functions <span><span class="math inline">\((E,D)\)</span></span> mapping strings to strings is a <em>valid private key encryption scheme</em> (or <em>encryption scheme</em> for short) with plaintext length function <span><span class="math inline">\(L(\cdot)\)</span></span> and ciphertext length function <span><span class="math inline">\(C(\cdot)\)</span></span> if for every <span><span class="math inline">\(n\in \N\)</span></span>, <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(x \in \{0,1\}^{L(n)}\)</span></span>, <span><span class="math inline">\(|E_k(x)|= C(n)\)</span></span> and <span>
<div class='myequationbox'><span class="math display">\[
D(k,E(k,x))=x \;. \;\;(20.1)
\]</span><a id='eqvalidenc'></a></div></span></p>
</div>
<p>We will often write the first input (i.e., the key) to the encryption and decryption as a subscript and so can write <a href='#eqvalidenc'>Equation 20.1</a> also as <span><span class="math inline">\(D_k(E_k(x))=x\)</span></span>.</p>
<figure>
<img src="../figure/encryptionvalid.png" alt="20.6: A private-key encryption scheme is a pair of algorithms E,D such that for every key k\in \{0,1\}^n and plaintext x\in \{0,1\}^{L(n)}, y=E_k(x) is a ciphertext of length C(n). The encryption scheme is valid if for every such y, D_k(y)=x. That is, the decryption of an encryption of x is x, as long as both encryption and decryption use the same key." id="validencryption" class="margin" /><figcaption>20.6: A private-key encryption scheme is a pair of algorithms <span><span class="math inline">\(E,D\)</span></span> such that for every key <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and plaintext <span><span class="math inline">\(x\in \{0,1\}^{L(n)}\)</span></span>, <span><span class="math inline">\(y=E_k(x)\)</span></span> is a ciphertext of length <span><span class="math inline">\(C(n)\)</span></span>. The encryption scheme is <em>valid</em> if for every such <span><span class="math inline">\(y\)</span></span>, <span><span class="math inline">\(D_k(y)=x\)</span></span>. That is, the decryption of an encryption of <span><span class="math inline">\(x\)</span></span> is <span><span class="math inline">\(x\)</span></span>, as long as both encryption and decryption use the same key.</figcaption>
</figure>
<div id="lengthsciphertextplaintext" class="solvedexercise" title="Lengths of ciphertext and plaintext" name="Solvedexercise 20.1 (Lengths of ciphertext and plaintext) ">
<p>Prove that for every valid encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with functions <span><span class="math inline">\(L,C\)</span></span>. <span><span class="math inline">\(C(n) \geq L(n)\)</span></span> for every <span><span class="math inline">\(n\)</span></span>.</p>
</div>
<div class="solution" data-ref="lengthsciphertextplaintext" name="Solution 20.2">
<p>For every fixed key <span><span class="math inline">\(k \in \{0,1\}^n\)</span></span>, the equation <a href='#eqvalidenc'>Equation 20.1</a> implies that the map <span><span class="math inline">\(y \mapsto D_k(y)\)</span></span> inverts the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span>, which in particular means that the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> must be one to one. Hence its codomain must be at least as large as its domain, and since its domain is <span><span class="math inline">\(\{0,1\}^{L(n)}\)</span></span> and its codomain is <span><span class="math inline">\(\{0,1\}^{C(n)}\)</span></span> it follows that <span><span class="math inline">\(C(n) \geq L(n)\)</span></span>.</p>
</div>
<p>Since the ciphertext length is always at least the plaintext length (and in most applications it is not much longer than that), we typically focus on the plaintext length as the quantity to optimize in an encryption scheme. The <em>larger</em> <span><span class="math inline">\(L(n)\)</span></span> is, the better the scheme, since it means we need a shorter secret key to protect messages of the same length.</p>
<h2 id="defining-security-of-encryption" data-number="20.3">Defining security of encryption</h2>
<p><a href='#encryptiondef'>Definition 20.1</a> says nothing about the <em>security</em> of <span><span class="math inline">\(E\)</span></span> and <span><span class="math inline">\(D\)</span></span>, and even allows the trivial encryption scheme that ignores the key altogether and sets <span><span class="math inline">\(E_k(x)=x\)</span></span> for every <span><span class="math inline">\(x\)</span></span>. Defining security is not a trivial matter.</p>
<div id="section-1" class="pause" name="Pause">
<p>You would appreciate the subtleties of defining security of encryption more if at this point you take a five minute break from reading, and try (possibly with a partner) to brainstorm on how you would mathematically define the notion that an encryption scheme is <em>secure</em>, in the sense that it protects the secrecy of the plaintext <span><span class="math inline">\(x\)</span></span>.</p>
</div>
<p>Throughout history, many attacks on cryptosystems were rooted in the cryptosystem designers’ reliance on “security through obscurity”— trusting that the fact their <em>methods</em> are not known to their enemy will protect them from being broken. This is a faulty assumption - if you reuse a method again and again (even with a different key each time) then eventually your adversaries will figure out what you are doing. And if Alice and Bob meet frequently in a secure location to decide on a new method, they might as well take the opportunity to exchange their secrets. These considerations led Auguste Kerckhoffs in 1883 to state the following principle:</p>
<blockquote>
<p><em>A cryptosystem should be secure even if everything about the system, except the key, is public knowledge.</em><sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>
</blockquote>
<p>Why is it OK to assume the key is secret and not the algorithm? Because we can always choose a fresh key. But of course that won’t help us much if our key is “1234” or “passw0rd!”. In fact, if you use <em>any</em> deterministic algorithm to choose the key then eventually your adversary will figure this out. Therefore for security we must choose the key at <em>random</em> and can restate Kerckhoffs’s principle as follows:</p>
<blockquote>
<p><em>There is no secrecy without randomness</em></p>
</blockquote>
<p>This is such a crucial point that is worth repeating:</p>
<div id="securityrandomness" class="bigidea" name="Bigidea 25">
<p>There is no <em>secrecy</em> without <em>randomness</em>.</p>
</div>
<p>At the heart of every cryptographic scheme there is a secret key, and the secret key is always chosen at random. A corollary of that is that to understand cryptography, you need to know probability theory.</p>
<div id="randomnessinlife" class="remark" title="Randomness in the real world" name="Remark 20.2 (Randomness in the real world) ">
<p>Choosing the secrets for cryptography requires generating randomness, which is often done by measuring some “unpredictable” or “high entropy” data, and then applying hash functions to the result to “extract” a uniformly random string. Great care must be taken in doing this, and randomness generators often turn out to be the Achilles heel of secure systems.</p>
<p>In 2006 a programmer removed a line of code from the procedure to generate entropy in OpenSSL package distributed by Debian since it caused a warning in some automatic verification code. As a result for two years (until this was discovered) all the randomness generated by this procedure used only the process ID as an “unpredictable” source. This means that all communication done by users in that period is fairly easily breakable (and in particular, if some entities recorded that communication they could break it also retroactively). See <a href="http://www.xkcd.com/424/">XKCD’s take</a> on that incident.</p>
<p>In 2012 two separate teams of researchers scanned a large number of RSA keys on the web and found out that about 4 percent of them are easy to break. The main issue were devices such as routers, internet-connected printers and such. These devices sometimes run variants of Linux- a desktop operating system- but without a hard drive, mouse or keyboard, they don’t have access to many of the entropy sources that desktop have. Coupled with some good old fashioned ignorance of cryptography and software bugs, this led to many keys that are downright trivial to break, see <a href="https://freedom-to-tinker.com/blog/nadiah/new-research-theres-no-need-panic-over-factorable-keys-just-mind-your-ps-and-qs/">this blog post</a> and <a href="https://factorable.net/">this web page</a> for more details.</p>
<p>Since randomness is so crucial to security, breaking the procedure to generate randomness can lead to a complete break of the system that uses this randomness. Indeed, the Snowden documents, combined with observations of Shumow and Ferguson, <a href="https://en.wikipedia.org/wiki/Dual_EC_DRBG">strongly suggest</a> that the NSA has deliberately inserted a <em>trapdoor</em> in one of the pseudorandom generators published by the National Institute of Standards and Technologies (NIST). Fortunately, this generator wasn’t widely adapted but apparently the NSA did pay 10 million dollars to RSA security so the latter would make this generator their default option in their products.</p>
</div>
<h2 id="perfect-secrecy" data-number="20.4">Perfect secrecy</h2>
<p>If you think about encryption scheme security for a while, you might come up with the following principle for defining security: <em>“An encryption scheme is secure if it is not possible to recover the key <span><span class="math inline">\(k\)</span></span> from <span><span class="math inline">\(E_k(x)\)</span></span>”</em>. However, a moment’s thought shows that the key is not really what we’re trying to protect. After all, the whole point of an encryption is to protect the confidentiality of the <em>plaintext</em> <span><span class="math inline">\(x\)</span></span>. So, we can try to define that <em>“an encryption scheme is secure if it is not possible to recover the plaintext <span><span class="math inline">\(x\)</span></span> from <span><span class="math inline">\(E_k(x)\)</span></span>”</em>. Yet it is not clear what this means either. Suppose that an encryption scheme reveals the first 10 bits of the plaintext <span><span class="math inline">\(x\)</span></span>. It might still not be possible to recover <span><span class="math inline">\(x\)</span></span> completely, but on an intuitive level, this seems like it would be extremely unwise to use such an encryption scheme in practice. Indeed, often even <em>partial information</em> about the plaintext is enough for the adversary to achieve its goals.</p>
<p>The above thinking led Shannon in 1945 to formalize the notion of <em>perfect secrecy</em>, which is that an encryption reveals absolutely nothing about the message. There are several equivalent ways to define it, but perhaps the cleanest one is the following:</p>
<div id="perfectsecrecy" class="definition" title="Perfect secrecy" name="Definition 20.3 (Perfect secrecy) ">
<p>A valid encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with plaintext length <span><span class="math inline">\(L(\cdot)\)</span></span> is <em>perfectly secret</em> if for every <span><span class="math inline">\(n\in \N\)</span></span> and plaintexts <span><span class="math inline">\(x,x&#39; \in \{0,1\}^{L(n)}\)</span></span>, the following two distributions <span><span class="math inline">\(Y\)</span></span> and <span><span class="math inline">\(Y&#39;\)</span></span> over <span><span class="math inline">\(\{0,1\}^*\)</span></span> are identical:</p>
<ul>
<li><p><span><span class="math inline">\(Y\)</span></span> is obtained by sampling <span><span class="math inline">\(k\sim \{0,1\}^n\)</span></span> and outputting <span><span class="math inline">\(E_k(x)\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(Y&#39;\)</span></span> is obtained by sampling <span><span class="math inline">\(k\sim \{0,1\}^n\)</span></span> and outputting <span><span class="math inline">\(E_k(x&#39;)\)</span></span>.</p></li>
</ul>
</div>
<div class="pause" name="Pause 20.4">
<p>This definition might take more than one reading to parse. Try to think of how this condition would correspond to your intuitive notion of “learning no information” about <span><span class="math inline">\(x\)</span></span> from observing <span><span class="math inline">\(E_k(x)\)</span></span>, and to Shannon’s quote in the beginning of this chapter.</p>
<p>In particular, suppose that you knew ahead of time that Alice sent either an encryption of <span><span class="math inline">\(x\)</span></span> or an encryption of <span><span class="math inline">\(x&#39;\)</span></span>. Would you learn anything new from observing the encryption of the message that Alice actually sent? It may help you to look at <a href='#perfectsecfig'>Figure 20.7</a>.</p>
</div>
<figure>
<img src="../figure/perfectsecrecy.png" alt="20.7: For any key length n, we can visualize an encryption scheme (E,D) as a graph with a vertex for every one of the 2^{L(n)} possible plaintexts and for every one of the ciphertexts in \{0,1\}^* of the form E_k(x) for k\in \{0,1\}^n and x\in \{0,1\}^{L(n)}. For every plaintext x and key k, we add an edge labeled k between x and E_k(x). By the validity condition, if we pick any fixed key k, the map x \mapsto E_k(x) must be one-to-one. The condition of perfect secrecy simply corresponds to requiring that every two plaintexts x and x&#39; have exactly the same set of neighbors (or multi-set, if there are parallel edges)." id="perfectsecfig" class="margin" /><figcaption>20.7: For any key length <span><span class="math inline">\(n\)</span></span>, we can visualize an encryption scheme <span><span class="math inline">\((E,D)\)</span></span> as a graph with a vertex for every one of the <span><span class="math inline">\(2^{L(n)}\)</span></span> possible plaintexts and for every one of the ciphertexts in <span><span class="math inline">\(\{0,1\}^*\)</span></span> of the form <span><span class="math inline">\(E_k(x)\)</span></span> for <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(x\in \{0,1\}^{L(n)}\)</span></span>. For every plaintext <span><span class="math inline">\(x\)</span></span> and key <span><span class="math inline">\(k\)</span></span>, we add an edge labeled <span><span class="math inline">\(k\)</span></span> between <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(E_k(x)\)</span></span>. By the validity condition, if we pick any fixed key <span><span class="math inline">\(k\)</span></span>, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> must be one-to-one. The condition of perfect secrecy simply corresponds to requiring that every two plaintexts <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(x&#39;\)</span></span> have exactly the same set of neighbors (or multi-set, if there are parallel edges).</figcaption>
</figure>
<h3 id="example-perfect-secrecy-in-the-battlefield" data-number="20.4.1">Example: Perfect secrecy in the battlefield</h3>
<p>To understand <a href='#perfectsecrecy'>Definition 20.3</a>, suppose that Alice sends only one of two possible messages: “attack” or “retreat”, which we denote by <span><span class="math inline">\(x_0\)</span></span> and <span><span class="math inline">\(x_1\)</span></span> respectively, and that she sends each one of those messages with probability <span><span class="math inline">\(1/2\)</span></span>. Let us put ourselves in the shoes of <em>Eve</em>, the eavesdropping adversary. A priori we would have guessed that Alice sent either <span><span class="math inline">\(x_0\)</span></span> or <span><span class="math inline">\(x_1\)</span></span> with probability <span><span class="math inline">\(1/2\)</span></span>. Now we observe <span><span class="math inline">\(y=E_k(x_i)\)</span></span> where <span><span class="math inline">\(k\)</span></span> is a uniformly chosen key in <span><span class="math inline">\(\{0,1\}^n\)</span></span>. How does this new information cause us to update our beliefs on whether Alice sent the plaintext <span><span class="math inline">\(x_0\)</span></span> or the plaintext <span><span class="math inline">\(x_1\)</span></span>?</p>
<div id="section-2" class="pause" name="Pause">
<p>Before reading the next paragraph, you might want to try the analysis yourself. You may find it useful to look at the <a href="https://en.wikipedia.org/wiki/Bayesian_inference">Wikipedia entry on Bayesian Inference</a> or <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading11.pdf">these MIT lecture notes</a>.</p>
</div>
<p>Let us define <span><span class="math inline">\(p_0(y)\)</span></span> to be the probability (taken over <span><span class="math inline">\(k\sim \{0,1\}^n\)</span></span>) that <span><span class="math inline">\(y=E_k(x_0)\)</span></span> and similarly <span><span class="math inline">\(p_1(y)\)</span></span> to be <span><span class="math inline">\(\Pr_{k \sim \{0,1\}^n}[y=E_k(x_1)]\)</span></span>. Note that, since Alice chooses the message to send at random, our a priori probability for observing <span><span class="math inline">\(y\)</span></span> is <span><span class="math inline">\(\tfrac{1}{2}p_0(y) + \tfrac{1}{2}p_1(y)\)</span></span>. However, as per <a href='#perfectsecrecy'>Definition 20.3</a>, the perfect secrecy condition guarantees that <span><span class="math inline">\(p_0(y)=p_1(y)\)</span></span>! Let us denote the number <span><span class="math inline">\(p_0(y)=p_1(y)\)</span></span> by <span><span class="math inline">\(p\)</span></span>. By the formula for conditional probability, the probability that Alice sent the message <span><span class="math inline">\(x_0\)</span></span> conditioned on our observation <span><span class="math inline">\(y\)</span></span> is simply <span>
<div class='myequationbox'><span class="math display">\[
\Pr[i=0 | y=E_k(x_i)] = \frac{\Pr[i=0 \wedge y = E_k(x_i)]}{\Pr[y = E_k(x)]} \;. \;\;(20.2)
\]</span><a id='bayeseq'></a></div></span></p>
<p>(The equation <a href='#bayeseq'>Equation 20.2</a> is a special case of <em>Bayes’ rule</em> which, although a simple restatement of the formula for conditional probability, is an extremely important and widely used tool in statistics and data analysis.)</p>
<p>Since the probability that <span><span class="math inline">\(i=0\)</span></span> and <span><span class="math inline">\(y\)</span></span> is the ciphertext <span><span class="math inline">\(E_k(0)\)</span></span> is equal to <span><span class="math inline">\(\tfrac{1}{2}\cdot p_0(y)\)</span></span>, and the a priori probability of observing <span><span class="math inline">\(y\)</span></span> is <span><span class="math inline">\(\tfrac{1}{2}p_0(y) + \tfrac{1}{2}p_1(y)\)</span></span>, we can rewrite <a href='#bayeseq'>Equation 20.2</a> as <span>
<div class='myequationbox'><span class="math display">\[
\Pr[i=0 | y=E_k(x_i)] = \frac{\tfrac{1}{2}p_0(y)}{\tfrac{1}{2}p_0(y)+\tfrac{1}{2}p_1(y)}  =  \frac{p}{p +p}  = \frac{1}{2}
\]</span></div></span> using the fact that <span><span class="math inline">\(p_0(y)=p_1(y)=p\)</span></span>. This means that observing the ciphertext <span><span class="math inline">\(y\)</span></span> did not help us at all! We still would not be able to guess whether Alice sent “attack” or “retreat” with better than 50/50 odds!</p>
<p>This example can be vastly generalized to show that perfect secrecy is indeed “perfect” in the sense that observing a ciphertext gives Eve <em>no additional information</em> about the plaintext beyond her a priori knowledge.</p>
<h3 id="constructing-perfectly-secret-encryption" data-number="20.4.2">Constructing perfectly secret encryption</h3>
<p><em>Perfect secrecy</em> is an extremely strong condition, and implies that an eavesdropper does not learn <em>any</em> information from observing the ciphertext. You might think that an encryption scheme satisfying such a strong condition will be impossible, or at least extremely complicated, to achieve. However it turns out we can in fact obtain perfectly secret encryption scheme fairly easily. Such a scheme for two-bit messages is illustrated in <a href='#onetimepadtwofig'>Figure 20.8</a></p>
<figure>
<img src="../figure/onetimepadtwobits.png" alt="20.8: A perfectly secret encryption scheme for two-bit keys and messages. The blue vertices represent plaintexts and the red vertices represent ciphertexts, each edge mapping a plaintext x to a ciphertext y=E_k(x) is labeled with the corresponding key k. Since there are four possible keys, the degree of the graph is four and it is in fact a complete bipartite graph. The encryption scheme is valid in the sense that for every k\in \{0,1\}^2, the map x \mapsto E_k(x) is one-to-one, which in other words means that the set of edges labeled with k is a matching." id="onetimepadtwofig" class="margin" /><figcaption>20.8: A perfectly secret encryption scheme for two-bit keys and messages. The blue vertices represent plaintexts and the red vertices represent ciphertexts, each edge mapping a plaintext <span><span class="math inline">\(x\)</span></span> to a ciphertext <span><span class="math inline">\(y=E_k(x)\)</span></span> is labeled with the corresponding key <span><span class="math inline">\(k\)</span></span>. Since there are four possible keys, the degree of the graph is four and it is in fact a complete bipartite graph. The encryption scheme is valid in the sense that for every <span><span class="math inline">\(k\in \{0,1\}^2\)</span></span>, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> is one-to-one, which in other words means that the set of edges labeled with <span><span class="math inline">\(k\)</span></span> is a <em>matching</em>.</figcaption>
</figure>
<p>In fact, this can be generalized to any number of bits:</p>
<div id="onetimepad" class="theorem" title="One Time Pad (Vernam 1917, Shannon 1949)" name="Theorem 20.4 (One Time Pad (Vernam 1917, Shannon 1949)) ">
<p>There is a perfectly secret valid encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with <span><span class="math inline">\(L(n)=C(n)=n\)</span></span>.</p>
</div>
<div id="section-3" class="proofidea" data-ref="onetimepad" name="Proofidea">
<p>Our scheme is the <a href="https://en.wikipedia.org/wiki/One-time_pad">one-time pad</a> also known as the “Vernam Cipher”, see <a href='#onetimepadfig'>Figure 20.9</a>. The encryption is exceedingly simple: to encrypt a message <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> with a key <span><span class="math inline">\(k \in \{0,1\}^n\)</span></span> we simply output <span><span class="math inline">\(x \oplus k\)</span></span> where <span><span class="math inline">\(\oplus\)</span></span> is the bitwise XOR operation that outputs the string corresponding to XORing each coordinate of <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(k\)</span></span>.</p>
</div>
<div class="proof" data-ref="onetimepad" name="Proof 20.4.2">
<p>For two binary strings <span><span class="math inline">\(a\)</span></span> and <span><span class="math inline">\(b\)</span></span> of the same length <span><span class="math inline">\(n\)</span></span>, we define <span><span class="math inline">\(a \oplus b\)</span></span> to be the string <span><span class="math inline">\(c \in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(c_i = a_i + b_i \mod 2\)</span></span> for every <span><span class="math inline">\(i\in [n]\)</span></span>. The encryption scheme <span><span class="math inline">\((E,D)\)</span></span> is defined as follows: <span><span class="math inline">\(E_k(x) = x\oplus k\)</span></span> and <span><span class="math inline">\(D_k(y)= y \oplus k\)</span></span>. By the associative law of addition (which works also modulo two), <span><span class="math inline">\(D_k(E_k(x))=(x\oplus k) \oplus k = x \oplus (k \oplus k) = x \oplus 0^n = x\)</span></span>, using the fact that for every bit <span><span class="math inline">\(\sigma \in \{0,1\}\)</span></span>, <span><span class="math inline">\(\sigma + \sigma \mod 2 = 0\)</span></span> and <span><span class="math inline">\(\sigma + 0 = \sigma \mod 2\)</span></span>. Hence <span><span class="math inline">\((E,D)\)</span></span> form a valid encryption.</p>
<p>To analyze the perfect secrecy property, we claim that for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, the distribution <span><span class="math inline">\(Y_x=E_k(x)\)</span></span> where <span><span class="math inline">\(k \sim \{0,1\}^n\)</span></span> is simply the uniform distribution over <span><span class="math inline">\(\{0,1\}^n\)</span></span>, and hence in particular the distributions <span><span class="math inline">\(Y_{x}\)</span></span> and <span><span class="math inline">\(Y_{x&#39;}\)</span></span> are identical for every <span><span class="math inline">\(x,x&#39; \in \{0,1\}^n\)</span></span>. Indeed, for every particular <span><span class="math inline">\(y\in \{0,1\}^n\)</span></span>, the value <span><span class="math inline">\(y\)</span></span> is output by <span><span class="math inline">\(Y_x\)</span></span> if and only if <span><span class="math inline">\(y = x \oplus k\)</span></span> which holds if and only if <span><span class="math inline">\(k= x \oplus y\)</span></span>. Since <span><span class="math inline">\(k\)</span></span> is chosen uniformly at random in <span><span class="math inline">\(\{0,1\}^n\)</span></span>, the probability that <span><span class="math inline">\(k\)</span></span> happens to equal <span><span class="math inline">\(x \oplus y\)</span></span> is exactly <span><span class="math inline">\(2^{-n}\)</span></span>, which means that every string <span><span class="math inline">\(y\)</span></span> is output by <span><span class="math inline">\(Y_x\)</span></span> with probability <span><span class="math inline">\(2^{-n}\)</span></span>.</p>
</div>
<figure>
<img src="../figure/onetimepad.png" alt="20.9: In the one time pad encryption scheme we encrypt a plaintext x\in \{0,1\}^n with a key k\in \{0,1\}^n by the ciphertext x \oplus k where \oplus denotes the bitwise XOR operation." id="onetimepadfig" class="margin" /><figcaption>20.9: In the <em>one time pad</em> encryption scheme we encrypt a plaintext <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> with a key <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> by the ciphertext <span><span class="math inline">\(x \oplus k\)</span></span> where <span><span class="math inline">\(\oplus\)</span></span> denotes the bitwise XOR operation.</figcaption>
</figure>
<div id="section-4" class="pause" name="Pause">
<p>The argument above is quite simple but is worth reading again. To understand why the one-time pad is perfectly secret, it is useful to envision it as a bipartite graph as we’ve done in <a href='#onetimepadtwofig'>Figure 20.8</a>. (In fact the encryption scheme of <a href='#onetimepadtwofig'>Figure 20.8</a> is precisely the one-time pad for <span><span class="math inline">\(n=2\)</span></span>.) For every <span><span class="math inline">\(n\)</span></span>, the one-time pad encryption scheme corresponds to a bipartite graph with <span><span class="math inline">\(2^n\)</span></span> vertices on the “left side” corresponding to the plaintexts in <span><span class="math inline">\(\{0,1\}^n\)</span></span> and <span><span class="math inline">\(2^n\)</span></span> vertices on the “right side” corresponding to the ciphertexts <span><span class="math inline">\(\{0,1\}^n\)</span></span>. For every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span>, we connect <span><span class="math inline">\(x\)</span></span> to the vertex <span><span class="math inline">\(y=E_k(x)\)</span></span> with an edge that we label with <span><span class="math inline">\(k\)</span></span>. One can see that this is the complete bipartite graph, where every vertex on the left is connected to <em>all</em> vertices on the right. In particular this means that for every left vertex <span><span class="math inline">\(x\)</span></span>, the distribution on the ciphertexts obtained by taking a random <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and going to the neighbor of <span><span class="math inline">\(x\)</span></span> on the edge labeled <span><span class="math inline">\(k\)</span></span> is the uniform distribution over <span><span class="math inline">\(\{0,1\}^n\)</span></span>. This ensures the perfect secrecy condition.</p>
</div>
<h2 id="necessity-of-long-keys" data-number="20.5">Necessity of long keys</h2>
<p>So, does <a href='#onetimepad'>Theorem 20.4</a> give the final word on cryptography, and means that we can all communicate with perfect secrecy and live happily ever after? No it doesn’t. While the one-time pad is efficient, and gives perfect secrecy, it has one glaring disadvantage: to communicate <span><span class="math inline">\(n\)</span></span> bits you need to store a key of length <span><span class="math inline">\(n\)</span></span>. In contrast, practically used cryptosystems such as AES-128 have a short key of <span><span class="math inline">\(128\)</span></span> bits (i.e., <span><span class="math inline">\(16\)</span></span> bytes) that can be used to protect terabytes or more of communication! Imagine that we all needed to use the one time pad. If that was the case, then if you had to communicate with <span><span class="math inline">\(m\)</span></span> people, you would have to maintain (securely!) <span><span class="math inline">\(m\)</span></span> huge files that are each as long as the length of the maximum total communication you expect with that person. Imagine that every time you opened an account with Amazon, Google, or any other service, they would need to send you in the mail (ideally with a secure courier) a DVD full of random numbers, and every time you suspected a virus, you’d need to ask all these services for a fresh DVD. This doesn’t sound so appealing.</p>
<p>This is not just a theoretical issue. The Soviets have used the one-time pad for their confidential communication since before the 1940’s. In fact, even before Shannon’s work, the U.S. intelligence already knew in 1941 that the one-time pad is in principle “unbreakable” (see page 32 in the <a href="http://nsarchive.gwu.edu/NSAEBB/NSAEBB278/01.PDF">Venona document</a>). However, it turned out that the hassle of manufacturing so many keys for all the communication took its toll on the Soviets and they ended up reusing the same keys for more than one message. They did try to use them for completely different receivers in the (false) hope that this wouldn’t be detected. The <a href="https://en.wikipedia.org/wiki/Venona_project">Venona Project</a> of the U.S. Army was founded in February 1943 by Gene Grabeel (see <a href='#genegrabeelfig'>Figure 20.10</a>), a former home economics teacher from Madison Heights, Virgnia and Lt. Leonard Zubko. In October 1943, they had their breakthrough when it was discovered that the Russians were reusing their keys. In the 37 years of its existence, the project has resulted in a treasure chest of intelligence, exposing hundreds of KGB agents and Russian spies in the U.S. and other countries, including Julius Rosenberg, Harry Gold, Klaus Fuchs, Alger Hiss, Harry Dexter White and many others.</p>
<figure>
<img src="../figure/genevenona.png" alt="20.10: Gene Grabeel, who founded the U.S. Russian SigInt program on 1 Feb 1943. Photo taken in 1942, see Page 7 in the Venona historical study." id="genegrabeelfig" class="margin" /><figcaption>20.10: Gene Grabeel, who founded the U.S. Russian SigInt program on 1 Feb 1943. Photo taken in 1942, see Page 7 in the Venona historical study.</figcaption>
</figure>
<figure>
<img src="../figure/longkeygraph.png" alt="20.11: An encryption scheme where the number of keys is smaller than the number of plaintexts corresponds to a bipartite graph where the degree is smaller than the number of vertices on the left side. Together with the validity condition this implies that there will be two left vertices x,x&#39; with non-identical neighborhoods, and hence the scheme does not satisfy perfect secrecy." id="longkeygraphfig" class="margin" /><figcaption>20.11: An encryption scheme where the number of keys is smaller than the number of plaintexts corresponds to a bipartite graph where the degree is smaller than the number of vertices on the left side. Together with the validity condition this implies that there will be two left vertices <span><span class="math inline">\(x,x&#39;\)</span></span> with non-identical neighborhoods, and hence the scheme does <em>not</em> satisfy perfect secrecy.</figcaption>
</figure>
<p>Unfortunately it turns out that that such long keys are <em>necessary</em> for perfect secrecy:</p>
<div id="longkeysthm" class="theorem" title="Perfect secrecy requires long keys" name="Theorem 20.5 (Perfect secrecy requires long keys) ">
<p>For every perfectly secret encryption scheme <span><span class="math inline">\((E,D)\)</span></span> the length function <span><span class="math inline">\(L\)</span></span> satisfies <span><span class="math inline">\(L(n) \leq n\)</span></span>.</p>
</div>
<div id="section-5" class="proofidea" data-ref="longkeysthm" name="Proofidea">
<p>The idea behind the proof is illustrated in <a href='#longkeygraphfig'>Figure 20.11</a>. We define a graph between the plaintexts and ciphertexts, where we put an edge between plaintext <span><span class="math inline">\(x\)</span></span> and ciphertext <span><span class="math inline">\(y\)</span></span> if there is some key <span><span class="math inline">\(k\)</span></span> such that <span><span class="math inline">\(y=E_k(x)\)</span></span>. The <em>degree</em> of this graph is at most the number of potential keys. The fact that the degree is smaller than the number of plaintexts (and hence of ciphertexts) implies that there would be two plaintexts <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(x&#39;\)</span></span> with different sets of neighbors, and hence the distribution of a ciphertext corresponding to <span><span class="math inline">\(x\)</span></span> (with a random key) will not be identical to the distribution of a ciphertext corresponding to <span><span class="math inline">\(x&#39;\)</span></span>.</p>
</div>
<div class="proof" data-ref="longkeysthm" name="Proof 20.5">
<p>Let <span><span class="math inline">\(E,D\)</span></span> be a valid encryption scheme with messages of length <span><span class="math inline">\(L\)</span></span> and key of length <span><span class="math inline">\(n&lt;L\)</span></span>. We will show that <span><span class="math inline">\((E,D)\)</span></span> is not perfectly secret by providing two plaintexts <span><span class="math inline">\(x_0,x_1 \in \{0,1\}^L\)</span></span> such that the distributions <span><span class="math inline">\(Y_{x_0}\)</span></span> and <span><span class="math inline">\(Y_{x_1}\)</span></span> are not identical, where <span><span class="math inline">\(Y_x\)</span></span> is the distribution obtained by picking <span><span class="math inline">\(k \sim \{0,1\}^n\)</span></span> and outputting <span><span class="math inline">\(E_k(x)\)</span></span>.</p>
<p>We choose <span><span class="math inline">\(x_0 = 0^L\)</span></span>. Let <span><span class="math inline">\(S_0 \subseteq \{0,1\}^*\)</span></span> be the set of all ciphertexts that have nonzero probability of being output in <span><span class="math inline">\(Y_{x_0}\)</span></span>. That is, <span><span class="math inline">\(S_0=\{ y \;|\; \exists_{k\in \{0,1\}^n} y=E_k(x_0) \}\)</span></span>. Since there are only <span><span class="math inline">\(2^n\)</span></span> keys, we know that <span><span class="math inline">\(|S_0| \leq 2^n\)</span></span>.</p>
<p>We will show the following claim:</p>
<p><strong>Claim I:</strong> There exists some <span><span class="math inline">\(x_1 \in \{0,1\}^L\)</span></span> and <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(E_k(x_1) \not\in S_0\)</span></span>.</p>
<p>Claim I implies that the string <span><span class="math inline">\(E_k(x_1)\)</span></span> has positive probability of being output by <span><span class="math inline">\(Y_{x_1}\)</span></span> and zero probability of being output by <span><span class="math inline">\(Y_{x_0}\)</span></span> and hence in particular <span><span class="math inline">\(Y_{x_0}\)</span></span> and <span><span class="math inline">\(Y_{x_1}\)</span></span> are not identical. To prove Claim I, just choose a fixed <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span>. By the validity condition, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> is a one to one map of <span><span class="math inline">\(\{0,1\}^L\)</span></span> to <span><span class="math inline">\(\{0,1\}^*\)</span></span> and hence in particular the <em>image</em> of this map which is the set <span><span class="math inline">\(I_k = \{ y \;|\; \exists_{x\in \{0,1\}^L} y=E_k(x) \}\)</span></span> has size at least (in fact exactly) <span><span class="math inline">\(2^L\)</span></span>. Since <span><span class="math inline">\(|S_0| \leq 2^n &lt; 2^L\)</span></span>, this means that <span><span class="math inline">\(|I_k|&gt;|S_0|\)</span></span> and so in particular there exists some string <span><span class="math inline">\(y\)</span></span> in <span><span class="math inline">\(I_k \setminus S_0\)</span></span>. But by the definition of <span><span class="math inline">\(I_k\)</span></span> this means that there is some <span><span class="math inline">\(x\in \{0,1\}^L\)</span></span> such that <span><span class="math inline">\(E_k(x) \not\in S_0\)</span></span> which concludes the proof of Claim I and hence of <a href='#longkeysthm'>Theorem 20.5</a>.</p>
</div>
<h2 id="computational-secrecy" data-number="20.6">Computational secrecy</h2>
<p>To sum up the previous episodes, we now know that:</p>
<ul>
<li>It is possible to obtain a perfectly secret encryption scheme with key length the same as the plaintext.</li>
</ul>
<p>and</p>
<ul>
<li>It is not possible to obtain such a scheme with key that is even a single bit shorter than the plaintext.</li>
</ul>
<p>How does this mesh with the fact that, as we’ve already seen, people routinely use cryptosystems with a 16 byte (i.e., 128 bit) key but many terabytes of plaintext? The proof of <a href='#longkeysthm'>Theorem 20.5</a> does give in fact a way to break all these cryptosystems, but an examination of this proof shows that it only yields an algorithm with time <em>exponential in the length of the key</em>. This motivates the following relaxation of perfect secrecy to a condition known as <em>“computational secrecy”</em>. Intuitively, an encryption scheme is computationally secret if no polynomial time algorithm can break it. The formal definition is below:</p>
<div id="compsecdef" class="definition" title="Computational secrecy" name="Definition 20.6 (Computational secrecy) ">
<p>Let <span><span class="math inline">\((E,D)\)</span></span> be a valid encryption scheme where for keys of length <span><span class="math inline">\(n\)</span></span>, the plaintexts are of length <span><span class="math inline">\(L(n)\)</span></span> and the ciphertexts are of length <span><span class="math inline">\(m(n)\)</span></span>. We say that <span><span class="math inline">\((E,D)\)</span></span> is <em>computationally secret</em> if for every polynomial <span><span class="math inline">\(p:\N \rightarrow \N\)</span></span>, and large enough <span><span class="math inline">\(n\)</span></span>, if <span><span class="math inline">\(P\)</span></span> is an <span><span class="math inline">\(m(n)\)</span></span>-input and single output NAND-CIRC program of at most <span><span class="math inline">\(p(n)\)</span></span> lines, and <span><span class="math inline">\(x_0,x_1 \in \{0,1\}^{L(n)}\)</span></span> then</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\left| \E_{k \sim \{0,1\}^n} [P(E_k(x_0))] -   \E_{k \sim \{0,1\}^n} [P(E_k(x_1))] \right| &lt; \tfrac{1}{p(n)} \;\;(20.4)
\]</span><a id='eqindist'></a></div></span></p>
</div>
<div id="section-6" class="pause" name="Pause">
<p><a href='#compsecdef'>Definition 20.6</a> requires a second or third read and some practice to truly understand. One excellent exercise to make sure you follow it is to see that if we allow <span><span class="math inline">\(P\)</span></span> to be an <em>arbitrary</em> function mapping <span><span class="math inline">\(\{0,1\}^{m(n)}\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span>, and we replace the condition in <a href='#eqindist'>Equation 20.4</a> that the lefthand side is smaller than <span><span class="math inline">\(\tfrac{1}{p(L(n))}\)</span></span> with the condition that it is equal to <span><span class="math inline">\(0\)</span></span> then we get the perfect secrecy condition of <a href='#perfectsecrecy'>Definition 20.3</a>. Indeed if the distributions <span><span class="math inline">\(E_k(x_0)\)</span></span> and <span><span class="math inline">\(E_k(x_1)\)</span></span> are identical then applying any function <span><span class="math inline">\(P\)</span></span> to them we get the same expectation. On the other hand, if the two distributions above give a different probability for some element <span><span class="math inline">\(y^*\in \{0,1\}^{m(n)}\)</span></span>, then the function <span><span class="math inline">\(P(y)\)</span></span> that outputs <span><span class="math inline">\(1\)</span></span> iff <span><span class="math inline">\(y=y^*\)</span></span> will have a different expectation under the former distribution than under the latter.</p>
</div>
<p><a href='#compsecdef'>Definition 20.6</a> raises two natural questions:</p>
<ul>
<li><p>Is it strong enough to ensure that a computationally secret encryption scheme protects the secrecy of messages that are encrypted with it?</p></li>
<li><p>It is weak enough that, unlike perfect secrecy, it is possible to obtain a computationally secret encryption scheme where the key is much smaller than the message?</p></li>
</ul>
<p>To the best of our knowledge, the answer to both questions is <em>Yes</em>.</p>
<div id="computationcrypto" class="bigidea" name="Bigidea 26">
<p><em>Computational hardness</em> is necessary and sufficient for a great many cryptographic constructions, and in particular for encryption schemes with keys shorter than the message.</p>
</div>
<p>Regarding the first question, it is not hard to show that if, for example, Alice uses a computationally secret encryption algorithm to encrypt either “attack” or “retreat” (each chosen with probability <span><span class="math inline">\(1/2\)</span></span>), then as long as she’s restricted to polynomial-time algorithms, an adversary Eve will not be able to guess the message with probability better than, say, <span><span class="math inline">\(0.51\)</span></span>, even after observing its encrypted form. (We omit the proof, but it is an excellent exercise for you to work it out on your own.)</p>
<p>To answer the second question we will show that under the same assumption we used for derandomizing <span><span class="math inline">\(\mathbf{BPP}\)</span></span>, we can obtain a computationally secret cryptosystem where the key is almost <em>exponentially</em> smaller than the plaintext.</p>
<h3 id="stream-ciphers-or-the-derandomized-one-time-pad" data-number="20.6.1">Stream ciphers or the “derandomized one-time pad”</h3>
<p>It turns out that if pseudorandom generators exist as in the optimal PRG conjecture, then there exists a computationally secret encryption scheme with keys that are much shorter than the plaintext. The construction below is known as a <a href="https://en.wikipedia.org/wiki/Stream_cipher">stream cipher</a>, though perhaps a better name is the “derandomized one-time pad”. It is widely used in practice with keys on the order of a few tens or hundreds of bits protecting many terabytes or even petabytes of communication.</p>
<figure>
<img src="../figure/derandonetimepad.png" alt="20.12: In a stream cipher or “derandomized one-time pad” we use a pseudorandom generator G:\{0,1\}^n \rightarrow \{0,1\}^L to obtain an encryption scheme with a key length of n and plaintexts of length L. We encrypt the plaintext x\in \{0,1\}^L with key k\in \{0,1\}^n by the ciphertext x \oplus G(k)." id="derandonetimepadfig" class="margin" /><figcaption>20.12: In a <em>stream cipher</em> or “derandomized one-time pad” we use a pseudorandom generator <span><span class="math inline">\(G:\{0,1\}^n \rightarrow \{0,1\}^L\)</span></span> to obtain an encryption scheme with a key length of <span><span class="math inline">\(n\)</span></span> and plaintexts of length <span><span class="math inline">\(L\)</span></span>. We encrypt the plaintext <span><span class="math inline">\(x\in \{0,1\}^L\)</span></span> with key <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> by the ciphertext <span><span class="math inline">\(x \oplus G(k)\)</span></span>.</figcaption>
</figure>
<p>We start by recalling the notion of a <em>pseudorandom generator</em>, as defined in <a href='lec_17_model_rand.html#prgdef'>Definition 19.9</a>. For this chapter, we will fix a special case of the definition:</p>
<div id="cryptoprg" class="definition" title="Cryptographic pseudorandom generator" name="Definition 20.7 (Cryptographic pseudorandom generator) ">
<p>Let <span><span class="math inline">\(L:\N \rightarrow \N\)</span></span> be some function. A <em>cryptographic pseudorandom generator</em> with stretch <span><span class="math inline">\(L(\cdot)\)</span></span> is a polynomial-time computable function <span><span class="math inline">\(G:\{0,1\}^* \rightarrow \{0,1\}^*\)</span></span> such that:</p>
<ul>
<li><p>For every <span><span class="math inline">\(n\in \N\)</span></span> and <span><span class="math inline">\(s\in \{0,1\}^n\)</span></span>, <span><span class="math inline">\(|G(s)|=L(n)\)</span></span>.</p></li>
<li><p>For every polynomial <span><span class="math inline">\(p:\N \rightarrow \N\)</span></span> and <span><span class="math inline">\(n\)</span></span> large enough, if <span><span class="math inline">\(C\)</span></span> is a circuit of <span><span class="math inline">\(L(n)\)</span></span> inputs, one output, and at most <span><span class="math inline">\(p(n)\)</span></span> gates then <span>
<div class='myequationbox'><span class="math display">\[
\left| \Pr_{s\sim \{0,1\}^\ell}[C(G(s))=1] - \Pr_{r \sim \{0,1\}^m}[C(r)=1] \right| &lt; \frac{1}{p(n)} \;.
\]</span></div></span></p></li>
</ul>
</div>
<p>In this chapter we will call a cryptographic pseudorandom generator simply a <em>pseudorandom generator</em> or PRG for short. The optimal PRF conjecture of <a href='lec_17_model_rand.html#optimalprgconj'>Subsection 19.4.2</a> implies that there is a pseudorandom generator that can “fool” circuits of <em>exponential size</em> and where the gap in probabilities is at most one over an exponential quantity. Since exponential grow faster than every polynomial, the optimal PRG conjecture implies the following:</p>
<blockquote>
<p><strong>The crypto PRG conjecture:</strong> For every <span><span class="math inline">\(a \in \N\)</span></span>, there is a cryptographic pseudorandom generator with <span><span class="math inline">\(L(n)=n^a\)</span></span>.</p>
</blockquote>
<p>The crypto PRG conjecture is a weaker conjecture than the optimal PRG conjecture, but it too (as we will see) is still stronger than the conjecture that <span><span class="math inline">\(\mathbf{P} \neq \mathbf{NP}\)</span></span>.</p>
<div id="PRGtoENC" class="theorem" title="Derandomized one-time pad" name="Theorem 20.8 (Derandomized one-time pad) ">
<p>Suppose that the crypto PRG conjecture is true. Then for every constant <span><span class="math inline">\(a\in \N\)</span></span> there is a computationally secret encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with plaintext length <span><span class="math inline">\(L(n)\)</span></span> at least <span><span class="math inline">\(n^a\)</span></span>.</p>
</div>
<div id="section-7" class="proofidea" data-ref="PRGtoENC" name="Proofidea">
<p>The proof is illustrated in <a href='#derandonetimepadfig'>Figure 20.12</a>. We simply take the one-time pad on <span><span class="math inline">\(L\)</span></span> bit plaintexts, but replace the key with <span><span class="math inline">\(G(k)\)</span></span> where <span><span class="math inline">\(k\)</span></span> is a string in <span><span class="math inline">\(\{0,1\}^n\)</span></span> and <span><span class="math inline">\(G:\{0,1\}^n \rightarrow \{0,1\}^L\)</span></span> is a pseudorandom generator. Since the one time pad cannot be broken, an adversary that breaks the derandomized one-time pad can be used to distinguish between the output of the pseudorandom generator and the uniform distribution.</p>
</div>
<div class="proof" data-ref="PRGtoENC" name="Proof 20.6.1">
<p>Let <span><span class="math inline">\(G:\{0,1\}^n \rightarrow \{0,1\}^L\)</span></span> for <span><span class="math inline">\(L = n^a\)</span></span> be the restriction to input length <span><span class="math inline">\(n\)</span></span> of the pseudorandom generator <span><span class="math inline">\(G\)</span></span> whose existence we are guaranteed from the crypto PRG conjecture. We now define our encryption scheme as follows: given key <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and plaintext <span><span class="math inline">\(x\in \{0,1\}^L\)</span></span>, the encryption <span><span class="math inline">\(E_k(x)\)</span></span> is simply <span><span class="math inline">\(x \oplus G(k)\)</span></span>. To decrypt a string <span><span class="math inline">\(y \in \{0,1\}^m\)</span></span> we output <span><span class="math inline">\(y \oplus G(k)\)</span></span>. This is a valid encryption since <span><span class="math inline">\(G\)</span></span> is computable in polynomial time and <span><span class="math inline">\((x \oplus G(k)) \oplus G(k) = x \oplus (G(k) \oplus G(k))=x\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^L\)</span></span>.</p>
<p>Computational secrecy follows from the condition of a pseudorandom generator. Suppose, towards a contradiction, that there is a polynomial <span><span class="math inline">\(p\)</span></span>, NAND-CIRC program <span><span class="math inline">\(Q\)</span></span> of at most <span><span class="math inline">\(p(L)\)</span></span> lines and <span><span class="math inline">\(x,x&#39; \in \{0,1\}^{L(n)}\)</span></span> such that <span>
<div class='myequationbox'><span class="math display">\[
\left| \E_{k \sim \{0,1\}^n}[ Q(E_k(x))] - \E_{k \sim \{0,1\}^n}[Q(E_k(x&#39;))] \right| &gt; \tfrac{1}{p(L)} \;.
\]</span></div></span> (We use here the simple fact that for a <span><span class="math inline">\(\{0,1\}\)</span></span>-valued random variable <span><span class="math inline">\(X\)</span></span>, <span><span class="math inline">\(\Pr[X=1]=\E[X]\)</span></span>.)</p>
<p>By the definition of our encryption scheme, this means that <span>
<div class='myequationbox'><span class="math display">\[
\left| \E_{k \sim \{0,1\}^n}[ Q(G(k) \oplus x)] - \E_{k \sim \{0,1\}^n}[Q(G(k) \oplus x&#39;)] \right| &gt; \tfrac{1}{p(L)} \;. \;\;(20.7)
\]</span><a id='eqprgsecone'></a></div></span></p>
<p>Now since (as we saw in the security analysis of the one-time pad), for every strings <span><span class="math inline">\(x,x&#39;\in \{0,1\}^L\)</span></span>, the distribution <span><span class="math inline">\(r \oplus x\)</span></span> and <span><span class="math inline">\(r \oplus x&#39;\)</span></span> are identical, where <span><span class="math inline">\(r\sim \{0,1\}^L\)</span></span>. Hence <span>
<div class='myequationbox'><span class="math display">\[
\E_{r \sim \{0,1\}^L} [ Q(r \oplus x)] =  \E_{r \sim \{0,1\}^L} [ Q(r \oplus x&#39;)]  \;.  \;\;(20.8)
\]</span><a id='eqprgsectwo'></a></div></span> By plugging <a href='#eqprgsectwo'>Equation 20.8</a> into <a href='#eqprgsecone'>Equation 20.7</a> we can derive that <span>
<div class='myequationbox'><span class="math display">\[
\left| \E_{k \sim \{0,1\}^n}[ Q(G(k) \oplus x)] - \E_{r \sim \{0,1\}^L} [ Q(r \oplus x)] +  \E_{r \sim \{0,1\}^L} [ Q(r \oplus x&#39;)]  -  \E_{k \sim \{0,1\}^n}[Q(G(k) \oplus x&#39;)] \right| &gt; \tfrac{1}{p(L)} \;. \;\;(20.9)
\]</span><a id='eqprgsethree'></a></div></span> (Please make sure that you can see why this is true.)</p>
<p>Now we can use the <em>triangle inequality</em> that <span><span class="math inline">\(|A+B| \leq |A|+|B|\)</span></span> for every two numbers <span><span class="math inline">\(A,B\)</span></span>, applying it for <span><span class="math inline">\(A= \E_{k \sim \{0,1\}^n}[ Q(G(k) \oplus x)] - \E_{r \sim \{0,1\}^L} [ Q(r \oplus x)]\)</span></span> and <span><span class="math inline">\(B= \E_{r \sim \{0,1\}^L} [ Q(r \oplus x&#39;)] - \E_{k \sim \{0,1\}^n}[Q(G(k) \oplus x&#39;)]\)</span></span> to derive <span>
<div class='myequationbox'><span class="math display">\[
\left| \E_{k \sim \{0,1\}^n}[ Q(G(k) \oplus x)] - \E_{r \sim \{0,1\}^L} [ Q(r \oplus x)] \right| + \left|  \E_{r \sim \{0,1\}^L} [ Q(r \oplus x&#39;)]  -  \E_{k \sim \{0,1\}^n}[Q(G(k) \oplus x&#39;)] \right| &gt; \tfrac{1}{p(L)} \;. \;\;(20.10)
\]</span><a id='eqprgsefour'></a></div></span></p>
<p>In particular, either the first term or the second term of the lefthand-side of <a href='#eqprgsefour'>Equation 20.10</a> must be at least <span><span class="math inline">\(\tfrac{1}{2p(L)}\)</span></span>. Let us assume the first case holds (the second case is analyzed in exactly the same way). Then we get that <span>
<div class='myequationbox'><span class="math display">\[
\left| \E_{k \sim \{0,1\}^n}[ Q(G(k) \oplus x)] - \E_{r \sim \{0,1\}^L} [ Q(r \oplus x)] \right| &gt; \tfrac{1}{2p(L)} \;. \;\;(20.11)
\]</span><a id='distingprgeq'></a></div></span></p>
<p>But if we now define the NAND-CIRC program <span><span class="math inline">\(P_x\)</span></span> that on input <span><span class="math inline">\(r\in \{0,1\}^L\)</span></span> outputs <span><span class="math inline">\(Q(r \oplus x)\)</span></span> then (since XOR of <span><span class="math inline">\(L\)</span></span> bits can be computed in <span><span class="math inline">\(O(L)\)</span></span> lines), we get that <span><span class="math inline">\(P_x\)</span></span> has <span><span class="math inline">\(p(L)+O(L)\)</span></span> lines and by <a href='#distingprgeq'>Equation 20.11</a> it can distinguish between an input of the form <span><span class="math inline">\(G(k)\)</span></span> and an input of the form <span><span class="math inline">\(r \sim \{0,1\}^k\)</span></span> with advantage better than <span><span class="math inline">\(\tfrac{1}{2p(L)}\)</span></span>. Since a polynomial is dominated by an exponential, if we make <span><span class="math inline">\(L\)</span></span> large enough, this will contradict the <span><span class="math inline">\((2^{\delta n},2^{-\delta n})\)</span></span> security of the pseudorandom generator <span><span class="math inline">\(G\)</span></span>.</p>
</div>
<div id="streamciphersrem" class="remark" title="Stream ciphers in practice" name="Remark 20.9 (Stream ciphers in practice) ">
<p>The two most widely used forms of (private key) encryption schemes in practice are <em>stream ciphers</em> and <em>block ciphers</em>. (To make things more confusing, a block cipher is always used in some <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">mode of operation</a> and some of these modes effectively turn a block cipher into a stream cipher.) A block cipher can be thought as a sort of a “random invertible map” from <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}^n\)</span></span>, and can be used to construct a pseudorandom generator and from it a stream cipher, or to encrypt data directly using other modes of operations. There are a great many other security notions and considerations for encryption schemes beyond computational secrecy. Many of those involve handling scenarios such as <em>chosen plaintext</em>, <em>man in the middle</em>, and <em>chosen ciphertext</em> attacks, where the adversary is not just merely a passive eavesdropper but can influence the communication in some way. While this chapter is meant to give you some taste of the ideas behind cryptography, there is much more to know before applying it correctly to obtain secure applications, and a great many people have managed to get it wrong.</p>
</div>
<h2 id="computational-secrecy-and-mathbfnp" data-number="20.7">Computational secrecy and <span><span class="math inline">\(\mathbf{NP}\)</span></span></h2>
<p>We’ve also mentioned before that an efficient algorithm for <span><span class="math inline">\(\mathbf{NP}\)</span></span> could be used to break all cryptography. We now give an example of how this can be done:</p>
<div id="breakingcryptowithnp" class="theorem" title="Breaking encryption using $\mathbf{NP}$ algorithm" name="Theorem 20.10 (Breaking encryption using $\mathbf{NP}$ algorithm) ">
<p>If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then there is no computationally secret encryption scheme with <span><span class="math inline">\(L(n) &gt; n\)</span></span>.</p>
<p>Furthermore, for every valid encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with <span><span class="math inline">\(L(n) &gt; n+100\)</span></span> there is a polynomial <span><span class="math inline">\(p\)</span></span> such that for every large enough <span><span class="math inline">\(n\)</span></span> there exist <span><span class="math inline">\(x_0,x_1 \in \{0,1\}^{L(n)}\)</span></span> and a <span><span class="math inline">\(p(n)\)</span></span>-line NAND-CIRC program <span><span class="math inline">\(\ensuremath{\mathit{EVE}}\)</span></span> s.t. <span>
<div class='myequationbox'><span class="math display">\[
\Pr_{i \sim \{0,1\}, k \sim \{0,1\}^n}[ \ensuremath{\mathit{EVE}}(E_k(x_i))=i ] \geq 0.99 \;.
\]</span></div></span></p>
</div>
<p>Note that the “furthermore” part is extremely strong. It means that if the plaintext is even a little bit larger than the key, then we can already break the scheme in a very strong way. That is, there will be a pair of messages <span><span class="math inline">\(x_0\)</span></span>, <span><span class="math inline">\(x_1\)</span></span> (think of <span><span class="math inline">\(x_0\)</span></span> as “sell” and <span><span class="math inline">\(x_1\)</span></span> as “buy”) and an efficient strategy for Eve such that if Eve gets a ciphertext <span><span class="math inline">\(y\)</span></span> then she will be able to tell whether <span><span class="math inline">\(y\)</span></span> is an encryption of <span><span class="math inline">\(x_0\)</span></span> or <span><span class="math inline">\(x_1\)</span></span> with probability very close to <span><span class="math inline">\(1\)</span></span>. (We model breaking the scheme as Eve outputting <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span> corresponding to whether the message sent was <span><span class="math inline">\(x_0\)</span></span> or <span><span class="math inline">\(x_1\)</span></span>. Note that we could have just as well modified Eve to output <span><span class="math inline">\(x_0\)</span></span> instead of <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(x_1\)</span></span> instead of <span><span class="math inline">\(1\)</span></span>. The key point is that a priori Eve only had a 50/50 chance of guessing whether Alice sent <span><span class="math inline">\(x_0\)</span></span> or <span><span class="math inline">\(x_1\)</span></span> but after seeing the ciphertext this chance increases to better than 99/1.) The condition <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> can be relaxed to <span><span class="math inline">\(\mathbf{NP}\subseteq \mathbf{BPP}\)</span></span> and even the weaker condition <span><span class="math inline">\(\mathbf{NP} \subseteq \mathbf{P_{/poly}}\)</span></span> with essentially the same proof.</p>
<div class="proofidea" data-ref="breakingcryptowithnp" name="Proofidea 20.7">
<p>The proof follows along the lines of <a href='#longkeysthm'>Theorem 20.5</a> but this time paying attention to the computational aspects. If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then for every plaintext <span><span class="math inline">\(x\)</span></span> and ciphertext <span><span class="math inline">\(y\)</span></span>, we can efficiently tell whether there exists <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(E_k(x)=y\)</span></span>. So, to prove this result we need to show that if the plaintexts are long enough, there would exist a pair <span><span class="math inline">\(x_0,x_1\)</span></span> such that the probability that a random encryption of <span><span class="math inline">\(x_1\)</span></span> also is a valid encryption of <span><span class="math inline">\(x_0\)</span></span> will be very small. The details of how to show this are below.</p>
</div>
<div class="proof" data-ref="breakingcryptowithnp" name="Proof 20.7">
<p>We focus on showing only the “furthermore” part since it is the more interesting and the other part follows by essentially the same proof.</p>
<p>Suppose that <span><span class="math inline">\((E,D)\)</span></span> is such an encryption, let <span><span class="math inline">\(n\)</span></span> be large enough, and let <span><span class="math inline">\(x_0 = 0^{L(n)}\)</span></span>. For every <span><span class="math inline">\(x\in \{0,1\}^{L(n)}\)</span></span> we define <span><span class="math inline">\(S_x\)</span></span> to be the set of all valid encryption of <span><span class="math inline">\(x\)</span></span>. That is <span><span class="math inline">\(S_x = \{ y \;|\; \exists_{k\in \{0,1\}^n} y=E_k(x) \}\)</span></span>. As in the proof of <a href='#longkeysthm'>Theorem 20.5</a>, since there are <span><span class="math inline">\(2^n\)</span></span> keys <span><span class="math inline">\(k\)</span></span>, <span><span class="math inline">\(|S_x| \leq 2^n\)</span></span> for every <span><span class="math inline">\(x\in \{0,1\}^{L(n)}\)</span></span>.</p>
<p>We denote by <span><span class="math inline">\(S_0\)</span></span> the set <span><span class="math inline">\(S_{x_0}\)</span></span>. We define our algorithm <span><span class="math inline">\(\ensuremath{\mathit{EVE}}\)</span></span> to output <span><span class="math inline">\(0\)</span></span> on input <span><span class="math inline">\(y\in \{0,1\}^*\)</span></span> if <span><span class="math inline">\(y\in S_0\)</span></span> and to output <span><span class="math inline">\(1\)</span></span> otherwise. This can be implemented in polynomial time if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, since the key <span><span class="math inline">\(k\)</span></span> can serve the role of an efficiently verifiable solution. (Can you see why?) Clearly <span><span class="math inline">\(\Pr[ \ensuremath{\mathit{EVE}}(E_k(x_0))=0 ] =1\)</span></span> and so in the case that <span><span class="math inline">\(\ensuremath{\mathit{EVE}}\)</span></span> gets an encryption of <span><span class="math inline">\(x_0\)</span></span> then she guesses correctly with probability <span><span class="math inline">\(1\)</span></span>. The remainder of the proof is devoted to showing that there exists <span><span class="math inline">\(x_1 \in \{0,1\}^{L(n)}\)</span></span> such that <span><span class="math inline">\(\Pr[ \ensuremath{\mathit{EVE}}(E_k(x_1))=0 ] \leq 0.01\)</span></span>, which will conclude the proof by showing that <span><span class="math inline">\(\ensuremath{\mathit{EVE}}\)</span></span> guesses wrongly with probability at most <span><span class="math inline">\(\tfrac{1}{2}0 + \tfrac{1}{2}0.01 &lt; 0.01\)</span></span>.</p>
<p>Consider now the following probabilistic experiment (which we define solely for the sake of analysis). We consider the sample space of choosing <span><span class="math inline">\(x\)</span></span> uniformly in <span><span class="math inline">\(\{0,1\}^{L(n)}\)</span></span> and define the random variable <span><span class="math inline">\(Z_k(x)\)</span></span> to equal <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(E_k(x)\in S_0\)</span></span>. For every <span><span class="math inline">\(k\)</span></span>, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> is one-to-one, which means that the probability that <span><span class="math inline">\(Z_k=1\)</span></span> is equal to the probability that <span><span class="math inline">\(x \in E_k^{-1}(S_0)\)</span></span> which is <span><span class="math inline">\(\tfrac{|S_0|}{2^{L(n)}}\)</span></span>. So by the linearity of expectation <span><span class="math inline">\(\E[\sum_{k \in \{0,1\}^n} Z_k] \leq \tfrac{2^n|S_0|}{2^{L(n)}} \leq \tfrac{2^{2n}}{2^{L(n)}}\)</span></span>.</p>
<p>We will now use the following extremely simple but useful fact known as the <em>averaging principle</em> (see also <a href='lec_15_probability.html#averagingprinciplerem'>Lemma 17.10</a>): for every random variable <span><span class="math inline">\(Z\)</span></span>, if <span><span class="math inline">\(\E[Z]=\mu\)</span></span>, then with positive probability <span><span class="math inline">\(Z \leq \mu\)</span></span>. (Indeed, if <span><span class="math inline">\(Z&gt;\mu\)</span></span> with probability one, then the expected value of <span><span class="math inline">\(Z\)</span></span> will have to be larger than <span><span class="math inline">\(\mu\)</span></span>, just like you can’t have a class in which all students got A or A- and yet the overall average is B+.) In our case it means that with positive probability <span><span class="math inline">\(\sum_{k\in \{0,1\}^n} Z_k \leq \tfrac{2^{2n}}{2^{L(n)}}\)</span></span>. In other words, there exists some <span><span class="math inline">\(x_1 \in \{0,1\}^{L(n)}\)</span></span> such that <span><span class="math inline">\(\sum_{k\in \{0,1\}^n} Z_k(x_1) \leq \tfrac{2^{2n}}{2^{L(n)}}\)</span></span>. Yet this means that if we choose a random <span><span class="math inline">\(k \sim \{0,1\}^n\)</span></span>, then the probability that <span><span class="math inline">\(E_k(x_1) \in S_0\)</span></span> is at most <span><span class="math inline">\(\tfrac{1}{2^n} \cdot \tfrac{2^{2n}}{2^{L(n)}} = 2^{n-L(n)}\)</span></span>. So, in particular if we have an algorithm <span><span class="math inline">\(\ensuremath{\mathit{EVE}}\)</span></span> that outputs <span><span class="math inline">\(0\)</span></span> if <span><span class="math inline">\(x\in S_0\)</span></span> and outputs <span><span class="math inline">\(1\)</span></span> otherwise, then <span><span class="math inline">\(\Pr[ \ensuremath{\mathit{EVE}}(E_k(x_0))=0]=1\)</span></span> and <span><span class="math inline">\(\Pr[\ensuremath{\mathit{EVE}}(E_k(x_1))=0] \leq 2^{n-L(n)}\)</span></span> which will be smaller than <span><span class="math inline">\(2^{-10} &lt; 0.01\)</span></span> if <span><span class="math inline">\(L(n) \geq n+10\)</span></span>.</p>
</div>
<p>In retrospect <a href='#breakingcryptowithnp'>Theorem 20.10</a> is perhaps not surprising. After all, as we’ve mentioned before it is known that the Optimal PRG conjecture (which is the basis for the derandomized one-time pad encryption) is <em>false</em> if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> (and in fact even if <span><span class="math inline">\(\mathbf{NP}\subseteq \mathbf{BPP}\)</span></span> or even <span><span class="math inline">\(\mathbf{NP} \subseteq \mathbf{P_{/poly}}\)</span></span>).</p>
<h2 id="public-key-cryptography" data-number="20.8">Public key cryptography</h2>
<p>People have been dreaming about heavier-than-air flight since at least the days of Leonardo Da Vinci (not to mention Icarus from the greek mythology). Jules Verne wrote with rather insightful details about going to the moon in 1865. But, as far as I know, in all the thousands of years people have been using secret writing, until about 50 years ago no one has considered the possibility of communicating securely without first exchanging a shared secret key.</p>
<p>Yet in the late 1960’s and early 1970’s, several people started to question this “common wisdom”. Perhaps the most surprising of these visionaries was an undergraduate student at Berkeley named Ralph Merkle. In the fall of 1974 Merkle wrote in a <a href="http://www.merkle.com/1974/">project proposal</a> for his computer security course that while “it might seem intuitively obvious that if two people have never had the opportunity to prearrange an encryption method, then they will be unable to communicate securely over an insecure channel… I believe it is false”. The project proposal was rejected by his professor as “not good enough”. Merkle later submitted a paper to the communication of the ACM where he apologized for the lack of references since he was unable to find any mention of the problem in the scientific literature, and the only source where he saw the problem even <em>raised</em> was in a science fiction story. The paper was rejected with the comment that “Experience shows that it is extremely dangerous to transmit key information in the clear.” Merkle showed that one can design a protocol where Alice and Bob can use <span><span class="math inline">\(T\)</span></span> invocations of a hash function to exchange a key, but an adversary (in the random oracle model, though he of course didn’t use this name) would need roughly <span><span class="math inline">\(T^2\)</span></span> invocations to break it. He conjectured that it may be possible to obtain such protocols where breaking is <em>exponentially harder</em> than using them, but could not think of any concrete way to doing so.</p>
<p>We only found out much later that in the late 1960’s, a few years before Merkle, James Ellis of the British Intelligence agency GCHQ was <a href="http://cryptome.org/jya/ellisdoc.htm">having similar thoughts</a>. His curiosity was spurred by an old World-War II manuscript from Bell labs that suggested the following way that two people could communicate securely over a phone line. Alice would inject noise to the line, Bob would relay his messages, and then Alice would subtract the noise to get the signal. The idea is that an adversary over the line sees only the sum of Alice’s and Bob’s signals, and doesn’t know what came from what. This got James Ellis thinking whether it would be possible to achieve something like that digitally. As Ellis later recollected, in 1970 he realized that in principle this should be possible, since he could think of an hypothetical black box <span><span class="math inline">\(B\)</span></span> that on input a “handle” <span><span class="math inline">\(\alpha\)</span></span> and plaintext <span><span class="math inline">\(x\)</span></span> would give a “ciphertext” <span><span class="math inline">\(y\)</span></span> and that there would be a secret key <span><span class="math inline">\(\beta\)</span></span> corresponding to <span><span class="math inline">\(\alpha\)</span></span>, such that feeding <span><span class="math inline">\(\beta\)</span></span> and <span><span class="math inline">\(y\)</span></span> to the box would recover <span><span class="math inline">\(x\)</span></span>. However, Ellis had no idea how to actually instantiate this box. He and others kept giving this question as a puzzle to bright new recruits until one of them, Clifford Cocks, came up in 1973 with a candidate solution loosely based on the factoring problem; in 1974 another GCHQ recruit, Malcolm Williamson, came up with a solution using modular exponentiation.</p>
<p>But among all those thinking of public key cryptography, probably the people who saw the furthest were two researchers at Stanford, Whit Diffie and Martin Hellman. They realized that with the advent of electronic communication, cryptography would find new applications beyond the military domain of spies and submarines, and they understood that in this new world of many users and point to point communication, cryptography will need to scale up. Diffie and Hellman envisioned an object which we now call “trapdoor permutation” though they called “one way trapdoor function” or sometimes simply “public key encryption”. Though they didn’t have full formal definitions, their idea was that this is an injective function that is easy (e.g., polynomial-time) to <em>compute</em> but hard (e.g., exponential-time) to <em>invert</em>. However, there is a certain <em>trapdoor</em>, knowledge of which would allow polynomial time inversion. Diffie and Hellman argued that using such a trapdoor function, it would be possible for Alice and Bob to communicate securely <em>without ever having exchanged a secret key</em>. But they didn’t stop there. They realized that protecting the <em>integrity</em> of communication is no less important than protecting its <em>secrecy</em>. Thus they imagined that Alice could “run encryption in reverse” in order to certify or <em>sign</em> messages.</p>
<p>At the point, Diffie and Hellman were in a position not unlike physicists who predicted that a certain particle should exist but without any experimental verification. Luckily they <a href="http://cr.yp.to/bib/1988/diffie.pdf">met Ralph Merkle</a>, and his ideas about a probabilistic <em>key exchange protocol</em>, together with a suggestion from their Stanford colleague <a href="http://hdl.handle.net/11299/107353">John Gill</a>, inspired them to come up with what today is known as the <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie Hellman Key Exchange</a> (which unbeknownst to them was found two years earlier at GCHQ by Malcolm Williamson). They published their paper <a href="https://www-ee.stanford.edu/~hellman/publications/24.pdf">“New Directions in Cryptography”</a> in 1976, and it is considered to have brought about the birth of modern cryptography.</p>
<p>The Diffie-Hellman Key Exchange is still widely used today for secure communication. However, it still felt short of providing Diffie and Hellman’s elusive trapdoor function. This was done the next year by Rivest, Shamir and Adleman who came up with the RSA trapdoor function, which through the framework of Diffie and Hellman yielded not just encryption but also signatures. (A close variant of the RSA function was discovered earlier by Clifford Cocks at GCHQ, though as far as I can tell Cocks, Ellis and Williamson did not realize the application to digital signatures.) From this point on began a flurry of advances in cryptography which hasn’t died down till this day.</p>
<figure>
<img src="../figure/rsadhmg.png" alt="20.13: Top left: Ralph Merkle, Martin Hellman and Whit Diffie, who together came up in 1976 with the concept of public key encryption and a key exchange protocol. Bottom left: Adi Shamir, Ron Rivest, and Leonard Adleman who, following Diffie and Hellman’s paper, discovered the RSA function that can be used for public key encryption and digital signatures. Interestingly, one can see the equation \mathbf{P}=\mathbf{NP} on the blackboard behind them. Right: John Gill, who was the first person to suggest to Diffie and Hellman that they use modular exponentiation as an easy-to-compute but hard-to-invert function." id="diffiehellmanmerklegillfig" class="margin" /><figcaption>20.13: Top left: Ralph Merkle, Martin Hellman and Whit Diffie, who together came up in 1976 with the concept of <em>public key encryption</em> and a <em>key exchange protocol</em>. Bottom left: Adi Shamir, Ron Rivest, and Leonard Adleman who, following Diffie and Hellman’s paper, discovered the RSA function that can be used for public key encryption and digital signatures. Interestingly, one can see the equation <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> on the blackboard behind them. Right: John Gill, who was the first person to suggest to Diffie and Hellman that they use modular exponentiation as an easy-to-compute but hard-to-invert function.</figcaption>
</figure>
<h3 id="defining-public-key-encryption" data-number="20.8.1">Defining public key encryption</h3>
<p>A <em>public key encryption</em> consists of a triple of algorithms:</p>
<ul>
<li><p>The <em>key generation algorithm</em>, which we denote by <span><span class="math inline">\(KeyGen\)</span></span> or <span><span class="math inline">\(\ensuremath{\mathit{KG}}\)</span></span> for short, is a randomized algorithm that outputs a pair of strings <span><span class="math inline">\((e,d)\)</span></span> where <span><span class="math inline">\(e\)</span></span> is known as the <em>public</em> (or <em>encryption</em>) key, and <span><span class="math inline">\(d\)</span></span> is known as the <em>private</em> (or <em>decryption</em>) key. The key generation algorithm gets as input <span><span class="math inline">\(1^n\)</span></span> (i.e., a string of ones of length <span><span class="math inline">\(n\)</span></span>). We refer to <span><span class="math inline">\(n\)</span></span> as the <em>security parameter</em> of the scheme. The bigger we make <span><span class="math inline">\(n\)</span></span>, the more secure the encryption will be, but also the less efficient it will be.</p></li>
<li><p>The <em>encryption algorithm</em>, which we denote by <span><span class="math inline">\(E\)</span></span>, takes the encryption key <span><span class="math inline">\(e\)</span></span> and a plaintext <span><span class="math inline">\(x\)</span></span>, and outputs the ciphertext <span><span class="math inline">\(y=E_e(x)\)</span></span>.</p></li>
<li><p>The <em>decryption algorithm</em>, which we denote by <span><span class="math inline">\(D\)</span></span>, takes the decryption key <span><span class="math inline">\(d\)</span></span> and a ciphertext <span><span class="math inline">\(y\)</span></span>, and outputs the plaintext <span><span class="math inline">\(x=D_d(y)\)</span></span>.</p></li>
</ul>
<figure>
<img src="../figure/publickeyenc.png" alt="20.14: In a public key encryption, Alice generates a private/public keypair (e,d), publishes e and keeps d secret. To encrypt a message for Alice, one only needs to know e. To decrypt it we need to know d." id="publickeyencfig" class="margin" /><figcaption>20.14: In a <em>public key encryption</em>, Alice generates a private/public keypair <span><span class="math inline">\((e,d)\)</span></span>, publishes <span><span class="math inline">\(e\)</span></span> and keeps <span><span class="math inline">\(d\)</span></span> secret. To encrypt a message for Alice, one only needs to know <span><span class="math inline">\(e\)</span></span>. To decrypt it we need to know <span><span class="math inline">\(d\)</span></span>.</figcaption>
</figure>
<p>We now make this a formal definition:</p>
<div id="publickeyencdef" class="definition" title="Public Key Encryption" name="Definition 20.11 (Public Key Encryption) ">
<p>A <em>computationally secret public key encryption</em> with plaintext length <span><span class="math inline">\(L:\N \rightarrow \N\)</span></span> is a triple of randomized polynomial-time algorithms <span><span class="math inline">\((\ensuremath{\mathit{KG}},E,D)\)</span></span> that satisfy the following conditions:</p>
<ul>
<li><p>For every <span><span class="math inline">\(n\)</span></span>, if <span><span class="math inline">\((e,d)\)</span></span> is output by <span><span class="math inline">\(\ensuremath{\mathit{KG}}(1^n)\)</span></span> with positive probability, and <span><span class="math inline">\(x\in \{0,1\}^{L(n)}\)</span></span>, then <span><span class="math inline">\(D_d(E_e(x))=x\)</span></span> with probability one.</p></li>
<li><p>For every polynomial <span><span class="math inline">\(p\)</span></span>, and sufficiently large <span><span class="math inline">\(n\)</span></span>, if <span><span class="math inline">\(P\)</span></span> is a NAND-CIRC program of at most <span><span class="math inline">\(p(n)\)</span></span> lines then for every <span><span class="math inline">\(x,x&#39;\in \{0,1\}^{L(n)}\)</span></span>, <span><span class="math inline">\(\left| \E[ P(e,E_e(x))] - \E[P(e,E_e(x&#39;))] \right| &lt; 1/p(n)\)</span></span>, where this probability is taken over the coins of <span><span class="math inline">\(\ensuremath{\mathit{KG}}\)</span></span> and <span><span class="math inline">\(E\)</span></span>.</p></li>
</ul>
</div>
<p><a href='#publickeyencdef'>Definition 20.11</a> allows <span><span class="math inline">\(E\)</span></span> and <span><span class="math inline">\(D\)</span></span> to be <em>randomized</em> algorithms. In fact, it turns out that it is <em>necessary</em> for <span><span class="math inline">\(E\)</span></span> to be randomized to obtain computational secrecy. It also turns out that, unlike the private key case, we can transform a public-key encryption that works for messages that are <em>only one bit long</em> into a public-key encryption scheme that can encrypt arbitrarily long messages, and in particular messages that are <em>longer than the key</em>. In particular this means that we cannot obtain a perfectly secret public-key encryption scheme even for one-bit long messages (since it would imply a perfectly secret public-key, and hence in particular private-key, encryption with messages longer than the key).</p>
<p>We will not give full constructions for public key encryption schemes in this chapter, but will mention some of the ideas that underlie the most widely used schemes today. These generally belong to one of two families:</p>
<ul>
<li><p><em>Group theoretic constructions</em> based on problems such as <em>integer factoring</em> and the <em>discrete logarithm</em> over finite fields or elliptic curves.</p></li>
<li><p><em>Lattice/coding based constructions</em> based on problems such as the <em>closest vector in a lattice</em> or <em>bounded distance decoding</em>.</p></li>
</ul>
<p>Group-theory based encryptions such as the RSA cryptosystem, the Diffie-Hellman protocol, and Elliptic-Curve Cryptography, are currently more widely implemented. But the lattice/coding schemes are recently on the rise, particularly because the known group theoretic encryption schemes can be broken by <em>quantum computers</em>, which we discuss in <a href='lec_26_quantum_computing.html#quantumchap'>Chapter 22</a>.</p>
<h3 id="diffie-hellman-key-exchange" data-number="20.8.2">Diffie-Hellman key exchange</h3>
<p>As just one example of how public key encryption schemes are constructed, let us now describe the Diffie-Hellman key exchange. We describe the Diffie-Hellman protocol in a somewhat of an informal level, without presenting a full security analysis.</p>
<p>The computational problem underlying the Diffie Hellman protocol is the <em>discrete logarithm problem</em>. Let’s suppose that <span><span class="math inline">\(g\)</span></span> is some integer. We can compute the map <span><span class="math inline">\(x \mapsto g^x\)</span></span> and also its <em>inverse</em> <span><span class="math inline">\(y \mapsto \log_g y\)</span></span>. (For example, we can compute a logarithm is by <em>binary search</em>: start with some interval <span><span class="math inline">\([x_{min},x_{max}]\)</span></span> that is guaranteed to contain <span><span class="math inline">\(\log_g y\)</span></span>. We can then test whether the interval’s midpoint <span><span class="math inline">\(x_{mid}\)</span></span> satisfies <span><span class="math inline">\(g^{x_{mid}} &gt; y\)</span></span>, and based on that halve the size of the interval.)</p>
<p>However, suppose now that we use <em>modular arithmetic</em> and work modulo some prime number <span><span class="math inline">\(p\)</span></span>. If <span><span class="math inline">\(p\)</span></span> has <span><span class="math inline">\(n\)</span></span> binary digits and <span><span class="math inline">\(g\)</span></span> is in <span><span class="math inline">\([p]\)</span></span> then we can compute the map <span><span class="math inline">\(x \mapsto g^x \mod p\)</span></span> in time polynomial in <span><span class="math inline">\(n\)</span></span>. (This is not trivial, and is a great exercise for you to work this out; as a hint, start by showing that one can compute the map <span><span class="math inline">\(k \mapsto g^{2^k} \mod p\)</span></span> using <span><span class="math inline">\(k\)</span></span> modular multiplications modulo <span><span class="math inline">\(p\)</span></span>, if you’re stumped, you can look up <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">this Wikipedia entry</a>.) On the other hand, because of the “wraparound” property of modular arithmetic, we cannot run binary search to find the inverse of this map (known as the <em>discrete logarithm</em>). In fact, there is no known polynomial-time algorithm for computing this discrete logarithm map map <span><span class="math inline">\((g,x,p) \mapsto \log_g x \mod p\)</span></span>, where we define <span><span class="math inline">\(\log_g x \mod p\)</span></span> as the number <span><span class="math inline">\(a \in [p]\)</span></span> such that <span><span class="math inline">\(g^a = x \mod p\)</span></span>.</p>
<p>The Diffie-Hellman protocol for Bob to send a message to Alice is as follows:</p>
<ul>
<li><p><strong>Alice:</strong> Chooses <span><span class="math inline">\(p\)</span></span> to be a random <span><span class="math inline">\(n\)</span></span> bit long prime (which can be done by choosing random numbers and running a primality testing algorithm on them), and <span><span class="math inline">\(g\)</span></span> and <span><span class="math inline">\(a\)</span></span> at random in <span><span class="math inline">\([p]\)</span></span>. She sends to Bob the triple <span><span class="math inline">\((p,g,g^a \mod p)\)</span></span>.</p></li>
<li><p><strong>Bob:</strong> Given the triple <span><span class="math inline">\((p,g,h)\)</span></span>, Bob sends a message <span><span class="math inline">\(x \in \{0,1\}^L\)</span></span> to Alice by choosing <span><span class="math inline">\(b\)</span></span> at random in <span><span class="math inline">\([p]\)</span></span>, and sending to Alice the pair <span><span class="math inline">\((g^b \mod p, rep(h^b \mod p) \oplus x)\)</span></span> where <span><span class="math inline">\(rep:[p] \rightarrow \{0,1\}^*\)</span></span> is some “representation function” that maps <span><span class="math inline">\([p]\)</span></span> to <span><span class="math inline">\(\{0,1\}^L\)</span></span>. (The function <span><span class="math inline">\(rep\)</span></span> does not need to be one-to-one and you can think of <span><span class="math inline">\(rep(z)\)</span></span> as simply outputting <span><span class="math inline">\(L\)</span></span> of the bits of <span><span class="math inline">\(z\)</span></span> in the natural binary representation, it does need to satisfy certain technical conditions which we omit in this description.)</p></li>
<li><p><strong>Alice:</strong> Given <span><span class="math inline">\(g&#39;,z\)</span></span>, Alice recovers <span><span class="math inline">\(x\)</span></span> by outputting <span><span class="math inline">\(rep(g&#39;^a \mod p) \oplus z\)</span></span>.</p></li>
</ul>
<p>The correctness of the protocol follows from the simple fact that <span><span class="math inline">\((g^a)^b = (g^b)^a\)</span></span> for every <span><span class="math inline">\(g,a,b\)</span></span> and this still holds if we work modulo <span><span class="math inline">\(p\)</span></span>. Its security relies on the computational assumption that computing this map is hard, even in a certain “average case” sense (this computational assumption is known as the <a href="https://en.wikipedia.org/wiki/Decisional_Diffie%E2%80%93Hellman_assumption">Decisional Diffie Hellman assumption</a>). The Diffie-Hellman key exchange protocol can be thought of as a public key encryption where the Alice’s first message is the public key, and Bob’s message is the encryption.</p>
<p>One can think of the Diffie-Hellman protocol as being based on a “trapdoor pseudorandom generator” whereas the triple <span><span class="math inline">\(g^a,g^{b},g^{ab}\)</span></span> looks “random” to someone that doesn’t know <span><span class="math inline">\(a\)</span></span>, but someone that does know <span><span class="math inline">\(a\)</span></span> can see that raising the second element to the <span><span class="math inline">\(a\)</span></span>-th power yields the third element. The Diffie-Hellman protocol can be described abstractly in the context of any <a href="https://en.wikipedia.org/wiki/Abelian_group">finite Abelian group</a> for which we can efficiently compute the group operation. It has been implemented on other groups than numbers modulo <span><span class="math inline">\(p\)</span></span>, and in particular <a href="https://en.wikipedia.org/wiki/Elliptic-curve_cryptography">Elliptic Curve Cryptography (ECC)</a> is obtained by basing the Diffie Hellman on elliptic curve groups which gives some practical advantages. Another common group theoretic basis for key-exchange/public key encryption protocol is the RSA function. A big disadvantage of Diffie-Hellman (both the modular arithmetic and elliptic curve variants) and RSA is that both schemes can be broken in polynomial time by a <em>quantum computer</em>. We will discuss quantum computing later in this course.</p>
<h2 id="other-security-notions" data-number="20.9">Other security notions</h2>
<p>There is a great deal to cryptography beyond just encryption schemes, and beyond the notion of a passive adversary. A central objective is <em>integrity</em> or <em>authentication</em>: protecting communications from being modified by an adversary. Integrity is often more fundamental than secrecy: whether it is a software update or viewing the news, you might often not care about the communication being secret as much as that it indeed came from its claimed source. <em>Digital signature schemes</em> are the analog of public key encryption for authentication, and are widely used (in particular as the basis for <a href="https://en.wikipedia.org/wiki/Public_key_certificate">public key certificates</a>) to provide a foundation of trust in the digital world.</p>
<p>Similarly, even for encryption, we often need to ensure security against <em>active attacks</em>, and so notions such as non-malleability and <a href="https://en.wikipedia.org/wiki/Adaptive_chosen-ciphertext_attack">adaptive chosen ciphertext</a> security have been proposed. An encryption scheme is only as secure as the secret key, and mechanisms to make sure the key is generated properly, and is protected against refresh or even compromise (i.e., <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>) have been studied as well. Hopefully this chapter provides you with some appreciation for cryptography as an intellectual field, but does not imbue you with a false self of confidence in implementing it.</p>
<p><em>Cryptographic hash functions</em> is another widely used tool with a variety of uses, including extracting randomness from high entropy sources, achieving hard-to-forge short “digests” of files, protecting passwords, and much more.</p>
<h2 id="magic" data-number="20.10">Magic</h2>
<p>Beyond encryption and signature schemes, cryptographers have managed to obtain objects that truly seem paradoxical and “magical”. We briefly discuss some of these objects. We do not give any details, but hopefully this will spark your curiosity to find out more.</p>
<h3 id="zero-knowledge-proofs" data-number="20.10.1">Zero knowledge proofs</h3>
<p>On October 31, 1903, the mathematician Frank Nelson Cole, gave an hourlong lecture to a meeting of the American Mathematical Society where he did not speak a single word. Rather, he calculated on the board the value <span><span class="math inline">\(2^{67}-1\)</span></span> which is equal to <span><span class="math inline">\(147,573,952,589,676,412,927\)</span></span>, and then showed that this number is equal to <span><span class="math inline">\(193,707,721 \times 761,838,257,287\)</span></span>. Cole’s proof showed that <span><span class="math inline">\(2^{67}-1\)</span></span> is not a prime, but it also revealed additional information, namely its actual factors. This is often the case with proofs: they teach us more than just the validity of the statements.</p>
<p>In <em>Zero Knowledge Proofs</em> we try to achieve the opposite effect. We want a proof for a statement <span><span class="math inline">\(X\)</span></span> where we can <em>rigorously show</em> that the proofs reveals <em>absolutely no additional information about <span><span class="math inline">\(X\)</span></span></em> beyond the fact that it is true. This turns out to be an extremely useful object for a variety of tasks including authentication, secure protocols, voting, <a href="https://z.cash/technology/zksnarks.html">anonymity in cryptocurrencies</a>, and more. Constructing these objects relies on the theory of <span><span class="math inline">\(\mathbf{NP}\)</span></span> completeness. Thus this theory that originally was designed to give a <em>negative result</em> (show that some problems are hard) ended up yielding <em>positive applications</em>, enabling us to achieve tasks that were not possible otherwise.</p>
<h3 id="fully-homomorphic-encryption" data-number="20.10.2">Fully homomorphic encryption</h3>
<p>Suppose that we are given a bit-by-bit encryption of a string <span><span class="math inline">\(E_k(x_0),\ldots,E_k(x_{n-1})\)</span></span>. By design, these ciphertexts are supposed to be “completely unscrutable” and we should not be able to extract any information about <span><span class="math inline">\(x_i\)</span></span>’s from it. However, already in 1978, Rivest, Adleman and Dertouzos observed that this does not imply that we could not <em>manipulate</em> these encryptions. For example, it turns out the security of an encryption scheme does not immediately rule out the ability to take a pair of encryptions <span><span class="math inline">\(E_k(a)\)</span></span> and <span><span class="math inline">\(E_k(b)\)</span></span> and compute from them <span><span class="math inline">\(E_k(a \ensuremath{\mathit{NAND}} b)\)</span></span> <em>without knowing the secret key <span><span class="math inline">\(k\)</span></span></em>. But do there exist encryption schemes that allow such manipulations? And if so, is this a bug or a feature?</p>
<p>Rivest et al already showed that such encryption schemes could be <em>immensely</em> useful, and their utility has only grown in the age of cloud computing. After all, if we can compute NAND then we can use this to run any algorithm <span><span class="math inline">\(P\)</span></span> on the encrypted data, and map <span><span class="math inline">\(E_k(x_0),\ldots,E_k(x_{n-1})\)</span></span> to <span><span class="math inline">\(E_k(P(x_0,\ldots,x_{n-1}))\)</span></span>. For example, a client could store their secret data <span><span class="math inline">\(x\)</span></span> in encrypted form on the cloud, and have the cloud provider perform all sorts of computation on these data without ever revealing to the provider the private key, and so without the provider <em>ever learning any information</em> about the secret data.</p>
<p>The question of <em>existence</em> of such a scheme took much longer time to resolve. Only in 2009 Craig Gentry gave the first construction of an encryption scheme that allows to compute a universal basis of gates on the data (known as a <em>Fully Homomorphic Encryption scheme</em> in crypto parlance). Gentry’s scheme left much to be desired in terms of efficiency, and improving upon it has been the focus of an intensive research program that has already seen significant improvements.</p>
<h3 id="multiparty-secure-computation" data-number="20.10.3">Multiparty secure computation</h3>
<p>Cryptography is about enabling mutually distrusting parties to achieve a common goal. Perhaps the most general primitive achieving this objective is <a href="https://en.wikipedia.org/wiki/Secure_multi-party_computation">secure multiparty computation</a>. The idea in secure multiparty computation is that <span><span class="math inline">\(n\)</span></span> parties interact together to compute some function <span><span class="math inline">\(F(x_0,\ldots,x_{n-1})\)</span></span> where <span><span class="math inline">\(x_i\)</span></span> is the private input of the <span><span class="math inline">\(i\)</span></span>-th party. The crucial point is that there is <em>no commonly trusted party or authority</em> and that nothing is revealed about the secret data beyond the function’s output. One example is an <em>electronic voting protocol</em> where only the total vote count is revealed, with the privacy of the individual voters protected, but without having to trust any authority to either count the votes correctly or to keep information confidential. Another example is implementing a <a href="https://en.wikipedia.org/wiki/Vickrey_auction">second price (aka Vickrey) auction</a> where <span><span class="math inline">\(n-1\)</span></span> parties submit bids to an item owned by the <span><span class="math inline">\(n\)</span></span>-th party, and the item goes to the highest bidder but at the price of the <em>second highest bid</em>. Using secure multiparty computation we can implement second price auction in a way that will ensure the secrecy of the numerical values of all bids (including even the top one) except the second highest one, and the secrecy of the identity of all bidders (including even the second highest bidder) except the top one. We emphasize that such a protocol requires no trust even in the auctioneer itself, that will also not learn any additional information. Secure multiparty computation can be used even for computing <em>randomized</em> processes, with one example being playing Poker over the net without having to trust any server for correct shuffling of cards or not revealing the information.</p>
<div class="recap" name="Recap 20.10.3">
<ul>
<li><p>We can formally define the notion of security of an encryption scheme.</p></li>
<li><p><em>Perfect secrecy</em> ensures that an adversary does not learn <em>anything</em> about the plaintext from the ciphertext, regardless of their computational powers.</p></li>
<li><p>The one-time pad is a perfectly secret encryption with the length of the key equaling the length of the message. No perfectly secret encryption can have key shorter than the message.</p></li>
<li><p><em>Computational secrecy</em> can be as good as perfect secrecy since it ensures that the advantage that computationally bounded adversaries gain from observing the ciphertext is exponentially small. If the optimal PRG conjecture is true then there exists a computationally secret encryption scheme with messages that can be (almost) <em>exponentially bigger</em> than the key.</p></li>
<li><p>There are many cryptographic tools that go well beyond private key encryption. These include <em>public key encryption</em>, <em>digital signatures</em> and <em>hash functions</em>, as well as more “magical” tools such as <em>multiparty secure computation</em>, <em>fully homomorphic encryption</em>, <em>zero knowledge proofs</em>, and many others.</p></li>
</ul>
</div>
<h2 id="exercises" data-number="20.11">Exercises</h2>
<h2 id="bibliographical-notes" data-number="20.12">Bibliographical notes</h2>
<p>Much of this text is taken from <a href="https://intensecrypto.org">my lecture notes on cryptography</a>.</p>
<p>Shannon’s manuscript was written in 1945 but was classified, and a partial version was only published in 1949. Still it has revolutionized cryptography, and is the forerunner to much of what followed.</p>
<p>The Venona project’s history is described in <a href="http://nsarchive.gwu.edu/NSAEBB/NSAEBB278/01.PDF">this document</a>. Aside from Grabeel and Zubko, credit to the discovery that the Soviets were reusing keys is shared by Lt. Richard Hallock, Carrie Berry, Frank Lewis, and Lt. Karl Elmquist, and there are others that have made important contribution to this project. See pages 27 and 28 in the document.</p>
<p>In a <a href="https://www.nsa.gov/news-features/declassified-documents/nash-letters/assets/files/nash_letters1.pdf">1955 letter to the NSA</a> that only recently came forward, John Nash proposed an “unbreakable” encryption scheme. He wrote <em>“I hope my handwriting, etc. do not give the impression I am just a crank or circle-squarer…. The significance of this conjecture [that certain encryption schemes are exponentially secure against key recovery attacks] .. is that it is quite feasible to design ciphers that are effectively unbreakable.”</em>. John Nash made seminal contributions in mathematics and game theory, and was awarded both the Abel Prize in mathematics and the Nobel Memorial Prize in Economic Sciences. However, he has struggled with mental illness throughout his life. His biography, <a href="https://en.wikipedia.org/wiki/A_Beautiful_Mind_(book)">A Beautiful Mind</a> was made into a popular movie. It is natural to compare Nash’s 1955 letter to the NSA to Gödel’s letter to von Neumann we mentioned before. From the theoretical computer science point of view, the crucial difference is that while Nash informally talks about exponential vs polynomial computation time, he does not mention the word “Turing Machine” or other models of computation, and it is not clear if he is aware or not that his conjecture can be made mathematically precise (assuming a formalization of “sufficiently complex types of enciphering”).</p>
<p>The definition of computational secrecy we use is the notion of <em>computational indistinguishability</em> (known to be equivalent to <em>semantic security</em>) that was given by Goldwasser and Micali in 1982.</p>
<p>Although they used a different terminology, Diffie and Hellman already made clear in their paper that their protocol can be used as a public key encryption, with the first message being put in a “public file”. In 1985, ElGamal showed how to obtain a <em>signature scheme</em> based on the Diffie Hellman ideas, and since he described the Diffie-Hellman encryption scheme in the same paper, the public key encryption scheme originally proposed by Diffie and Hellman is sometimes also known as ElGamal encryption.</p>
<p><a href="https://eccc.weizmann.ac.il/report/2017/065/">My survey</a> contains a discussion on the different types of public key assumptions. While the standard elliptic curve cryptographic schemes are as susceptible to quantum computers as Diffie-Hellman and RSA, their main advantage is that the best known classical algorithms for computing discrete logarithms over elliptic curve groups take time <span><span class="math inline">\(2^{\epsilon n}\)</span></span> for some <span><span class="math inline">\(\epsilon&gt;0\)</span></span> where <span><span class="math inline">\(n\)</span></span> is the number of bits to describe a group element. In contrast, for the multiplicative group modulo a prime <span><span class="math inline">\(p\)</span></span> the best algorithm take time <span><span class="math inline">\(2^{O(n^{1/3} polylog(n))}\)</span></span> which means that (assuming the known algorithms are optimal) we need to set the prime to be bigger (and so have larger key sizes with corresponding overhead in communication and computation) to get the same level of security.</p>
<p>Zero-knowledge proofs were constructed by Goldwasser, Micali, and Rackoff in 1982, and their wide applicability was shown (using the theory of <span><span class="math inline">\(\mathbf{NP}\)</span></span> completeness) by Goldreich, Micali, and Wigderson in 1986.</p>
<p>Two party and multiparty secure computation protocols were constructed (respectively) by Yao in 1982 and Goldreich, Micali, and Wigderson in 1987. The latter work gave a general transformation from security against passive adversaries to security against active adversaries using zero knowledge proofs.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>Here is a nice exercise: compute (up to an order of magnitude) the probability that a 50-letter long message composed of random letters will end up not containing the letter “L”.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>The actual quote is “Il faut qu’il n’exige pas le secret, et qu’il puisse sans inconvénient tomber entre les mains de l’ennemi” loosely translated as “The system must not require secrecy and can be stolen by the enemy without causing trouble”. According to Steve Bellovin the NSA version is “assume that the first copy of any device we make is shipped to the Kremlin”.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 21:39:47</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_19_cryptography.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
