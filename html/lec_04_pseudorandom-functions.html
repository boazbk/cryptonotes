<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An intensive introduction to cryptography: Pseudorandom functions</title>
  <meta name="description" content="Lecture notes on Cryptography by Boaz Barak">

  <meta property="og:title" content="An intensive introduction to cryptography: Pseudorandom functions" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://intensecrypto.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="github-repo" content="boazbk/crypto" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An intensive introduction to cryptography" />
  <meta name="twitter:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="twitter:image" content="https://intensecrypto.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">An intensive introduction to cryptography</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html"><i class="fa fa-check"></i><b>p</b> Foreword and Syllabus</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#syllabus"><i class="fa fa-check"></i><b>p.1</b> Syllabus</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#prerequisites"><i class="fa fa-check"></i><b>p.1.1</b> Prerequisites</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#why-is-cryptography-hard"><i class="fa fa-check"></i><b>p.2</b> Why is cryptography hard?</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html"><i class="fa fa-check"></i><b>0</b> Mathematical Background</a><ul><li class="chapter" data-level="0.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#a-quick-overview-of-mathematical-prerequisites"><i class="fa fa-check"></i><b>0.1</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="0.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#mathematical-proofs"><i class="fa fa-check"></i><b>0.2</b> Mathematical Proofs</a><ul><li class="chapter" data-level="0.2.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#example-the-existence-of-infinitely-many-primes."><i class="fa fa-check"></i><b>0.2.1</b> Example: The existence of infinitely many primes.</a></li></ul></li><li class="chapter" data-level="0.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#probability-and-sample-spaces"><i class="fa fa-check"></i><b>0.3</b> Probability and Sample spaces</a><ul><li class="chapter" data-level="0.3.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#random-variables"><i class="fa fa-check"></i><b>0.3.1</b> Random variables</a></li><li class="chapter" data-level="0.3.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#distributions-over-strings"><i class="fa fa-check"></i><b>0.3.2</b> Distributions over strings</a></li><li class="chapter" data-level="0.3.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>0.3.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="0.4" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#correlations-and-independence"><i class="fa fa-check"></i><b>0.4</b> Correlations and independence</a><ul><li class="chapter" data-level="0.4.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#independent-random-variables"><i class="fa fa-check"></i><b>0.4.1</b> Independent random variables</a></li><li class="chapter" data-level="0.4.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>0.4.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="0.5" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>0.5</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>0.5.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="0.5.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#the-chernoff-bound"><i class="fa fa-check"></i><b>0.5.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#exercises-1"><i class="fa fa-check"></i><b>0.7</b> Exercises</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul><li class="chapter" data-level="1.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#some-history"><i class="fa fa-check"></i><b>1.1</b> Some history</a></li><li class="chapter" data-level="1.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-encryptions"><i class="fa fa-check"></i><b>1.2</b> Defining encryptions</a></li><li class="chapter" data-level="1.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>1.3</b> Defining security of encryption</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#generating-randomness-in-actual-cryptographic-systems"><i class="fa fa-check"></i><b>1.3.1</b> Generating randomness in actual cryptographic systems</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-the-secrecy-requirement."><i class="fa fa-check"></i><b>1.4</b> Defining the secrecy requirement.</a></li><li class="chapter" data-level="1.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#perfect-secrecy"><i class="fa fa-check"></i><b>1.5</b> Perfect Secrecy</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#achieving-perfect-secrecy"><i class="fa fa-check"></i><b>1.5.1</b> Achieving perfect secrecy</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>1.6</b> Necessity of long keys</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#amplifying-success-probability"><i class="fa fa-check"></i><b>1.6.1</b> Amplifying success probability</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bibliographical-notes"><i class="fa fa-check"></i><b>1.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html"><i class="fa fa-check"></i><b>2</b> Computational Security</a><ul><li><ul><li class="chapter" data-level="2.0.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#proof-by-reduction"><i class="fa fa-check"></i><b>2.0.1</b> Proof by reduction</a></li></ul></li><li class="chapter" data-level="2.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#the-asymptotic-approach"><i class="fa fa-check"></i><b>2.1</b> The asymptotic approach</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#countoperation"><i class="fa fa-check"></i><b>2.1.1</b> Counting number of operations.</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#our-first-conjecture"><i class="fa fa-check"></i><b>2.2</b> Our first conjecture</a></li><li class="chapter" data-level="2.3" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#why-care-about-the-cipher-conjecture"><i class="fa fa-check"></i><b>2.3</b> Why care about the cipher conjecture?</a></li><li class="chapter" data-level="2.4" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#prelude-computational-indistinguishability"><i class="fa fa-check"></i><b>2.4</b> Prelude: Computational Indistinguishability</a></li><li class="chapter" data-level="2.5" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#the-length-extension-theorem"><i class="fa fa-check"></i><b>2.5</b> The Length Extension Theorem</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_computational-security.html"><a href="lec_02_computational-security.html#appendix-the-computational-model"><i class="fa fa-check"></i><b>2.5.1</b> Appendix: The computational model</a></li></ul></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html"><i class="fa fa-check"></i><b>3</b> Pseudorandomness</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#stream-ciphers"><i class="fa fa-check"></i><b>3.1</b> Stream ciphers</a></li><li class="chapter" data-level="3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#what-do-pseudorandom-generators-actually-look-like"><i class="fa fa-check"></i><b>3.2</b> What do pseudorandom generators actually look like?</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-0-the-counter-generator"><i class="fa fa-check"></i><b>3.2.1</b> Attempt 0: The counter generator</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-1-the-linear-checksum-linear-feedback-shift-register-lfsr"><i class="fa fa-check"></i><b>3.2.2</b> Attempt 1: The linear checksum / linear feedback shift register (LFSR)</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#from-insecurity-to-security"><i class="fa fa-check"></i><b>3.2.3</b> From insecurity to security</a></li><li class="chapter" data-level="3.2.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-2-linear-congruential-generators-with-dropped-bits"><i class="fa fa-check"></i><b>3.2.4</b> Attempt 2: Linear Congruential Generators with dropped bits</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#successful-examples"><i class="fa fa-check"></i><b>3.3</b> Successful examples</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-1-subset-sum-generator"><i class="fa fa-check"></i><b>3.3.1</b> Case Study 1: Subset Sum Generator</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-2-rc4"><i class="fa fa-check"></i><b>3.3.2</b> Case Study 2: RC4</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#non-constructive-existence-of-pseudorandom-generators"><i class="fa fa-check"></i><b>3.4</b> Non-constructive existence of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html"><i class="fa fa-check"></i><b>4</b> Pseudorandom functions</a><ul><li class="chapter" data-level="4.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#one-time-passwords-e.g.-google-authenticator-rsa-id-etc."><i class="fa fa-check"></i><b>4.1</b> One time passwords (e.g. Google Authenticator, RSA ID, etc.)</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#how-do-pseudorandom-functions-help-in-the-login-problem"><i class="fa fa-check"></i><b>4.1.1</b> How do pseudorandom functions help in the login problem?</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#message-authentication-codes"><i class="fa fa-check"></i><b>4.2</b> Message Authentication Codes</a></li><li class="chapter" data-level="4.3" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#macs-from-prfs"><i class="fa fa-check"></i><b>4.3</b> MACs from PRFs</a></li><li class="chapter" data-level="4.4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#input-length-extension-for-macs-and-prfs"><i class="fa fa-check"></i><b>4.4</b> Input length extension for MACs and PRFs</a></li><li class="chapter" data-level="4.5" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#aside-natural-proofs"><i class="fa fa-check"></i><b>4.5</b> Aside: natural proofs</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html"><i class="fa fa-check"></i><b>5</b> Pseudorandom functions from pseudorandom generators</a><ul><li class="chapter" data-level="5.1" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#securely-encrypting-many-messages---chosen-plaintext-security"><i class="fa fa-check"></i><b>5.1</b> Securely encrypting many messages - chosen plaintext security</a></li><li class="chapter" data-level="5.2" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#pseudorandom-permutations-block-ciphers"><i class="fa fa-check"></i><b>5.2</b> Pseudorandom permutations / block ciphers</a></li><li class="chapter" data-level="5.3" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#encryption-modes"><i class="fa fa-check"></i><b>5.3</b> Encryption modes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html"><i class="fa fa-check"></i><b>6</b> Chosen Ciphertext Security</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#short-recap"><i class="fa fa-check"></i><b>6.1</b> Short recap</a></li><li class="chapter" data-level="6.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#going-beyond-cpa"><i class="fa fa-check"></i><b>6.2</b> Going beyond CPA</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#example-the-wired-equivalence-protocol-wep"><i class="fa fa-check"></i><b>6.2.1</b> Example: The Wired Equivalence Protocol (WEP)</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-security-1"><i class="fa fa-check"></i><b>6.2.2</b> Chosen ciphertext security</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#constructing-cca-secure-encryption"><i class="fa fa-check"></i><b>6.3</b> Constructing CCA secure encryption</a></li><li class="chapter" data-level="6.4" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#simplified-gcm-encryption"><i class="fa fa-check"></i><b>6.4</b> (Simplified) GCM encryption</a></li><li class="chapter" data-level="6.5" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#padding-chopping-and-their-pitfalls-the-buffer-overflow-of-cryptography"><i class="fa fa-check"></i><b>6.5</b> Padding, chopping, and their pitfalls: the "buffer overflow" of cryptography</a></li><li class="chapter" data-level="6.6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-attack-as-implementing-metaphors"><i class="fa fa-check"></i><b>6.6</b> Chosen ciphertext attack as implementing metaphors</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html"><i class="fa fa-check"></i><b>7</b> Hash functions and random oracles</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-problem"><i class="fa fa-check"></i><b>7.1</b> The "bitcoin" problem</a><ul><li class="chapter" data-level="7.1.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-currency-problem"><i class="fa fa-check"></i><b>7.1.1</b> The currency problem</a></li><li class="chapter" data-level="7.1.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#bitcoin-architecture"><i class="fa fa-check"></i><b>7.1.2</b> Bitcoin architecture</a></li></ul></li><li class="chapter" data-level="7.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-ledger"><i class="fa fa-check"></i><b>7.2</b> The bitcoin ledger</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#from-proof-of-work-to-consensus-on-ledger"><i class="fa fa-check"></i><b>7.2.1</b> From proof of work to consensus on ledger</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#collision-resistance-hash-functions-and-creating-short-unique-identifiers"><i class="fa fa-check"></i><b>7.3</b> Collision resistance hash functions and creating short "unique" identifiers</a></li><li class="chapter" data-level="7.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-constructions-of-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4</b> Practical constructions of cryptographic hash functions</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-random-ish-functions"><i class="fa fa-check"></i><b>7.4.1</b> Practical random-ish functions</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#some-history"><i class="fa fa-check"></i><b>7.4.2</b> Some history</a></li><li class="chapter" data-level="7.4.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-nsa-and-hash-functions."><i class="fa fa-check"></i><b>7.4.3</b> The NSA and hash functions.</a></li><li class="chapter" data-level="7.4.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#cryptographic-vs-non-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4.4</b> Cryptographic vs non-cryptographic hash functions:</a></li></ul></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html"><i class="fa fa-check"></i><b>8</b> Key derivation, protecting passwords, slow hashes, Merkle trees</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#keys-from-passwords"><i class="fa fa-check"></i><b>8.1</b> Keys from passwords</a></li><li class="chapter" data-level="8.2" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#merkle-trees-and-verifying-storage."><i class="fa fa-check"></i><b>8.2</b> Merkle trees and verifying storage.</a></li><li class="chapter" data-level="8.3" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#proofs-of-retrievability"><i class="fa fa-check"></i><b>8.3</b> Proofs of Retrievability</a></li><li class="chapter" data-level="8.4" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#entropy-extraction"><i class="fa fa-check"></i><b>8.4</b> Entropy extraction</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#forward-and-backward-secrecy"><i class="fa fa-check"></i><b>8.4.1</b> Forward and backward secrecy</a></li></ul></li></ul></li><li class="chapter" data-level="9" data-path="lec_09_priv_recap.html"><a href="lec_09_priv_recap.html"><i class="fa fa-check"></i><b>9</b> Private key crypto recap</a><ul><li><ul><li class="chapter" data-level="9.0.1" data-path="lec_09_priv_recap.html"><a href="lec_09_priv_recap.html#attacks-on-private-key-cryptosystems"><i class="fa fa-check"></i><b>9.0.1</b> Attacks on private key cryptosystems</a></li></ul></li></ul></li><li class="chapter" data-level="10" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html"><i class="fa fa-check"></i><b>10</b> Public key cryptography</a><ul><li class="chapter" data-level="10.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#private-key-crypto-recap"><i class="fa fa-check"></i><b>10.1</b> Private key crypto recap</a></li><li class="chapter" data-level="10.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#public-key-encryptions-definition"><i class="fa fa-check"></i><b>10.2</b> Public Key Encryptions: Definition</a><ul><li class="chapter" data-level="10.2.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-obfuscation-paradigm"><i class="fa fa-check"></i><b>10.2.1</b> The obfuscation paradigm</a></li></ul></li><li class="chapter" data-level="10.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#some-concrete-candidates"><i class="fa fa-check"></i><b>10.3</b> Some concrete candidates:</a><ul><li class="chapter" data-level="10.3.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#diffie-hellman-encryption-aka-el-gamal"><i class="fa fa-check"></i><b>10.3.1</b> Diffie-Hellman Encryption (aka El-Gamal)</a></li><li class="chapter" data-level="10.3.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#sampling-random-primes"><i class="fa fa-check"></i><b>10.3.2</b> Sampling random primes</a></li><li class="chapter" data-level="10.3.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#a-little-bit-of-group-theory."><i class="fa fa-check"></i><b>10.3.3</b> A little bit of group theory.</a></li><li class="chapter" data-level="10.3.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#digital-signatures"><i class="fa fa-check"></i><b>10.3.4</b> Digital Signatures</a></li><li class="chapter" data-level="10.3.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-digital-signature-algorithm-dsa"><i class="fa fa-check"></i><b>10.3.5</b> The Digital Signature Algorithm (DSA)</a></li></ul></li><li class="chapter" data-level="10.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#putting-everything-together---security-in-practice."><i class="fa fa-check"></i><b>10.4</b> Putting everything together - security in practice.</a></li><li class="chapter" data-level="10.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#appendix-an-alternative-proof-of-the-density-of-primes"><i class="fa fa-check"></i><b>10.5</b> Appendix: An alternative proof of the density of primes</a></li><li class="chapter" data-level="10.6" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#additional-group-theory-exercises-and-proofs"><i class="fa fa-check"></i><b>10.6</b> Additional Group Theory Exercises and Proofs</a><ul><li class="chapter" data-level="10.6.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#solved-exercises"><i class="fa fa-check"></i><b>10.6.1</b> Solved exercises:</a></li></ul></li></ul></li><li class="chapter" data-level="11" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html"><i class="fa fa-check"></i><b>11</b> Concrete candidates for public key crypto</a><ul><li class="chapter" data-level="11.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#some-number-theory."><i class="fa fa-check"></i><b>11.1</b> Some number theory.</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#primaliy-testing"><i class="fa fa-check"></i><b>11.1.1</b> Primaliy testing</a></li><li class="chapter" data-level="11.1.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#fields"><i class="fa fa-check"></i><b>11.1.2</b> Fields</a></li><li class="chapter" data-level="11.1.3" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#chinese-remainder-theorem"><i class="fa fa-check"></i><b>11.1.3</b> Chinese remainder theorem</a></li><li class="chapter" data-level="11.1.4" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#the-rsa-and-rabin-functions"><i class="fa fa-check"></i><b>11.1.4</b> The RSA and Rabin functions</a></li><li class="chapter" data-level="11.1.5" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#abstraction-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.5</b> Abstraction: trapdoor permutations</a></li><li class="chapter" data-level="11.1.6" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#public-key-encryption-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.6</b> Public key encryption from trapdoor permutations</a></li><li class="chapter" data-level="11.1.7" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#digital-signatures-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.7</b> Digital signatures from trapdoor permutations</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#hardcore-bits-and-security-without-random-oracles"><i class="fa fa-check"></i><b>11.2</b> Hardcore bits and security without random oracles</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html"><i class="fa fa-check"></i><b>12</b> Lattice based cryptography</a><ul><li><ul><li class="chapter" data-level="12.0.1" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#quick-linear-algebra-recap"><i class="fa fa-check"></i><b>12.0.1</b> Quick linear algebra recap</a></li></ul></li><li class="chapter" data-level="12.1" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#a-world-without-gaussian-elimination"><i class="fa fa-check"></i><b>12.1</b> A world without Gaussian elimination</a></li><li class="chapter" data-level="12.2" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#security-in-the-real-world."><i class="fa fa-check"></i><b>12.2</b> Security in the real world.</a></li><li class="chapter" data-level="12.3" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#search-to-decision"><i class="fa fa-check"></i><b>12.3</b> Search to decision</a></li><li class="chapter" data-level="12.4" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#an-lwe-based-encryption-scheme"><i class="fa fa-check"></i><b>12.4</b> An LWE based encryption scheme</a></li><li class="chapter" data-level="12.5" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#but-what-are-lattices"><i class="fa fa-check"></i><b>12.5</b> But what are lattices?</a></li><li class="chapter" data-level="12.6" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#ring-based-lattices"><i class="fa fa-check"></i><b>12.6</b> Ring based lattices</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12a_CCA_public_key.html"><a href="lec_12a_CCA_public_key.html"><i class="fa fa-check"></i><b>13</b> Chosen ciphertext security for public key encryption</a></li><li class="chapter" data-level="14" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html"><i class="fa fa-check"></i><b>14</b> Establishing secure connections over insecure channels</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cryptographys-obsession-with-adjectives."><i class="fa fa-check"></i><b>14.1</b> Cryptography’s obsession with adjectives.</a></li><li class="chapter" data-level="14.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#basic-key-exchange-protocol"><i class="fa fa-check"></i><b>14.2</b> Basic Key Exchange protocol</a></li><li class="chapter" data-level="14.3" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#authenticated-key-exchange"><i class="fa fa-check"></i><b>14.3</b> Authenticated key exchange</a><ul><li class="chapter" data-level="14.3.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#bleichenbachers-attack-on-rsa-pkcs-v1.5-and-ssl-v3.0"><i class="fa fa-check"></i><b>14.3.1</b> Bleichenbacher’s attack on RSA PKCS V1.5 and SSL V3.0</a></li></ul></li><li class="chapter" data-level="14.4" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#chosen-ciphertext-attack-security-for-public-key-cryptography"><i class="fa fa-check"></i><b>14.4</b> Chosen ciphertext attack security for public key cryptography</a></li><li class="chapter" data-level="14.5" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cca-secure-public-key-encryption-in-the-random-oracle-model"><i class="fa fa-check"></i><b>14.5</b> CCA secure public key encryption in the Random Oracle Model</a><ul><li class="chapter" data-level="14.5.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#defining-secure-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.1</b> Defining secure authenticated key exchange</a></li><li class="chapter" data-level="14.5.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#the-compiler-approach-for-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.2</b> The compiler approach for authenticated key exchange</a></li></ul></li><li class="chapter" data-level="14.6" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#password-authenticated-key-exchange."><i class="fa fa-check"></i><b>14.6</b> Password authenticated key exchange.</a></li><li class="chapter" data-level="14.7" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#client-to-client-key-exchange-for-secure-text-messaging---zrtp-otr-textsecure"><i class="fa fa-check"></i><b>14.7</b> Client to client key exchange for secure text messaging - ZRTP, OTR, TextSecure</a></li><li class="chapter" data-level="14.8" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#heartbleed-and-logjam-attacks"><i class="fa fa-check"></i><b>14.8</b> Heartbleed and logjam attacks</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html"><i class="fa fa-check"></i><b>15</b> Zero knowledge proofs</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#applications-for-zero-knowledge-proofs."><i class="fa fa-check"></i><b>15.1</b> Applications for zero knowledge proofs.</a><ul><li class="chapter" data-level="15.1.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#nuclear-disarmament"><i class="fa fa-check"></i><b>15.1.1</b> Nuclear disarmament</a></li><li class="chapter" data-level="15.1.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#voting"><i class="fa fa-check"></i><b>15.1.2</b> Voting</a></li><li class="chapter" data-level="15.1.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#more-applications"><i class="fa fa-check"></i><b>15.1.3</b> More applications</a></li></ul></li><li class="chapter" data-level="15.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-and-constructing-zero-knowledge-proofs"><i class="fa fa-check"></i><b>15.2</b> Defining and constructing zero knowledge proofs</a></li><li class="chapter" data-level="15.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-zero-knowledge"><i class="fa fa-check"></i><b>15.3</b> Defining zero knowledge</a></li><li class="chapter" data-level="15.4" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#zero-knowledge-proof-for-hamiltonicity."><i class="fa fa-check"></i><b>15.4</b> Zero knowledge proof for Hamiltonicity.</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#why-is-this-interesting"><i class="fa fa-check"></i><b>15.4.1</b> Why is this interesting?</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#parallel-repetition-and-turning-zero-knowledge-proofs-to-signatures."><i class="fa fa-check"></i><b>15.5</b> Parallel repetition and turning zero knowledge proofs to signatures.</a><ul><li class="chapter" data-level="15.5.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#bonus-features-of-zero-knowledge"><i class="fa fa-check"></i><b>15.5.1</b> "Bonus features" of zero knowledge</a></li></ul></li></ul></li><li class="chapter" data-level="16" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html"><i class="fa fa-check"></i><b>16</b> Fully homomorphic encryption: Introduction and bootstrapping</a><ul><li class="chapter" data-level="16.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#defining-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>16.1</b> Defining fully homomorphic encryption</a><ul><li class="chapter" data-level="16.1.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#another-application-fully-homomorphic-encryption-for-verifying-computation"><i class="fa fa-check"></i><b>16.1.1</b> Another application: fully homomorphic encryption for verifying computation</a></li></ul></li><li class="chapter" data-level="16.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#example-an-xor-homomorphic-encryption"><i class="fa fa-check"></i><b>16.2</b> Example: An XOR homomorphic encryption</a><ul><li class="chapter" data-level="16.2.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#abstraction-a-trapdoor-pseudorandom-generator."><i class="fa fa-check"></i><b>16.2.1</b> Abstraction: A trapdoor pseudorandom generator.</a></li></ul></li><li class="chapter" data-level="16.3" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#from-linear-homomorphism-to-full-homomorphism"><i class="fa fa-check"></i><b>16.3</b> From linear homomorphism to full homomorphism</a></li><li class="chapter" data-level="16.4" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#bootstrapping-fully-homomorphic-escape-velocity"><i class="fa fa-check"></i><b>16.4</b> Bootstrapping: Fully Homomorphic "escape velocity"</a><ul><li class="chapter" data-level="16.4.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#radioactive-legos-analogy"><i class="fa fa-check"></i><b>16.4.1</b> Radioactive legos analogy</a></li><li class="chapter" data-level="16.4.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#proving-the-bootstrapping-theorem"><i class="fa fa-check"></i><b>16.4.2</b> Proving the bootstrapping theorem</a></li></ul></li></ul></li><li class="chapter" data-level="17" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html"><i class="fa fa-check"></i><b>17</b> Fully homomorphic encryption : Construction</a><ul><li class="chapter" data-level="17.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#prelude-from-vectors-to-matrices"><i class="fa fa-check"></i><b>17.1</b> Prelude: from vectors to matrices</a></li><li class="chapter" data-level="17.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#real-world-partially-homomorphic-encryption"><i class="fa fa-check"></i><b>17.2</b> Real world partially homomorphic encryption</a></li><li class="chapter" data-level="17.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#noise-management-via-encoding"><i class="fa fa-check"></i><b>17.3</b> Noise management via encoding</a></li><li class="chapter" data-level="17.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#putting-it-all-together"><i class="fa fa-check"></i><b>17.4</b> Putting it all together</a></li><li class="chapter" data-level="17.5" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#analysis-of-our-scheme"><i class="fa fa-check"></i><b>17.5</b> Analysis of our scheme</a><ul><li class="chapter" data-level="17.5.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#correctness"><i class="fa fa-check"></i><b>17.5.1</b> Correctness</a></li><li class="chapter" data-level="17.5.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#cpa-security"><i class="fa fa-check"></i><b>17.5.2</b> CPA Security</a></li><li class="chapter" data-level="17.5.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#homomorphism"><i class="fa fa-check"></i><b>17.5.3</b> Homomorphism</a></li><li class="chapter" data-level="17.5.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#shallow-decryption-circuit"><i class="fa fa-check"></i><b>17.5.4</b> Shallow decryption circuit</a></li></ul></li><li class="chapter" data-level="17.6" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#example-application-private-information-retrieval"><i class="fa fa-check"></i><b>17.6</b> Example application: Private information retrieval</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html"><i class="fa fa-check"></i><b>18</b> Multiparty secure computation I: Definition and Honest-But-Curious to Malicious complier</a><ul><li class="chapter" data-level="18.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#ideal-vs.-real-model-security."><i class="fa fa-check"></i><b>18.1</b> Ideal vs. Real Model Security.</a></li><li class="chapter" data-level="18.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#formally-defining-secure-multiparty-computation"><i class="fa fa-check"></i><b>18.2</b> Formally defining secure multiparty computation</a><ul><li class="chapter" data-level="18.2.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#first-attempt-a-slightly-too-ideal-definition"><i class="fa fa-check"></i><b>18.2.1</b> First attempt: a slightly "too ideal" definition</a></li><li class="chapter" data-level="18.2.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#allowing-for-aborts"><i class="fa fa-check"></i><b>18.2.2</b> Allowing for aborts</a></li><li class="chapter" data-level="18.2.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#some-comments"><i class="fa fa-check"></i><b>18.2.3</b> Some comments:</a></li></ul></li><li class="chapter" data-level="18.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#example-second-price-auction-using-bitcoin"><i class="fa fa-check"></i><b>18.3</b> Example: Second price auction using bitcoin</a><ul><li class="chapter" data-level="18.3.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#another-example-distributed-and-threshold-cryptography"><i class="fa fa-check"></i><b>18.3.1</b> Another example: distributed and threshold cryptography</a></li></ul></li><li class="chapter" data-level="18.4" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#proving-the-fundamental-theorem"><i class="fa fa-check"></i><b>18.4</b> Proving the fundamental theorem:</a></li><li class="chapter" data-level="18.5" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#malicious-to-honest-but-curious-reduction"><i class="fa fa-check"></i><b>18.5</b> Malicious to honest but curious reduction</a><ul><li class="chapter" data-level="18.5.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#handling-probabilistic-strategies"><i class="fa fa-check"></i><b>18.5.1</b> Handling probabilistic strategies:</a></li></ul></li></ul></li><li class="chapter" data-level="19" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html"><i class="fa fa-check"></i><b>19</b> Multiparty secure computation: Construction using Fully Homomorphic Encryption</a><ul><li class="chapter" data-level="19.1" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#constructing-2-party-honest-but-curious-computation-from-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.1</b> Constructing 2 party honest but curious computation from fully homomorphic encryption</a></li><li class="chapter" data-level="19.2" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#achieving-circuit-privacy-in-a-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.2</b> Achieving circuit privacy in a fully homomorphic encryption</a></li><li class="chapter" data-level="19.3" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#bottom-line-a-two-party-honest-but-curious-two-party-secure-computation-protocol"><i class="fa fa-check"></i><b>19.3</b> Bottom line: A two party honest but curious two party secure computation protocol</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html"><i class="fa fa-check"></i><b>20</b> Quantum computing and cryptography I</a><ul><li><ul><li class="chapter" data-level="20.0.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>20.0.1</b> Quantum computing and computation - an executive summary.</a></li></ul></li><li class="chapter" data-level="20.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-101"><i class="fa fa-check"></i><b>20.1</b> Quantum 101</a><ul><li class="chapter" data-level="20.1.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>20.1.1</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="20.1.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bra-ket-notation"><i class="fa fa-check"></i><b>20.1.2</b> Bra-ket notation</a></li><li class="chapter" data-level="20.1.3" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bells-inequality"><i class="fa fa-check"></i><b>20.1.3</b> Bell’s Inequality</a></li></ul></li><li class="chapter" data-level="20.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#grovers-algorithm"><i class="fa fa-check"></i><b>20.2</b> Grover’s Algorithm</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html"><i class="fa fa-check"></i><b>21</b> Quantum computing and cryptography II</a><ul><li class="chapter" data-level="21.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-order-finding-to-factoring-and-discrete-log"><i class="fa fa-check"></i><b>21.1</b> From order finding to factoring and discrete log</a></li><li class="chapter" data-level="21.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#finding-periods-of-a-function-simons-algorithm"><i class="fa fa-check"></i><b>21.2</b> Finding periods of a function: Simon’s Algorithm</a></li><li class="chapter" data-level="21.3" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-simon-to-shor"><i class="fa fa-check"></i><b>21.3</b> From Simon to Shor</a><ul><li class="chapter" data-level="21.3.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.1</b> The Fourier transform over \Z_m</a><ul><li class="chapter" data-level="21.3.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#fast-fourier-transform."><i class="fa fa-check"></i><b>21.3.1.1</b> Fast Fourier Transform.</a></li></ul></li><li class="chapter" data-level="21.3.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.2</b> Quantum Fourier Transform over \Z_m</a></li></ul></li><li class="chapter" data-level="21.4" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#shors-order-finding-algorithm."><i class="fa fa-check"></i><b>21.4</b> Shor’s Order-Finding Algorithm.</a><ul><li class="chapter" data-level="21.4.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#analysis-the-case-that-rm"><i class="fa fa-check"></i><b>21.4.1</b> Analysis: the case that r|m</a><ul><li class="chapter" data-level="21.4.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-general-case"><i class="fa fa-check"></i><b>21.4.1.1</b> The general case</a></li></ul></li></ul></li><li class="chapter" data-level="21.5" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#rational-approximation-of-real-numbers"><i class="fa fa-check"></i><b>21.5</b> Rational approximation of real numbers</a><ul><li class="chapter" data-level="21.5.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-cryptography"><i class="fa fa-check"></i><b>21.5.1</b> Quantum cryptography</a></li></ul></li></ul></li><li class="chapter" data-level="22" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html"><i class="fa fa-check"></i><b>22</b> Software Obfuscation</a><ul><li class="chapter" data-level="22.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#witness-encryption"><i class="fa fa-check"></i><b>22.1</b> Witness encryption</a></li><li class="chapter" data-level="22.2" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#deniable-encryption"><i class="fa fa-check"></i><b>22.2</b> Deniable encryption</a></li><li class="chapter" data-level="22.3" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#functional-encryption"><i class="fa fa-check"></i><b>22.3</b> Functional encryption</a></li><li class="chapter" data-level="22.4" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#the-software-patch-problem"><i class="fa fa-check"></i><b>22.4</b> The software patch problem</a></li><li class="chapter" data-level="22.5" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#software-obfuscation-1"><i class="fa fa-check"></i><b>22.5</b> Software obfuscation</a></li><li class="chapter" data-level="22.6" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#applications-of-obfuscation"><i class="fa fa-check"></i><b>22.6</b> Applications of obfuscation</a></li><li class="chapter" data-level="22.7" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#impossibility-of-obfuscation"><i class="fa fa-check"></i><b>22.7</b> Impossibility of obfuscation</a><ul><li class="chapter" data-level="22.7.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#proof-of-impossibility-of-vbb-obfuscation"><i class="fa fa-check"></i><b>22.7.1</b> Proof of impossibility of VBB obfuscation</a></li></ul></li><li class="chapter" data-level="22.8" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#indistinguishability-obfuscation"><i class="fa fa-check"></i><b>22.8</b> Indistinguishability obfuscation</a></li></ul></li><li class="chapter" data-level="23" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html"><i class="fa fa-check"></i><b>23</b> More obfuscation, exotic encryptions</a><ul><li class="chapter" data-level="23.1" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#slower-weaker-less-securer"><i class="fa fa-check"></i><b>23.1</b> Slower, weaker, less securer</a></li><li class="chapter" data-level="23.2" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#how-to-get-ibe-from-pairing-based-assumptions."><i class="fa fa-check"></i><b>23.2</b> How to get IBE from pairing based assumptions.</a></li><li class="chapter" data-level="23.3" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#beyond-pairing-based-cryptography"><i class="fa fa-check"></i><b>23.3</b> Beyond pairing based cryptography</a></li></ul></li><li class="chapter" data-level="24" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html"><i class="fa fa-check"></i><b>24</b> Anonymous communication</a><ul><li class="chapter" data-level="24.1" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#steganography"><i class="fa fa-check"></i><b>24.1</b> Steganography</a></li><li class="chapter" data-level="24.2" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#anonymous-routing"><i class="fa fa-check"></i><b>24.2</b> Anonymous routing</a></li><li class="chapter" data-level="24.3" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#tor"><i class="fa fa-check"></i><b>24.3</b> Tor</a></li><li class="chapter" data-level="24.4" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#telex"><i class="fa fa-check"></i><b>24.4</b> Telex</a></li><li class="chapter" data-level="24.5" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#riposte"><i class="fa fa-check"></i><b>24.5</b> Riposte</a></li></ul></li><li class="chapter" data-level="25" data-path="lec_24_policy.html"><a href="lec_24_policy.html"><i class="fa fa-check"></i><b>25</b> Ethical, moral, and policy dimensions to cryptography</a><ul><li class="chapter" data-level="25.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#reading-prior-to-lecture"><i class="fa fa-check"></i><b>25.1</b> Reading prior to lecture:</a></li><li class="chapter" data-level="25.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#case-studies."><i class="fa fa-check"></i><b>25.2</b> Case studies.</a><ul><li class="chapter" data-level="25.2.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#the-snowden-revelations"><i class="fa fa-check"></i><b>25.2.1</b> The Snowden revelations</a></li><li class="chapter" data-level="25.2.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#fbi-vs-apple-case"><i class="fa fa-check"></i><b>25.2.2</b> FBI vs Apple case</a></li><li class="chapter" data-level="25.2.3" data-path="lec_24_policy.html"><a href="lec_24_policy.html#juniper-backdoor-case-and-the-opm-break-in"><i class="fa fa-check"></i><b>25.2.3</b> Juniper backdoor case and the OPM break-in</a></li></ul></li></ul></li><li class="chapter" data-level="26" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html"><i class="fa fa-check"></i><b>26</b> Course recap</a><ul><li class="chapter" data-level="26.1" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#some-things-we-did-not-cover"><i class="fa fa-check"></i><b>26.1</b> Some things we did not cover</a></li><li class="chapter" data-level="26.2" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#what-i-hope-you-learned"><i class="fa fa-check"></i><b>26.2</b> What I hope you learned</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Pseudorandom functions</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/crypto/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/crypto/lec_04_pseudorandom-functions.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="pseudorandom-functions" data-number="4">Pseudorandom functions</h1>
<p>In the last lecture we saw the notion of <em>pseudorandom generators</em>, and introduced the <strong>PRG conjecture</strong>, which stated that there exists a pseudorandom generator mapping <span><span class="math inline">\(n\)</span></span> bits to <span><span class="math inline">\(n+1\)</span></span> bits. We have seen the <em>length extension</em> theorem, which states that given such a pseudorandom generator, there exists a generator mapping <span><span class="math inline">\(n\)</span></span> bits to <span><span class="math inline">\(m\)</span></span> bits for an arbitrarily large polynomial <span><span class="math inline">\(m(n)\)</span></span>. But can we extend it even further? Say, to <span><span class="math inline">\(2^n\)</span></span> bits? Does this question even make sense? And why would we want to do that? This is the topic of this lecture.</p>
<p>At a first look, the notion of extending the output length of a pseudorandom generator to <span><span class="math inline">\(2^n\)</span></span> bits seems nonsensical. After all, we want our generator to be <em>efficient</em> and just writing down the output will take exponential time. However, there is a way around this conundrum. While we can’t efficiently write down the full output, we can require that it would be possible, given an index <span><span class="math inline">\(i\in \{0,\ldots,2^n-1\}\)</span></span>, to compute the <span><span class="math inline">\(i^{th}\)</span></span> bit of the output in polynomial time.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> That is, we require that the function <span><span class="math inline">\(i \mapsto G(s)_i\)</span></span> is efficiently computable and (by security of the pseudorandom generator) indistinguishable from a function that maps each index <span><span class="math inline">\(i\)</span></span> to an independent random bit in <span><span class="math inline">\(\{0,1\}\)</span></span>. This is the notion of a <em>pseudorandom function generator</em> which is a bit subtle to define and construct, but turns out to have a great many applications in cryptography.</p>
<div id="prfdef" class="definition" title="Pseudorandom Function Generator" data-number="4" name="Definition 4.1 (Pseudorandom Function Generator) ">
<p>An efficiently computable function <span><span class="math inline">\(F\)</span></span> taking two inputs <span><span class="math inline">\(s\in\{0,1\}^n\)</span></span> and <span><span class="math inline">\(i\in \{0,\ldots,2^n-1\}\)</span></span> and outputting a single bit <span><span class="math inline">\(F(s,i)\)</span></span> is a <em>pseudorandom function (PRF) generator</em> if for every polynomial time adversary <span><span class="math inline">\(A\)</span></span> outputting a single bit and polynomial <span><span class="math inline">\(p(n)\)</span></span>, if <span><span class="math inline">\(n\)</span></span> is large enough then:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[ \left| \E_{s\in\{0,1\}^n}[ A^{F(s,\cdot)}(1^n)] - \E_{H \leftarrow_R [2^n]\rightarrow\{0,1\}}[A^H(1^n)] \right| &lt; 1/p(n) \;.\]</span></div></span></p>
</div>
<p>Some notes on notation are in order. The input <span><span class="math inline">\(1^n\)</span></span> is simply a string of <span><span class="math inline">\(n\)</span></span> ones, and it is a typical cryptography convention to assume that such an input is always given to the adversary. This is simply because by “polynomial time adversary” we really mean polynomial in <span><span class="math inline">\(n\)</span></span> (which is our key size or security parameter)<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>. The notation <span><span class="math inline">\(A^{F(s,\cdot)}\)</span></span> means that <span><span class="math inline">\(A\)</span></span> has <em>black box</em> (also known as <em>oracle</em>) access to the function that maps <span><span class="math inline">\(i\)</span></span> to <span><span class="math inline">\(F(s,i)\)</span></span>. That is, <span><span class="math inline">\(A\)</span></span> can choose an index <span><span class="math inline">\(i\)</span></span>, query the box and get <span><span class="math inline">\(F(s,i)\)</span></span>, then choose a new index <span><span class="math inline">\(i&#39;\)</span></span>, query the box to get <span><span class="math inline">\(F(s,i&#39;)\)</span></span>, and so on for a polynomial number of queries. The notation <span><span class="math inline">\(H \leftarrow_R [2^n] \rightarrow \{0,1\}\)</span></span> means that <span><span class="math inline">\(H\)</span></span> is a completely random function that maps every index <span><span class="math inline">\(i\)</span></span> to an independent and random different bit.</p>
<div id="randfuncs" class="remark" title="Completely Random Functions" data-number="4" name="Remark 4.2 (Completely Random Functions) ">
<p>This notion of a randomly chosen function can be difficult to wrap your mind around. Try to imagine a table of all of the strings in <span><span class="math inline">\(\{0, 1\}^n\)</span></span>. We now go to each possible input, randomly generate a bit to be its output, and write down the result in the table. When we’re done, we have a length <span><span class="math inline">\(2^n\)</span></span> lookup table that maps each input to an output that was generated uniformly at random and independently of all other outputs. This lookup table is now our random function <span><span class="math inline">\(H\)</span></span>.</p>
<p>In practice it’s too cumbersome to actually generate all <span><span class="math inline">\(2^n\)</span></span> bits, and sometimes in theory it’s convenient to think of each output as generated only after a query is made. This leads to adopting the <em>lazy evaluation model</em>. In the lazy evaluation model, we imagine that a lazy person is sitting in a room with the same lookup table as before, but with all entries blank. If someone makes some query <span><span class="math inline">\(H(s)\)</span></span>, the lazy person checks if the entry for <span><span class="math inline">\(s\)</span></span> in the lookup table is blank. If so, the lazy evaluator generates a random bit, writes down the result for <span><span class="math inline">\(s\)</span></span>, and returns it. Otherwise, if an output has already been generated for <span><span class="math inline">\(s\)</span></span> previously (because <span><span class="math inline">\(s\)</span></span> has been queried before), the lazy evaluator simply returns this value. Can you see why this model is more convenient in some ways?</p>
<p>One last way to think about how a completely random function is determined is to first observe that there exist a total of <span><span class="math inline">\(2^{2^n}\)</span></span> functions from <span><span class="math inline">\(\{0, 1\}^n\)</span></span> to <span><span class="math inline">\(\{0, 1\}\)</span></span> (can you see why? It may be easier to think of them as functions from <span><span class="math inline">\([2^n]\)</span></span> to ${0, 1}). We choose one of them uniformly at random to be <span><span class="math inline">\(H\)</span></span>, and it’s still the case that for any given input <span><span class="math inline">\(s\)</span></span> the result <span><span class="math inline">\(H(s)\)</span></span> is <span><span class="math inline">\(0\)</span></span> or <span><span class="math inline">\(1\)</span></span> with equal probability independent of any other input.</p>
<p>Regardless of which model we use to think about generating <span><span class="math inline">\(H\)</span></span>, after we’ve chosen <span><span class="math inline">\(H\)</span></span> and put it in a black box, the behavior of <span><span class="math inline">\(H\)</span></span> is in some sense “deterministic” because given the same query it will always return the same result. However, before we ever make any given query <span><span class="math inline">\(s\)</span></span> we can only guess <span><span class="math inline">\(H(s)\)</span></span> correctly with probability <span><span class="math inline">\(\tfrac{1}{2}\)</span></span>, because without previously observing <span><span class="math inline">\(H(s)\)</span></span> it is effectively random and undecided to us (just like in the lazy evaluator model).</p>
</div>
<div id="section" class="pause" data-number="4" name="Pause">
<p>Now would be a fantastic time to stop and think deeply about the three constructions in the remark above, and in particular why they are all equivalent. If you don’t feel like thinking then at the very least you should make a mental note to come back later if you’re confused, because this idea will be very useful down the road.</p>
</div>
<p>Thus, the notation <span><span class="math inline">\(A^H\)</span></span> in the PRF definition means <span><span class="math inline">\(A\)</span></span> has access to a completely random black box that returns a random bit for any new query made, and on previously seen queries returns the same bit as before. Finally one last note: below we will identify the set <span><span class="math inline">\([2^n] = \{0,\ldots,2^n-1\}\)</span></span> with the set <span><span class="math inline">\(\{0,1\}^n\)</span></span> (there is a one to one mapping between those sets using the binary representation), and so we will treat <span><span class="math inline">\(i\)</span></span> interchangeably as a number in <span><span class="math inline">\([2^n]\)</span></span> or a string in <span><span class="math inline">\(\{0,1\}^n\)</span></span>.</p>
<p>Informally, if <span><span class="math inline">\(F\)</span></span> is a pseudorandom function generator, then if we choose a random string <span><span class="math inline">\(s\)</span></span> and consider the function <span><span class="math inline">\(f_s\)</span></span> defined by <span><span class="math inline">\(f_s(i) = F(s,i)\)</span></span>, no efficient algorithm can distinguish between black box access to <span><span class="math inline">\(f_s(\cdot)\)</span></span> and black box access to a completely random function (see <a href='#prfmodelfig'>Figure 4.1</a>). Notably, black box access implies that a priori the adversary does not know which function it’s querying. From the adversary’s point of view, they query some oracle <span><span class="math inline">\(O\)</span></span> (which behind the scenes is either <span><span class="math inline">\(f_s(\cdot)\)</span></span> or <span><span class="math inline">\(H\)</span></span>), and must decide if <span><span class="math inline">\(O = f_s(\cdot)\)</span></span> or <span><span class="math inline">\(O = H\)</span></span>. Thus often instead of talking about a pseudorandom function generator we will refer to a <em>pseudorandom function collection</em> <span><span class="math inline">\(\{ f_s \}\)</span></span> where by that we mean the map <span><span class="math inline">\(F(s,i)=f_s(i)\)</span></span> is a pseudorandom function generator.</p>
<figure>
<img src="../figure/pseudorandom_function.jpg" alt="4.1: In a pseudorandom function, an adversary cannot tell whether they are given a black box that computes the function i \mapsto F(s,i) for some secret s that was chosen at random and fixed, or whether the black box computes a completely random function that tosses a fresh random coin whenever it’s given a new input i." id="prfmodelfig" style="width:50.0%" /><figcaption>4.1: In a pseudorandom function, an adversary cannot tell whether they are given a black box that computes the function <span><span class="math inline">\(i \mapsto F(s,i)\)</span></span> for some secret <span><span class="math inline">\(s\)</span></span> that was chosen at random and fixed, or whether the black box computes a completely random function that tosses a fresh random coin whenever it’s given a new input <span><span class="math inline">\(i\)</span></span>.</figcaption>
</figure>
<p>In the next lecture we will see the proof of following theorem (due to Goldreich, Goldwasser, and Micali)</p>
<div id="prffromprgthmone" class="theorem" title="PRFs from PRGs" data-number="4" name="Theorem 4.3 (PRFs from PRGs) ">
<p>Assuming the PRG conjecture, there exists a secure pseudorandom function generator.</p>
</div>
<p>But before we see the proof of <a href='#prffromprgthmone'>Theorem 4.3</a>, let us see why pseudorandom functions could be useful.</p>
<h2 id="one-time-passwords-e.g.-google-authenticator-rsa-id-etc." data-number="4.1">One time passwords (e.g. Google Authenticator, RSA ID, etc.)</h2>
<p>Until now we have talked about the task of <em>encryption</em>, or protecting the <em>secrecy</em> of messages. But the task of <em>authentication</em>, or protecting the <em>integrity</em> of messages is no less important. For example, consider the case that you receive a software update for your PC, phone, car, pacemaker, etc. over an open channel such as an unencrypted Wi-Fi connection. The contents of that update are not secret, but it is of crucial importance that it was unchanged from the message sent out by the company and that no malicious attacker had modified the code. Similarly, when you log into your bank, you might be much more concerned about the possibility of someone impersonating you and cleaning out your account than you are about the secrecy of your information.</p>
<p>Let’s start with a very simple scenario which we’ll call <strong>the login problem</strong>. <strong>Alice</strong> and <strong>Bob</strong> share a key as before, but now Alice wants to simply prove her identity to Bob. What makes this challenging is that this time they need to contend with not the passive eavesdropping Eve but the active adversary <strong>Mallory</strong>, who completely controls the communication channel between them and can modify (or <em>mall</em>) any message that they send. Specifically for the identity proving case, we think of the following scenario. Each instance of such an <strong>identification protocol</strong> consists of some interaction between Alice and Bob that ends with Bob deciding whether to accept it as authentic or reject as an impersonation attempt. Mallory’s goal is to fool Bob into accepting her as Alice.</p>
<p>The most basic way to try to solve the login problem is by simply using a <em>password</em>. That is, if we assume that Alice and Bob can share a key, we can treat this key as some secret password <span><span class="math inline">\(p\)</span></span> that was selected at random from <span><span class="math inline">\(\{0,1\}^n\)</span></span> (and hence can only be guessed with probability <span><span class="math inline">\(2^{-n}\)</span></span>). Why doesn’t Alice simply send <span><span class="math inline">\(p\)</span></span> to Bob to prove to him her identity? A moment’s thought shows that this would be a very bad idea. Since Mallory is controlling the communication line, she would learn <span><span class="math inline">\(p\)</span></span> after the first identification attempt and could then easily impersonate Alice in future interactions. However, we seem to have just the tool to protect the secrecy of <span><span class="math inline">\(p\)</span></span>— <em>encryption</em>. Suppose that Alice and Bob share a secret key <span><span class="math inline">\(k\)</span></span> and an additional secret password <span><span class="math inline">\(p\)</span></span>. Wouldn’t a simple way to solve the login problem be for Alice to send to Bob an encryption of the password <span><span class="math inline">\(p\)</span></span>? After all, the security of the encryption should guarantee that Mallory can’t learn <span><span class="math inline">\(p\)</span></span>, right?</p>
<div id="section-1" class="pause" data-number="4.1" name="Pause">
<p>This would be a good time to stop reading and try to think for yourself whether using a secure encryption to encrypt <span><span class="math inline">\(p\)</span></span> would guarantee security for the login problem. (No really, stop and think about it.)</p>
</div>
<p>The problem is that Mallory does not have to learn the password <span><span class="math inline">\(p\)</span></span> in order to impersonate Alice. For example, she can simply record the message Alice <span><span class="math inline">\(c_1\)</span></span> sends to Bob in the first session and then <em>replay</em> it to Bob in the next session. Since the message is a valid encryption of <span><span class="math inline">\(p\)</span></span>, then Bob would accept it from Mallory! (This is known as a <em>replay attack</em> and is a common attack one needs to protect against in cryptographic protocols.) One can try to put in countermeasures to defend against this particular attack, but its existence demonstrates that secrecy of the password does not guarantee security of the login protocol.</p>
<h3 id="how-do-pseudorandom-functions-help-in-the-login-problem" data-number="4.1.1">How do pseudorandom functions help in the login problem?</h3>
<p>The idea is that they create what’s known as a <em>one time password</em>. Alice and Bob will share an index <span><span class="math inline">\(s\in\{0,1\}^n\)</span></span> for the pseudorandom function generator <span><span class="math inline">\(\{ f_s \}\)</span></span>. When Alice wants to prove to Bob her identity, Bob will choose a random <span><span class="math inline">\(i\leftarrow_R\{0,1\}^n\)</span></span>, and send <span><span class="math inline">\(i\)</span></span> to Alice, and then Alice will send <span><span class="math inline">\(f_s(i),f_s(i+1),\ldots,f_s(i+\ell-1)\)</span></span> to Bob where <span><span class="math inline">\(\ell\)</span></span> is some parameter (you can think of <span><span class="math inline">\(\ell=n\)</span></span> for simplicity). Bob will check that indeed <span><span class="math inline">\(y=f_s(i)\)</span></span> and if so accept the session as authentic.</p>
<p>The formal protocol is as follows:</p>
<p><strong>Protocol</strong> <code>PRF-Login</code><strong>:</strong></p>
<ul>
<li>Shared input: <span><span class="math inline">\(s\in\{0,1\}^n\)</span></span>. Alice and Bob treat it as a seed for a pseudorandom function generator <span><span class="math inline">\(\{ f_s \}\)</span></span>.</li>
<li>In every session Alice and Bob do the following:
<ol type="1">
<li>Bob chooses a random <span><span class="math inline">\(i\leftarrow_R[2^n]\)</span></span> and sends <span><span class="math inline">\(i\)</span></span> to Alice.</li>
<li>Alice sends <span><span class="math inline">\(y_1,\ldots,y_\ell\)</span></span> to Bob where <span><span class="math inline">\(y_j = f_s(i+j-1)\)</span></span>.</li>
<li>Bob checks that for every <span><span class="math inline">\(j\in\{1,\ldots,\ell\}\)</span></span>, <span><span class="math inline">\(y_j = f_s(i+j-1)\)</span></span> and if so accepts the session; otherwise he rejects it.</li>
</ol></li>
</ul>
<p>As we will see it’s not really crucial that the input <span><span class="math inline">\(i\)</span></span> (which is known in crypto parlance as a <em>nonce</em>) is random. What is crucial is that it never repeats itself, to foil a replay attack. For this reason in many applications Alice and Bob compute <span><span class="math inline">\(i\)</span></span> as a function of the current time (for example, the index of the current minute based on some agreed-upon starting point), and hence we can make it into a one message protocol. Also the parameter <span><span class="math inline">\(\ell\)</span></span> is sometimes chosen to be deliberately short so that it will be easy for people to type the values <span><span class="math inline">\(y_1,\ldots,y_\ell\)</span></span>.</p>
<figure>
<img src="../figure/google-authenticator.jpg" alt="21.1: The Google Authenticator app is one popular example of a one-time password scheme using pseudorandom functions. Another example is RSA’s SecurID token." id="tmplabelfig" class="margin" /><figcaption>21.1: The Google Authenticator app is one popular example of a one-time password scheme using pseudorandom functions. Another example is RSA’s SecurID token.</figcaption>
</figure>
<p><em>Why is this secure?</em> The key to understanding schemes using pseudorandom functions is to imagine what would happen if instead of a <em>pseudo</em> random function, <span><span class="math inline">\(f_s\)</span></span> would be an <em>actual</em> random function. In a truly random function, every one of the values <span><span class="math inline">\(f_s(0),\ldots,f_s(2^n-1)\)</span></span> is chosen independently and uniformly at random from <span><span class="math inline">\(\{0,1\}\)</span></span>. One useful way to imagine this is using the concept of “lazy evaluation”. We can think of <span><span class="math inline">\(f_S\)</span></span> as determined by tossing <span><span class="math inline">\(2^n\)</span></span> different coins for the values <span><span class="math inline">\(f(0),\ldots,f(2^n-1)\)</span></span>. Now consider the case where we don’t actually toss the <span><span class="math inline">\(i^{th}\)</span></span> coin until we need it. The crucial point is that if we have queried the function in <span><span class="math inline">\(T\ll 2^n\)</span></span> places, then when Bob chooses a random <span><span class="math inline">\(i\in[2^n]\)</span></span> it is <em>extremely unlikely</em> that any one of the set <span><span class="math inline">\(\{i,i+1,\ldots,i+\ell-1\}\)</span></span> will be one of those locations that we previously queried. Thus, if the function was truly random, Mallory has <em>no information</em> on the value of the function in these coordinates, and would be able to predict (or rather, guess) it in all these locations with probability at most <span><span class="math inline">\(2^{-\ell}\)</span></span>.</p>
<div id="section-2" class="pause" data-number="4.1.1" name="Pause">
<p>Please make sure you understand the informal reasoning above, since we will now translate this into a formal theorem and proof.</p>
</div>
<div id="loginprfthm" class="theorem" title="Login protocol via PRF" data-number="4.1.1" name="Theorem 4.4 (Login protocol via PRF) ">
<p>Suppose that <span><span class="math inline">\(\{ f_s \}\)</span></span> is a secure pseudorandom function generator and Alice and Bob interact using Protocol <code>PRF-Login</code> for some polynomial number <span><span class="math inline">\(T\)</span></span> of sessions (over a channel controlled by Mallory). After observing these interactions, Mallory then interacts with Bob, where Bob follows the protocol’s instructions but Mallory has access to arbitrary efficient computation. Then, the probability that Bob accepts the interaction is at most <span><span class="math inline">\(2^{-\ell}+\mu(n)\)</span></span> where <span><span class="math inline">\(\mu(\cdot)\)</span></span> is some negligible function.</p>
</div>
<div id="section-3" class="proof" data-ref="loginprfthm" data-number="4.1.1" name="Proof">
<p>This proof, as so many others in this course, uses an argument via contradiction. We assume, towards the sake of contradiction, that there exists an adversary <span><span class="math inline">\(M\)</span></span> (for Mallory) that can break the identification scheme <code>PRF-Login</code> with probability <span><span class="math inline">\(2^{-\ell}+\epsilon\)</span></span> after <span><span class="math inline">\(T\)</span></span> interactions. We then construct an attacker <span><span class="math inline">\(A\)</span></span> that can distinguish access to <span><span class="math inline">\(\{ f_s \}\)</span></span> from access to a random function in <span><span class="math inline">\(poly(T)\)</span></span> time and with bias at least <span><span class="math inline">\(\epsilon/2\)</span></span>.</p>
<p>How do we construct this adversary <span><span class="math inline">\(A\)</span></span>? The idea is as follows. First, we prove that if we ran the protocol <code>PRF-Login</code> using an <em>actual random</em> function, then <span><span class="math inline">\(M\)</span></span> would not be able to succeed in impersonating with probability better than <span><span class="math inline">\(2^{-\ell}+negligible\)</span></span>. Therefore, if <span><span class="math inline">\(M\)</span></span> does do better, then we can use that to distinguish <span><span class="math inline">\(f_s\)</span></span> from a random function. The adversary <span><span class="math inline">\(A\)</span></span> gets some black box <span><span class="math inline">\(O(\cdot)\)</span></span> (for <em>oracle</em>) and will use it while internally simulating all the parties— Alice, Bob and Mallory (using <span><span class="math inline">\(M\)</span></span>) in the <span><span class="math inline">\(T+1\)</span></span> interactions of the <code>PRF-Login</code> protocol. Whenever any of the parties needs to evaluate <span><span class="math inline">\(f_s(i)\)</span></span>, <span><span class="math inline">\(A\)</span></span> will forward <span><span class="math inline">\(i\)</span></span> to its black box <span><span class="math inline">\(O(\cdot)\)</span></span> and return the value <span><span class="math inline">\(O(i)\)</span></span>. It will then output <span><span class="math inline">\(1\)</span></span> if an only if <span><span class="math inline">\(M\)</span></span> succeeds in impersonation in this internal simulation. The argument above showed that if <span><span class="math inline">\(O(\cdot)\)</span></span> is a truly random function, then the probability that <span><span class="math inline">\(A\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> is at most <span><span class="math inline">\(2^{-\ell}+negligible\)</span></span> (and so in particular less than <span><span class="math inline">\(2^{-\ell}+\epsilon/2\)</span></span>). On the other hand, if <span><span class="math inline">\(O(\cdot)\)</span></span> is the function <span><span class="math inline">\(i \mapsto f_s(i)\)</span></span> for some fixed and random <span><span class="math inline">\(s\)</span></span>, then this probability is at least <span><span class="math inline">\(2^{-\ell}+\epsilon\)</span></span>. Thus <span><span class="math inline">\(A\)</span></span> will distinguish between the two cases with bias at least <span><span class="math inline">\(\epsilon/2\)</span></span>. We now turn to the formal proof:</p>
<p><strong>Claim 1:</strong> Let <code>PRF-Login*</code> be the hypothetical variant of the protocol <code>PRF-Login</code> where Alice and Bob share a completely random function <span><span class="math inline">\(H:[2^n]\rightarrow\{0,1\}\)</span></span>. Then, no matter what Mallory does, the probability she can impersonate Alice after observing <span><span class="math inline">\(T\)</span></span> interactions is at most <span><span class="math inline">\(2^{-\ell}+(8\ell T)/2^n\)</span></span>.</p>
<p>(If <code>PRF-Login*</code> is easier to prove secure than <code>PRF-Login</code>, you might wonder why we bother with <code>PRF-Login</code> in the first place and not simply use <code>PRF-Login*</code>. The reason is that specifying a random function <span><span class="math inline">\(H\)</span></span> requires specifying <span><span class="math inline">\(2^n\)</span></span> bits, and so that would be a <em>huge</em> shared key. So <code>PRF-Login*</code> is not a protocol we can actually run but rather a hypothetical “mental experiment” that helps us in arguing about the security of <code>PRF-Login</code>.)</p>
<p><strong>Proof of Claim 1:</strong> Let <span><span class="math inline">\(i_1,\ldots,i_{2T}\)</span></span> be the nonces chosen by Bob and recieved by Alice in the first <span><span class="math inline">\(T\)</span></span> iterations. That is, <span><span class="math inline">\(i_1\)</span></span> is the nonce chosen by Bob in the first iteration while <span><span class="math inline">\(i_2\)</span></span> is the nonce that Alice received in the first iteration (if Mallory doesn’t modify it then <span><span class="math inline">\(i_1=i_2\)</span></span>). Similarly, <span><span class="math inline">\(i_3\)</span></span> is the nonce chosen by Bob in the second iteration while <span><span class="math inline">\(i_4\)</span></span> is the nonce received by Alice and so on and so forth. Let <span><span class="math inline">\(i\)</span></span> be the nonce chosen in the <span><span class="math inline">\(T+1^{st}\)</span></span> iteration in which Mallory tries to impersonate Alice. We claim that the probability that there exists some <span><span class="math inline">\(j\in\{1,\ldots,2T\}\)</span></span> such that <span><span class="math inline">\(|i-i_j|&lt;2\ell\)</span></span> is at most <span><span class="math inline">\(8\ell T/2^n\)</span></span>. Indeed, let <span><span class="math inline">\(S\)</span></span> be the union of all the intervals of the form <span><span class="math inline">\(\{ i_j-2\ell+1,\ldots, i_j+2\ell-1 \}\)</span></span> for <span><span class="math inline">\(1 \leq j \leq 2T\)</span></span>. Since it’s a union of <span><span class="math inline">\(2T\)</span></span> intervals each of length less than <span><span class="math inline">\(4\ell\)</span></span>, <span><span class="math inline">\(S\)</span></span> contains at most <span><span class="math inline">\(8T\ell\)</span></span> elements, so the probability that <span><span class="math inline">\(i\in S\)</span></span> is <span><span class="math inline">\(|S|/2^n \leq (8T\ell)/2^n\)</span></span>. Now, if there does <em>not</em> exists a <span><span class="math inline">\(j\)</span></span> such that <span><span class="math inline">\(|i-i_j|&lt;2\ell\)</span></span> then it means in particular that all the queries to <span><span class="math inline">\(H(\cdot)\)</span></span> made by either Alice or Bob during the first <span><span class="math inline">\(T\)</span></span> iterations are disjoint from the interval <span><span class="math inline">\(\{ i,i+1,\ldots,i+\ell-1 \}\)</span></span>. Since <span><span class="math inline">\(H(\cdot)\)</span></span> is a completely random function, the values <span><span class="math inline">\(H(i),\ldots,H(i+\ell-1)\)</span></span> are chosen uniformly and independently from all the rest of the values of this function. Since Mallory’s message <span><span class="math inline">\(y\)</span></span> to Bob in the <span><span class="math inline">\(T+1^{st}\)</span></span> iteration depends only on what she observed in the past, the values <span><span class="math inline">\(H(i),\ldots,H(i+\ell-1)\)</span></span> are <em>independent</em> from <span><span class="math inline">\(y\)</span></span>, and hence under this condition that there is no overlap between this interval and prior queries, the probability that they equal <span><span class="math inline">\(y\)</span></span> is <span><span class="math inline">\(2^{-\ell}\)</span></span>. QED (Claim 1).</p>
<p>The proof of Claim 1 is not hard but it is somewhat subtle, so it’s good to go over it again and make sure you understand it.</p>
<p>Now that we have Claim 1, the proof of the theorem follows as outlined above. We build an adversary <span><span class="math inline">\(A\)</span></span> to the pseudorandom function generator from <span><span class="math inline">\(M\)</span></span> by having <span><span class="math inline">\(A\)</span></span> simulate “inside its belly” all the parties Alice, Bob and Mallory and output <span><span class="math inline">\(1\)</span></span> if Mallory succeeds in impersonating. Since we assumed <span><span class="math inline">\(\epsilon\)</span></span> is non-negligible and <span><span class="math inline">\(T\)</span></span> is polynomial, we can assume that <span><span class="math inline">\((8\ell T)/2^n &lt; \epsilon/2\)</span></span> and hence by Claim 1, if the black box is a random function, then we are in the <code>PRF-Login*</code> setting and Mallory’s success will be at most <span><span class="math inline">\(2^{-\ell}+\epsilon/2\)</span></span>. If the black box is <span><span class="math inline">\(f_s(\cdot)\)</span></span>, then we get exactly the <code>PRF-Login</code> setting and hence under our assumption the success will be at least <span><span class="math inline">\(2^{-\ell}+\epsilon\)</span></span>. We conclude that the difference in probability of <span><span class="math inline">\(A\)</span></span> outputting <span><span class="math inline">\(1\)</span></span> between the random and pseudorandom case is at least <span><span class="math inline">\(\epsilon/2\)</span></span> thus contradicting the security of the pseudorandom function generator.</p>
</div>
<div id="outputincprfrem" class="remark" title="Increasing output length of PRFs" data-number="4.1.1" name="Remark 4.5 (Increasing output length of PRFs) ">
<p>In the course of constructing this one-time-password scheme from a PRF, we have actually proven a general statement that is useful on its own: that we can transform standard PRF which is a collection <span><span class="math inline">\(\{ f_s \}\)</span></span> of functions mapping <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span>, into a PRF where the functions have a longer output <span><span class="math inline">\(\ell\)</span></span> (see the problem set for a formal statement of this result) Thus from now on whenever we are given a PRF, we will allow ourselves to assume that it has any output size that is convenient for us.</p>
</div>
<h2 id="message-authentication-codes" data-number="4.2">Message Authentication Codes</h2>
<p>One time passwords are a tool allowing you to prove your <em>identity</em> to, say, your email server. But even after you did so, how can the server trust that future communication comes from you and not from some attacker that can interfere with the communication channel between you and the server (so called “man in the middle” attack)? Similarly, one time passwords may allow a software company to prove their identity before they send you a software update, but how do you know that an attacker does not change some bits of this software update on route between their servers and your device?</p>
<p>This is where <em>Message Authentication Codes (MACs)</em> come into play- their role is to authenticate not only the <em>identity</em> of the parties but also their <em>communication</em>. Once again we have <strong>Alice</strong> and <strong>Bob</strong>, and the adversary <strong>Mallory</strong> who can actively modify messages (in contrast to the passive eavesdropper Eve). Similar to the case to encryption, Alice has a <em>message</em> <span><span class="math inline">\(m\)</span></span> she wants to send to Bob, but now we are not concerned with Mallory <em>learning</em> the contents of the message. Rather, we want to make sure that Bob gets precisely the message <span><span class="math inline">\(m\)</span></span> sent by Alice. Actually this is too much to ask for, since Mallory can always decide to block all communication, but we can ask that either Bob gets precisely <span><span class="math inline">\(m\)</span></span> or he detects failure and accepts no message at all. Since we are in the <em>private key</em> setting, we assume that Alice and Bob share a key <span><span class="math inline">\(k\)</span></span> that is unknown to Mallory.</p>
<p>What kind of security would we want? We clearly want Mallory not to be able to cause Bob to accept a message <span><span class="math inline">\(m&#39;\neq m\)</span></span>. But, like in the encryption setting, we want more than that. We would like Alice and Bob to be able to use the same key for <em>many</em> messages. So, Mallory might observe the interactions of Alice and Bob on messages <span><span class="math inline">\(m_1,\ldots,m_T\)</span></span> before trying to cause Bob to accept a message <span><span class="math inline">\(m&#39;_{T+1} \neq m_{T+1}\)</span></span>. In fact, to make our notion of security more robust, we will even allow Mallory to <em>choose</em> the messages <span><span class="math inline">\(m_1,\ldots,m_T\)</span></span> (this is known as a <em>chosen message</em> or <em>chosen plaintext</em> attack). The resulting formal definition is below:</p>
<div id="MACdef" class="definition" title="Message Authentication Codes (MAC)" data-number="4.2" name="Definition 4.6 (Message Authentication Codes (MAC)) ">
<p>Let <span><span class="math inline">\((S,V)\)</span></span> (for <em>sign</em> and <em>verify</em>) be a pair of efficiently computable algorithms where <span><span class="math inline">\(S\)</span></span> takes as input a key <span><span class="math inline">\(k\)</span></span> and a message <span><span class="math inline">\(m\)</span></span>, and produces a tag <span><span class="math inline">\(\tau \in \{0,1\}^*\)</span></span>, while <span><span class="math inline">\(V\)</span></span> takes as input a key <span><span class="math inline">\(k\)</span></span>, a message <span><span class="math inline">\(m\)</span></span>, and a tag <span><span class="math inline">\(\tau\)</span></span>, and produces a bit <span><span class="math inline">\(b\in\{0,1\}\)</span></span>. We say that <span><span class="math inline">\((S,V)\)</span></span> is a <em>Message Authentication Code (MAC)</em> if:</p>
<ul>
<li>For every key <span><span class="math inline">\(k\)</span></span> and message <span><span class="math inline">\(m\)</span></span>, <span><span class="math inline">\(V_k(m,S_k(m))=1\)</span></span>.<br />
</li>
<li>For every polynomial-time adversary <span><span class="math inline">\(A\)</span></span> and polynomial <span><span class="math inline">\(p(n)\)</span></span>, it is with less than <span><span class="math inline">\(1/p(n)\)</span></span> probability over the choice of <span><span class="math inline">\(k\leftarrow_R\{0,1\}^n\)</span></span> that <span><span class="math inline">\(A^{S_k(\cdot)}(1^n)=(m&#39;,\tau&#39;)\)</span></span> such that <span><span class="math inline">\(m&#39;\)</span></span> is <em>not</em> one of the messages <span><span class="math inline">\(A\)</span></span> queries and <span><span class="math inline">\(V_k(m&#39;,\tau&#39;)=1\)</span></span>.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></li>
</ul>
</div>
<p>If Alice and Bob share the key <span><span class="math inline">\(k\)</span></span>, then to send a message <span><span class="math inline">\(m\)</span></span> to Bob, Alice will simply send over the pair <span><span class="math inline">\((m,\tau)\)</span></span> where <span><span class="math inline">\(\tau = S_k(m)\)</span></span>. If Bob receives a message <span><span class="math inline">\((m&#39;,\tau&#39;)\)</span></span>, then he will accept <span><span class="math inline">\(m&#39;\)</span></span> if and only if <span><span class="math inline">\(V_k(m&#39;,\tau&#39;)=1\)</span></span>. Mallory now observes <span><span class="math inline">\(t\)</span></span> rounds of communication of the form <span><span class="math inline">\((m_i,S_k(m_i))\)</span></span> for messages <span><span class="math inline">\(m_1,\ldots,m_t\)</span></span> of her choice, and her goal is to try to create a new message <span><span class="math inline">\(m&#39;\)</span></span> that was <em>not</em> sent by Alice, but for which she can forge a valid tag <span><span class="math inline">\(\tau&#39;\)</span></span> that will pass verification. Our notion of security guarantees that she’ll only be able to do so with negligible probability, in which case the MAC is <strong>CMA-secure</strong>.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></p>
<div id="choosemessages" class="remark" title="Why can Mallory choose the messages?" data-number="4.2" name="Remark 4.7 (Why can Mallory choose the messages?) ">
<p>The notion of a “chosen message attack” might seem a little “over the top”. After all, Alice is going to send to Bob the messages of <em>her</em> choice, rather than those chosen by her adversary Mallory. However, as cryptographers have learned time and again the hard way, it is better to be conservative in our security definitions and think of an attacker that has as much power as possible. First of all, we want a message authentication code that will work for <em>any</em> sequence of messages, and so it’s better to consider this “worst case” setting of allowing Mallory to choose them. Second, in many realistic settings an adversary could have some effect on the messages that are being sent by the parties. This has occurred time and again in cases ranging from web servers to German submarines in World War II, and we’ll return to this point when we talk about <em>chosen plaintext</em> and <em>chosen ciphertext</em> attacks on encryption schemes.</p>
</div>
<div id="strongunforgability" class="remark" title="Strong unforgability" data-number="4.2" name="Remark 4.8 (Strong unforgability) ">
<p>Some texts (such as Boneh Shoup) define a stronger notion of unforgability where the adversary cannot even produce new signatures for messages it <em>has</em> queried in the attack. That is, the adversary cannot produce a valid message-signature pair that it has not seen before. This stronger definition can be useful for some applications. It is fairly easy to transform MACs satisfying <a href='#MACdef'>Definition 4.6</a> into MACs satisfying strong unforgability. In particular, if the signing function is deterministic, and we use a <em>canonical verifier algorithm</em> where <span><span class="math inline">\(V_k(m,\sigma)=1\)</span></span> iff <span><span class="math inline">\(S_k(m)=\sigma\)</span></span> then weak unforgability automatically implies strong unforgability since every message has a single signature that would pass verification (can you see why?).</p>
</div>
<h2 id="macs-from-prfs" data-number="4.3">MACs from PRFs</h2>
<p>We now show how pseudorandom function generators yield message authentication codes. In fact, the construction is so immediate that much of the more applied cryptographic literature does not distinguish between these two concepts, and uses the name “Message Authentication Codes” to refer to both MAC’s and PRF’s. However, since this is not applied cryptographic literature, the distinction is rather important.</p>
<div id="MACfromPRFthm" class="theorem" title="MAC Theorem" data-number="4.3" name="Theorem 4.9 (MAC Theorem) ">
<p>Under the PRF Conjecture, there exists a secure MAC.</p>
</div>
<div id="section-4" class="proof" data-ref="MACfromPRFthm" data-number="4.3" name="Proof">
<p>Let <span><span class="math inline">\(F(\cdot,\cdot)\)</span></span> be a secure pseudorandom function generator with <span><span class="math inline">\(n/2\)</span></span> bits output (as mentioned in <a href='#outputincprfrem'>Remark 4.5</a>, such PRF’s can be constructed from one bit output PRF’s). We define <span><span class="math inline">\(S_k(m) = F(k,m)\)</span></span> and <span><span class="math inline">\(V_k(m,\tau)\)</span></span> to output <span><span class="math inline">\(1\)</span></span> iff <span><span class="math inline">\(F_k(m)=\tau\)</span></span>. Suppose towards the sake of contradiction that there exists an adversary <span><span class="math inline">\(A\)</span></span> breaks the security of this construction of a MAC. That is, <span><span class="math inline">\(A\)</span></span> queries <span><span class="math inline">\(S_k(\cdot)\)</span></span> <span><span class="math inline">\(poly(n)\)</span></span> many times and with probability <span><span class="math inline">\(1/p(n)\)</span></span> for some polynomial <span><span class="math inline">\(p\)</span></span> outputs <span><span class="math inline">\((m&#39;,\tau&#39;)\)</span></span> that she did <em>not</em> ask for such that <span><span class="math inline">\(F(k,m&#39;)=\tau&#39;\)</span></span>.</p>
</div>
<p>We use <span><span class="math inline">\(A\)</span></span> to construct an adversary <span><span class="math inline">\(A&#39;\)</span></span> that can distinguish between oracle access to a PRF and a random function by simulating the MAC security game inside <span><span class="math inline">\(A&#39;\)</span></span>. Every time <span><span class="math inline">\(A\)</span></span> requests the signature of some message <span><span class="math inline">\(m\)</span></span>, <span><span class="math inline">\(A&#39;\)</span></span> returns <span><span class="math inline">\(O(m)\)</span></span>. When <span><span class="math inline">\(A\)</span></span> returns <span><span class="math inline">\((m&#39;, \tau&#39;)\)</span></span> at the end of the <span><span class="math inline">\(\ensuremath{\mathit{MAC}}\)</span></span> game, <span><span class="math inline">\(A&#39;\)</span></span> returns <span><span class="math inline">\(1\)</span></span> if <span><span class="math inline">\(O(m&#39;) = \tau&#39;\)</span></span>, and <span><span class="math inline">\(0\)</span></span> otherwise. If <span><span class="math inline">\(O(\cdot) = H(\cdot)\)</span></span> for some completely random function <span><span class="math inline">\(H(\cdot)\)</span></span>, then the value <span><span class="math inline">\(H(m&#39;)\)</span></span> would be completely random in <span><span class="math inline">\(\{0,1\}^{n/2}\)</span></span> and independent of all prior queries. Hence the probability that this value would equal <span><span class="math inline">\(\tau&#39;\)</span></span> is at most <span><span class="math inline">\(2^{-n/2}\)</span></span>. If instead <span><span class="math inline">\(O(\cdot) = F_k(\cdot)\)</span></span>, then by the fact that <span><span class="math inline">\(A\)</span></span> wins the MAC security game with probability <span><span class="math inline">\(1/p(n)\)</span></span>, the adversary <span><span class="math inline">\(A&#39;\)</span></span> will output <span><span class="math inline">\(1\)</span></span> with probability <span><span class="math inline">\(1/p(n)\)</span></span>. That means that such an adversary <span><span class="math inline">\(A&#39;\)</span></span> can distinguish between an oracle to <span><span class="math inline">\(F_k(\cdot)\)</span></span> and an oracle to a random function <span><span class="math inline">\(H\)</span></span>, which gives us a contradiction.</p>
<h2 id="input-length-extension-for-macs-and-prfs" data-number="4.4">Input length extension for MACs and PRFs</h2>
<p>So far we required the message to be signed <span><span class="math inline">\(m\)</span></span> to be no longer than the key <span><span class="math inline">\(k\)</span></span> (i.e., both <span><span class="math inline">\(n\)</span></span> bits long). However, it is not hard to see that this requirement is not really needed. If our message is longer, we can divide it into blocks <span><span class="math inline">\(m_1,\ldots,m_t\)</span></span> and sign each message <span><span class="math inline">\((i,m_i)\)</span></span> individually. The disadvantage here is that the size of the tag (i.e., MAC output) will grow with the size of the message. However, even this is not really needed. Because the tag has length <span><span class="math inline">\(n/2\)</span></span> for length <span><span class="math inline">\(n\)</span></span> messages, we can sign the <em>tags</em> <span><span class="math inline">\(\tau_1,\ldots,\tau_t\)</span></span> and only output those. The verifier can repeat this computation to verify this. We can continue this way and so get tags of <span><span class="math inline">\(O(n)\)</span></span> length for arbitrarily long messages. Hence in the future, whenever we need to, we will assume that our PRFs and MACs can get inputs in <span><span class="math inline">\(\{0,1\}^*\)</span></span> — i.e., arbitrarily length strings.</p>
<p>We note that this issue of length extension is actually quite a thorny and important one in practice. The above approach is not the most efficient way to achieve this, and there are several more practical variants in the literature (see Boneh-Shoup Sections 6.4-6.8). Also, one needs to be very careful on the exact way one chops the message into blocks and pads it to an integer multiple of the block size. Several attacks have been mounted on schemes that performed this incorrectly.</p>
<h2 id="aside-natural-proofs" data-number="4.5">Aside: natural proofs</h2>
<p>Pseudorandom functions play an important role in computational complexity, where they have been used as a way to give “barrier results” for proving results such as <span><span class="math inline">\(\mathbf{P}\neq \mathbf{NP}\)</span></span>.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> Specifically, the <a href="https://goo.gl/fiH3Pe">Natural Proofs</a> barrier for proving circuit lower bounds says that if strong enough pseudorandom functions exist, then certain types of arguments are bound to fail. These are arguments which come up with a property <span><span class="math inline">\(\ensuremath{\mathit{EASY}}\)</span></span> of a Boolean function <span><span class="math inline">\(f:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> such that:</p>
<ul>
<li><p>If <span><span class="math inline">\(f\)</span></span> can be computed by a polynomial sized circuit, then it has the property <span><span class="math inline">\(\ensuremath{\mathit{EASY}}\)</span></span>.</p></li>
<li><p>The property <span><span class="math inline">\(\ensuremath{\mathit{EASY}}\)</span></span> fails to hold for a random function with high probability.</p></li>
<li><p>Checking whether <span><span class="math inline">\(\ensuremath{\mathit{EASY}}\)</span></span> holds can be done in time polynomial <em>in the truth table size of <span><span class="math inline">\(f\)</span></span></em>. That is, in <span><span class="math inline">\(2^{O(n)}\)</span></span> time.</p></li>
</ul>
<p>A priori these technical conditions might not seem very “natural” but it turns out that many approaches for proving circuit lower bounds (for restricted families of circuits) have this form. The idea is that such approaches find a “non generic” property of easily computable function, such as finding some interesting correlations between the some input bits and the output. These are correlations that are unlikely to occur in random functions. The lower bound typically follows by exhibiting a function <span><span class="math inline">\(f_0\)</span></span> that does not have this property, and then using that to derive that <span><span class="math inline">\(f_0\)</span></span> cannot be efficiently computed by this particular restricted family of circuits.</p>
<p>The existence of strong enough pseudorandom functions can be shown to contradict the existence of such a property <span><span class="math inline">\(\ensuremath{\mathit{EASY}}\)</span></span>, since a pseudorandom function can be computed by a polynomial sized circuit, but it cannot be distinguished from a random function. While a priori a pseudorandom function is only secure for polynomial time distinguishers, under certain assumptions it might be possible to create a pseudorandom function with a seed of size, say, <span><span class="math inline">\(n^5\)</span></span>, that would be secure with respect to adversaries running in time <span><span class="math inline">\(2^{O(n^2)}\)</span></span>.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>In this course we will often index strings and numbers starting from zero rather than one, and so typically index the coordinates of a string <span><span class="math inline">\(y\in \{0,1\}^N\)</span></span> as <span><span class="math inline">\(0,\ldots,N-1\)</span></span> rather than <span><span class="math inline">\(1,\ldots,N\)</span></span>. But we will not be religious about it and occasionally “lapse” into one-based indexing. In almost all cases, this makes no difference.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>This also allows us to be consistent with the notion of “polynomial in the size of the input.”</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>Clearly if the adversary outputs a pair <span><span class="math inline">\((m,\tau)\)</span></span> that it did query from its oracle then that pair will pass verification. This suggests the possibility of a <em>replay</em> attack whereby Mallory resends to Bob a message that Alice sent him in the past. As above, once can thwart this by insisting the every message <span><span class="math inline">\(m\)</span></span> begins with a fresh nonce or a value derived from the current time.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>A priori you might ask if we should not also give Mallory an oracle to <span><span class="math inline">\(V_k(\cdot)\)</span></span> as well. After all, in the course of those many interactions, Mallory could also send Bob many messages <span><span class="math inline">\((m&#39;,\tau&#39;)\)</span></span> of her choice, and observe from his behavior whether or not these passed verification. It is a good exercise to show that adding such an oracle does not change the power of the definition, though we note that this is decidedly <em>not</em> the case in the analogous question for encryption.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>This discussion has more to do with computational complexity than cryptography, and so can be safely skipped without harming understanding of future material in this course.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/crypto/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/crypto/issues?q=Pseudorandom functions+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 03/01/2020 16:59:40</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/crypto/lec_04_pseudorandom-functions.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
