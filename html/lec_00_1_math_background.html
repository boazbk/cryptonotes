<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: Mathematical Background</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: Mathematical Background" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#lecture-summary"><i class="fa fa-check"></i><b>16.1</b> Lecture summary</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.2</b> Exercises</a></li><li class="chapter" data-level="16.3" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.3</b> Bibliographical notes</a></li><li class="chapter" data-level="16.4" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#further-explorations"><i class="fa fa-check"></i><b>16.4</b> Further explorations</a></li><li class="chapter" data-level="16.5" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#acknowledgements"><i class="fa fa-check"></i><b>16.5</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.1</b> Exercises</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.2</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematical Background</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_00_1_math_background.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="chapmath" data-number="1">Mathematical Background</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>Recall basic mathematical notions such as sets, functions, numbers, logical operators and quantifiers, strings, and graphs.</li>
<li>Rigorously define Big-<span><span class="math inline">\(O\)</span></span> notation.</li>
<li>Proofs by induction.</li>
<li>Practice with reading mathematical <em>definitions</em>, <em>statements</em>, and <em>proofs</em>.</li>
<li>Transform an intuitive argument into a rigorous proof.</li>
</ul>
</div>
<blockquote>
<p><em>“I found that every number, which may be expressed from one to ten, surpasses the preceding by one unit: afterwards the ten is doubled or tripled … until a hundred; then the hundred is doubled and tripled in the same manner as the units and the tens … and so forth to the utmost limit of numeration.”</em>, Muhammad ibn Mūsā al-Khwārizmī, 820, translation by Fredric Rosen, 1831.</p>
</blockquote>
<p>In this chapter we review some of the mathematical concepts that we use in this book. These concepts are typically covered in courses or textbooks on “mathematics for computer science” or “discrete mathematics”; see the “Bibliographical Notes” section (<a href='#notesmathchap'>Section 1.9</a>) for several excellent resources on these topics that are freely-available online.</p>
<p><em>A mathematician’s apology.</em> Some students might wonder why this book contains so much math. Mathematics is a language for modeling concepts in a precise and unambiguous way. In this book we use math to model the concept of <em>computation</em>. For example, we will consider questions such as <em>“is there an efficient algorithm to find the prime factors of a given integer?”</em>. (We will see that this question is particularly interesting, touching on areas as far apart as Internet security and quantum mechanics!) To even <em>phrase</em> such a question, we need to give a precise <em>definition</em> of the notion of an <em>algorithm</em>, and of what it means for an algorithm to be <em>efficient</em>. Also, since there is no empirical experiment that will prove the <em>nonexistence</em> of an algorithm, the only way to establish such a result is using a <em>mathematical proof</em>.</p>
<h2 id="manualbackground" data-number="1.1">This chapter: a reader’s manual</h2>
<p>Depending on your background, you can approach this chapter in two different ways:</p>
<ul>
<li><p>If you already have taken a “discrete mathematics”, “mathematics for computer science” or similar courses, you can take a quick look at <a href='#secmathoverview'>Section 1.2</a> to see the main tools we will use, <a href='#notationsec'>Section 1.7</a> for our notation and conventions, and then skip ahead to the rest of this book. Alternatively, you can sit back, relax, and read this chapter just to get familiar with our notation, as well as to enjoy (or not) my philosophical musings and attempts at humor. You might also want to start brushing up on <em>discrete probability</em>, which we’ll use later in this book.</p></li>
<li><p>If your background is less extensive, see <a href='#notesmathchap'>Section 1.9</a> for some resources on these topics. This chapter briefly covers the concepts that we need, but you may find it helpful to see a more in-depth treatment. As usual with math, the best way to get comfort with this material is to work out exercises on your own.</p></li>
</ul>
<h2 id="secmathoverview" data-number="1.2">A quick overview of mathematical prerequisites</h2>
<p>The main mathematical concepts we use in this book are:</p>
<ul>
<li><p><strong>Proofs:</strong> First and foremost, this book involves a heavy dose of formal mathematical reasoning, which includes mathematical <em>definitions</em>, <em>statements</em>, and <em>proofs</em>.</p></li>
<li><p><strong>Sets:</strong> The basic set <em>relations</em> of membership (<span><span class="math inline">\(\in\)</span></span>) and containment (<span><span class="math inline">\(\subseteq\)</span></span>), and set <em>operations</em>, principally union (<span><span class="math inline">\(\cup\)</span></span>), intersection (<span><span class="math inline">\(\cap\)</span></span>), set difference (<span><span class="math inline">\(\setminus\)</span></span>) and Cartesian product (<span><span class="math inline">\(\times\)</span></span>).</p></li>
<li><p><strong>Tuples and strings:</strong> The set <span><span class="math inline">\(\Sigma^k\)</span></span> of length-<span><span class="math inline">\(k\)</span></span> strings/lists over elements in <span><span class="math inline">\(\Sigma\)</span></span>, where <span><span class="math inline">\(\Sigma\)</span></span> is some finite set which is called the <em>alphabet</em> (quite often <span><span class="math inline">\(\Sigma = \{0,1\}\)</span></span>). We use <span><span class="math inline">\(\Sigma^*\)</span></span> for the set of all strings of finite length.</p></li>
<li><p><strong>Some special sets:</strong> The set <span><span class="math inline">\(\N\)</span></span> of natural numbers. Following typical computer science convention, our indices start from zero and so we write <span><span class="math inline">\(\N = \{0,1,2,\ldots \}\)</span></span>. We use <span><span class="math inline">\([n]\)</span></span> for the set <span><span class="math inline">\(\{0,1,2,\ldots,n-1\}\)</span></span>. We use <span><span class="math inline">\(\{0,1\}^*\)</span></span> for the set of all binary strings and <span><span class="math inline">\(\{0,1\}^n\)</span></span> for the set of strings of length <span><span class="math inline">\(n\)</span></span> for some natural number <span><span class="math inline">\(n\in\N\)</span></span>. If <span><span class="math inline">\(x\)</span></span> is a string of length <span><span class="math inline">\(n\)</span></span>, then we refer to its elements by <span><span class="math inline">\(x_0,\ldots,x_{n-1}\)</span></span>.</p></li>
<li><p><strong>Functions:</strong> The <em>domain</em> and <em>codomain</em> of a function, properties such as being <em>one-to-one</em> (also known as <em>injective</em>) or <em>onto</em> (also known as <em>surjective</em>) functions, as well as <em>partial functions</em> (that, unlike standard or “total” functions, are not necessarily defined on all elements of their domain).</p></li>
<li><p><strong>Logical operations:</strong> The operations AND (<span><span class="math inline">\(\wedge\)</span></span>), OR (<span><span class="math inline">\(\vee\)</span></span>), and NOT (<span><span class="math inline">\(\neg\)</span></span>) and the quantifiers “there exists” (<span><span class="math inline">\(\exists\)</span></span>) and “for all” (<span><span class="math inline">\(\forall\)</span></span>).</p></li>
<li><p><strong>Basic combinatorics:</strong> Notions such as <span><span class="math inline">\(\binom{n}{k}\)</span></span> (the number of <span><span class="math inline">\(k\)</span></span>-sized subsets of a set of size <span><span class="math inline">\(n\)</span></span>).</p></li>
<li><p><strong>Graphs:</strong> Undirected and directed graphs, connectivity, paths, and cycles.</p></li>
<li><p><strong>Big-<span><span class="math inline">\(O\)</span></span> notation:</strong> <span><span class="math inline">\(O,o,\Omega,\omega,\Theta\)</span></span> notation for analyzing asymptotic growth of functions.</p></li>
<li><p><strong>Discrete probability:</strong> We will use <em>probability theory</em>, and specifically probability over <em>finite</em> samples spaces such as tossing <span><span class="math inline">\(n\)</span></span> coins, including notions such as <em>random variables</em>, <em>expectation</em>, and <em>concentration</em>. We will only use probability theory in the second half of this text, and will review it beforehand. However, probabilistic reasoning is a subtle (and extremely useful!) skill, and it’s always good to start early in acquiring it.</p></li>
</ul>
<p>In the rest of this chapter we briefly review the above notions. This is partially to remind the reader and reinforce material that might not be fresh in your mind, and partially to introduce our notation and conventions which might occasionally differ from those you’ve encountered before.</p>
<h2 id="reading-mathematical-texts" data-number="1.3">Reading mathematical texts</h2>
<p>Reading mathematical texts take practice to get used to the notation and symbols. Mathematicians use jargon for the same reason that it is used in many other professions such engineering, law, medicine, and others. We want to make terms <em>precise</em> and introduce shorthand for concepts that are frequently reused. Mathematical texts tend to “pack a lot of punch” per sentence, and so the key is to read them slowly and carefully, parsing each symbol at a time.</p>
<p>With time and practice you will see that reading mathematical texts becomes easier and jargon is no longer an issue. Moreover, reading mathematical texts is one of the most transferable skills you could take from this book. Our world is changing rapidly, not just in the realm of technology, but also in many other human endeavors, whether it is medicine, economics, law or even culture. Whatever your future aspirations, it is likely that you will encounter texts that use new concepts that you have not seen before (see <a href='#alphagozerofig'>Figure 1.1</a> and <a href='#zerocashfig'>Figure 1.2</a> for two recent examples from current “hot areas”). Being able to internalize and then apply new definitions can be hugely important. It is a skill that’s much easier to acquire in the relatively safe and stable context of a mathematical course, where one at least has the guarantee that the concepts are fully specified, and you have access to your teaching staff for questions.</p>
<figure>
<img src="../figure/alphagozero.png" alt="1.1: A snippet from the “methods” section of the “AlphaGo Zero” paper by Silver et al, Nature, 2017." id="alphagozerofig" class="margin" /><figcaption>1.1: A snippet from the “methods” section of the <a href="https://goo.gl/k8pVpL">“AlphaGo Zero” paper</a> by Silver et al, <em>Nature</em>, 2017.</figcaption>
</figure>
<figure>
<img src="../figure/zerocash.png" alt="1.2: A snippet from the “Zerocash” paper of Ben-Sasson et al, that forms the basis of the cryptocurrency startup Zcash." id="zerocashfig" class="margin" /><figcaption>1.2: A snippet from the <a href="http://zerocash-project.org/paper">“Zerocash” paper</a> of Ben-Sasson et al, that forms the basis of the cryptocurrency startup Zcash.</figcaption>
</figure>
<p>The basic components of a mathematical text are <strong>definitions</strong>, <strong>assertions</strong> and <strong>proofs</strong>.</p>
<h3 id="definitions" data-number="1.3.1">Definitions</h3>
<p>Mathematicians often define new concepts in terms of old concepts.<br />
Here is a mathematical definition which you may have encountered in the past (and will see again shortly):</p>
<div id="onetoonedef" class="definition" title="One to one function" name="Definition 1.1 (One to one function) ">
<p>Let <span><span class="math inline">\(S,T\)</span></span> be sets. We say that a function <span><span class="math inline">\(f:S \rightarrow T\)</span></span> is <em>one to one</em> (also known as <em>injective</em>) if for every two elements <span><span class="math inline">\(x,x&#39; \in S\)</span></span>, if <span><span class="math inline">\(x \neq x&#39;\)</span></span> then <span><span class="math inline">\(f(x) \neq f(x&#39;)\)</span></span>.</p>
</div>
<p><a href='#onetoonedef'>Definition 1.1</a> captures a simple concept, but even so it uses quite a bit of notation. When reading such a definition, it is often useful to annotate it with a pen as you’re going through it, as in <a href='#onetoonedefannotatedef'>Figure 1.3</a>. For example, when you see an identifier such as <span><span class="math inline">\(f\)</span></span>, <span><span class="math inline">\(S\)</span></span> or <span><span class="math inline">\(x\)</span></span>, make sure that you realize what sort of object is it: is it a set, a function, an element, a number, a gremlin? You might also find it useful to explain the definition in words to a friend (or to yourself).</p>
<figure>
<img src="../figure/onetoonedef.png" alt="1.3: An annotated form of , marking which type is every object, and with a doodle explaining what the definition says." id="onetoonedefannotatedef" class="margin" /><figcaption>1.3: An annotated form of <a href='#onetoonedef'>Definition 1.1</a>, marking which type is every object, and with a doodle explaining what the definition says.</figcaption>
</figure>
<h3 id="assertions-theorems-lemmas-claims" data-number="1.3.2">Assertions: Theorems, lemmas, claims</h3>
<p>Theorems, lemmas, claims and the like are true statements about the concepts that we defined. Deciding whether to call a particular statement a “Theorem”, a “Lemma” or a “Claim” is a judgement call, and does not make a mathematical difference. All three correspond to true statements which can be proven. The difference is that a <em>Theorem</em> refers to a significant result, that we would want to remember and highlight. A <em>Lemma</em> often refers to a technical result, that is not necessarily important in its own right, but can be often very useful in proving other theorems. A <em>Claim</em> is a “throw away” statement, that we need to use in order to prove some other bigger results, but do not care so much about for its own sake.</p>
<h3 id="proofs" data-number="1.3.3">Proofs</h3>
<p>Mathematical <em>proofs</em> are the arguments we use to demonstrate that our theorems, lemmas, and claims area indeed true. We discuss proofs in <a href='#proofsbackgroundsec'>Section 1.5</a> below, but the main point is that the mathematical standard of proof is very high. Unlike in some other realms, in mathematics a proof is an “airtight” argument that demonstrates that the statement is true beyond a shadow of a doubt. Some examples in this section for mathematical proofs are given in <a href='#simplepathlemex'>Solvedexercise 1.1</a> and <a href='#topsortsec'>Section 1.6</a>. As mentioned in the preface, as a general rule, it is more important you understand the <strong>definitions</strong> than the <strong>theorems</strong>, and it is more important you understand a <strong>theorem statement</strong> than its <strong>proof</strong>.</p>
<h2 id="basic-discrete-math-objects" data-number="1.4">Basic discrete math objects</h2>
<p>In this section we quickly review some of the mathematical objects (the “basic data structures” of mathematics, if you will) we use in this book.</p>
<h3 id="sets" data-number="1.4.1">Sets</h3>
<p>A <em>set</em> is an unordered collection of objects. For example, when we write <span><span class="math inline">\(S = \{ 2,4, 7 \}\)</span></span>, we mean that <span><span class="math inline">\(S\)</span></span> denotes the set that contains the numbers <span><span class="math inline">\(2\)</span></span>, <span><span class="math inline">\(4\)</span></span>, and <span><span class="math inline">\(7\)</span></span>. (We use the notation “<span><span class="math inline">\(2 \in S\)</span></span>” to denote that <span><span class="math inline">\(2\)</span></span> is an element of <span><span class="math inline">\(S\)</span></span>.) Note that the set <span><span class="math inline">\(\{ 2, 4, 7 \}\)</span></span> and <span><span class="math inline">\(\{ 7 , 4, 2 \}\)</span></span> are identical, since they contain the same elements. Also, a set either contains an element or does not contain it – there is no notion of containing it “twice” – and so we could even write the same set <span><span class="math inline">\(S\)</span></span> as <span><span class="math inline">\(\{ 2, 2, 4, 7\}\)</span></span> (though that would be a little weird). The <em>cardinality</em> of a finite set <span><span class="math inline">\(S\)</span></span>, denoted by <span><span class="math inline">\(|S|\)</span></span>, is the number of elements it contains. (Cardinality can be defined for <em>infinite</em> sets as well; see the sources in <a href='#notesmathchap'>Section 1.9</a>.) So, in the example above, <span><span class="math inline">\(|S|=3\)</span></span>. A set <span><span class="math inline">\(S\)</span></span> is a <em>subset</em> of a set <span><span class="math inline">\(T\)</span></span>, denoted by <span><span class="math inline">\(S \subseteq T\)</span></span>, if every element of <span><span class="math inline">\(S\)</span></span> is also an element of <span><span class="math inline">\(T\)</span></span>. (We can also describe this by saying that <span><span class="math inline">\(T\)</span></span> is a <em>superset</em> of <span><span class="math inline">\(S\)</span></span>.) For example, <span><span class="math inline">\(\{2,7\} \subseteq \{ 2,4,7\}\)</span></span>. The set that contains no elements is known as the <em>empty set</em> and it is denoted by <span><span class="math inline">\(\emptyset\)</span></span>. If <span><span class="math inline">\(A\)</span></span> is a subset of <span><span class="math inline">\(B\)</span></span> that is not equal to <span><span class="math inline">\(B\)</span></span> we say that <span><span class="math inline">\(A\)</span></span> is a <em>strict subset</em> of <span><span class="math inline">\(B\)</span></span>, and denote this by <span><span class="math inline">\(A \subsetneq B\)</span></span>.</p>
<p>We can define sets by either listing all their elements or by writing down a rule that they satisfy such as <span>
<div class='myequationbox'><span class="math display">\[
\text{EVEN} = \{ x  \;|\; \text{ $x=2y$ for some non-negative integer $y$} \} \;.
\]</span></div></span></p>
<p>Of course there is more than one way to write the same set, and often we will use intuitive notation listing a few examples that illustrate the rule. For example, we can also define <span><span class="math inline">\(\text{EVEN}\)</span></span> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\text{EVEN} = \{ 0,2,4, \ldots \} \;.
\]</span></div></span></p>
<p>Note that a set can be either finite (such as the set <span><span class="math inline">\(\{2,4,7\}\)</span></span>) or infinite (such as the set <span><span class="math inline">\(\text{EVEN}\)</span></span>). Also, the elements of a set don’t have to be numbers. We can talk about the sets such as the set <span><span class="math inline">\(\{a,e,i,o,u \}\)</span></span> of all the vowels in the English language, or the set <span><span class="math inline">\(\{\)</span></span><code>New York</code>, <code>Los Angeles</code>, <code>Chicago</code>, <code>Houston</code>, <code>Philadelphia</code>, <code>Phoenix</code>, <code>San Antonio</code>, <code>San Diego</code>, <code>Dallas</code><span><span class="math inline">\(\}\)</span></span> of all cities in the U.S. with population more than one million per the 2010 census. A set can even have other sets as elements, such as the set <span><span class="math inline">\(\{ \emptyset, \{1,2\},\{2,3\},\{1,3\} \}\)</span></span> of all even-sized subsets of <span><span class="math inline">\(\{1,2,3\}\)</span></span>.</p>
<p><strong>Operations on sets:</strong> The <em>union</em> of two sets <span><span class="math inline">\(S,T\)</span></span>, denoted by <span><span class="math inline">\(S \cup T\)</span></span>, is the set that contains all elements that are either in <span><span class="math inline">\(S\)</span></span> <em>or</em> in <span><span class="math inline">\(T\)</span></span>. The <em>intersection</em> of <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span>, denoted by <span><span class="math inline">\(S \cap T\)</span></span>, is the set of elements that are both in <span><span class="math inline">\(S\)</span></span> <em>and</em> in <span><span class="math inline">\(T\)</span></span>. The <em>set difference</em> of <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span>, denoted by <span><span class="math inline">\(S \setminus T\)</span></span> (and in some texts also by <span><span class="math inline">\(S-T\)</span></span>), is the set of elements that are in <span><span class="math inline">\(S\)</span></span> but <em>not</em> in <span><span class="math inline">\(T\)</span></span>.</p>
<p><strong>Tuples, lists, strings, sequences:</strong> A <em>tuple</em> is an <em>ordered</em> collection of items. For example <span><span class="math inline">\((1,5,2,1)\)</span></span> is a tuple with four elements (also known as a <span><span class="math inline">\(4\)</span></span>-tuple or quadruple). Since order matters, this is not the same tuple as the <span><span class="math inline">\(4\)</span></span>-tuple <span><span class="math inline">\((1,1,5,2)\)</span></span> or the <span><span class="math inline">\(3\)</span></span>-tuple <span><span class="math inline">\((1,5,2)\)</span></span>. A <span><span class="math inline">\(2\)</span></span>-tuple is also known as a <em>pair</em>. We use the terms <em>tuples</em> and <em>lists</em> interchangeably. A tuple where every element comes from some finite set <span><span class="math inline">\(\Sigma\)</span></span> (such as <span><span class="math inline">\(\{0,1\}\)</span></span>) is also known as a <em>string</em>. Analogously to sets, we denote the <em>length</em> of a tuple <span><span class="math inline">\(T\)</span></span> by <span><span class="math inline">\(|T|\)</span></span>. Just like sets, we can also think of infinite analogues of tuples, such as the ordered collection <span><span class="math inline">\((1,4,9,\ldots )\)</span></span> of all perfect squares. Infinite ordered collections are known as <em>sequences</em>; we might sometimes use the term “infinite sequence” to emphasize this, and use “finite sequence” as a synonym for a tuple. (We can identify a sequence <span><span class="math inline">\((a_0,a_1,a_2,\ldots)\)</span></span> of elements in some set <span><span class="math inline">\(S\)</span></span> with a <em>function</em> <span><span class="math inline">\(A:\N \rightarrow S\)</span></span> (where <span><span class="math inline">\(a_n = A(n)\)</span></span> for every <span><span class="math inline">\(n\in \N\)</span></span>). Similarly, we can identify a <span><span class="math inline">\(k\)</span></span>-tuple <span><span class="math inline">\((a_0,\ldots,a_{k-1})\)</span></span> of elements in <span><span class="math inline">\(S\)</span></span> with a function <span><span class="math inline">\(A:[k] \rightarrow S\)</span></span>.)</p>
<p><strong>Cartesian product:</strong> If <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span> are sets, then their <em>Cartesian product</em>, denoted by <span><span class="math inline">\(S \times T\)</span></span>, is the set of all ordered pairs <span><span class="math inline">\((s,t)\)</span></span> where <span><span class="math inline">\(s\in S\)</span></span> and <span><span class="math inline">\(t\in T\)</span></span>. For example, if <span><span class="math inline">\(S = \{1,2,3 \}\)</span></span> and <span><span class="math inline">\(T = \{10,12 \}\)</span></span>, then <span><span class="math inline">\(S\times T\)</span></span> contains the <span><span class="math inline">\(6\)</span></span> elements <span><span class="math inline">\((1,10),(2,10),(3,10),(1,12),(2,12),(3,12)\)</span></span>. Similarly if <span><span class="math inline">\(S,T,U\)</span></span> are sets then <span><span class="math inline">\(S\times T \times U\)</span></span> is the set of all ordered triples <span><span class="math inline">\((s,t,u)\)</span></span> where <span><span class="math inline">\(s\in S\)</span></span>, <span><span class="math inline">\(t\in T\)</span></span>, and <span><span class="math inline">\(u\in U\)</span></span>. More generally, for every positive integer <span><span class="math inline">\(n\)</span></span> and sets <span><span class="math inline">\(S_0,\ldots,S_{n-1}\)</span></span>, we denote by <span><span class="math inline">\(S_0 \times S_1 \times \cdots \times S_{n-1}\)</span></span> the set of ordered <span><span class="math inline">\(n\)</span></span>-tuples <span><span class="math inline">\((s_0,\ldots,s_{n-1})\)</span></span> where <span><span class="math inline">\(s_i\in S_i\)</span></span> for every <span><span class="math inline">\(i \in \{0,\ldots, n-1\}\)</span></span>. For every set <span><span class="math inline">\(S\)</span></span>, we denote the set <span><span class="math inline">\(S\times S\)</span></span> by <span><span class="math inline">\(S^2\)</span></span>, <span><span class="math inline">\(S\times S\times S\)</span></span> by <span><span class="math inline">\(S^3\)</span></span>, <span><span class="math inline">\(S\times S\times S \times S\)</span></span> by <span><span class="math inline">\(S^4\)</span></span>, and so on and so forth.</p>
<h3 id="specialsets" data-number="1.4.2">Special sets</h3>
<p>There are several sets that we will use in this book time and again. The set</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\N = \{ 0, 1,2, \ldots \}
\]</span></div></span> contains all <em>natural numbers</em>, i.e., non-negative integers. For any natural number <span><span class="math inline">\(n\in\N\)</span></span>, we define the set <span><span class="math inline">\([n]\)</span></span> as <span><span class="math inline">\(\{0,\ldots, n-1\} = \{ k\in \N : k &lt; n \}\)</span></span>. (We start our indexing of both <span><span class="math inline">\(\N\)</span></span> and <span><span class="math inline">\([n]\)</span></span> from <span><span class="math inline">\(0\)</span></span>, while many other texts index those sets from <span><span class="math inline">\(1\)</span></span>. Starting from zero or one is simply a convention that doesn’t make much difference, as long as one is consistent about it.)</p>
<p>We will also occasionally use the set <span><span class="math inline">\(\Z=\{\ldots,-2,-1,0,+1,+2,\ldots \}\)</span></span> of (negative and non-negative) <em>integers</em>,<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> as well as the set <span><span class="math inline">\(\R\)</span></span> of <em>real</em> numbers. (This is the set that includes not just the integers, but also fractional and irrational numbers; e.g., <span><span class="math inline">\(\R\)</span></span> contains numbers such as <span><span class="math inline">\(+0.5\)</span></span>, <span><span class="math inline">\(-\pi\)</span></span>, etc.) We denote by <span><span class="math inline">\(\R_+\)</span></span> the set <span><span class="math inline">\(\{ x\in \R : x &gt; 0 \}\)</span></span> of <em>positive</em> real numbers. This set is sometimes also denoted as <span><span class="math inline">\((0,\infty)\)</span></span>.</p>
<p><strong>Strings:</strong> Another set we will use time and again is</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\{0,1\}^n = \{ (x_0,\ldots,x_{n-1}) \;:\; x_0,\ldots,x_{n-1} \in \{0,1\}  \}
\]</span></div></span> which is the set of all <span><span class="math inline">\(n\)</span></span>-length binary strings for some natural number <span><span class="math inline">\(n\)</span></span>. That is <span><span class="math inline">\(\{0,1\}^n\)</span></span> is the set of all <span><span class="math inline">\(n\)</span></span>-tuples of zeroes and ones. This is consistent with our notation above: <span><span class="math inline">\(\{0,1\}^2\)</span></span> is the Cartesian product <span><span class="math inline">\(\{0,1\} \times \{0,1\}\)</span></span>, <span><span class="math inline">\(\{0,1\}^3\)</span></span> is the product <span><span class="math inline">\(\{0,1\} \times \{0,1\} \times \{0,1\}\)</span></span> and so on.</p>
<p>We will write the string <span><span class="math inline">\((x_0,x_1,\ldots,x_{n-1})\)</span></span> as simply <span><span class="math inline">\(x_0x_1\cdots x_{n-1}\)</span></span>. For example,</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\{0,1\}^3 = \{ 000 , 001, 010 , 011, 100, 101, 110, 111 \} \;.
\]</span></div></span></p>
<p>For every string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(i\in [n]\)</span></span>, we write <span><span class="math inline">\(x_i\)</span></span> for the <span><span class="math inline">\(i^{th}\)</span></span> element of <span><span class="math inline">\(x\)</span></span>.</p>
<p>We will also often talk about the set of binary strings of <em>all</em> lengths, which is</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\{0,1\}^* = \{ (x_0,\ldots,x_{n-1}) \;:\; n\in\N \;,\;, x_0,\ldots,x_{n-1} \in \{0,1\} \} \;.
\]</span></div></span></p>
<p>Another way to write this set is as <span>
<div class='myequationbox'><span class="math display">\[
\{0,1\}^* = \{0,1\}^0 \cup \{0,1\}^1 \cup \{0,1\}^2 \cup \cdots
\]</span></div></span> or more concisely as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\{0,1\}^* = \cup_{n\in\N} \{0,1\}^n \;.
\]</span></div></span></p>
<p>The set <span><span class="math inline">\(\{0,1\}^*\)</span></span> includes the “string of length <span><span class="math inline">\(0\)</span></span>” or “the empty string”, which we will denote by <span><span class="math inline">\(\ensuremath{\text{\texttt{&quot;&quot;}}}\)</span></span>. (In using this notation we follow the convention of many programming languages. Other texts sometimes use <span><span class="math inline">\(\epsilon\)</span></span> or <span><span class="math inline">\(\lambda\)</span></span> to denote the empty string.)</p>
<p><strong>Generalizing the star operation:</strong> For every set <span><span class="math inline">\(\Sigma\)</span></span>, we define</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\Sigma^* = \cup_{n\in \N} \Sigma^n \;.\]</span></div></span> For example, if <span><span class="math inline">\(\Sigma = \{a,b,c,d,\ldots,z \}\)</span></span> then <span><span class="math inline">\(\Sigma^*\)</span></span> denotes the set of all finite length strings over the alphabet a-z.</p>
<p><strong>Concatenation:</strong> The <em>concatenation</em> of two strings <span><span class="math inline">\(x\in \Sigma^n\)</span></span> and <span><span class="math inline">\(y\in \Sigma^m\)</span></span> is the <span><span class="math inline">\((n+m)\)</span></span>-length string <span><span class="math inline">\(xy\)</span></span> obtained by writing <span><span class="math inline">\(y\)</span></span> after <span><span class="math inline">\(x\)</span></span>. That is, if <span><span class="math inline">\(x \in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(y\in \{0,1\}^m\)</span></span>, then <span><span class="math inline">\(xy\)</span></span> is equal to the string <span><span class="math inline">\(z\in \{0,1\}^{n+m}\)</span></span> such that for <span><span class="math inline">\(i\in [n]\)</span></span>, <span><span class="math inline">\(z_i=x_i\)</span></span> and for <span><span class="math inline">\(i\in \{n,\ldots,n+m-1\}\)</span></span>, <span><span class="math inline">\(z_i = y_{i-n}\)</span></span>.</p>
<h3 id="functionsec" data-number="1.4.3">Functions</h3>
<p>If <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span> are nonempty sets, a <em>function</em> <span><span class="math inline">\(F\)</span></span> mapping <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span>, denoted by <span><span class="math inline">\(F:S \rightarrow T\)</span></span>, associates with every element <span><span class="math inline">\(x\in S\)</span></span> an element <span><span class="math inline">\(F(x)\in T\)</span></span>. The set <span><span class="math inline">\(S\)</span></span> is known as the <em>domain</em> of <span><span class="math inline">\(F\)</span></span> and the set <span><span class="math inline">\(T\)</span></span> is known as the <em>codomain</em> of <span><span class="math inline">\(F\)</span></span>. The <em>image</em> of a function <span><span class="math inline">\(F\)</span></span> is the set <span><span class="math inline">\(\{ F(x) \;|\; x\in S\}\)</span></span> which is the subset of <span><span class="math inline">\(F\)</span></span>’s codomain consisting of all output elements that are mapped from some input. (Some texts use <em>range</em> to denote the image of a function, while other texts use <em>range</em> to denote the codomain of a function. Hence we will avoid using the term “range” altogether.) As in the case of sets, we can write a function either by listing the table of all the values it gives for elements in <span><span class="math inline">\(S\)</span></span> or by using a rule. For example if <span><span class="math inline">\(S = \{0,1,2,3,4,5,6,7,8,9 \}\)</span></span> and <span><span class="math inline">\(T = \{0,1 \}\)</span></span>, then the table below defines a function <span><span class="math inline">\(F: S \rightarrow T\)</span></span>. Note that this function is the same as the function defined by the rule <span><span class="math inline">\(F(x)= (x \mod 2)\)</span></span>.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>
<table>
<caption>An example of a function.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Input</th>
<th style="text-align: left;">Output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">5</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">7</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">8</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">9</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p>If <span><span class="math inline">\(f:S \rightarrow T\)</span></span> satisfies that <span><span class="math inline">\(f(x)\neq f(y)\)</span></span> for all <span><span class="math inline">\(x \neq y\)</span></span> then we say that <span><span class="math inline">\(f\)</span></span> is <em>one-to-one</em> (<a href='#onetoonedef'>Definition 1.1</a>, also known as an <em>injective</em> function or simply an <em>injection</em>). If <span><span class="math inline">\(F\)</span></span> satisfies that for every <span><span class="math inline">\(y\in T\)</span></span> there is some <span><span class="math inline">\(x\in S\)</span></span> such that <span><span class="math inline">\(F(x)=y\)</span></span> then we say that <span><span class="math inline">\(F\)</span></span> is <em>onto</em> (also known as a <em>surjective</em> function or simply a <em>surjection</em>). A function that is both one-to-one and onto is known as a <em>bijective</em> function or simply a <em>bijection</em>. A bijection from a set <span><span class="math inline">\(S\)</span></span> to itself is also known as a <em>permutation</em> of <span><span class="math inline">\(S\)</span></span>. If <span><span class="math inline">\(F:S \rightarrow T\)</span></span> is a bijection then for every <span><span class="math inline">\(y\in T\)</span></span> there is a unique <span><span class="math inline">\(x\in S\)</span></span> such that <span><span class="math inline">\(F(x)=y\)</span></span>. We denote this value <span><span class="math inline">\(x\)</span></span> by <span><span class="math inline">\(F^{-1}(y)\)</span></span>. Note that <span><span class="math inline">\(F^{-1}\)</span></span> is itself a bijection from <span><span class="math inline">\(T\)</span></span> to <span><span class="math inline">\(S\)</span></span> (can you see why?).</p>
<p>Giving a bijection between two sets is often a good way to show they have the same size. In fact, the standard mathematical definition of the notion that “<span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span> have the same cardinality” is that there exists a bijection <span><span class="math inline">\(f:S \rightarrow T\)</span></span>. Further, the cardinality of a set <span><span class="math inline">\(S\)</span></span> is defined to be <span><span class="math inline">\(n\)</span></span> if there is a bijection from <span><span class="math inline">\(S\)</span></span> to the set <span><span class="math inline">\(\{0,\ldots,n-1\}\)</span></span>. As we will see later in this book, this is a definition that generalizes to defining the cardinality of <em>infinite</em> sets.</p>
<p><strong>Partial functions:</strong> We will sometimes be interested in <em>partial</em> functions from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span>. A partial function is allowed to be undefined on some subset of <span><span class="math inline">\(S\)</span></span>. That is, if <span><span class="math inline">\(F\)</span></span> is a partial function from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span>, then for every <span><span class="math inline">\(s\in S\)</span></span>, either there is (as in the case of standard functions) an element <span><span class="math inline">\(F(s)\)</span></span> in <span><span class="math inline">\(T\)</span></span>, or <span><span class="math inline">\(F(s)\)</span></span> is undefined. For example, the partial function <span><span class="math inline">\(F(x)= \sqrt{x}\)</span></span> is only defined on non-negative real numbers. When we want to distinguish between partial functions and standard (i.e., non-partial) functions, we will call the latter <em>total</em> functions. When we say “function” without any qualifier then we mean a <em>total</em> function.</p>
<p>The notion of partial functions is a strict generalization of functions, and so every function is a partial function, but not every partial function is a function. (That is, for every nonempty <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span>, the set of partial functions from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span> is a proper superset of the set of total functions from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span>.) When we want to emphasize that a function <span><span class="math inline">\(f\)</span></span> from <span><span class="math inline">\(A\)</span></span> to <span><span class="math inline">\(B\)</span></span> might not be total, we will write <span><span class="math inline">\(f: A \rightarrow_p B\)</span></span>. We can think of a partial function <span><span class="math inline">\(F\)</span></span> from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span> also as a total function from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T \cup \{ \bot \}\)</span></span> where <span><span class="math inline">\(\bot\)</span></span> is a special “failure symbol”. So, instead of saying that <span><span class="math inline">\(F\)</span></span> is undefined at <span><span class="math inline">\(x\)</span></span>, we can say that <span><span class="math inline">\(F(x)=\bot\)</span></span>.</p>
<p><strong>Basic facts about functions:</strong> Verifying that you can prove the following results is an excellent way to brush up on functions:</p>
<ul>
<li><p>If <span><span class="math inline">\(F:S \rightarrow T\)</span></span> and <span><span class="math inline">\(G:T \rightarrow U\)</span></span> are one-to-one functions, then their <em>composition</em> <span><span class="math inline">\(H:S \rightarrow U\)</span></span> defined as <span><span class="math inline">\(H(s)=G(F(s))\)</span></span> is also one to one.</p></li>
<li><p>If <span><span class="math inline">\(F:S \rightarrow T\)</span></span> is one to one, then there exists an onto function <span><span class="math inline">\(G:T \rightarrow S\)</span></span> such that <span><span class="math inline">\(G(F(s))=s\)</span></span> for every <span><span class="math inline">\(s\in S\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(G:T \rightarrow S\)</span></span> is onto then there exists a one-to-one function <span><span class="math inline">\(F:S \rightarrow T\)</span></span> such that <span><span class="math inline">\(G(F(s))=s\)</span></span> for every <span><span class="math inline">\(s\in S\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span> are finite sets then the following conditions are equivalent to one another: <strong>(a)</strong> <span><span class="math inline">\(|S| \leq |T|\)</span></span>, <strong>(b)</strong> there is a one-to-one function <span><span class="math inline">\(F:S \rightarrow T\)</span></span>, and <strong>(c)</strong> there is an onto function <span><span class="math inline">\(G:T \rightarrow S\)</span></span>. (This is actually true even for <em>infinite</em> <span><span class="math inline">\(S\)</span></span> and <span><span class="math inline">\(T\)</span></span>: in that case <strong>(b)</strong> (or equivalently <strong>(c)</strong>) is the commonly accepted <em>definition</em> for <span><span class="math inline">\(|S| \leq |T|\)</span></span>.)</p></li>
</ul>
<figure>
<img src="../figure/functionsdiagram.png" alt="1.4: We can represent finite functions as a directed graph where we put an edge from x to f(x). The onto condition corresponds to requiring that every vertex in the codomain of the function has in-degree at least one. The one-to-one condition corresponds to requiring that every vertex in the codomain of the function has in-degree at most one. In the examples above F is an onto function, G is one to one, and H is neither onto nor one to one." id="functionsdiagrampng" class="margin" /><figcaption>1.4: We can represent finite functions as a directed graph where we put an edge from <span><span class="math inline">\(x\)</span></span> to <span><span class="math inline">\(f(x)\)</span></span>. The <em>onto</em> condition corresponds to requiring that every vertex in the codomain of the function has in-degree <em>at least</em> one. The <em>one-to-one</em> condition corresponds to requiring that every vertex in the codomain of the function has in-degree <em>at most</em> one. In the examples above <span><span class="math inline">\(F\)</span></span> is an onto function, <span><span class="math inline">\(G\)</span></span> is one to one, and <span><span class="math inline">\(H\)</span></span> is neither onto nor one to one.</figcaption>
</figure>
<div id="section-1" class="pause" name="Pause">
<p>You can find the proofs of these results in many discrete math texts, including for example, Section 4.5 in the <a href="https://cs121.boazbarak.org/LLM_data_types.pdf">Lehman-Leighton-Meyer notes</a>. However, I strongly suggest you try to prove them on your own, or at least convince yourself that they are true by proving special cases of those for small sizes (e.g., <span><span class="math inline">\(|S|=3,|T|=4,|U|=5\)</span></span>).</p>
</div>
<p>Let us prove one of these facts as an example:</p>
<div id="onetooneimpliesonto" class="lemma" name="Lemma 1.2">
<p>If <span><span class="math inline">\(S,T\)</span></span> are non-empty sets and <span><span class="math inline">\(F:S \rightarrow T\)</span></span> is one to one, then there exists an onto function <span><span class="math inline">\(G:T \rightarrow S\)</span></span> such that <span><span class="math inline">\(G(F(s))=s\)</span></span> for every <span><span class="math inline">\(s\in S\)</span></span>.</p>
</div>
<div id="section-2" class="proof" data-ref="onetooneimpliesonto" name="Proof">
<p>Choose some <span><span class="math inline">\(s_0 \in S\)</span></span>. We will define the function <span><span class="math inline">\(G:T \rightarrow S\)</span></span> as follows: for every <span><span class="math inline">\(t\in T\)</span></span>, if there is some <span><span class="math inline">\(s\in S\)</span></span> such that <span><span class="math inline">\(F(s)=t\)</span></span> then set <span><span class="math inline">\(G(t)=s\)</span></span> (the choice of <span><span class="math inline">\(s\)</span></span> is well defined since by the one-to-one property of <span><span class="math inline">\(F\)</span></span>, there cannot be two distinct <span><span class="math inline">\(s,s&#39;\)</span></span> that both map to <span><span class="math inline">\(t\)</span></span>). Otherwise, set <span><span class="math inline">\(G(t)=s_0\)</span></span>. Now for every <span><span class="math inline">\(s\in S\)</span></span>, by the definition of <span><span class="math inline">\(G\)</span></span>, if <span><span class="math inline">\(t=F(s)\)</span></span> then <span><span class="math inline">\(G(t)=G(F(s))=s\)</span></span>. Moreover, this also shows that <span><span class="math inline">\(G\)</span></span> is <em>onto</em>, since it means that for every <span><span class="math inline">\(s\in S\)</span></span> there is some <span><span class="math inline">\(t\)</span></span>, namely <span><span class="math inline">\(t=F(s)\)</span></span>, such that <span><span class="math inline">\(G(t)=s\)</span></span>.</p>
</div>
<h3 id="graphsec" data-number="1.4.4">Graphs</h3>
<p><em>Graphs</em> are ubiquitous in Computer Science, and many other fields as well. They are used to model a variety of data types including social networks, scheduling constraints, road networks, deep neural nets, gene interactions, correlations between observations, and a great many more. Formal definitions of several kinds of graphs are given next, but if you have not seen graphs before in a course, I urge you to read up on them in one of the sources mentioned in <a href='#notesmathchap'>Section 1.9</a>.</p>
<p>Graphs come in two basic flavors: <em>undirected</em> and <em>directed</em>.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>
<figure>
<img src="../figure/graphsexampe.png" alt="1.5: An example of an undirected and a directed graph. The undirected graph has vertex set \{1,2,3,4\} and edge set \{ \{1,2\},\{2,3\},\{2,4\} \}. The directed graph has vertex set \{a,b,c\} and the edge set \{ (a,b),(b,c),(c,a),(a,c) \}." id="graphsexampefig" class="margin" data-offset="1.5in" /><figcaption>1.5: An example of an undirected and a directed graph. The undirected graph has vertex set <span><span class="math inline">\(\{1,2,3,4\}\)</span></span> and edge set <span><span class="math inline">\(\{ \{1,2\},\{2,3\},\{2,4\} \}\)</span></span>. The directed graph has vertex set <span><span class="math inline">\(\{a,b,c\}\)</span></span> and the edge set <span><span class="math inline">\(\{ (a,b),(b,c),(c,a),(a,c) \}\)</span></span>.</figcaption>
</figure>
<div id="undirgraph" class="definition" title="Undirected graphs" name="Definition 1.3 (Undirected graphs) ">
<p>An <em>undirected graph</em> <span><span class="math inline">\(G = (V,E)\)</span></span> consists of a set <span><span class="math inline">\(V\)</span></span> of <em>vertices</em> and a set <span><span class="math inline">\(E\)</span></span> of edges. Every edge is a size two subset of <span><span class="math inline">\(V\)</span></span>. We say that two vertices <span><span class="math inline">\(u,v \in V\)</span></span> are <em>neighbors</em>, if the edge <span><span class="math inline">\(\{u,v\}\)</span></span> is in <span><span class="math inline">\(E\)</span></span>.</p>
</div>
<p>Given this definition, we can define several other properties of graphs and their vertices. We define the <em>degree</em> of <span><span class="math inline">\(u\)</span></span> to be the number of neighbors <span><span class="math inline">\(u\)</span></span> has. A <em>path</em> in the graph is a tuple <span><span class="math inline">\((u_0,\ldots,u_k) \in V^{k+1}\)</span></span>, for some <span><span class="math inline">\(k&gt;0\)</span></span> such that <span><span class="math inline">\(u_{i+1}\)</span></span> is a neighbor of <span><span class="math inline">\(u_i\)</span></span> for every <span><span class="math inline">\(i\in [k]\)</span></span>. A <em>simple path</em> is a path <span><span class="math inline">\((u_0,\ldots,u_{k-1})\)</span></span> where all the <span><span class="math inline">\(u_i\)</span></span>’s are distinct. A <em>cycle</em> is a path <span><span class="math inline">\((u_0,\ldots,u_k)\)</span></span> where <span><span class="math inline">\(u_0=u_{k}\)</span></span>. We say that two vertices <span><span class="math inline">\(u,v\in V\)</span></span> are <em>connected</em> if either <span><span class="math inline">\(u=v\)</span></span> or there is a path from <span><span class="math inline">\((u_0,\ldots,u_k)\)</span></span> where <span><span class="math inline">\(u_0=u\)</span></span> and <span><span class="math inline">\(u_k=v\)</span></span>. We say that the graph <span><span class="math inline">\(G\)</span></span> is <em>connected</em> if every pair of vertices in it is connected.</p>
<p>Here are some basic facts about undirected graphs. We give some informal arguments below, but leave the full proofs as exercises (the proofs can be found in many of the resources listed in <a href='#notesmathchap'>Section 1.9</a>).</p>
<div id="degreesegeslem" class="lemma" name="Lemma 1.4">
<p>In any undirected graph <span><span class="math inline">\(G=(V,E)\)</span></span>, the sum of the degrees of all vertices is equal to twice the number of edges.</p>
</div>
<p><a href='#degreesegeslem'>Lemma 1.4</a> can be shown by seeing that every edge <span><span class="math inline">\(\{ u,v\}\)</span></span> contributes twice to the sum of the degrees (once for <span><span class="math inline">\(u\)</span></span> and the second time for <span><span class="math inline">\(v\)</span></span>).</p>
<div id="conntranslem" class="lemma" name="Lemma 1.5">
<p>The connectivity relation is <em>transitive</em>, in the sense that if <span><span class="math inline">\(u\)</span></span> is connected to <span><span class="math inline">\(v\)</span></span>, and <span><span class="math inline">\(v\)</span></span> is connected to <span><span class="math inline">\(w\)</span></span>, then <span><span class="math inline">\(u\)</span></span> is connected to <span><span class="math inline">\(w\)</span></span>.</p>
</div>
<p><a href='#conntranslem'>Lemma 1.5</a> can be shown by simply attaching a path of the form <span><span class="math inline">\((u,u_1,u_2,\ldots,u_{k-1},v)\)</span></span> to a path of the form <span><span class="math inline">\((v,u&#39;_1,\ldots,u&#39;_{k&#39;-1},w)\)</span></span> to obtain the path <span><span class="math inline">\((u,u_1,\ldots,u_{k-1},v,u&#39;_1,\ldots,u&#39;_{k&#39;-1},w)\)</span></span> that connects <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(w\)</span></span>.</p>
<div id="simplepathlem" class="lemma" name="Lemma 1.6">
<p>For every undirected graph <span><span class="math inline">\(G=(V,E)\)</span></span> and connected pair <span><span class="math inline">\(u,v\)</span></span>, the shortest path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> is simple. In particular, for every connected pair there exists a simple path that connects them.</p>
</div>
<p><a href='#simplepathlem'>Lemma 1.6</a> can be shown by “shortcutting” any non simple path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> where the same vertex <span><span class="math inline">\(w\)</span></span> appears twice to remove it (see <a href='#shortcutpathfig'>Figure 1.6</a>). It is a good exercise to transforming this intuitive reasoning to a formal proof:</p>
<figure>
<img src="../figure/shortcutpath.png" alt="1.6: If there is a path from u to v in a graph that passes twice through a vertex w then we can “shortcut” it by removing the loop from w to itself to find a path from u to v that only passes once through w." id="shortcutpathfig" /><figcaption>1.6: If there is a path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> in a graph that passes twice through a vertex <span><span class="math inline">\(w\)</span></span> then we can “shortcut” it by removing the loop from <span><span class="math inline">\(w\)</span></span> to itself to find a path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> that only passes once through <span><span class="math inline">\(w\)</span></span>.</figcaption>
</figure>
<div id="simplepathlemex" class="solvedexercise" title="Connected vertices have simple paths" name="Solvedexercise 1.1 (Connected vertices have simple paths) ">
<p>Prove <a href='#simplepathlem'>Lemma 1.6</a></p>
</div>
<div class="solution" data-ref="simplepathlemex" name="Solution 1.4.4">
<p>The proof follows the idea illustrated in <a href='#shortcutpathfig'>Figure 1.6</a>. One complication is that there can be more than one vertex that is visited twice by a path, and so “shortcutting” might not necessarily result in a simple path; we deal with this by looking at a <em>shortest</em> path between <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(v\)</span></span>. Details follow.</p>
<p>Let <span><span class="math inline">\(G=(V,E)\)</span></span> be a graph and <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(v\)</span></span> in <span><span class="math inline">\(V\)</span></span> be two connected vertices in <span><span class="math inline">\(G\)</span></span>. We will prove that there is a simple graph between <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(v\)</span></span>. Let <span><span class="math inline">\(k\)</span></span> be the shortest length of a path between <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(v\)</span></span> and let <span><span class="math inline">\(P=(u_0,u_1,u_2,\ldots,u_{k-1},u_k)\)</span></span> be a <span><span class="math inline">\(k\)</span></span>-length path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> (there can be more than one such path: if so we just choose one of them). (That is <span><span class="math inline">\(u_0=u\)</span></span>, <span><span class="math inline">\(u_k=v\)</span></span>, and <span><span class="math inline">\((u_\ell,u_{\ell+1})\in E\)</span></span> for all <span><span class="math inline">\(\ell \in [k]\)</span></span>.) We claim that <span><span class="math inline">\(P\)</span></span> is simple. Indeed, suppose otherwise that there is some vertex <span><span class="math inline">\(w\)</span></span> that occurs twice in the path: <span><span class="math inline">\(w = u_i\)</span></span> and <span><span class="math inline">\(w=u_j\)</span></span> for some <span><span class="math inline">\(i&lt;j\)</span></span>. Then we can “shortcut” the path <span><span class="math inline">\(P\)</span></span> by considering the path <span><span class="math inline">\(P&#39; = (u_0,u_1,\ldots,u_{i-1},w,u_{j+1},\ldots,u_k)\)</span></span> obtained by taking the first <span><span class="math inline">\(i\)</span></span> vertices of <span><span class="math inline">\(P\)</span></span> (from <span><span class="math inline">\(u_0=0\)</span></span> to the first occurrence of <span><span class="math inline">\(w\)</span></span>) and the last <span><span class="math inline">\(k-j\)</span></span> ones (from the vertex <span><span class="math inline">\(u_{j+1}\)</span></span> following the second occurrence of <span><span class="math inline">\(w\)</span></span> to <span><span class="math inline">\(u_k=v\)</span></span>). The path <span><span class="math inline">\(P&#39;\)</span></span> is a valid path between <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(v\)</span></span> since every consecutive pair of vertices in it is connected by an edge (in particular, since <span><span class="math inline">\(w=u_i=w_j\)</span></span>, both <span><span class="math inline">\((u_{i-1},w)\)</span></span> and <span><span class="math inline">\((w,u_{j+1})\)</span></span> are edges in <span><span class="math inline">\(E\)</span></span>), but since the length of <span><span class="math inline">\(P&#39;\)</span></span> is <span><span class="math inline">\(k-(j-i)&lt;k\)</span></span>, this contradicts the minimality of <span><span class="math inline">\(P\)</span></span>.</p>
</div>
<div id="comingupwithproofs" class="remark" title="Finding proofs" name="Remark 1.7 (Finding proofs) ">
<p><a href='#simplepathlemex'>Solvedexercise 1.1</a> is a good example of the process of finding a proof. You start by ensuring you understand what the statement means, and then come up with an informal argument why it should be true. You then transform the informal argument into a rigorous proof. This proof need not be very long or overly formal, but should clearly establish why the conclusion of the statement follows from its assumptions.</p>
</div>
<p>The concepts of degrees and connectivity extend naturally to <em>directed graphs</em>, defined as follows.</p>
<div id="directedgraphdef" class="definition" title="Directed graphs" name="Definition 1.8 (Directed graphs) ">
<p>A <em>directed graph</em> <span><span class="math inline">\(G=(V,E)\)</span></span> consists of a set <span><span class="math inline">\(V\)</span></span> and a set <span><span class="math inline">\(E \subseteq V\times V\)</span></span> of <em>ordered pairs</em> of <span><span class="math inline">\(V\)</span></span>. We sometimes denote the edge <span><span class="math inline">\((u,v)\)</span></span> also as <span><span class="math inline">\(u \rightarrow v\)</span></span>. If the edge <span><span class="math inline">\(u \rightarrow v\)</span></span> is present in the graph then we say that <span><span class="math inline">\(v\)</span></span> is an <em>out-neighbor</em> of <span><span class="math inline">\(u\)</span></span> and <span><span class="math inline">\(u\)</span></span> is an <em>in-neighbor</em> of <span><span class="math inline">\(v\)</span></span>.</p>
</div>
<p>A directed graph might contain both <span><span class="math inline">\(u \rightarrow v\)</span></span> and <span><span class="math inline">\(v \rightarrow u\)</span></span> in which case <span><span class="math inline">\(u\)</span></span> will be both an in-neighbor and an out-neighbor of <span><span class="math inline">\(v\)</span></span> and vice versa. The <em>in-degree</em> of <span><span class="math inline">\(u\)</span></span> is the number of in-neighbors it has, and the <em>out-degree</em> of <span><span class="math inline">\(v\)</span></span> is the number of out-neighbors it has. A <em>path</em> in the graph is a tuple <span><span class="math inline">\((u_0,\ldots,u_k) \in V^{k+1}\)</span></span>, for some <span><span class="math inline">\(k&gt;0\)</span></span> such that <span><span class="math inline">\(u_{i+1}\)</span></span> is an out-neighbor of <span><span class="math inline">\(u_i\)</span></span> for every <span><span class="math inline">\(i\in [k]\)</span></span>. As in the undirected case, a <em>simple path</em> is a path <span><span class="math inline">\((u_0,\ldots,u_{k-1})\)</span></span> where all the <span><span class="math inline">\(u_i\)</span></span>’s are distinct and a <em>cycle</em> is a path <span><span class="math inline">\((u_0,\ldots,u_k)\)</span></span> where <span><span class="math inline">\(u_0=u_{k}\)</span></span>. One type of directed graphs we often care about is <em>directed acyclic graphs</em> or <em>DAGs</em>, which, as their name implies, are directed graphs without any cycles:</p>
<div id="DAGdef" class="definition" title="Directed Acyclic Graphs" name="Definition 1.9 (Directed Acyclic Graphs) ">
<p>We say that <span><span class="math inline">\(G=(V,E)\)</span></span> is a <em>directed acyclic graph (DAG)</em> if it is a directed graph and there does not exist a list of vertices <span><span class="math inline">\(u_0,u_1,\ldots,u_k \in V\)</span></span> such that <span><span class="math inline">\(u_0=u_k\)</span></span> and for every <span><span class="math inline">\(i\in [k]\)</span></span>, the edge <span><span class="math inline">\(u_i \rightarrow u_{i+1}\)</span></span> is in <span><span class="math inline">\(E\)</span></span>.</p>
</div>
<p>The lemmas we mentioned above have analogs for directed graphs. We again leave the proofs (which are essentially identical to their undirected analogs) as exercises.</p>
<div id="diredgreesegeslem" class="lemma" name="Lemma 1.10">
<p>In any directed graph <span><span class="math inline">\(G=(V,E)\)</span></span>, the sum of the in-degrees is equal to the sum of the out-degrees, which is equal to the number of edges.</p>
</div>
<div id="dirconntranslem" class="lemma" name="Lemma 1.11">
<p>In any directed graph <span><span class="math inline">\(G\)</span></span>, if there is a path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> and a path from <span><span class="math inline">\(v\)</span></span> to <span><span class="math inline">\(w\)</span></span>, then there is a path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(w\)</span></span>.</p>
</div>
<div id="dirsimplepathlem" class="lemma" name="Lemma 1.12">
<p>For every directed graph <span><span class="math inline">\(G=(V,E)\)</span></span> and a pair <span><span class="math inline">\(u,v\)</span></span> such that there is a path from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span>, the <em>shortest path</em> from <span><span class="math inline">\(u\)</span></span> to <span><span class="math inline">\(v\)</span></span> is simple.</p>
</div>
<div id="labeledrem" class="remark" title="Labeled graphs" name="Remark 1.13 (Labeled graphs) ">
<p>For some applications we will consider <em>labeled graphs</em>, where the vertices or edges have associated <em>labels</em> (which can be numbers, strings, or members of some other set). We can think of such a graph as having an associated (possibly partial) <em>labelling function</em> <span><span class="math inline">\(L:V \cup E \rightarrow \mathcal{L}\)</span></span>, where <span><span class="math inline">\(\mathcal{L}\)</span></span> is the set of potential labels. However we will typically not refer explicitly to this labeling function and simply say things such as “vertex <span><span class="math inline">\(v\)</span></span> has the label <span><span class="math inline">\(\alpha\)</span></span>”.</p>
</div>
<h3 id="secquantifiers" data-number="1.4.5">Logic operators and quantifiers</h3>
<p>If <span><span class="math inline">\(P\)</span></span> and <span><span class="math inline">\(Q\)</span></span> are some statements that can be true or false, then <span><span class="math inline">\(P\)</span></span> AND <span><span class="math inline">\(Q\)</span></span> (denoted as <span><span class="math inline">\(P \wedge Q\)</span></span>) is a statement that is true if and only if both <span><span class="math inline">\(P\)</span></span> <em>and</em> <span><span class="math inline">\(Q\)</span></span> are true, and <span><span class="math inline">\(P\)</span></span> OR <span><span class="math inline">\(Q\)</span></span> (denoted as <span><span class="math inline">\(P \vee Q\)</span></span>) is a statement that is true if and only if either <span><span class="math inline">\(P\)</span></span> <em>or</em> <span><span class="math inline">\(Q\)</span></span> is true. The <em>negation</em> of <span><span class="math inline">\(P\)</span></span>, denoted as <span><span class="math inline">\(\neg P\)</span></span> or <span><span class="math inline">\(\overline{P}\)</span></span>, is true if and only if <span><span class="math inline">\(P\)</span></span> is false.</p>
<p>Suppose that <span><span class="math inline">\(P(x)\)</span></span> is a statement that depends on some <em>parameter</em> <span><span class="math inline">\(x\)</span></span> (also sometimes known as an <em>unbound</em> variable) in the sense that for every instantiation of <span><span class="math inline">\(x\)</span></span> with a value from some set <span><span class="math inline">\(S\)</span></span>, <span><span class="math inline">\(P(x)\)</span></span> is either true or false. For example, <span><span class="math inline">\(x&gt;7\)</span></span> is a statement that is not a priori true or false, but becomes true or false whenever we instantiate <span><span class="math inline">\(x\)</span></span> with some real number. We denote by <span><span class="math inline">\(\forall_{x\in S} P(x)\)</span></span> the statement that is true if and only if <span><span class="math inline">\(P(x)\)</span></span> is true <em>for every</em> <span><span class="math inline">\(x\in S\)</span></span>.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> We denote by <span><span class="math inline">\(\exists_{x\in S} P(x)\)</span></span> the statement that is true if and only if <em>there exists</em> some <span><span class="math inline">\(x\in S\)</span></span> such that <span><span class="math inline">\(P(x)\)</span></span> is true.</p>
<p>For example, the following is a formalization of the true statement that there exists a natural number <span><span class="math inline">\(n\)</span></span> larger than <span><span class="math inline">\(100\)</span></span> that is not divisible by <span><span class="math inline">\(3\)</span></span>:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\exists_{n\in \N} (n&gt;100) \wedge \left(\forall_{k\in N} k+k+k \neq n\right) \;.
\]</span></div></span></p>
<p><strong>“For sufficiently large <span><span class="math inline">\(n\)</span></span>.”</strong> One expression that we will see come up time and again in this book is the claim that some statement <span><span class="math inline">\(P(n)\)</span></span> is true “for sufficiently large <span><span class="math inline">\(n\)</span></span>”. What this means is that there exists an integer <span><span class="math inline">\(N_0\)</span></span> such that <span><span class="math inline">\(P(n)\)</span></span> is true for every <span><span class="math inline">\(n&gt;N_0\)</span></span>. We can formalize this as <span><span class="math inline">\(\exists_{N_0\in \N} \forall_{n&gt;N_0} P(n)\)</span></span>.</p>
<h3 id="secquantifierssums" data-number="1.4.6">Quantifiers for summations and products</h3>
<p>The following shorthands for summing up or taking products of several numbers are often convenient. If <span><span class="math inline">\(S = \{s_0,\ldots,s_{n-1} \}\)</span></span> is a finite set and <span><span class="math inline">\(f:S \rightarrow \R\)</span></span> is a function, then we write <span><span class="math inline">\(\sum_{x\in S} f(x)\)</span></span> as shorthand for</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
f(s_0) + f(s_1) + f(s_2) + \ldots + f(s_{n-1}) \;,
\]</span></div></span></p>
<p>and <span><span class="math inline">\(\prod_{x\in S} f(x)\)</span></span> as shorthand for</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
f(s_0) \cdot f(s_1) \cdot f(s_2) \cdot \ldots \cdot f(s_{n-1}) \;.
\]</span></div></span></p>
<p>For example, the sum of the squares of all numbers from <span><span class="math inline">\(1\)</span></span> to <span><span class="math inline">\(100\)</span></span> can be written as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\sum_{i\in \{1,\ldots,100\}} i^2 \;. \;\;(1.13)
\]</span><a id='eqsumsquarehundred'></a></div></span></p>
<p>Since summing up over intervals of integers is so common, there is a special notation for it. For every two integers, <span><span class="math inline">\(a \leq b\)</span></span>, <span><span class="math inline">\(\sum_{i=a}^b f(i)\)</span></span> denotes <span><span class="math inline">\(\sum_{i\in S} f(i)\)</span></span> where <span><span class="math inline">\(S =\{ x\in \Z : a \leq x \leq b \}\)</span></span>. Hence, we can write the sum <a href='#eqsumsquarehundred'>Equation 1.13</a> as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\sum_{i=1}^{100} i^2 \;.
\]</span></div></span></p>
<h3 id="boundvarsec" data-number="1.4.7">Parsing formulas: bound and free variables</h3>
<p>In mathematics, as in coding, we often have symbolic “variables” or “parameters”. It is important to be able to understand, given some formula, whether a given variable is <em>bound</em> or <em>free</em> in this formula. For example, in the following statement <span><span class="math inline">\(n\)</span></span> is free but <span><span class="math inline">\(a\)</span></span> and <span><span class="math inline">\(b\)</span></span> are bound by the <span><span class="math inline">\(\exists\)</span></span> quantifier:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\exists_{a,b \in \N} (a \neq 1) \wedge (a \neq n) \wedge (n = a \times b) \;\;(1.15)
\]</span><a id='aboutnstmt'></a></div></span></p>
<p>Since <span><span class="math inline">\(n\)</span></span> is free, it can be set to any value, and the truth of the statement <a href='#aboutnstmt'>Equation 1.15</a> depends on the value of <span><span class="math inline">\(n\)</span></span>. For example, if <span><span class="math inline">\(n=8\)</span></span> then <a href='#aboutnstmt'>Equation 1.15</a> is true, but for <span><span class="math inline">\(n=11\)</span></span> it is false. (Can you see why?)</p>
<p>The same issue appears when parsing code. For example, in the following snippet from the C programming language</p>
<pre class="clang"><code>for (int i=0 ; i&lt;n ; i=i+1) {
    printf(&quot;*&quot;);
}</code></pre>
<p>the variable <code>i</code> is bound within the <code>for</code> block but the variable <code>n</code> is free.</p>
<p>The main property of bound variables is that we can <em>rename</em> them (as long as the new name doesn’t conflict with another used variable) without changing the meaning of the statement. Thus for example the statement</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\exists_{x,y \in \N} (x \neq 1) \wedge (x \neq n) \wedge (n = x \times y) \;\;(1.16)
\]</span><a id='aboutnstmttwo'></a></div></span></p>
<p>is <em>equivalent</em> to <a href='#aboutnstmt'>Equation 1.15</a> in the sense that it is true for exactly the same set of <span><span class="math inline">\(n\)</span></span>’s.</p>
<p>Similarly, the code</p>
<pre class="clang"><code>for (int j=0 ; j&lt;n ; j=j+1) {
    printf(&quot;*&quot;);
}</code></pre>
<p>produces the same result as the code above that used <code>i</code> instead of <code>j</code>.</p>
<div id="notationrem" class="remark" title="Aside: mathematical vs programming notation" name="Remark 1.14 (Aside: mathematical vs programming notation) ">
<p>Mathematical notation has a lot of similarities with programming language, and for the same reasons. Both are formalisms meant to convey complex concepts in a precise way. However, there are some cultural differences. In programming languages, we often try to use meaningful variable names such as <code>NumberOfVertices</code> while in math we often use short identifiers such as <span><span class="math inline">\(n\)</span></span>. Part of it might have to do with the tradition of mathematical proofs as being handwritten and verbally presented, as opposed to typed up and compiled. Another reason is if the wrong variable name is used in a proof, at worst is causes confusion to readers; when the wrong variable name is used in a program, planes might crash, patients might die, and rockets could explode.</p>
<p>One consequence of that is that in mathematics we often end up reusing identifiers, and also “run out” of letters and hence use Greek letters too, as well as distinguish between small and capital letters and different font faces. Similarly, mathematical notation tends to use quite a lot of “overloading”, using operators such as <span><span class="math inline">\(+\)</span></span> for a great variety of objects (e.g., real numbers, matrices, finite field elements, etc..), and assuming that the meaning can be inferred from the context.</p>
<p>Both fields have a notion of “types”, and in math we often try to reserve certain letters for variables of a particular type. For example, variables such as <span><span class="math inline">\(i,j,k,\ell,m,n\)</span></span> will often denote integers, and <span><span class="math inline">\(\epsilon\)</span></span> will often denote a small positive real number (see <a href='#notationsec'>Section 1.7</a> for more on these conventions). When reading or writing mathematical texts, we usually don’t have the advantage of a “compiler” that will check type safety for us. Hence it is important to keep track of the type of each variable, and see that the operations that are performed on it “make sense”.</p>
<p>Kun’s book  (<a href="https://scholar.google.com/scholar?hl=en&q=Kun+A+programmer's+introduction+to+mathematics" target="_blank">Kun, 2018</a>)  contains an extensive discussion on the similarities and differences between the cultures of mathematics and programming.</p>
</div>
<h3 id="secbigohnotation" data-number="1.4.8">Asymptotics and Big-<span><span class="math inline">\(O\)</span></span> notation</h3>
<blockquote>
<p><em>“<span><span class="math inline">\(\log\log\log n\)</span></span> has been proved to go to infinity, but has never been observed to do so.”</em>, Anonymous, quoted by Carl Pomerance (2000)</p>
</blockquote>
<p>It is often very cumbersome to describe precisely quantities such as running time and is also not needed, since we are typically mostly interested in the “higher order terms”. That is, we want to understand the <em>scaling behavior</em> of the quantity as the input variable grows. For example, as far as running time goes, the difference between an <span><span class="math inline">\(n^5\)</span></span>-time algorithm and an <span><span class="math inline">\(n^2\)</span></span>-time one is much more significant than the difference between an <span><span class="math inline">\(100n^2 + 10n\)</span></span> time algorithm and an <span><span class="math inline">\(10n^2\)</span></span> time algorithm. For this purpose, <span><span class="math inline">\(O\)</span></span>-notation is extremely useful as a way to “declutter” our text and focus our attention on what really matters. For example, using <span><span class="math inline">\(O\)</span></span>-notation, we can say that both <span><span class="math inline">\(100n^2 + 10n\)</span></span> and <span><span class="math inline">\(10n^2\)</span></span> are simply <span><span class="math inline">\(\Theta(n^2)\)</span></span> (which informally means “the same up to constant factors”), while <span><span class="math inline">\(n^2 = o(n^5)\)</span></span> (which informally means that <span><span class="math inline">\(n^2\)</span></span> is “much smaller than” <span><span class="math inline">\(n^5\)</span></span>).</p>
<p>Generally (though still informally), if <span><span class="math inline">\(F,G\)</span></span> are two functions mapping natural numbers to non-negative reals, then “<span><span class="math inline">\(F=O(G)\)</span></span>” means that <span><span class="math inline">\(F(n) \leq G(n)\)</span></span> if we don’t care about constant factors, while “<span><span class="math inline">\(F=o(G)\)</span></span>” means that <span><span class="math inline">\(F\)</span></span> is much smaller than <span><span class="math inline">\(G\)</span></span>, in the sense that no matter by what constant factor we multiply <span><span class="math inline">\(F\)</span></span>, if we take <span><span class="math inline">\(n\)</span></span> to be large enough then <span><span class="math inline">\(G\)</span></span> will be bigger (for this reason, sometimes <span><span class="math inline">\(F=o(G)\)</span></span> is written as <span><span class="math inline">\(F \ll G\)</span></span>). We will write <span><span class="math inline">\(F= \Theta(G)\)</span></span> if <span><span class="math inline">\(F=O(G)\)</span></span> and <span><span class="math inline">\(G=O(F)\)</span></span>, which one can think of as saying that <span><span class="math inline">\(F\)</span></span> is the same as <span><span class="math inline">\(G\)</span></span> if we don’t care about constant factors. More formally, we define Big-<span><span class="math inline">\(O\)</span></span> notation as follows:</p>
<div id="bigohdef" class="definition" title="Big-$O$ notation" name="Definition 1.15 (Big-$O$ notation) ">
<p>Let <span><span class="math inline">\(\R_+= \{ x\in \R \;|\; x&gt;0\}\)</span></span> be the set of positive real numbers. For two functions <span><span class="math inline">\(F,G: \N \rightarrow \R_+\)</span></span>, we say that <em><span><span class="math inline">\(F=O(G)\)</span></span></em> if there exist numbers <span><span class="math inline">\(a,N_0 \in \N\)</span></span> such that <span><span class="math inline">\(F(n) \leq a\cdot G(n)\)</span></span> for every <span><span class="math inline">\(n&gt;N_0\)</span></span>. We say that <span><span class="math inline">\(F= \Theta(G)\)</span></span> if <span><span class="math inline">\(F=O(G)\)</span></span> and <span><span class="math inline">\(G=O(F)\)</span></span>. We say that <span><span class="math inline">\(F=\Omega(G)\)</span></span> if <span><span class="math inline">\(G=O(F)\)</span></span>.</p>
<p>We say that <em><span><span class="math inline">\(F =o(G)\)</span></span></em> if for every <span><span class="math inline">\(\epsilon&gt;0\)</span></span> there is some <span><span class="math inline">\(N_0\)</span></span> such that <span><span class="math inline">\(F(n) &lt;\epsilon G(n)\)</span></span> for every <span><span class="math inline">\(n&gt;N_0\)</span></span>. We say that <span><span class="math inline">\(F =\omega(G)\)</span></span> if <span><span class="math inline">\(G=o(F)\)</span></span>.</p>
</div>
<figure>
<img src="../figure/nvsnsquared.png" alt="1.7: If F(n)=o(G(n)) then for sufficiently large n, F(n) will be smaller than G(n). For example, if Algorithm A runs in time 1000\cdot n+10^6 and Algorithm B runs in time 0.01\cdot n^2 then even though B might be more efficient for smaller inputs, when the inputs get sufficiently large, A will run much faster than B." id="nvsnsquaredfig" class="margin" /><figcaption>1.7: If <span><span class="math inline">\(F(n)=o(G(n))\)</span></span> then for sufficiently large <span><span class="math inline">\(n\)</span></span>, <span><span class="math inline">\(F(n)\)</span></span> will be smaller than <span><span class="math inline">\(G(n)\)</span></span>. For example, if Algorithm <span><span class="math inline">\(A\)</span></span> runs in time <span><span class="math inline">\(1000\cdot n+10^6\)</span></span> and Algorithm <span><span class="math inline">\(B\)</span></span> runs in time <span><span class="math inline">\(0.01\cdot n^2\)</span></span> then even though <span><span class="math inline">\(B\)</span></span> might be more efficient for smaller inputs, when the inputs get sufficiently large, <span><span class="math inline">\(A\)</span></span> will run <em>much</em> faster than <span><span class="math inline">\(B\)</span></span>.</figcaption>
</figure>
<p>It’s often convenient to use “anonymous functions” in the context of <span><span class="math inline">\(O\)</span></span>-notation. For example, when we write a statement such as <span><span class="math inline">\(F(n) = O(n^3)\)</span></span>, we mean that <span><span class="math inline">\(F=O(G)\)</span></span> where <span><span class="math inline">\(G\)</span></span> is the function defined by <span><span class="math inline">\(G(n)=n^3\)</span></span>. Chapter 7 in <a href="http://www.cs.yale.edu/homes/aspnes/classes/202/notes.pdf">Jim Apsnes’ notes on discrete math</a> provides a good summary of <span><span class="math inline">\(O\)</span></span> notation; see also <a href="http://discrete.gr/complexity/">this tutorial</a> for a gentler and more programmer-oriented introduction.</p>
<p><em><span><span class="math inline">\(O\)</span></span> is not equality.</em> Using the equality sign for <span><span class="math inline">\(O\)</span></span>-notation is extremely common, but is somewhat of a misnomer, since a statement such as <span><span class="math inline">\(F = O(G)\)</span></span> really means that <span><span class="math inline">\(F\)</span></span> is in the set <span><span class="math inline">\(\{ G&#39; : \exists_{N,c} \text{ s.t. } \forall_{n&gt;N} G&#39;(n) \leq c G(n) \}\)</span></span>. If anything, it makes more sense to use <em>inequalities</em> and write <span><span class="math inline">\(F \leq O(G)\)</span></span> and <span><span class="math inline">\(F \geq \Omega(G)\)</span></span>, reserving equality for <span><span class="math inline">\(F = \Theta(G)\)</span></span>, and so we will sometimes use this notation too, but since the equality notation is quite firmly entrenched we often stick to it as well. (Some texts write <span><span class="math inline">\(F \in O(G)\)</span></span> instead of <span><span class="math inline">\(F = O(G)\)</span></span>, but we will not use this notation.) Despite the misleading equality sign, you should remember that a statement such as <span><span class="math inline">\(F = O(G)\)</span></span> means that <span><span class="math inline">\(F\)</span></span> is “at most” <span><span class="math inline">\(G\)</span></span> in some rough sense when we ignore constants, and a statement such as <span><span class="math inline">\(F = \Omega(G)\)</span></span> means that <span><span class="math inline">\(F\)</span></span> is “at least” <span><span class="math inline">\(G\)</span></span> in the same rough sense.</p>
<h3 id="some-rules-of-thumb-for-big-o-notation" data-number="1.4.9">Some “rules of thumb” for Big-<span><span class="math inline">\(O\)</span></span> notation</h3>
<p>There are some simple heuristics that can help when trying to compare two functions <span><span class="math inline">\(F\)</span></span> and <span><span class="math inline">\(G\)</span></span>:</p>
<ul>
<li><p>Multiplicative constants don’t matter in <span><span class="math inline">\(O\)</span></span>-notation, and so if <span><span class="math inline">\(F(n)=O(G(n))\)</span></span> then <span><span class="math inline">\(100F(n)=O(G(n))\)</span></span>.</p></li>
<li><p>When adding two functions, we only care about the larger one. For example, for the purpose of <span><span class="math inline">\(O\)</span></span>-notation, <span><span class="math inline">\(n^3+100n^2\)</span></span> is the same as <span><span class="math inline">\(n^3\)</span></span>, and in general in any polynomial, we only care about the larger exponent.</p></li>
<li><p>For every two constants <span><span class="math inline">\(a,b&gt;0\)</span></span>, <span><span class="math inline">\(n^a = O(n^b)\)</span></span> if and only if <span><span class="math inline">\(a \leq b\)</span></span>, and <span><span class="math inline">\(n^a = o(n^b)\)</span></span> if and only if <span><span class="math inline">\(a&lt;b\)</span></span>. For example, combining the two observations above, <span><span class="math inline">\(100n^2 + 10n + 100 = o(n^3)\)</span></span>.</p></li>
<li><p>Polynomial is always smaller than exponential: <span><span class="math inline">\(n^a = o(2^{n^\epsilon})\)</span></span> for every two constants <span><span class="math inline">\(a&gt;0\)</span></span> and <span><span class="math inline">\(\epsilon&gt;0\)</span></span> even if <span><span class="math inline">\(\epsilon\)</span></span> is much smaller than <span><span class="math inline">\(a\)</span></span>. For example, <span><span class="math inline">\(100n^{100} = o(2^{\sqrt{n}})\)</span></span>.</p></li>
<li><p>Similarly, logarithmic is always smaller than polynomial: <span><span class="math inline">\((\log n)^a\)</span></span> (which we write as <span><span class="math inline">\(\log^a n\)</span></span>) is <span><span class="math inline">\(o(n^\epsilon)\)</span></span> for every two constants <span><span class="math inline">\(a,\epsilon&gt;0\)</span></span>. For example, combining the observations above, <span><span class="math inline">\(100n^2 \log^{100} n = o(n^3)\)</span></span>.</p></li>
</ul>
<div id="bigonotime" class="remark" title="Big $O$ for other applications (optional)" name="Remark 1.16 (Big $O$ for other applications (optional)) ">
<p>While Big-<span><span class="math inline">\(O\)</span></span> notation is often used to analyze running time of algorithms, this is by no means the only application. We can use <span><span class="math inline">\(O\)</span></span> notation to bound asymptotic relations between any functions mapping integers to positive numbers. It can be used regardless of whether these functions are a measure of running time, memory usage, or any other quantity that may have nothing to do with computation. Here is one example which is unrelated to this book (and hence one that you can feel free to skip): one way to state the <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis">Riemann Hypothesis</a> (one of the most famous open questions in mathematics) is that it corresponds to the conjecture that the number of primes between <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(n\)</span></span> is equal to <span><span class="math inline">\(\int_2^n \tfrac{1}{\ln x} dx\)</span></span> up to an additive error of magnitude at most <span><span class="math inline">\(O(\sqrt{n}\log n)\)</span></span>.</p>
</div>
<h2 id="proofsbackgroundsec" data-number="1.5">Proofs</h2>
<p>Many people think of mathematical proofs as a sequence of logical deductions that starts from some axioms and ultimately arrives at a conclusion. In fact, some dictionaries <a href="http://www.thefreedictionary.com/mathematical+proof">define</a> proofs that way. This is not entirely wrong, but at its essence mathematical proof of a statement X is simply an argument that convinces the reader that X is true beyond a shadow of a doubt.</p>
<p>To produce such a proof you need to:</p>
<ol type="1">
<li><p>Understand precisely what X means.</p></li>
<li><p>Convince <em>yourself</em> that X is true.</p></li>
<li><p>Write your reasoning down in plain, precise and concise English (using formulas or notation only when they help clarity).</p></li>
</ol>
<p>In many cases, the first part is the most important one. Understanding what a statement means is oftentimes more than halfway towards understanding why it is true. In third part, to convince the reader beyond a shadow of a doubt, we will often want to break down the reasoning to “basic steps”, where each basic step is simple enough to be “self evident”. The combination of all steps yields the desired statement.</p>
<h3 id="proofs-and-programs" data-number="1.5.1">Proofs and programs</h3>
<p>There is a great deal of similarity between the process of writing <em>proofs</em> and that of writing <em>programs</em>, and both require a similar set of skills. Writing a <em>program</em> involves:</p>
<ol type="1">
<li><p>Understanding what is the <em>task</em> we want the program to achieve.</p></li>
<li><p>Convincing <em>yourself</em> that the task can be achieved by a computer, perhaps by planning on a whiteboard or notepad how you will break it up to simpler tasks.</p></li>
<li><p>Converting this plan into code that a compiler or interpreter can understand, by breaking up each task into a sequence of the basic operations of some programming language.</p></li>
</ol>
<p>In programs as in proofs, step 1 is often the most important one. A key difference is that the reader for proofs is a human being and the reader for programs is a computer. (This difference is eroding with time as more proofs are being written in a <em>machine verifiable</em> form; moreover, to ensure correctness and maintainability of programs, it is important that they can be read and understood by humans.) Thus our emphasis is on <em>readability</em> and having a <em>clear logical flow</em> for our proof (which is not a bad idea for programs as well). When writing a proof, you should think of your audience as an intelligent but highly skeptical and somewhat petty reader, that will “call foul” at every step that is not well justified.</p>
<h3 id="proof-writing-style" data-number="1.5.2">Proof writing style</h3>
<p>A mathematical proof is a piece of writing, but it is a specific genre of writing with certain conventions and preferred styles. As in any writing, practice makes perfect, and it is also important to revise your drafts for clarity.</p>
<p>In a proof for the statement <span><span class="math inline">\(X\)</span></span>, all the text between the words <strong>“Proof:”</strong> and <strong>“QED”</strong> should be focused on establishing that <span><span class="math inline">\(X\)</span></span> is true. Digressions, examples, or ruminations should be kept outside these two words, so they do not confuse the reader. The proof should have a clear logical flow in the sense that every sentence or equation in it should have some purpose and it should be crystal-clear to the reader what this purpose is. When you write a proof, for every equation or sentence you include, ask yourself:</p>
<ol type="1">
<li><p>Is this sentence or equation stating that some statement is true?</p></li>
<li><p>If so, does this statement follow from the previous steps, or are we going to establish it in the next step?</p></li>
<li><p>What is the <em>role</em> of this sentence or equation? Is it one step towards proving the original statement, or is it a step towards proving some intermediate claim that you have stated before?</p></li>
<li><p>Finally, would the answers to questions 1-3 be clear to the reader? If not, then you should reorder, rephrase or add explanations.</p></li>
</ol>
<p>Some helpful resources on mathematical writing include <a href="https://sites.math.washington.edu/~lee/Writing/writing-proofs.pdf">this handout by Lee</a>, <a href="https://math.berkeley.edu/~hutching/teach/proofs.pdf">this handout by Hutching</a>, as well as several of the excellent handouts in <a href="http://web.stanford.edu/class/cs103/">Stanford’s CS 103 class</a>.</p>
<h3 id="patterns-in-proofs" data-number="1.5.3">Patterns in proofs</h3>
<blockquote>
<p><em>“If it was so, it might be; and if it were so, it would be; but as it isn’t, it ain’t. That’s logic.”</em>, Lewis Carroll, <em>Through the looking-glass</em>.</p>
</blockquote>
<p>Just like in programming, there are several common patterns of proofs that occur time and again. Here are some examples:</p>
<p><strong>Proofs by contradiction:</strong> One way to prove that <span><span class="math inline">\(X\)</span></span> is true is to show that if <span><span class="math inline">\(X\)</span></span> was false it would result in a contradiction. Such proofs often start with a sentence such as “Suppose, towards a contradiction, that <span><span class="math inline">\(X\)</span></span> is false” and end with deriving some contradiction (such as a violation of one of the assumptions in the theorem statement). Here is an example:</p>
<div id="section-3" class="lemma" name="Lemma">
<p>There are no natural numbers <span><span class="math inline">\(a,b\)</span></span> such that <span><span class="math inline">\(\sqrt{2} = \tfrac{a}{b}\)</span></span>.</p>
</div>
<div id="section-4" class="proof" name="Proof">
<p>Suppose, towards a contradiction that this is false, and so let <span><span class="math inline">\(a\in \N\)</span></span> be the smallest number such that there exists some <span><span class="math inline">\(b\in\N\)</span></span> satisfying <span><span class="math inline">\(\sqrt{2}=\tfrac{a}{b}\)</span></span>. Squaring this equation we get that <span><span class="math inline">\(2=a^2/b^2\)</span></span> or <span><span class="math inline">\(a^2=2b^2\)</span></span> <span><span class="math inline">\((*)\)</span></span>. But this means that <span><span class="math inline">\(a^2\)</span></span> is <em>even</em>, and since the product of two odd numbers is odd, it means that <span><span class="math inline">\(a\)</span></span> is even as well, or in other words, <span><span class="math inline">\(a = 2a&#39;\)</span></span> for some <span><span class="math inline">\(a&#39; \in \N\)</span></span>. Yet plugging this into <span><span class="math inline">\((*)\)</span></span> shows that <span><span class="math inline">\(4a&#39;^2 = 2b^2\)</span></span> which means <span><span class="math inline">\(b^2 = 2a&#39;^2\)</span></span> is an even number as well. By the same considerations as above we get that <span><span class="math inline">\(b\)</span></span> is even and hence <span><span class="math inline">\(a/2\)</span></span> and <span><span class="math inline">\(b/2\)</span></span> are two natural numbers satisfying <span><span class="math inline">\(\tfrac{a/2}{b/2}=\sqrt{2}\)</span></span>, contradicting the minimality of <span><span class="math inline">\(a\)</span></span>.</p>
</div>
<p><strong>Proofs of a universal statement:</strong> Often we want to prove a statement <span><span class="math inline">\(X\)</span></span> of the form “Every object of type <span><span class="math inline">\(O\)</span></span> has property <span><span class="math inline">\(P\)</span></span>.” Such proofs often start with a sentence such as “Let <span><span class="math inline">\(o\)</span></span> be an object of type <span><span class="math inline">\(O\)</span></span>” and end by showing that <span><span class="math inline">\(o\)</span></span> has the property <span><span class="math inline">\(P\)</span></span>. Here is a simple example:</p>
<div id="section-5" class="lemma" name="Lemma">
<p>For every natural number <span><span class="math inline">\(n\in N\)</span></span>, either <span><span class="math inline">\(n\)</span></span> or <span><span class="math inline">\(n+1\)</span></span> is even.</p>
</div>
<div id="section-6" class="proof" name="Proof">
<p>Let <span><span class="math inline">\(n\in N\)</span></span> be some number. If <span><span class="math inline">\(n/2\)</span></span> is a whole number then we are done, since then <span><span class="math inline">\(n=2(n/2)\)</span></span> and hence it is even. Otherwise, <span><span class="math inline">\(n/2+1/2\)</span></span> is a whole number, and hence <span><span class="math inline">\(2(n/2+1/2)=n+1\)</span></span> is even.</p>
</div>
<p><strong>Proofs of an implication:</strong> Another common case is that the statement <span><span class="math inline">\(X\)</span></span> has the form “<span><span class="math inline">\(A\)</span></span> implies <span><span class="math inline">\(B\)</span></span>”. Such proofs often start with a sentence such as “Assume that <span><span class="math inline">\(A\)</span></span> is true” and end with a derivation of <span><span class="math inline">\(B\)</span></span> from <span><span class="math inline">\(A\)</span></span>. Here is a simple example:</p>
<div id="section-7" class="lemma" name="Lemma">
<p>If <span><span class="math inline">\(b^2 \geq 4ac\)</span></span> then there is a solution to the quadratic equation <span><span class="math inline">\(ax^2 + bx + c =0\)</span></span>.</p>
</div>
<div id="section-8" class="proof" name="Proof">
<p>Suppose that <span><span class="math inline">\(b^2 \geq 4ac\)</span></span>. Then <span><span class="math inline">\(d = b^2 - 4ac\)</span></span> is a non-negative number and hence it has a square root <span><span class="math inline">\(s\)</span></span>. Thus <span><span class="math inline">\(x = (-b+s)/(2a)\)</span></span> satisfies <span>
<div class='myequationbox'><span class="math display">\[
\begin{aligned}
ax^2 + bx + c &amp;= a(-b+s)^2/(4a^2) + b(-b+s)/(2a) + c \\
&amp;= (b^2-2bs+s^2)/(4a)+(-b^2+bs)/(2a)+c \;. \;\;(1.17)
\end{aligned}
\]</span><a id='eq:quadeq'></a></div></span></p>
</div>
<p>Rearranging the terms of <a href='#eq:quadeq'>Equation 1.17</a> we get <span>
<div class='myequationbox'><span class="math display">\[
s^2/(4a)+c- b^2/(4a) = (b^2-4ac)/(4a) + c - b^2/(4a) = 0
\]</span></div></span></p>
<p><strong>Proofs of equivalence:</strong> If a statement has the form “<span><span class="math inline">\(A\)</span></span> if and only if <span><span class="math inline">\(B\)</span></span>” (often shortened as “<span><span class="math inline">\(A\)</span></span> iff <span><span class="math inline">\(B\)</span></span>”) then we need to prove both that <span><span class="math inline">\(A\)</span></span> implies <span><span class="math inline">\(B\)</span></span> and that <span><span class="math inline">\(B\)</span></span> implies <span><span class="math inline">\(A\)</span></span>. We call the implication that <span><span class="math inline">\(A\)</span></span> implies <span><span class="math inline">\(B\)</span></span> the “only if” direction, and the implication that <span><span class="math inline">\(B\)</span></span> implies <span><span class="math inline">\(A\)</span></span> the “if” direction.</p>
<p><strong>Proofs by combining intermediate claims:</strong> When a proof is more complex, it is often helpful to break it apart into several steps. That is, to prove the statement <span><span class="math inline">\(X\)</span></span>, we might first prove statements <span><span class="math inline">\(X_1\)</span></span>,<span><span class="math inline">\(X_2\)</span></span>, and <span><span class="math inline">\(X_3\)</span></span> and then prove that <span><span class="math inline">\(X_1 \wedge X_2 \wedge X_3\)</span></span> implies <span><span class="math inline">\(X\)</span></span>. (Recall that <span><span class="math inline">\(\wedge\)</span></span> denotes the logical AND operator.)</p>
<p><strong>Proofs by case distinction:</strong> This is a special case of the above, where to prove a statement <span><span class="math inline">\(X\)</span></span> we split into several cases <span><span class="math inline">\(C_1,\ldots,C_k\)</span></span>, and prove that <strong>(a)</strong> the cases are <em>exhaustive</em>, in the sense that <em>one</em> of the cases <span><span class="math inline">\(C_i\)</span></span> must happen and <strong>(b)</strong> go one by one and prove that each one of the cases <span><span class="math inline">\(C_i\)</span></span> implies the result <span><span class="math inline">\(X\)</span></span> that we are after.</p>
<p><strong>Proofs by induction:</strong> We discuss induction and give an example in <a href='#inductionsec'>Subsection 1.6.1</a> below. We can think of such proofs as a variant of the above, where we have an unbounded number of intermediate claims <span><span class="math inline">\(X_0,X_2,\ldots,X_k\)</span></span>, and we prove that <span><span class="math inline">\(X_0\)</span></span> is true, as well as that <span><span class="math inline">\(X_0\)</span></span> implies <span><span class="math inline">\(X_1\)</span></span>, and that <span><span class="math inline">\(X_0 \wedge X_1\)</span></span> implies <span><span class="math inline">\(X_2\)</span></span>, and so on and so forth. The website for CMU course 15-251 contains a <a href="http://www.cs.cmu.edu/~./15251/notes/induction-pitfalls.pdf">useful handout</a> on potential pitfalls when making proofs by induction.</p>
<p><strong>“Without loss of generality (w.l.o.g)”:</strong> This term can be initially quite confusing. It is essentially a way to simplify proofs by case distinctions. The idea is that if Case 1 is equal to Case 2 up to a change of variables or a similar transformation, then the proof of Case 1 will also imply the proof of Case 2. It is always a statement that should be viewed with suspicion. Whenever you see it in a proof, ask yourself if you understand <em>why</em> the assumption made is truly without loss of generality, and when you use it, try to see if the use is indeed justified. When writing a proof, sometimes it might be easiest to simply repeat the proof of the second case (adding a remark that the proof is very similar to the first one).</p>
<div id="lamportrem" class="remark" title="Hierarchical Proofs (optional)" name="Remark 1.20 (Hierarchical Proofs (optional)) ">
<p>Mathematical proofs are ultimately written in English prose. The well-known computer scientist <a href="https://en.wikipedia.org/wiki/Leslie_Lamport">Leslie Lamport</a> argues that this is a problem, and proofs should be written in a more formal and rigorous way. In his <a href="https://lamport.azurewebsites.net/pubs/proof.pdf">manuscript</a> he proposes an approach for <em>structured hierarchical proofs</em>, that have the following form:</p>
<ul>
<li><p>A proof for a statement of the form “If <span><span class="math inline">\(A\)</span></span> then <span><span class="math inline">\(B\)</span></span>” is a sequence of numbered claims, starting with the assumption that <span><span class="math inline">\(A\)</span></span> is true, and ending with the claim that <span><span class="math inline">\(B\)</span></span> is true.</p></li>
<li><p>Every claim is followed by a proof showing how it is derived from the previous assumptions or claims.</p></li>
<li><p>The proof for each claim is itself a sequence of subclaims.</p></li>
</ul>
<p>The advantage of Lamport’s format is that the role that every sentence in the proof plays is very clear. It is also much easier to transform such proofs into machine-checkable forms. The disadvantage is that such proofs can be tedious to read and write, with less differentiation between the important parts of the arguments versus the more routine ones.</p>
</div>
<h2 id="topsortsec" data-number="1.6">Extended example: Topological Sorting</h2>
<p>In this section we will prove the following: every directed acyclic graph (DAG, see <a href='#DAGdef'>Definition 1.9</a>) can be arranged in layers so that for all directed edges <span><span class="math inline">\(u \rightarrow v\)</span></span>, the layer of <span><span class="math inline">\(v\)</span></span> is larger than the layer of <span><span class="math inline">\(u\)</span></span>. This result is known as <a href="https://goo.gl/QUskBc">topological sorting</a> and is used in many applications, including task scheduling, build systems, software package management, spreadsheet cell calculations, and many others (see <a href='#topologicalsortfig'>Figure 1.8</a>). In fact, we will also use it ourselves later on in this book.</p>
<figure>
<img src="../figure/topologicalsort.png" alt="1.8: An example of topological sorting. We consider a directed graph corresponding to a prerequisite graph of the courses in some Computer Science program. The edge u \rightarrow v means that the course u is a prerequisite for the course v. A layering or “topological sorting” of this graph is the same as mapping the courses to semesters so that if we decide to take the course v in semester f(v), then we have already taken all the prerequisites for v (i.e., its in-neighbors) in prior semesters." id="topologicalsortfig" /><figcaption>1.8: An example of <em>topological sorting</em>. We consider a directed graph corresponding to a prerequisite graph of the courses in some Computer Science program. The edge <span><span class="math inline">\(u \rightarrow v\)</span></span> means that the course <span><span class="math inline">\(u\)</span></span> is a prerequisite for the course <span><span class="math inline">\(v\)</span></span>. A <em>layering</em> or “topological sorting” of this graph is the same as mapping the courses to semesters so that if we decide to take the course <span><span class="math inline">\(v\)</span></span> in semester <span><span class="math inline">\(f(v)\)</span></span>, then we have already taken all the prerequisites for <span><span class="math inline">\(v\)</span></span> (i.e., its in-neighbors) in prior semesters.</figcaption>
</figure>
<p>We start with the following definition. A <em>layering</em> of a directed graph is a way to assign for every vertex <span><span class="math inline">\(v\)</span></span> a natural number (corresponding to its layer), such that <span><span class="math inline">\(v\)</span></span>’s in-neighbors are in lower-numbered layers than <span><span class="math inline">\(v\)</span></span>, and <span><span class="math inline">\(v\)</span></span>’s out-neighbors are in higher-numbered layers. The formal definition is as follows:</p>
<div id="layeringdef" class="definition" title="Layering of a DAG" name="Definition 1.21 (Layering of a DAG) ">
<p>Let <span><span class="math inline">\(G=(V,E)\)</span></span> be a directed graph. A <em>layering</em> of <span><span class="math inline">\(G\)</span></span> is a function <span><span class="math inline">\(f:V \rightarrow \N\)</span></span> such that for every edge <span><span class="math inline">\(u \rightarrow v\)</span></span> of <span><span class="math inline">\(G\)</span></span>, <span><span class="math inline">\(f(u) &lt; f(v)\)</span></span>.</p>
</div>
<p>In this section we prove that a directed graph is acyclic if and only if it has a valid layering.</p>
<div id="topologicalsortthm" class="theorem" title="Topological Sort" name="Theorem 1.22 (Topological Sort) ">
<p>Let <span><span class="math inline">\(G\)</span></span> be a directed graph. Then <span><span class="math inline">\(G\)</span></span> is acyclic if and only if there exists a layering <span><span class="math inline">\(f\)</span></span> of <span><span class="math inline">\(G\)</span></span>.</p>
</div>
<p>To prove such a theorem, we need to first understand what it means. Since it is an “if and only if” statement, <a href='#topologicalsortthm'>Theorem 1.22</a> corresponds to two statements:</p>
<div id="acyclictosortlem" class="lemma" name="Lemma 1.23">
<p>For every directed graph <span><span class="math inline">\(G\)</span></span>, if <span><span class="math inline">\(G\)</span></span> is acyclic then it has a layering.</p>
</div>
<div id="sorttoacycliclem" class="lemma" name="Lemma 1.24">
<p>For every directed graph <span><span class="math inline">\(G\)</span></span>, if <span><span class="math inline">\(G\)</span></span> has a layering, then it is acyclic.</p>
</div>
<p>To prove <a href='#topologicalsortthm'>Theorem 1.22</a> we need to prove both <a href='#acyclictosortlem'>Lemma 1.23</a> and <a href='#sorttoacycliclem'>Lemma 1.24</a>. <a href='#sorttoacycliclem'>Lemma 1.24</a> is actually not that hard to prove. Intuitively, if <span><span class="math inline">\(G\)</span></span> contains a <em>cycle</em>, then it cannot be the case that all edges on the cycle increase in layer number, since if we travel along the cycle at some point we must come back to the place we started from. The formal proof is as follows:</p>
<div class="proof" data-ref="sorttoacycliclem" name="Proof 1.6">
<p>Let <span><span class="math inline">\(G=(V,E)\)</span></span> be a directed graph and let <span><span class="math inline">\(f:V \rightarrow \N\)</span></span> be a layering of <span><span class="math inline">\(G\)</span></span> as per <a href='#layeringdef'>Definition 1.21</a> . Suppose, towards a contradiction, that <span><span class="math inline">\(G\)</span></span> is not acyclic, and hence there exists some cycle <span><span class="math inline">\(u_0,u_1,\ldots,u_k\)</span></span> such that <span><span class="math inline">\(u_0=u_k\)</span></span> and for every <span><span class="math inline">\(i\in [k]\)</span></span> the edge <span><span class="math inline">\(u_i \rightarrow u_{i+1}\)</span></span> is present in <span><span class="math inline">\(G\)</span></span>. Since <span><span class="math inline">\(f\)</span></span> is a layering, for every <span><span class="math inline">\(i \in [k]\)</span></span>, <span><span class="math inline">\(f(u_i) &lt; f(u_{i+1})\)</span></span>, which means that <span>
<div class='myequationbox'><span class="math display">\[
f(u_0) &lt; f(u_1)  &lt; \cdots  &lt; f(u_k)
\]</span></div></span> but this is a contradiction since <span><span class="math inline">\(u_0=u_k\)</span></span> and hence <span><span class="math inline">\(f(u_0)=f(u_k)\)</span></span>.</p>
</div>
<p><a href='#acyclictosortlem'>Lemma 1.23</a> corresponds to the more difficult (and useful) direction. To prove it, we need to show how given an arbitrary DAG <span><span class="math inline">\(G\)</span></span>, we can come up with a layering of the vertices of <span><span class="math inline">\(G\)</span></span> so that all edges “go up”.</p>
<div id="section-9" class="pause" name="Pause">
<p>If you have not seen the proof of this theorem before (or don’t remember it), this would be an excellent point to pause and try to prove it yourself. One way to do it would be to describe an <em>algorithm</em> that given as input a directed acyclic graph <span><span class="math inline">\(G\)</span></span> on <span><span class="math inline">\(n\)</span></span> vertices and <span><span class="math inline">\(n-2\)</span></span> or fewer edges, constructs an array <span><span class="math inline">\(F\)</span></span> of length <span><span class="math inline">\(n\)</span></span> such that for every edge <span><span class="math inline">\(u \rightarrow v\)</span></span> in the graph <span><span class="math inline">\(F[u] &lt; F[v]\)</span></span>.</p>
</div>
<h3 id="inductionsec" data-number="1.6.1">Mathematical induction</h3>
<p>There are several ways to prove <a href='#acyclictosortlem'>Lemma 1.23</a>. One approach to do is to start by proving it for small graphs, such as graphs with 1, 2 or 3 vertices (see <a href='#topsortexamplesfig'>Figure 1.9</a>, for which we can check all the cases, and then try to extend the proof for larger graphs. The technical term for this proof approach is <em>proof by induction</em>.</p>
<figure>
<img src="../figure/topologicalsortexamples.png" alt="1.9: Some examples of DAGs of one, two and three vertices, and valid ways to assign layers to the vertices." id="topsortexamplesfig" class="margin" /><figcaption>1.9: Some examples of DAGs of one, two and three vertices, and valid ways to assign layers to the vertices.</figcaption>
</figure>
<p><em>Induction</em> is simply an application of the self-evident <a href="https://en.wikipedia.org/wiki/Modus_ponens">Modus Ponens rule</a> that says that if</p>
<p><strong>(a)</strong> <span><span class="math inline">\(P\)</span></span> is true</p>
<p>and</p>
<p><strong>(b)</strong> <span><span class="math inline">\(P\)</span></span> implies <span><span class="math inline">\(Q\)</span></span></p>
<p>then <span><span class="math inline">\(Q\)</span></span> is true.</p>
<p>In the setting of proofs by induction we typically have a statement <span><span class="math inline">\(Q(k)\)</span></span> that is parameterized by some integer <span><span class="math inline">\(k\)</span></span>, and we prove that <strong>(a)</strong> <span><span class="math inline">\(Q(0)\)</span></span> is true, and <strong>(b)</strong> For every <span><span class="math inline">\(k&gt;0\)</span></span>, if <span><span class="math inline">\(Q(0),\ldots,Q(k-1)\)</span></span> are all true then <span><span class="math inline">\(Q(k)\)</span></span> is true. (Usually proving <strong>(b)</strong> is the hard part, though there are examples where the “base case” <strong>(a)</strong> is quite subtle.) By applying Modus Ponens, we can deduce from <strong>(a)</strong> and <strong>(b)</strong> that <span><span class="math inline">\(Q(1)\)</span></span> is true. Once we did so, since we now know that both <span><span class="math inline">\(Q(0)\)</span></span> and <span><span class="math inline">\(Q(1)\)</span></span> are true, then we can use this and <strong>(b)</strong> to deduce (again using Modus Ponens) that <span><span class="math inline">\(Q(2)\)</span></span> is true. We can repeat the same reasoning again and again to obtain that <span><span class="math inline">\(Q(k)\)</span></span> is true for every <span><span class="math inline">\(k\)</span></span>. The statement <strong>(a)</strong> is called the “base case”, while <strong>(b)</strong> is called the “inductive step”. The assumption in <strong>(b)</strong> that <span><span class="math inline">\(Q(i)\)</span></span> holds for <span><span class="math inline">\(i&lt;k\)</span></span> is called the “inductive hypothesis”. (The form of induction described here is sometimes called “strong induction” as opposed to “weak induction” where we replace <strong>(b)</strong> by the statement <strong>(b’)</strong> that if <span><span class="math inline">\(Q(k-1)\)</span></span> is true then <span><span class="math inline">\(Q(k)\)</span></span> is true; weak induction can be thought of as the special case of strong induction where we don’t use the assumption that <span><span class="math inline">\(Q(0),\ldots,Q(k-2)\)</span></span> are true.)</p>
<div id="inducrecrem" class="remark" title="Induction and recursion" name="Remark 1.25 (Induction and recursion) ">
<p>Proofs by induction are closely related to algorithms by recursion. In both cases we reduce solving a larger problem to solving a smaller instance of itself. In a recursive algorithm to solve some problem P on an input of length <span><span class="math inline">\(k\)</span></span> we ask ourselves “what if someone handed me a way to solve P on instances smaller than <span><span class="math inline">\(k\)</span></span>?”. In an inductive proof to prove a statement Q parameterized by a number <span><span class="math inline">\(k\)</span></span>, we ask ourselves “what if I already knew that <span><span class="math inline">\(Q(k&#39;)\)</span></span> is true for <span><span class="math inline">\(k&#39;&lt;k\)</span></span>?”. Both induction and recursion are crucial concepts for this course and Computer Science at large (and even other areas of inquiry, including not just mathematics but other sciences as well). Both can be confusing at first, but with time and practice they become clearer. For more on proofs by induction and recursion, you might find the following <a href="https://cs121.boazbarak.org/StanfordCS103Induction.pdf">Stanford CS 103 handout</a>, <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00sc-introduction-to-computer-science-and-programming-spring-2011/unit-1/lecture-6-recursion/">this MIT 6.00 lecture</a> or <a href="https://cs121.boazbarak.org/LL_induction.pdf">this excerpt of the Lehman-Leighton book</a> useful.</p>
</div>
<h3 id="proving-the-result-by-induction" data-number="1.6.2">Proving the result by induction</h3>
<p>There are several ways to use induction to prove <a href='#acyclictosortlem'>Lemma 1.23</a> by induction. We will use induction on the number <span><span class="math inline">\(n\)</span></span> of vertices, and so we will define the statement <span><span class="math inline">\(Q(n)\)</span></span> as follows:</p>
<blockquote>
<p><span><span class="math inline">\(Q(n)\)</span></span> is <em>“For every DAG <span><span class="math inline">\(G=(V,E)\)</span></span> with <span><span class="math inline">\(n\)</span></span> vertices, there is a layering of <span><span class="math inline">\(G\)</span></span>.”</em></p>
</blockquote>
<p>The statement for <span><span class="math inline">\(Q(0)\)</span></span> (where the graph contains no vertices) is trivial. Thus it will suffice to prove the following: <em>for every <span><span class="math inline">\(n&gt;0\)</span></span>, if <span><span class="math inline">\(Q(n-1)\)</span></span> is true then <span><span class="math inline">\(Q(n)\)</span></span> is true.</em></p>
<p>To do so, we need to somehow find a way, given a graph <span><span class="math inline">\(G\)</span></span> of <span><span class="math inline">\(n\)</span></span> vertices, to reduce the task of finding a layering for <span><span class="math inline">\(G\)</span></span> into the task of finding a layering for some other graph <span><span class="math inline">\(G&#39;\)</span></span> of <span><span class="math inline">\(n-1\)</span></span> vertices. The idea is that we will find a <em>source</em> of <span><span class="math inline">\(G\)</span></span>: a vertex <span><span class="math inline">\(v\)</span></span> that has no in-neighbors. We can then assign to <span><span class="math inline">\(v\)</span></span> the layer <span><span class="math inline">\(0\)</span></span>, and layer the remaining vertices using the inductive hypothesis in layers <span><span class="math inline">\(1,2,\ldots\)</span></span>.</p>
<p>The above is the intuition behind the proof of <a href='#acyclictosortlem'>Lemma 1.23</a>, but when writing the formal proof below, we use the benefit of hindsight, and try to streamline what was a messy journey into a linear and easy-to-follow flow of logic that starts with the word <strong>“Proof:”</strong> and ends with <strong>“QED”</strong> or the symbol <span><span class="math inline">\(\blacksquare\)</span></span>.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> Discussions, examples and digressions can be very insightful, but we keep them outside the space delimited between these two words, where (as described by this <a href="http://web.stanford.edu/class/cs103/handouts/120%20Proofwriting%20Checklist.pdf">excellent handout</a>) “every sentence must be load bearing”. Just like we do in programming, we can break the proof into little “subroutines” or “functions” (known as <em>lemmas</em> or <em>claims</em> in math language), which will be smaller statements that help us prove the main result. However, the proof should be structured in a way that ensures that it is always crystal-clear to the reader in what stage we are of the proof. The reader should be able to tell what is the role of every sentence in the proof and which part it belongs to. We now present the formal proof of <a href='#acyclictosortlem'>Lemma 1.23</a>.</p>
<div class="proof" data-ref="acyclictosortlem" name="Proof 1.6.2">
<p>Let <span><span class="math inline">\(G=(V,E)\)</span></span> be a DAG and <span><span class="math inline">\(n=|V|\)</span></span> be the number of its vertices. We prove the lemma by induction on <span><span class="math inline">\(n\)</span></span>. The base case is <span><span class="math inline">\(n=0\)</span></span> where there are no vertices, and so the statement is trivially true.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup> For the case of <span><span class="math inline">\(n&gt;0\)</span></span>, we make the inductive hypothesis that every DAG <span><span class="math inline">\(G&#39;\)</span></span> of at most <span><span class="math inline">\(n-1\)</span></span> vertices has a layering.</p>
<p>We make the following claim:</p>
<p><strong>Claim:</strong> <span><span class="math inline">\(G\)</span></span> must contain a vertex <span><span class="math inline">\(v\)</span></span> of in-degree zero.</p>
<p><strong>Proof of Claim:</strong> Suppose otherwise that every vertex <span><span class="math inline">\(v\in V\)</span></span> has an in-neighbor. Let <span><span class="math inline">\(v_0\)</span></span> be some vertex of <span><span class="math inline">\(G\)</span></span>, let <span><span class="math inline">\(v_1\)</span></span> be an in-neighbor of <span><span class="math inline">\(v_0\)</span></span>, <span><span class="math inline">\(v_2\)</span></span> be an in-neighbor of <span><span class="math inline">\(v_1\)</span></span>, and continue in this way for <span><span class="math inline">\(n\)</span></span> steps until we construct a list <span><span class="math inline">\(v_0,v_1,\ldots,v_n\)</span></span> such that for every <span><span class="math inline">\(i\in [n]\)</span></span>, <span><span class="math inline">\(v_{i+1}\)</span></span> is an in-neighbor of <span><span class="math inline">\(v_i\)</span></span>, or in other words the edge <span><span class="math inline">\(v_{i+1} \rightarrow v_i\)</span></span> is present in the graph. Since there are only <span><span class="math inline">\(n\)</span></span> vertices in this graph, one of the <span><span class="math inline">\(n+1\)</span></span> vertices in this sequence must repeat itself, and so there exists <span><span class="math inline">\(i&lt;j\)</span></span> such that <span><span class="math inline">\(v_i=v_j\)</span></span>. But then the sequence <span><span class="math inline">\(v_j \rightarrow v_{j-1} \rightarrow \cdots \rightarrow v_i\)</span></span> is a cycle in <span><span class="math inline">\(G\)</span></span>, contradicting our assumption that it is acyclic. <strong>(QED Claim)</strong></p>
<p>Given the claim, we can let <span><span class="math inline">\(v_0\)</span></span> be some vertex of in-degree zero in <span><span class="math inline">\(G\)</span></span>, and let <span><span class="math inline">\(G&#39;\)</span></span> be the graph obtained by removing <span><span class="math inline">\(v_0\)</span></span> from <span><span class="math inline">\(G\)</span></span>. <span><span class="math inline">\(G&#39;\)</span></span> has <span><span class="math inline">\(n-1\)</span></span> vertices and hence per the inductive hypothesis has a layering <span><span class="math inline">\(f&#39;:(V \setminus \{v_0\}) \rightarrow \N\)</span></span>. We define <span><span class="math inline">\(f:V \rightarrow \N\)</span></span> as follows:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[f(v) = \begin{cases}f&#39;(v)+1 &amp; v \neq v_0 \\ 0 &amp; v=v_0 \end{cases}\;.\]</span></div></span></p>
<p>We claim that <span><span class="math inline">\(f\)</span></span> is a valid layering, namely that for every edge <span><span class="math inline">\(u \rightarrow v\)</span></span>, <span><span class="math inline">\(f(u) &lt; f(v)\)</span></span>. To prove this, we split into cases:</p>
<ul>
<li><p><strong>Case 1:</strong> <span><span class="math inline">\(u \neq v_0\)</span></span>, <span><span class="math inline">\(v \neq v_0\)</span></span>. In this case the edge <span><span class="math inline">\(u \rightarrow v\)</span></span> exists in the graph <span><span class="math inline">\(G&#39;\)</span></span> and hence by the inductive hypothesis <span><span class="math inline">\(f&#39;(u) &lt; f&#39;(v)\)</span></span> which implies that <span><span class="math inline">\(f&#39;(u)+1 &lt; f&#39;(v)+1\)</span></span>.</p></li>
<li><p><strong>Case 2:</strong> <span><span class="math inline">\(u=v_0\)</span></span>, <span><span class="math inline">\(v \neq v_0\)</span></span>. In this case <span><span class="math inline">\(f(u)=0\)</span></span> and <span><span class="math inline">\(f(v) = f&#39;(v)+1&gt;0\)</span></span>.</p></li>
<li><p><strong>Case 3:</strong> <span><span class="math inline">\(u \neq v_0\)</span></span>, <span><span class="math inline">\(v=v_0\)</span></span>. This case can’t happen since <span><span class="math inline">\(v_0\)</span></span> does not have in-neighbors.</p></li>
<li><p><strong>Case 4:</strong> <span><span class="math inline">\(u=v_0, v=v_0\)</span></span>. This case again can’t happen since it means that <span><span class="math inline">\(v_0\)</span></span> is its own-neighbor — it is involved in a <em>self loop</em> which is a form cycle that is disallowed in an acyclic graph.</p></li>
</ul>
<p>Thus, <span><span class="math inline">\(f\)</span></span> is a valid layering for <span><span class="math inline">\(G\)</span></span> which completes the proof.</p>
</div>
<div id="section-10" class="pause" name="Pause">
<p>Reading a proof is no less of an important skill than producing one. In fact, just like understanding code, it is a highly non-trivial skill in itself. Therefore I strongly suggest that you re-read the above proof, asking yourself at every sentence whether the assumption it makes is justified, and whether this sentence truly demonstrates what it purports to achieve. Another good habit is to ask yourself when reading a proof for every variable you encounter (such as <span><span class="math inline">\(u\)</span></span>, <span><span class="math inline">\(i\)</span></span>, <span><span class="math inline">\(G&#39;\)</span></span>, <span><span class="math inline">\(f&#39;\)</span></span>, etc. in the above proof) the following questions: <strong>(1)</strong> What <em>type</em> of variable is it? is it a number? a graph? a vertex? a function? and <strong>(2)</strong> What do we know about it? Is it an arbitrary member of the set? Have we shown some facts about it?, and <strong>(3)</strong> What are we <em>trying</em> to show about it?.</p>
</div>
<h3 id="minimality-and-uniqueness" data-number="1.6.3">Minimality and uniqueness</h3>
<p><a href='#topologicalsortthm'>Theorem 1.22</a> guarantees that for every DAG <span><span class="math inline">\(G=(V,E)\)</span></span> there exists some layering <span><span class="math inline">\(f:V \rightarrow \N\)</span></span> but this layering is not necessarily <em>unique</em>. For example, if <span><span class="math inline">\(f:V \rightarrow \N\)</span></span> is a valid layering of the graph then so is the function <span><span class="math inline">\(f&#39;\)</span></span> defined as <span><span class="math inline">\(f&#39;(v) = 2\cdot f(v)\)</span></span>. However, it turns out that the <em>minimal</em> layering is unique. A minimal layering is one where every vertex is given the smallest layer number possible. We now formally define minimality and state the uniqueness theorem:</p>
<div id="minimallayeruniquethm" class="theorem" title="Minimal layering is unique" name="Theorem 1.26 (Minimal layering is unique) ">
<p>Let <span><span class="math inline">\(G=(V,E)\)</span></span> be a DAG. We say that a layering <span><span class="math inline">\(f:V \rightarrow \N\)</span></span> is <em>minimal</em> if for every vertex <span><span class="math inline">\(v \in V\)</span></span>, if <span><span class="math inline">\(v\)</span></span> has no in-neighbors then <span><span class="math inline">\(f(v)=0\)</span></span> and if <span><span class="math inline">\(v\)</span></span> has in-neighbors then there exists an in-neighbor <span><span class="math inline">\(u\)</span></span> of <span><span class="math inline">\(v\)</span></span> such that <span><span class="math inline">\(f(u) = f(v)-1\)</span></span>.</p>
<p>For every layering <span><span class="math inline">\(f,g:V \rightarrow \N\)</span></span> of <span><span class="math inline">\(G\)</span></span>, if both <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> are minimal then <span><span class="math inline">\(f=g\)</span></span>.</p>
</div>
<p>The definition of minimality in <a href='#minimallayeruniquethm'>Theorem 1.26</a> implies that for every vertex <span><span class="math inline">\(v \in V\)</span></span>, we cannot move it to a lower layer without making the layering invalid. If <span><span class="math inline">\(v\)</span></span> is a source (i.e., has in-degree zero) then a minimal layering <span><span class="math inline">\(f\)</span></span> must put it in layer <span><span class="math inline">\(0\)</span></span>, and for every other <span><span class="math inline">\(v\)</span></span>, if <span><span class="math inline">\(f(v)=i\)</span></span>, then we cannot modify this to set <span><span class="math inline">\(f(v) \leq i-1\)</span></span> since there is an-neighbor <span><span class="math inline">\(u\)</span></span> of <span><span class="math inline">\(v\)</span></span> satisfying <span><span class="math inline">\(f(u)=i-1\)</span></span>. What <a href='#minimallayeruniquethm'>Theorem 1.26</a> says is that a minimal layering <span><span class="math inline">\(f\)</span></span> is <em>unique</em> in the sense that every other minimal layering is equal to <span><span class="math inline">\(f\)</span></span>.</p>
<div id="section-11" class="proofidea" data-ref="minimallayeruniquethm" name="Proofidea">
<p>The idea is to prove the theorem by induction on the layers. If <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> are minimal then they must agree on the source vertices, since both <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> should assign these vertices to layer <span><span class="math inline">\(0\)</span></span>. We can then show that if <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> agree up to layer <span><span class="math inline">\(i-1\)</span></span>, then the minimality property implies that they need to agree in layer <span><span class="math inline">\(i\)</span></span> as well. In the actual proof we use a small trick to save on writing. Rather than proving the statement that <span><span class="math inline">\(f=g\)</span></span> (or in other words that <span><span class="math inline">\(f(v)=g(v)\)</span></span> for every <span><span class="math inline">\(v\in V\)</span></span>), we prove the weaker statement that <span><span class="math inline">\(f(v) \leq g(v)\)</span></span> for every <span><span class="math inline">\(v\in V\)</span></span>. (This is a weaker statement since the condition that <span><span class="math inline">\(f(v)\)</span></span> is lesser or equal than to <span><span class="math inline">\(g(v)\)</span></span> is implied by the condition that <span><span class="math inline">\(f(v)\)</span></span> is equal to <span><span class="math inline">\(g(v)\)</span></span>.) However, since <span><span class="math inline">\(f\)</span></span> and <span><span class="math inline">\(g\)</span></span> are just labels we give to two minimal layerings, by simply changing the names “<span><span class="math inline">\(f\)</span></span>” and “<span><span class="math inline">\(g\)</span></span>” the same proof also shows that <span><span class="math inline">\(g(v) \leq f(v)\)</span></span> for every <span><span class="math inline">\(v\in V\)</span></span> and hence that <span><span class="math inline">\(f=g\)</span></span>.</p>
</div>
<div class="proof" data-ref="minimallayeruniquethm" name="Proof 1.6.3">
<p>Let <span><span class="math inline">\(G=(V,E)\)</span></span> be a DAG and <span><span class="math inline">\(f,g:V \rightarrow \N\)</span></span> be two minimal valid layering of <span><span class="math inline">\(G\)</span></span>. We will prove that for every <span><span class="math inline">\(v \in V\)</span></span>, <span><span class="math inline">\(f(v) \leq g(v)\)</span></span>. Since we didn’t assume anything about <span><span class="math inline">\(f,g\)</span></span> except their minimality, the same proof will imply that for every <span><span class="math inline">\(v\in V\)</span></span>, <span><span class="math inline">\(g(v) \leq f(v)\)</span></span> and hence that <span><span class="math inline">\(f(v)=g(v)\)</span></span> for every <span><span class="math inline">\(v\in V\)</span></span>, which is what we needed to show.</p>
<p>We will prove that <span><span class="math inline">\(f(v) \leq g(v)\)</span></span> for every <span><span class="math inline">\(v \in V\)</span></span> by induction on <span><span class="math inline">\(i = f(v)\)</span></span>. The case <span><span class="math inline">\(i=0\)</span></span> is immediate: since in this case <span><span class="math inline">\(f(v)=0\)</span></span>, <span><span class="math inline">\(g(v)\)</span></span> must be at least <span><span class="math inline">\(f(v)\)</span></span>. For the case <span><span class="math inline">\(i&gt;0\)</span></span>, by the minimality of <span><span class="math inline">\(f\)</span></span>, if <span><span class="math inline">\(f(v)=i\)</span></span> then there must exist some in-neighbor <span><span class="math inline">\(u\)</span></span> of <span><span class="math inline">\(v\)</span></span> such that <span><span class="math inline">\(f(u) = i-1\)</span></span>. By the induction hypothesis we get that <span><span class="math inline">\(g(u) \geq i-1\)</span></span>, and since <span><span class="math inline">\(g\)</span></span> is a valid layering it must hold that <span><span class="math inline">\(g(v) &gt; g(u)\)</span></span> which means that <span><span class="math inline">\(g(v) \geq i = f(v)\)</span></span>.</p>
</div>
<div class="pause" name="Pause">
<p>The proof of <a href='#minimallayeruniquethm'>Theorem 1.26</a> is fully rigorous, but is written in a somewhat terse manner. Make sure that you read through it and understand <em>why</em> this is indeed an airtight proof of the Theorem’s statement.</p>
</div>
<h2 id="notationsec" data-number="1.7">This book: notation and conventions</h2>
<p>Most of the notation we use in this book is standard and is used in most mathematical texts. The main points where we diverge are:</p>
<ul>
<li><p>We index the natural numbers <span><span class="math inline">\(\N\)</span></span> starting with <span><span class="math inline">\(0\)</span></span> (though many other texts, especially in computer science, do the same).</p></li>
<li><p>We also index the set <span><span class="math inline">\([n]\)</span></span> starting with <span><span class="math inline">\(0\)</span></span>, and hence define it as <span><span class="math inline">\(\{0,\ldots,n-1\}\)</span></span>. In other texts it is often defined as <span><span class="math inline">\(\{1,\ldots, n \}\)</span></span>. Similarly, we index our strings starting with <span><span class="math inline">\(0\)</span></span>, and hence a string <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> is written as <span><span class="math inline">\(x_0x_1\cdots x_{n-1}\)</span></span>.</p></li>
<li><p>If <span><span class="math inline">\(n\)</span></span> is a natural number then <span><span class="math inline">\(1^n\)</span></span> does <em>not</em> equal the number <span><span class="math inline">\(1\)</span></span> but rather this is the length <span><span class="math inline">\(n\)</span></span> string <span><span class="math inline">\(11\cdots 1\)</span></span> (that is a string of <span><span class="math inline">\(n\)</span></span> ones). Similarly, <span><span class="math inline">\(0^n\)</span></span> refers to the length <span><span class="math inline">\(n\)</span></span> string <span><span class="math inline">\(00 \cdots 0\)</span></span>.</p></li>
<li><p><em>Partial</em> functions are functions that are not necessarily defined on all inputs. When we write <span><span class="math inline">\(f:A \rightarrow B\)</span></span> this means that <span><span class="math inline">\(f\)</span></span> is a <em>total</em> function unless we say otherwise. When we want to emphasize that <span><span class="math inline">\(f\)</span></span> can be a partial function, we will sometimes write <span><span class="math inline">\(f: A \rightarrow_p B\)</span></span>.</p></li>
<li><p>As we will see later on in the course, we will mostly describe our computational problems in terms of computing a <em>Boolean function</em> <span><span class="math inline">\(f: \{0,1\}^* \rightarrow \{0,1\}\)</span></span>. In contrast, many other textbooks refer to the same task as <em>deciding a language</em> <span><span class="math inline">\(L \subseteq \{0,1\}^*\)</span></span>. These two viewpoints are equivalent, since for every set <span><span class="math inline">\(L\subseteq \{0,1\}^*\)</span></span> there is a corresponding function <span><span class="math inline">\(F\)</span></span> such that <span><span class="math inline">\(F(x)=1\)</span></span> if and only if <span><span class="math inline">\(x\in L\)</span></span>. Computing <em>partial functions</em> corresponds to the task known in the literature as a solving a <em>promise problem</em>. Because the language notation is so prevalent in other textbooks, we will occasionally remind the reader of this correspondence.</p></li>
<li><p>We use <span><span class="math inline">\(\ceil{x}\)</span></span> and <span><span class="math inline">\(\floor{x}\)</span></span> for the “ceiling” and “floor” operators that correspond to “rounding up” or “rounding down” a number to the nearest integer. We use <span><span class="math inline">\((x \mod y)\)</span></span> to denote the “remainder” of <span><span class="math inline">\(x\)</span></span> when divided by <span><span class="math inline">\(y\)</span></span>. That is, <span><span class="math inline">\((x \mod y) = x - y\floor{x/y}\)</span></span>. In context when an integer is expected we’ll typically “silently round” the quantities to an integer. For example, if we say that <span><span class="math inline">\(x\)</span></span> is a string of length <span><span class="math inline">\(\sqrt{n}\)</span></span> then this means that <span><span class="math inline">\(x\)</span></span> is of length <span><span class="math inline">\(\lceil \sqrt{n}\, \rceil\)</span></span>. (We round up for the sake of convention, but in most such cases, it will not make a difference whether we round up or down.)</p></li>
<li><p>Like most Computer Science texts, we default to the logarithm in base two. Thus, <span><span class="math inline">\(\log n\)</span></span> is the same as <span><span class="math inline">\(\log_2 n\)</span></span>.</p></li>
<li><p>We will also use the notation <span><span class="math inline">\(f(n)=poly(n)\)</span></span> as a shorthand for <span><span class="math inline">\(f(n)=n^{O(1)}\)</span></span> (i.e., as shorthand for saying that there are some constants <span><span class="math inline">\(a,b\)</span></span> such that <span><span class="math inline">\(f(n) \leq a\cdot n^b\)</span></span> for every sufficiently large <span><span class="math inline">\(n\)</span></span>). Similarly, we will use <span><span class="math inline">\(f(n)=polylog(n)\)</span></span> as shorthand for <span><span class="math inline">\(f(n)=poly(\log n)\)</span></span> (i.e., as shorthand for saying that there are some constants <span><span class="math inline">\(a,b\)</span></span> such that <span><span class="math inline">\(f(n) \leq a\cdot (\log n)^b\)</span></span> for every sufficiently large <span><span class="math inline">\(n\)</span></span>).</p></li>
<li><p>As in often the case in mathematical literature, we use the apostrophe character to enrich our set of identifiers. Typically if <span><span class="math inline">\(x\)</span></span> denotes some object, then <span><span class="math inline">\(x&#39;\)</span></span>, <span><span class="math inline">\(x&#39;&#39;\)</span></span>, etc. will denote other objects of the same type.</p></li>
<li><p>To save on “cognitive load” we will often use round constants such as <span><span class="math inline">\(10,100,1000\)</span></span> in the statements of both theorems and problem set questions. When you see such a “round” constant, you can typically assume that it has no special significance and was just chosen arbitrarily. For example, if you see a theorem of the form “Algorithm <span><span class="math inline">\(A\)</span></span> takes at most <span><span class="math inline">\(1000\cdot n^2\)</span></span> steps to compute function <span><span class="math inline">\(F\)</span></span> on inputs of length <span><span class="math inline">\(n\)</span></span>” then probably the number <span><span class="math inline">\(1000\)</span></span> is an abitrary sufficiently large constant, and one could prove the same theorem with a bound of the form <span><span class="math inline">\(c \cdot n^2\)</span></span> for a constant <span><span class="math inline">\(c\)</span></span> that is smaller than <span><span class="math inline">\(1000\)</span></span>. Similarly, if a problem asks you to prove that some quantity is at least <span><span class="math inline">\(n/100\)</span></span>, it is quite possible that in truth the quantity is at least <span><span class="math inline">\(n/d\)</span></span> for some constant <span><span class="math inline">\(d\)</span></span> that is smaller than <span><span class="math inline">\(100\)</span></span>.</p></li>
</ul>
<h3 id="conventionsec" data-number="1.7.1">Variable name conventions</h3>
<p>Like programming, mathematics is full of <em>variables</em>. Whenever you see a variable, it is always important to keep track of what is its <em>type</em> (e.g., whether the variable is a number, a string, a function, a graph, etc.). To make this easier, we try to stick to certain conventions and consistently use certain identifiers for variables of the same type. Some of these conventions are listed in <a href='#notationtable'>Subsection 1.7.1</a> below. These conventions are not immutable laws and we might occasionally deviate from them. Also, such conventions do not replace the need to explicitly declare for each new variable the type of object that it denotes.</p>
<p><a name="notationtable"></a></p>
<table>
<caption>Conventions for identifiers in this book</caption>
<colgroup>
<col style="width: 11%" />
<col style="width: 88%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><p><em>Identifier</em></p></th>
<th style="text-align: left;"><p><em>Often denotes object of type</em></p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(i\)</span>,<span class="math inline">\(j\)</span>,<span class="math inline">\(k\)</span>,<span class="math inline">\(\ell\)</span>,<span class="math inline">\(m\)</span>,<span class="math inline">\(n\)</span></p></td>
<td style="text-align: left;"><p>Natural numbers (i.e., in <span class="math inline">\(\mathbb{N} = \{0,1,2,\ldots \}\)</span>)</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><span class="math inline">\(\epsilon,\delta\)</span></p></td>
<td style="text-align: left;"><p>Small positive real numbers (very close to <span class="math inline">\(0\)</span>)</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(x,y,z,w\)</span></p></td>
<td style="text-align: left;"><p>Typically strings in <span class="math inline">\(\{0,1\}^*\)</span> though sometimes numbers or other objects. We often identify an object with its representation as a string.</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><span class="math inline">\(G\)</span></p></td>
<td style="text-align: left;"><p>A <em>graph</em>. The set of <span class="math inline">\(G\)</span>’s vertices is typically denoted by <span class="math inline">\(V\)</span>. Often <span class="math inline">\(V=[n]\)</span>. The set of <span class="math inline">\(G\)</span>’s edges is typically denoted by <span class="math inline">\(E\)</span>.</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(S\)</span></p></td>
<td style="text-align: left;"><p>Set</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><span class="math inline">\(f,g,h\)</span></p></td>
<td style="text-align: left;"><p>Functions. We often (though not always) use lowercase identifiers for <em>finite functions</em>, which map <span class="math inline">\(\{0,1\}^n\)</span> to <span class="math inline">\(\{0,1\}^m\)</span> (often <span class="math inline">\(m=1\)</span>).</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(F,G,H\)</span></p></td>
<td style="text-align: left;"><p>Infinite (unbounded input) functions mapping <span class="math inline">\(\{0,1\}^*\)</span> to <span class="math inline">\(\{0,1\}^*\)</span> or <span class="math inline">\(\{0,1\}^*\)</span> to <span class="math inline">\(\{0,1\}^m\)</span> for some <span class="math inline">\(m\)</span>. Based on context, the identifiers <span class="math inline">\(G,H\)</span> are sometimes used to denote functions and sometimes graphs.</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><span class="math inline">\(A,B,C\)</span></p></td>
<td style="text-align: left;"><p>Boolean circuits</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(M,N\)</span></p></td>
<td style="text-align: left;"><p>Turing machines</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><span class="math inline">\(P,Q\)</span></p></td>
<td style="text-align: left;"><p>Programs</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(T\)</span></p></td>
<td style="text-align: left;"><p>A function mapping <span class="math inline">\(\mathbb{N}\)</span> to <span class="math inline">\(\mathbb{N}\)</span> that corresponds to a time bound.</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><p><span class="math inline">\(c\)</span></p></td>
<td style="text-align: left;"><p>A positive number (often an unspecified constant; e.g., <span class="math inline">\(T(n)=O(n)\)</span> corresponds to the existence of <span class="math inline">\(c\)</span> s.t. <span class="math inline">\(T(n) \leq c \cdot n\)</span> every <span class="math inline">\(n&gt;0\)</span>). We sometimes use <span class="math inline">\(a,b\)</span> in a similar way.</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><p><span class="math inline">\(\Sigma\)</span></p></td>
<td style="text-align: left;"><p>Finite set (often used as the <em>alphabet</em> for a set of strings).</p></td>
</tr>
</tbody>
</table>
<h3 id="some-idioms" data-number="1.7.2">Some idioms</h3>
<p>Mathematical texts often employ certain conventions or “idioms”. Some examples of such idioms that we use in this text include the following:</p>
<ul>
<li><p><strong>“Let <span><span class="math inline">\(X\)</span></span> be <span><span class="math inline">\(\ldots\)</span></span>”</strong>, <strong>“let <span><span class="math inline">\(X\)</span></span> denote <span><span class="math inline">\(\ldots\)</span></span>”</strong>, or <strong>“let <span><span class="math inline">\(X= \ldots\)</span></span>”:</strong> These are all different ways for us to say that we are <em>defining</em> the symbol <span><span class="math inline">\(X\)</span></span> to stand for whatever expression is in the <span><span class="math inline">\(\ldots\)</span></span>. When <span><span class="math inline">\(X\)</span></span> is a <em>property</em> of some objects we might define <span><span class="math inline">\(X\)</span></span> by writing something along the lines of <strong>“We say that <span><span class="math inline">\(\ldots\)</span></span> has the property <span><span class="math inline">\(X\)</span></span> if <span><span class="math inline">\(\ldots\)</span></span>.”</strong>. While we often try to define terms before they are used, sometimes a mathematical sentence reads easier if we use a term before defining it, in which case we add <strong>“Where <span><span class="math inline">\(X\)</span></span> is <span><span class="math inline">\(\ldots\)</span></span>”</strong> to explain how <span><span class="math inline">\(X\)</span></span> is defined in the preceding expression.</p></li>
<li><p><strong>Quantifiers:</strong> Mathematical texts involve many quantifiers such as “for all” and “exists”. We sometimes spell these in words as in <strong>“for all <span><span class="math inline">\(i\in\N\)</span></span>”</strong> or <strong>“there is <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>”</strong>, and sometimes use the formal symbols <span><span class="math inline">\(\forall\)</span></span> and <span><span class="math inline">\(\exists\)</span></span>. It is important to keep track on which variable is quantified in what way the <em>dependencies</em> between the variables. For example, a sentence fragment such as <strong>“for every <span><span class="math inline">\(k &gt;0\)</span></span> there exists <span><span class="math inline">\(n\)</span></span>”</strong> means that <span><span class="math inline">\(n\)</span></span> can be chosen in a way that <em>depends</em> on <span><span class="math inline">\(k\)</span></span>. The order of quantifiers is important. For example, the following is a true statement: <em>“for every natural number <span><span class="math inline">\(k&gt;1\)</span></span> there exists a prime number <span><span class="math inline">\(n\)</span></span> such that <span><span class="math inline">\(n\)</span></span> divides <span><span class="math inline">\(k\)</span></span>.”</em> In contrast, the following statement is false: <em>“there exists a prime number <span><span class="math inline">\(n\)</span></span> such that for every natural number <span><span class="math inline">\(k&gt;1\)</span></span>, <span><span class="math inline">\(n\)</span></span> divides <span><span class="math inline">\(k\)</span></span>.”</em></p></li>
<li><p><strong>Numbered equations, theorems, definitions:</strong> To keep track of all the terms we define and statements we prove, we often assign them a (typically numeric) label, and then refer back to them in other parts of the text.</p></li>
<li><p><strong>(i.e.,), (e.g.,):</strong> Mathematical texts tend to contain quite a few of these expressions. We use <span><span class="math inline">\(X\)</span></span> (i.e., <span><span class="math inline">\(Y\)</span></span>) in cases where <span><span class="math inline">\(Y\)</span></span> is equivalent to <span><span class="math inline">\(X\)</span></span> and <span><span class="math inline">\(X\)</span></span> (e.g., <span><span class="math inline">\(Y\)</span></span>) in cases where <span><span class="math inline">\(Y\)</span></span> is an example of <span><span class="math inline">\(X\)</span></span> (e.g., one can use phrases such as “a natural number (i.e., a non-negative integer)” or “a natural number (e.g., <span><span class="math inline">\(7\)</span></span>)”).</p></li>
<li><p><strong>“Thus”</strong>, <strong>“Therefore”</strong> , <strong>“We get that”</strong>: This means that the following sentence is implied by the preceding one, as in “The <span><span class="math inline">\(n\)</span></span>-vertex graph <span><span class="math inline">\(G\)</span></span> is connected. Therefore it contains at least <span><span class="math inline">\(n-1\)</span></span> edges.” We sometimes use <strong>“indeed”</strong> to indicate that the following text justifies the claim that was made in the preceding sentence as in <em>“The <span><span class="math inline">\(n\)</span></span>-vertex graph <span><span class="math inline">\(G\)</span></span> has at least <span><span class="math inline">\(n-1\)</span></span> edges. Indeed, this follows since <span><span class="math inline">\(G\)</span></span> is connected.”</em></p></li>
<li><p><strong>Constants:</strong> In Computer Science, we typically care about how our algorithms’ resource consumption (such as running time) <em>scales</em> with certain quantities (such as the length of the input). We refer to quantities that do not depend on the length of the input as <em>constants</em> and so often use statements such as <em>“there exists a constant <span><span class="math inline">\(c&gt;0\)</span></span> such that for every <span><span class="math inline">\(n\in \N\)</span></span>, Algorithm <span><span class="math inline">\(A\)</span></span> runs in at most <span><span class="math inline">\(c \cdot n^2\)</span></span> steps on inputs of length <span><span class="math inline">\(n\)</span></span>.”</em> The qualifier “constant” for <span><span class="math inline">\(c\)</span></span> is not strictly needed but is added to emphasize that <span><span class="math inline">\(c\)</span></span> here is a fixed number independent of <span><span class="math inline">\(n\)</span></span>. In fact sometimes, to reduce cognitive load, we will simply replace <span><span class="math inline">\(c\)</span></span> by a sufficiently large round number such as <span><span class="math inline">\(10\)</span></span>, <span><span class="math inline">\(100\)</span></span>, or <span><span class="math inline">\(1000\)</span></span>, or use <span><span class="math inline">\(O\)</span></span>-notation and write <em>“Algorithm <span><span class="math inline">\(A\)</span></span> runs in <span><span class="math inline">\(O(n^2)\)</span></span> time.”</em></p></li>
</ul>
<div id="section-12" class="recap" name="Recap">
<ul>
<li>The basic “mathematical data structures” we’ll need are <em>numbers</em>, <em>sets</em>, <em>tuples</em>, <em>strings</em>, <em>graphs</em> and <em>functions</em>.</li>
<li>We can use basic objects to define more complex notions. For example, <em>graphs</em> can be defined as a list of <em>pairs</em>.</li>
<li>Given precise <em>definitions</em> of objects, we can state unambiguous and precise <em>statements</em>. We can then use mathematical <em>proofs</em> to determine whether these statements are true or false.</li>
<li>A mathematical proof is not a formal ritual but rather a clear, precise and “bulletproof” argument certifying the truth of a certain statement.</li>
<li>Big-<span><span class="math inline">\(O\)</span></span> notation is an extremely useful formalism to suppress less significant details and allow us to focus on the high level behavior of quantities of interest.</li>
<li>The only way to get comfortable with mathematical notions is to apply them in the contexts of solving problems. You should expect to need to go back time and again to the definitions and notation in this chapter as you work through problems in this course.</li>
</ul>
</div>
<h2 id="exercises" data-number="1.8">Exercises</h2>
<div id="logicalex" class="exercise" title="Logical expressions" name="Exercise 1.1 (Logical expressions) ">
<ol type="a">
<li><p>Write a logical expression <span><span class="math inline">\(\varphi(x)\)</span></span> involving the variables <span><span class="math inline">\(x_0,x_1,x_2\)</span></span> and the operators <span><span class="math inline">\(\wedge\)</span></span> (AND), <span><span class="math inline">\(\vee\)</span></span> (OR), and <span><span class="math inline">\(\neg\)</span></span> (NOT), such that <span><span class="math inline">\(\varphi(x)\)</span></span> is true if the majority of the inputs are <em>True</em>.</p></li>
<li><p>Write a logical expression <span><span class="math inline">\(\varphi(x)\)</span></span> involving the variables <span><span class="math inline">\(x_0,x_1,x_2\)</span></span> and the operators <span><span class="math inline">\(\wedge\)</span></span> (AND), <span><span class="math inline">\(\vee\)</span></span> (OR), and <span><span class="math inline">\(\neg\)</span></span> (NOT), such that <span><span class="math inline">\(\varphi(x)\)</span></span> is true if the sum <span><span class="math inline">\(\sum_{i=0}^{2} x_i\)</span></span> (identifying “true” with <span><span class="math inline">\(1\)</span></span> and “false” with <span><span class="math inline">\(0\)</span></span>) is <em>odd</em>.</p></li>
</ol>
</div>
<div id="quantifiersex" class="exercise" title="Quantifiers" name="Exercise 1.2 (Quantifiers) ">
<p>Use the logical quantifiers <span><span class="math inline">\(\forall\)</span></span> (for all), <span><span class="math inline">\(\exists\)</span></span> (there exists), as well as <span><span class="math inline">\(\wedge,\vee,\neg\)</span></span> and the arithmetic operations <span><span class="math inline">\(+,\times,=,&gt;,&lt;\)</span></span> to write the following:</p>
<ol type="a">
<li><p>An expression <span><span class="math inline">\(\varphi(n,k)\)</span></span> such that for every natural numbers <span><span class="math inline">\(n,k\)</span></span>, <span><span class="math inline">\(\varphi(n,k)\)</span></span> is true if and only if <span><span class="math inline">\(k\)</span></span> divides <span><span class="math inline">\(n\)</span></span>.</p></li>
<li><p>An expression <span><span class="math inline">\(\varphi(n)\)</span></span> such that for every natural number <span><span class="math inline">\(n\)</span></span>, <span><span class="math inline">\(\varphi(n)\)</span></span> is true if and only if <span><span class="math inline">\(n\)</span></span> is a power of three.</p></li>
</ol>
</div>
<div id="section-13" class="exercise" name="Exercise">
<p>Describe the following statement in English words: <span><span class="math inline">\(\forall_{n\in\N} \exists_{p&gt;n} \forall{a,b \in \N} (a\times b \neq p) \vee (a=1)\)</span></span>.</p>
</div>
<div id="setsdescription" class="exercise" title="Set construction notation" name="Exercise 1.4 (Set construction notation) ">
<p>Describe in words the following sets:</p>
<ol type="a">
<li><p><span><span class="math inline">\(S = \{ x\in \{0,1\}^{100} : \forall_{i\in \{0,\ldots, 99\}} x_i = x_{99-i} \}\)</span></span></p></li>
<li><p><span><span class="math inline">\(T = \{ x\in \{0,1\}^* : \forall_{i,j \in \{2,\ldots,|x|-1 \} } i\cdot j \neq |x| \}\)</span></span></p></li>
</ol>
</div>
<div id="cardinalitiesex" class="exercise" title="Existence of one to one mappings" name="Exercise 1.5 (Existence of one to one mappings) ">
<p>For each one of the following pairs of sets <span><span class="math inline">\((S,T)\)</span></span>, prove or disprove the following statement: there is a one to one function <span><span class="math inline">\(f\)</span></span> mapping <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span>.</p>
<ol type="a">
<li><p>Let <span><span class="math inline">\(n&gt;10\)</span></span>. <span><span class="math inline">\(S = \{0,1\}^n\)</span></span> and <span><span class="math inline">\(T= [n] \times [n] \times [n]\)</span></span>.</p></li>
<li><p>Let <span><span class="math inline">\(n&gt;10\)</span></span>. <span><span class="math inline">\(S\)</span></span> is the set of all functions mapping <span><span class="math inline">\(\{0,1\}^n\)</span></span> to <span><span class="math inline">\(\{0,1\}\)</span></span>. <span><span class="math inline">\(T = \{0,1\}^{n^3}\)</span></span>.</p></li>
<li><p>Let <span><span class="math inline">\(n&gt;100\)</span></span>. <span><span class="math inline">\(S = \{k \in [n] \;|\; k \text{ is prime} \}\)</span></span>, <span><span class="math inline">\(T = \{0,1\}^{\ceil{\log n -1}}\)</span></span>.</p></li>
</ol>
</div>
<div id="inclex" class="exercise" title="Inclusion Exclusion" name="Exercise 1.6 (Inclusion Exclusion) ">
<ol type="a">
<li><p>Let <span><span class="math inline">\(A,B\)</span></span> be finite sets. Prove that <span><span class="math inline">\(|A\cup B| = |A|+|B|-|A\cap B|\)</span></span>.</p></li>
<li><p>Let <span><span class="math inline">\(A_0,\ldots,A_{k-1}\)</span></span> be finite sets. Prove that <span><span class="math inline">\(|A_0 \cup \cdots \cup A_{k-1}| \geq \sum_{i=0}^{k-1} |A_i| - \sum_{0 \leq i &lt; j &lt; k} |A_i \cap A_j|\)</span></span>.</p></li>
<li><p>Let <span><span class="math inline">\(A_0,\ldots,A_{k-1}\)</span></span> be finite subsets of <span><span class="math inline">\(\{1,\ldots, n\}\)</span></span>, such that <span><span class="math inline">\(|A_i|=m\)</span></span> for every <span><span class="math inline">\(i\in [k]\)</span></span>. Prove that if <span><span class="math inline">\(k&gt;100n\)</span></span>, then there exist two distinct sets <span><span class="math inline">\(A_i,A_j\)</span></span> s.t. <span><span class="math inline">\(|A_i \cap A_j| \geq m^2/(10n)\)</span></span>.</p></li>
</ol>
</div>
<div class="exercise" name="Exercise 1.8">
<p>Prove that if <span><span class="math inline">\(S,T\)</span></span> are finite and <span><span class="math inline">\(F:S \rightarrow T\)</span></span> is one to one then <span><span class="math inline">\(|S| \leq |T|\)</span></span>.</p>
</div>
<div id="section-14" class="exercise" name="Exercise">
<p>Prove that if <span><span class="math inline">\(S,T\)</span></span> are finite and <span><span class="math inline">\(F:S \rightarrow T\)</span></span> is onto then <span><span class="math inline">\(|S| \geq |T|\)</span></span>.</p>
</div>
<div id="section-15" class="exercise" name="Exercise">
<p>Prove that for every finite <span><span class="math inline">\(S,T\)</span></span>, there are <span><span class="math inline">\((|T|+1)^{|S|}\)</span></span> partial functions from <span><span class="math inline">\(S\)</span></span> to <span><span class="math inline">\(T\)</span></span>.</p>
</div>
<div id="section-16" class="exercise" name="Exercise">
<p>Suppose that <span><span class="math inline">\(\{ S_n \}_{n\in \N}\)</span></span> is a sequence such that <span><span class="math inline">\(S_0 \leq 10\)</span></span> and for <span><span class="math inline">\(n&gt;1\)</span></span> <span><span class="math inline">\(S_n \leq 5 S_{\lfloor \tfrac{n}{5} \rfloor} + 2n\)</span></span>. Prove by induction that <span><span class="math inline">\(S_n \leq 100 n \log n\)</span></span> for every <span><span class="math inline">\(n\)</span></span>.</p>
</div>
<div id="section-17" class="exercise" name="Exercise">
<p>Prove that for every undirected graph <span><span class="math inline">\(G\)</span></span> of <span><span class="math inline">\(100\)</span></span> vertices, if every vertex has degree at most <span><span class="math inline">\(4\)</span></span>, then there exists a subset <span><span class="math inline">\(S\)</span></span> of at <span><span class="math inline">\(20\)</span></span> vertices such that no two vertices in <span><span class="math inline">\(S\)</span></span> are neighbors of one another.</p>
</div>
<div id="ohnotationex" class="exercise" title="$O$-notation" name="Exercise 1.12 ($O$-notation) ">
<p>For every pair of functions <span><span class="math inline">\(F,G\)</span></span> below, determine which of the following relations holds: <span><span class="math inline">\(F=O(G)\)</span></span>, <span><span class="math inline">\(F=\Omega(G)\)</span></span>, <span><span class="math inline">\(F=o(G)\)</span></span> or <span><span class="math inline">\(F=\omega(G)\)</span></span>.</p>
<ol type="a">
<li><p><span><span class="math inline">\(F(n)=n\)</span></span>, <span><span class="math inline">\(G(n)=100n\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(F(n)=n\)</span></span>, <span><span class="math inline">\(G(n)=\sqrt{n}\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(F(n)=n\log n\)</span></span>, <span><span class="math inline">\(G(n)=2^{(\log (n))^2}\)</span></span>.</p></li>
<li><p><span><span class="math inline">\(F(n)=\sqrt{n}\)</span></span>, <span><span class="math inline">\(G(n)=2^{\sqrt{\log n}}\)</span></span></p></li>
<li><p><span><span class="math inline">\(F(n) = \binom{n}{\ceil{0.2 n}}\)</span></span> , <span><span class="math inline">\(G(n) = 2^{0.1 n}\)</span></span> (where <span><span class="math inline">\(\binom{n}{k}\)</span></span> is the number of <span><span class="math inline">\(k\)</span></span>-sized subsets of a set of size <span><span class="math inline">\(n\)</span></span>) and <span><span class="math inline">\(g(n) = 2^{0.1 n}\)</span></span>. See footnote for hint.<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup></p></li>
</ol>
</div>
<div id="section-18" class="exercise" name="Exercise">
<p>Give an example of a pair of functions <span><span class="math inline">\(F,G:\N \rightarrow \N\)</span></span> such that neither <span><span class="math inline">\(F=O(G)\)</span></span> nor <span><span class="math inline">\(G=O(F)\)</span></span> holds.</p>
</div>
<div id="graphcycleex" class="exercise" name="Exercise 1.14">
<p>Prove that for every undirected graph <span><span class="math inline">\(G\)</span></span> on <span><span class="math inline">\(n\)</span></span> vertices, if <span><span class="math inline">\(G\)</span></span> has at least <span><span class="math inline">\(n\)</span></span> edges then <span><span class="math inline">\(G\)</span></span> contains a cycle.</p>
</div>
<div id="indsetex" class="exercise" name="Exercise 1.15">
<p>Prove that for every undirected graph <span><span class="math inline">\(G\)</span></span> of <span><span class="math inline">\(1000\)</span></span> vertices, if every vertex has degree at most <span><span class="math inline">\(4\)</span></span>, then there exists a subset <span><span class="math inline">\(S\)</span></span> of at least <span><span class="math inline">\(200\)</span></span> vertices such that no two vertices in <span><span class="math inline">\(S\)</span></span> are neighbors of one another.</p>
</div>
<h2 id="notesmathchap" data-number="1.9">Bibliographical notes</h2>
<p>The heading “A Mathematician’s Apology”, refers to Hardy’s classic book  (<a href="https://scholar.google.com/scholar?hl=en&q=Hardy+A+Mathematician's+Apology" target="_blank">Hardy, 1941</a>) . Even when Hardy is wrong, he is very much worth reading.</p>
<p>There are many online sources for the mathematical background needed for this book. In particular, the lecture notes for MIT 6.042 “Mathematics for Computer Science”  (<a href="https://scholar.google.com/scholar?hl=en&q=Lehman,+Leighton,+Meyer+Mathematics+for+Computer+Science" target="_blank">Lehman, Leighton, Meyer, 2018</a>)  are extremely comprehensive, and videos and assignments for this course are available online. Similarly, <a href="http://www.eecs70.org/">Berkeley CS 70: “Discrete Mathematics and Probability Theory”</a> has extensive lecture notes online.</p>
<p>Other sources for discrete mathematics are Rosen  (<a href="https://scholar.google.com/scholar?hl=en&q=Rosen+Discrete+mathematics+and+its+applications" target="_blank">Rosen, 2019</a>)  and Jim Aspens’ online book  (<a href="https://scholar.google.com/scholar?hl=en&q=Aspens+Notes+on+Discrete+Mathematics" target="_blank">Aspens, 2018</a>) . Lewis and Zax  (<a href="https://scholar.google.com/scholar?hl=en&q=Lewis,+Zax+Essential+Discrete+Mathematics+for+Computer+Science" target="_blank">Lewis, Zax, 2019</a>) , as well as the online book of Fleck  (<a href="https://scholar.google.com/scholar?hl=en&q=Fleck+Building+Blocks+for+Theoretical+Computer+Science" target="_blank">Fleck, 2018</a>) , give a more gentle overview of the much of the same material. Solow  (<a href="https://scholar.google.com/scholar?hl=en&q=Solow+How+to+read+and+do+proofs+:+an+introduction+to+mathematical+thought+processes" target="_blank">Solow, 2014</a>)  is a good introduction to proof reading and writing. Kun  (<a href="https://scholar.google.com/scholar?hl=en&q=Kun+A+programmer's+introduction+to+mathematics" target="_blank">Kun, 2018</a>)  gives an introduction to mathematics aimed at readers with programming background. Stanford’s <a href="https://cs103.stanford.edu">CS 103 course</a> has a wonderful collections of handouts on mathematical proof techniques and discrete mathematics.</p>
<p>The word <em>graph</em> in the sense of <a href='#undirgraph'>Definition 1.3</a> was coined by the mathematician Sylvester in 1878 in analogy with the chemical graphs used to visualize molecules. There is an unfortunate confusion between this term and the more common usage of the word “graph” as a way to plot data, and in particular a plot of some function <span><span class="math inline">\(f(x)\)</span></span> as a function of <span><span class="math inline">\(x\)</span></span>. One way to relate these two notions is to identify every function <span><span class="math inline">\(f:A \rightarrow B\)</span></span> with the directed graph <span><span class="math inline">\(G_f\)</span></span> over the vertex set <span><span class="math inline">\(V= A \cup B\)</span></span> such that <span><span class="math inline">\(G_f\)</span></span> contains the edge <span><span class="math inline">\(x \rightarrow f(x)\)</span></span> for every <span><span class="math inline">\(x\in A\)</span></span>. In a graph <span><span class="math inline">\(G_f\)</span></span> constructed in this way, every vertex in <span><span class="math inline">\(A\)</span></span> has out-degree equal to one. If the function <span><span class="math inline">\(f\)</span></span> is <em>one to one</em> then every vertex in <span><span class="math inline">\(B\)</span></span> has in-degree at most one. If the function <span><span class="math inline">\(f\)</span></span> is <em>onto</em> then every vertex in <span><span class="math inline">\(B\)</span></span> has in-degree at least one. If <span><span class="math inline">\(f\)</span></span> is a bijection then every vertex in <span><span class="math inline">\(B\)</span></span> has in-degree exactly equal to one.</p>
<p>Carl Pomerance’s quote is taken from <a href="http://sites.math.rutgers.edu/~zeilberg/quotes.html">the home page of Doron Zeilberger</a>.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>The letter Z stands for the German word “Zahlen”, which means <em>numbers</em>.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>For two natural numbers <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(a\)</span></span>, <span><span class="math inline">\(x \mod a\)</span></span> (shorthand for <a href="https://goo.gl/b7Fdzm">“modulo”</a>) denotes the <em>remainder</em> of <span><span class="math inline">\(x\)</span></span> when it is divided by <span><span class="math inline">\(a\)</span></span>. That is, it is the number <span><span class="math inline">\(r\)</span></span> in <span><span class="math inline">\(\{0,\ldots,a-1\}\)</span></span> such that <span><span class="math inline">\(x = ak +r\)</span></span> for some integer <span><span class="math inline">\(k\)</span></span>. We sometimes also use the notation <span><span class="math inline">\(x = y\; (\mod a)\)</span></span> to denote the assertion that <span><span class="math inline">\(x \mod a\)</span></span> is the same as <span><span class="math inline">\(y \mod a\)</span></span>.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>It is possible, and sometimes useful, to think of an undirected graph as the special case of a directed graph that has the special property that for every pair <span><span class="math inline">\(u,v\)</span></span> either both the edges <span><span class="math inline">\((u,v)\)</span></span> and <span><span class="math inline">\((v,u)\)</span></span> are present or neither of them is. However, in many settings there is a significant difference between undirected and directed graphs, and so it’s typically best to think of them as separate categories.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>In this book, we place the variable bound by a quantifier in a subscript and so write <span><span class="math inline">\(\forall_{x\in S}P(x)\)</span></span>. Many other texts do not use this subscript notation and so will write the same statement as <span><span class="math inline">\(\forall x\in S, \; P(x)\)</span></span>.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>QED stands for “quod erat demonstrandum”, which is Latin for “what was to be demonstrated” or “the very thing it was required to have shown”.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p>Using <span><span class="math inline">\(n=0\)</span></span> as the base case is logically valid, but can be confusing. If you find the trivial <span><span class="math inline">\(n=0\)</span></span> case to be confusing, you can always directly verify the statement for <span><span class="math inline">\(n=1\)</span></span> and then use both <span><span class="math inline">\(n=0\)</span></span> and <span><span class="math inline">\(n=1\)</span></span> as the base cases.</p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:7"><p>
<div>
<p>one way to do this is to use <a href="https://goo.gl/cqEmS2">Stirling’s approximation for the factorial function.</a>.</p>
</div>
<a href="#fnref:7" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 21:38:43</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_00_1_math_background.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
