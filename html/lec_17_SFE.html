<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An intensive introduction to cryptography: Multiparty secure computation</title>
  <meta name="description" content="Lecture notes on Cryptography by Boaz Barak">

  <meta property="og:title" content="An intensive introduction to cryptography: Multiparty secure computation" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://intensecrypto.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="github-repo" content="boazbk/crypto" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An intensive introduction to cryptography" />
  <meta name="twitter:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="twitter:image" content="https://intensecrypto.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">An intensive introduction to cryptography</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html"><i class="fa fa-check"></i><b>p</b> Foreword and Syllabus</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#syllabus"><i class="fa fa-check"></i><b>p.1</b> Syllabus</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#prerequisites"><i class="fa fa-check"></i><b>p.1.1</b> Prerequisites</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#why-is-cryptography-hard"><i class="fa fa-check"></i><b>p.2</b> Why is cryptography hard?</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html"><i class="fa fa-check"></i><b>0</b> Mathematical Background</a><ul><li class="chapter" data-level="0.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#a-quick-overview-of-mathematical-prerequisites"><i class="fa fa-check"></i><b>0.1</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="0.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#mathematical-proofs"><i class="fa fa-check"></i><b>0.2</b> Mathematical Proofs</a><ul><li class="chapter" data-level="0.2.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#example-the-existence-of-infinitely-many-primes."><i class="fa fa-check"></i><b>0.2.1</b> Example: The existence of infinitely many primes.</a></li></ul></li><li class="chapter" data-level="0.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#probability-and-sample-spaces"><i class="fa fa-check"></i><b>0.3</b> Probability and Sample spaces</a><ul><li class="chapter" data-level="0.3.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#random-variables"><i class="fa fa-check"></i><b>0.3.1</b> Random variables</a></li><li class="chapter" data-level="0.3.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#distributions-over-strings"><i class="fa fa-check"></i><b>0.3.2</b> Distributions over strings</a></li><li class="chapter" data-level="0.3.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>0.3.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="0.4" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#correlations-and-independence"><i class="fa fa-check"></i><b>0.4</b> Correlations and independence</a><ul><li class="chapter" data-level="0.4.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#independent-random-variables"><i class="fa fa-check"></i><b>0.4.1</b> Independent random variables</a></li><li class="chapter" data-level="0.4.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>0.4.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="0.5" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#concentration"><i class="fa fa-check"></i><b>0.5</b> Concentration</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>0.5.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="0.5.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#the-chernoff-bound"><i class="fa fa-check"></i><b>0.5.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul><li class="chapter" data-level="1.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-encryptions"><i class="fa fa-check"></i><b>1.1</b> Defining encryptions</a><ul><li class="chapter" data-level="1.1.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#generating-randomness-in-actual-cryptographic-systems"><i class="fa fa-check"></i><b>1.1.1</b> Generating randomness in actual cryptographic systems</a></li></ul></li><li class="chapter" data-level="1.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-the-secrecy-requirement."><i class="fa fa-check"></i><b>1.2</b> Defining the secrecy requirement.</a></li><li class="chapter" data-level="1.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#perfect-secrecy"><i class="fa fa-check"></i><b>1.3</b> Perfect Secrecy</a></li><li class="chapter" data-level="1.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>1.4</b> Necessity of long keys</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#advanced-comment-adding-probability-into-the-picture"><i class="fa fa-check"></i><b>1.4.1</b> Advanced comment: Adding probability into the picture</a></li></ul></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html"><i class="fa fa-check"></i><b>2</b> Computational Security</a><ul><li><ul><li class="chapter" data-level="2.0.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#proof-by-reduction"><i class="fa fa-check"></i><b>2.0.1</b> Proof by reduction</a></li></ul></li><li class="chapter" data-level="2.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#the-asymptotic-approach"><i class="fa fa-check"></i><b>2.1</b> The asymptotic approach</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#counting-number-of-operations."><i class="fa fa-check"></i><b>2.1.1</b> Counting number of operations.</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#our-first-conjecture"><i class="fa fa-check"></i><b>2.2</b> Our first conjecture</a></li><li class="chapter" data-level="2.3" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#why-care-about-the-cipher-conjecture"><i class="fa fa-check"></i><b>2.3</b> Why care about the cipher conjecture?</a></li><li class="chapter" data-level="2.4" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#prelude-computational-indistinguishability"><i class="fa fa-check"></i><b>2.4</b> Prelude: Computational Indistinguishability</a></li><li class="chapter" data-level="2.5" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#the-length-extension-theorem"><i class="fa fa-check"></i><b>2.5</b> The Length Extension Theorem</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#appendix-the-computational-model"><i class="fa fa-check"></i><b>2.5.1</b> Appendix: The computational model</a></li></ul></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html"><i class="fa fa-check"></i><b>3</b> Pseudorandomness</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#stream-ciphers"><i class="fa fa-check"></i><b>3.1</b> Stream ciphers</a></li><li class="chapter" data-level="3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#what-do-pseudorandom-generators-actually-look-like"><i class="fa fa-check"></i><b>3.2</b> What do pseudorandom generators actually look like?</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-0-the-counter-generator"><i class="fa fa-check"></i><b>3.2.1</b> Attempt 0: The counter generator</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-1-the-linear-checksum-linear-feedback-shift-register-lfsr"><i class="fa fa-check"></i><b>3.2.2</b> Attempt 1: The linear checksum / linear feedback shift register (LFSR)</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#from-insecurity-to-security"><i class="fa fa-check"></i><b>3.2.3</b> From insecurity to security</a></li><li class="chapter" data-level="3.2.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-2-linear-congruential-generators-with-dropped-bits"><i class="fa fa-check"></i><b>3.2.4</b> Attempt 2: Linear Congruential Generators with dropped bits</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#successful-examples"><i class="fa fa-check"></i><b>3.3</b> Successful examples</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-1-subset-sum-generator"><i class="fa fa-check"></i><b>3.3.1</b> Case Study 1: Subset Sum Generator</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-2-rc4"><i class="fa fa-check"></i><b>3.3.2</b> Case Study 2: RC4</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#non-constructive-existence-of-pseudorandom-generators"><i class="fa fa-check"></i><b>3.4</b> Non-constructive existence of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html"><i class="fa fa-check"></i><b>4</b> Pseudorandom functions</a><ul><li class="chapter" data-level="4.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#one-time-passwords-e.g.-google-authenticator-rsa-id-etc."><i class="fa fa-check"></i><b>4.1</b> One time passwords (e.g. Google Authenticator, RSA ID, etc.)</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#how-do-pseudorandom-functions-help-in-the-login-problem"><i class="fa fa-check"></i><b>4.1.1</b> How do pseudorandom functions help in the login problem?</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#message-authentication-codes"><i class="fa fa-check"></i><b>4.2</b> Message Authentication Codes</a></li><li class="chapter" data-level="4.3" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#macs-from-prfs"><i class="fa fa-check"></i><b>4.3</b> MACs from PRFs</a></li><li class="chapter" data-level="4.4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#input-length-extension-for-macs-and-prfs"><i class="fa fa-check"></i><b>4.4</b> Input length extension for MACs and PRFs</a></li><li class="chapter" data-level="4.5" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#aside-natural-proofs"><i class="fa fa-check"></i><b>4.5</b> Aside: natural proofs</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html"><i class="fa fa-check"></i><b>5</b> Pseudorandom functions from pseudorandom generators</a><ul><li class="chapter" data-level="5.1" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#securely-encrypting-many-messages---chosen-plaintext-security"><i class="fa fa-check"></i><b>5.1</b> Securely encrypting many messages - chosen plaintext security</a></li><li class="chapter" data-level="5.2" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#pseudorandom-permutations-block-ciphers"><i class="fa fa-check"></i><b>5.2</b> Pseudorandom permutations / block ciphers</a></li><li class="chapter" data-level="5.3" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#encryption-modes"><i class="fa fa-check"></i><b>5.3</b> Encryption modes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html"><i class="fa fa-check"></i><b>6</b> Chosen Ciphertext Security</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#short-recap"><i class="fa fa-check"></i><b>6.1</b> Short recap</a></li><li class="chapter" data-level="6.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#going-beyond-cpa"><i class="fa fa-check"></i><b>6.2</b> Going beyond CPA</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#example-the-wired-equivalence-protocol-wep"><i class="fa fa-check"></i><b>6.2.1</b> Example: The Wired Equivalence Protocol (WEP)</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-security-1"><i class="fa fa-check"></i><b>6.2.2</b> Chosen ciphertext security</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#constructing-cca-secure-encryption"><i class="fa fa-check"></i><b>6.3</b> Constructing CCA secure encryption</a></li><li class="chapter" data-level="6.4" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#simplified-gcm-encryption"><i class="fa fa-check"></i><b>6.4</b> (Simplified) GCM encryption</a></li><li class="chapter" data-level="6.5" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#padding-chopping-and-their-pitfalls-the-buffer-overflow-of-cryptography"><i class="fa fa-check"></i><b>6.5</b> Padding, chopping, and their pitfalls: the buffer overflow of cryptography</a></li><li class="chapter" data-level="6.6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-attack-as-implementing-metaphors"><i class="fa fa-check"></i><b>6.6</b> Chosen ciphertext attack as implementing metaphors</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html"><i class="fa fa-check"></i><b>7</b> Hash functions and random oracles</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-problem"><i class="fa fa-check"></i><b>7.1</b> The bitcoin problem</a><ul><li class="chapter" data-level="7.1.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-currency-problem"><i class="fa fa-check"></i><b>7.1.1</b> The currency problem</a></li><li class="chapter" data-level="7.1.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#bitcoin-architecture"><i class="fa fa-check"></i><b>7.1.2</b> Bitcoin architecture</a></li></ul></li><li class="chapter" data-level="7.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-ledger"><i class="fa fa-check"></i><b>7.2</b> The bitcoin ledger</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#from-proof-of-work-to-consensus-on-ledger"><i class="fa fa-check"></i><b>7.2.1</b> From proof of work to consensus on ledger</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#collision-resistance-hash-functions-and-creating-short-unique-identifiers"><i class="fa fa-check"></i><b>7.3</b> Collision resistance hash functions and creating short unique identifiers</a></li><li class="chapter" data-level="7.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-constructions-of-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4</b> Practical constructions of cryptographic hash functions</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-random-ish-functions"><i class="fa fa-check"></i><b>7.4.1</b> Practical random-ish functions</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#some-history"><i class="fa fa-check"></i><b>7.4.2</b> Some history</a></li><li class="chapter" data-level="7.4.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-nsa-and-hash-functions."><i class="fa fa-check"></i><b>7.4.3</b> The NSA and hash functions.</a></li><li class="chapter" data-level="7.4.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#cryptographic-vs-non-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4.4</b> Cryptographic vs non-cryptographic hash functions:</a></li></ul></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html"><i class="fa fa-check"></i><b>8</b> Key derivation, protecting passwords, slow hashes, Merkle trees</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#keys-from-passwords"><i class="fa fa-check"></i><b>8.1</b> Keys from passwords</a></li><li class="chapter" data-level="8.2" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#merkle-trees-and-verifying-storage."><i class="fa fa-check"></i><b>8.2</b> Merkle trees and verifying storage.</a></li><li class="chapter" data-level="8.3" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#proofs-of-retrievability"><i class="fa fa-check"></i><b>8.3</b> Proofs of Retrievability</a></li><li class="chapter" data-level="8.4" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#entropy-extraction"><i class="fa fa-check"></i><b>8.4</b> Entropy extraction</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#forward-and-backward-secrecy"><i class="fa fa-check"></i><b>8.4.1</b> Forward and backward secrecy</a></li></ul></li></ul></li><li class="chapter" data-level="9" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html"><i class="fa fa-check"></i><b>9</b> Private key crypto recap</a><ul><li><ul><li class="chapter" data-level="9.0.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#attacks-on-private-key-cryptosystems"><i class="fa fa-check"></i><b>9.0.1</b> Attacks on private key cryptosystems</a></li></ul></li></ul></li><li class="chapter" data-level="10" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html"><i class="fa fa-check"></i><b>10</b> Public key cryptography</a><ul><li class="chapter" data-level="10.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#private-key-crypto-recap"><i class="fa fa-check"></i><b>10.1</b> Private key crypto recap</a></li><li class="chapter" data-level="10.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#public-key-encryptions-definition"><i class="fa fa-check"></i><b>10.2</b> Public Key Encryptions: Definition</a><ul><li class="chapter" data-level="10.2.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-obfuscation-paradigm"><i class="fa fa-check"></i><b>10.2.1</b> The obfuscation paradigm</a></li></ul></li><li class="chapter" data-level="10.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#some-concrete-candidates"><i class="fa fa-check"></i><b>10.3</b> Some concrete candidates:</a><ul><li class="chapter" data-level="10.3.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#diffie-hellman-encryption-aka-el-gamal"><i class="fa fa-check"></i><b>10.3.1</b> Diffie-Hellman Encryption (aka El-Gamal)</a></li><li class="chapter" data-level="10.3.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#sampling-random-primes"><i class="fa fa-check"></i><b>10.3.2</b> Sampling random primes</a></li><li class="chapter" data-level="10.3.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#a-little-bit-of-group-theory."><i class="fa fa-check"></i><b>10.3.3</b> A little bit of group theory.</a></li><li class="chapter" data-level="10.3.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#digital-signatures"><i class="fa fa-check"></i><b>10.3.4</b> Digital Signatures</a></li><li class="chapter" data-level="10.3.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-digital-signature-algorithm-dsa"><i class="fa fa-check"></i><b>10.3.5</b> The Digital Signature Algorithm (DSA)</a></li></ul></li><li class="chapter" data-level="10.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#putting-everything-together---security-in-practice."><i class="fa fa-check"></i><b>10.4</b> Putting everything together - security in practice.</a></li><li class="chapter" data-level="10.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#appendix-an-alternative-proof-of-the-density-of-primes"><i class="fa fa-check"></i><b>10.5</b> Appendix: An alternative proof of the density of primes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html"><i class="fa fa-check"></i><b>11</b> Concrete candidates for public key crypto</a><ul><li class="chapter" data-level="11.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#some-number-theory."><i class="fa fa-check"></i><b>11.1</b> Some number theory.</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#primaliy-testing"><i class="fa fa-check"></i><b>11.1.1</b> Primaliy testing</a></li><li class="chapter" data-level="11.1.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#fields"><i class="fa fa-check"></i><b>11.1.2</b> Fields</a></li><li class="chapter" data-level="11.1.3" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#chinese-remainder-theorem"><i class="fa fa-check"></i><b>11.1.3</b> Chinese remainder theorem</a></li><li class="chapter" data-level="11.1.4" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#the-rsa-and-rabin-functions"><i class="fa fa-check"></i><b>11.1.4</b> The RSA and Rabin functions</a></li><li class="chapter" data-level="11.1.5" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#abstraction-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.5</b> Abstraction: trapdoor permutations</a></li><li class="chapter" data-level="11.1.6" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#public-key-encryption-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.6</b> Public key encryption from trapdoor permutations</a></li><li class="chapter" data-level="11.1.7" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#digital-signatures-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.7</b> Digital signatures from trapdoor permutations</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#hardcore-bits-and-security-without-random-oracles"><i class="fa fa-check"></i><b>11.2</b> Hardcore bits and security without random oracles</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html"><i class="fa fa-check"></i><b>12</b> Lattice based cryptography</a><ul><li class="chapter" data-level="12.1" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#a-world-without-gaussian-elimination"><i class="fa fa-check"></i><b>12.1</b> A world without Gaussian elimination</a></li><li class="chapter" data-level="12.2" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#security-in-the-real-world."><i class="fa fa-check"></i><b>12.2</b> Security in the real world.</a></li><li class="chapter" data-level="12.3" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#search-to-decision"><i class="fa fa-check"></i><b>12.3</b> Search to decision</a></li><li class="chapter" data-level="12.4" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#an-lwe-based-encryption-scheme"><i class="fa fa-check"></i><b>12.4</b> An LWE based encryption scheme</a></li><li class="chapter" data-level="12.5" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#but-what-are-lattices"><i class="fa fa-check"></i><b>12.5</b> But what are lattices?</a></li><li class="chapter" data-level="12.6" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#ring-based-lattices"><i class="fa fa-check"></i><b>12.6</b> Ring based lattices</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12a_CCA_public_key.html"><a href="lec_12a_CCA_public_key.html"><i class="fa fa-check"></i><b>13</b> Chosen ciphertext security for public key encryption</a></li><li class="chapter" data-level="14" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html"><i class="fa fa-check"></i><b>14</b> Establishing secure connections over insecure channels</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cryptographys-obsession-with-adjectives."><i class="fa fa-check"></i><b>14.1</b> Cryptography’s obsession with adjectives.</a></li><li class="chapter" data-level="14.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#basic-key-exchange-protocol"><i class="fa fa-check"></i><b>14.2</b> Basic Key Exchange protocol</a></li><li class="chapter" data-level="14.3" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#authenticated-key-exchange"><i class="fa fa-check"></i><b>14.3</b> Authenticated key exchange</a><ul><li class="chapter" data-level="14.3.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#bleichenbachers-attack-on-rsa-pkcs-v1.5-and-ssl-v3.0"><i class="fa fa-check"></i><b>14.3.1</b> Bleichenbacher’s attack on RSA PKCS V1.5 and SSL V3.0</a></li></ul></li><li class="chapter" data-level="14.4" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#chosen-ciphertext-attack-security-for-public-key-cryptography"><i class="fa fa-check"></i><b>14.4</b> Chosen ciphertext attack security for public key cryptography</a></li><li class="chapter" data-level="14.5" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cca-secure-public-key-encryption-in-the-random-oracle-model"><i class="fa fa-check"></i><b>14.5</b> CCA secure public key encryption in the Random Oracle Model</a><ul><li class="chapter" data-level="14.5.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#defining-secure-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.1</b> Defining secure authenticated key exchange</a></li><li class="chapter" data-level="14.5.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#the-compiler-approach-for-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.2</b> The compiler approach for authenticated key exchange</a></li></ul></li><li class="chapter" data-level="14.6" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#password-authenticated-key-exchange."><i class="fa fa-check"></i><b>14.6</b> Password authenticated key exchange.</a></li><li class="chapter" data-level="14.7" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#client-to-client-key-exchange-for-secure-text-messaging---zrtp-otr-textsecure"><i class="fa fa-check"></i><b>14.7</b> Client to client key exchange for secure text messaging - ZRTP, OTR, TextSecure</a></li><li class="chapter" data-level="14.8" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#heartbleed-and-logjam-attacks"><i class="fa fa-check"></i><b>14.8</b> Heartbleed and logjam attacks</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html"><i class="fa fa-check"></i><b>15</b> Zero knowledge proofs</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#applications-for-zero-knowledge-proofs."><i class="fa fa-check"></i><b>15.1</b> Applications for zero knowledge proofs.</a><ul><li class="chapter" data-level="15.1.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#nuclear-disarmament"><i class="fa fa-check"></i><b>15.1.1</b> Nuclear disarmament</a></li><li class="chapter" data-level="15.1.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#voting"><i class="fa fa-check"></i><b>15.1.2</b> Voting</a></li><li class="chapter" data-level="15.1.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#more-applications"><i class="fa fa-check"></i><b>15.1.3</b> More applications</a></li></ul></li><li class="chapter" data-level="15.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-and-constructing-zero-knowledge-proofs"><i class="fa fa-check"></i><b>15.2</b> Defining and constructing zero knowledge proofs</a></li><li class="chapter" data-level="15.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-zero-knowledge"><i class="fa fa-check"></i><b>15.3</b> Defining zero knowledge</a></li><li class="chapter" data-level="15.4" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#zero-knowledge-proof-for-hamiltonicity."><i class="fa fa-check"></i><b>15.4</b> Zero knowledge proof for Hamiltonicity.</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#why-is-this-interesting"><i class="fa fa-check"></i><b>15.4.1</b> Why is this interesting?</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#parallel-repetition-and-turning-zero-knowledge-proofs-to-signatures."><i class="fa fa-check"></i><b>15.5</b> Parallel repetition and turning zero knowledge proofs to signatures.</a><ul><li class="chapter" data-level="15.5.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#bonus-features-of-zero-knowledge"><i class="fa fa-check"></i><b>15.5.1</b> Bonus features of zero knowledge</a></li></ul></li></ul></li><li class="chapter" data-level="16" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html"><i class="fa fa-check"></i><b>16</b> Fully homomorphic encryption: Introduction and bootstrapping</a><ul><li class="chapter" data-level="16.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#defining-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>16.1</b> Defining fully homomorphic encryption</a><ul><li class="chapter" data-level="16.1.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#another-application-fully-homomorphic-encryption-for-verifying-computation"><i class="fa fa-check"></i><b>16.1.1</b> Another application: fully homomorphic encryption for verifying computation</a></li></ul></li><li class="chapter" data-level="16.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#example-an-xor-homomorphic-encryption"><i class="fa fa-check"></i><b>16.2</b> Example: An XOR homomorphic encryption</a><ul><li class="chapter" data-level="16.2.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#abstraction-a-trapdoor-pseudorandom-generator."><i class="fa fa-check"></i><b>16.2.1</b> Abstraction: A trapdoor pseudorandom generator.</a></li></ul></li><li class="chapter" data-level="16.3" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#from-linear-homomorphism-to-full-homomorphism"><i class="fa fa-check"></i><b>16.3</b> From linear homomorphism to full homomorphism</a></li><li class="chapter" data-level="16.4" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#bootstrapping-fully-homomorphic-escape-velocity"><i class="fa fa-check"></i><b>16.4</b> Bootstrapping: Fully Homomorphic escape velocity</a><ul><li class="chapter" data-level="16.4.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#radioactive-legos-analogy"><i class="fa fa-check"></i><b>16.4.1</b> Radioactive legos analogy</a></li><li class="chapter" data-level="16.4.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#proving-the-bootstrapping-theorem"><i class="fa fa-check"></i><b>16.4.2</b> Proving the bootstrapping theorem</a></li></ul></li></ul></li><li class="chapter" data-level="17" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html"><i class="fa fa-check"></i><b>17</b> Fully homomorphic encryption : Construction</a><ul><li class="chapter" data-level="17.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#prelude-from-vectors-to-matrices"><i class="fa fa-check"></i><b>17.1</b> Prelude: from vectors to matrices</a></li><li class="chapter" data-level="17.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#real-world-partially-homomorphic-encryption"><i class="fa fa-check"></i><b>17.2</b> Real world partially homomorphic encryption</a></li><li class="chapter" data-level="17.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#noise-management-via-encoding"><i class="fa fa-check"></i><b>17.3</b> Noise management via encoding</a></li><li class="chapter" data-level="17.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#putting-it-all-together"><i class="fa fa-check"></i><b>17.4</b> Putting it all together</a></li><li class="chapter" data-level="17.5" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#analysis-of-our-scheme"><i class="fa fa-check"></i><b>17.5</b> Analysis of our scheme</a><ul><li class="chapter" data-level="17.5.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#correctness"><i class="fa fa-check"></i><b>17.5.1</b> Correctness</a></li><li class="chapter" data-level="17.5.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#cpa-security"><i class="fa fa-check"></i><b>17.5.2</b> CPA Security</a></li><li class="chapter" data-level="17.5.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#homomorphism"><i class="fa fa-check"></i><b>17.5.3</b> Homomorphism</a></li><li class="chapter" data-level="17.5.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#shallow-decryption-circuit"><i class="fa fa-check"></i><b>17.5.4</b> Shallow decryption circuit</a></li></ul></li><li class="chapter" data-level="17.6" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#example-application-private-information-retrieval"><i class="fa fa-check"></i><b>17.6</b> Example application: Private information retrieval</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html"><i class="fa fa-check"></i><b>18</b> Multiparty secure computation I: Definition and Honest-But-Curious to Malicious complier</a><ul><li class="chapter" data-level="18.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#ideal-vs.-real-model-security."><i class="fa fa-check"></i><b>18.1</b> Ideal vs. Real Model Security.</a></li><li class="chapter" data-level="18.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#formally-defining-secure-multiparty-computation"><i class="fa fa-check"></i><b>18.2</b> Formally defining secure multiparty computation</a><ul><li class="chapter" data-level="18.2.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#first-attempt-a-slightly-too-ideal-definition"><i class="fa fa-check"></i><b>18.2.1</b> First attempt: a slightly too ideal definition</a></li><li class="chapter" data-level="18.2.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#allowing-for-aborts"><i class="fa fa-check"></i><b>18.2.2</b> Allowing for aborts</a></li><li class="chapter" data-level="18.2.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#some-comments"><i class="fa fa-check"></i><b>18.2.3</b> Some comments:</a></li></ul></li><li class="chapter" data-level="18.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#example-second-price-auction-using-bitcoin"><i class="fa fa-check"></i><b>18.3</b> Example: Second price auction using bitcoin</a><ul><li class="chapter" data-level="18.3.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#another-example-distributed-and-threshold-cryptography"><i class="fa fa-check"></i><b>18.3.1</b> Another example: distributed and threshold cryptography</a></li></ul></li><li class="chapter" data-level="18.4" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#proving-the-fundamental-theorem"><i class="fa fa-check"></i><b>18.4</b> Proving the fundamental theorem:</a></li><li class="chapter" data-level="18.5" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#malicious-to-honest-but-curious-reduction"><i class="fa fa-check"></i><b>18.5</b> Malicious to honest but curious reduction</a><ul><li class="chapter" data-level="18.5.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#handling-probabilistic-strategies"><i class="fa fa-check"></i><b>18.5.1</b> Handling probabilistic strategies:</a></li></ul></li></ul></li><li class="chapter" data-level="19" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html"><i class="fa fa-check"></i><b>19</b> Multiparty secure computation: Construction using Fully Homomorphic Encryption</a><ul><li class="chapter" data-level="19.1" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#constructing-2-party-honest-but-curious-computation-from-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.1</b> Constructing 2 party honest but curious computation from fully homomorphic encryption</a></li><li class="chapter" data-level="19.2" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#achieving-circuit-privacy-in-a-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.2</b> Achieving circuit privacy in a fully homomorphic encryption</a></li><li class="chapter" data-level="19.3" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#bottom-line-a-two-party-honest-but-curious-two-party-secure-computation-protocol"><i class="fa fa-check"></i><b>19.3</b> Bottom line: A two party honest but curious two party secure computation protocol</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html"><i class="fa fa-check"></i><b>20</b> Quantum computing and cryptography I</a><ul><li><ul><li class="chapter" data-level="20.0.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>20.0.1</b> Quantum computing and computation - an executive summary.</a></li></ul></li><li class="chapter" data-level="20.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-101"><i class="fa fa-check"></i><b>20.1</b> Quantum 101</a><ul><li class="chapter" data-level="20.1.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>20.1.1</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="20.1.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bra-ket-notation"><i class="fa fa-check"></i><b>20.1.2</b> Bra-ket notation</a></li><li class="chapter" data-level="20.1.3" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bells-inequality"><i class="fa fa-check"></i><b>20.1.3</b> Bell’s Inequality</a></li></ul></li><li class="chapter" data-level="20.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#grovers-algorithm"><i class="fa fa-check"></i><b>20.2</b> Grover’s Algorithm</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html"><i class="fa fa-check"></i><b>21</b> Quantum computing and cryptography II</a><ul><li class="chapter" data-level="21.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-order-finding-to-factoring-and-discrete-log"><i class="fa fa-check"></i><b>21.1</b> From order finding to factoring and discrete log</a></li><li class="chapter" data-level="21.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#finding-periods-of-a-function-simons-algorithm"><i class="fa fa-check"></i><b>21.2</b> Finding periods of a function: Simon’s Algorithm</a></li><li class="chapter" data-level="21.3" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-simon-to-shor"><i class="fa fa-check"></i><b>21.3</b> From Simon to Shor</a><ul><li class="chapter" data-level="21.3.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.1</b> The Fourier transform over \Z_m</a><ul><li class="chapter" data-level="21.3.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#fast-fourier-transform."><i class="fa fa-check"></i><b>21.3.1.1</b> Fast Fourier Transform.</a></li></ul></li><li class="chapter" data-level="21.3.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.2</b> Quantum Fourier Transform over \Z_m</a></li></ul></li><li class="chapter" data-level="21.4" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#shors-order-finding-algorithm."><i class="fa fa-check"></i><b>21.4</b> Shor’s Order-Finding Algorithm.</a><ul><li class="chapter" data-level="21.4.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#analysis-the-case-that-rm"><i class="fa fa-check"></i><b>21.4.1</b> Analysis: the case that r|m</a><ul><li class="chapter" data-level="21.4.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-general-case"><i class="fa fa-check"></i><b>21.4.1.1</b> The general case</a></li></ul></li></ul></li><li class="chapter" data-level="21.5" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#rational-approximation-of-real-numbers"><i class="fa fa-check"></i><b>21.5</b> Rational approximation of real numbers</a><ul><li class="chapter" data-level="21.5.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-cryptography"><i class="fa fa-check"></i><b>21.5.1</b> Quantum cryptography</a></li></ul></li></ul></li><li class="chapter" data-level="22" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html"><i class="fa fa-check"></i><b>22</b> Software Obfuscation</a><ul><li class="chapter" data-level="22.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#witness-encryption"><i class="fa fa-check"></i><b>22.1</b> Witness encryption</a></li><li class="chapter" data-level="22.2" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#deniable-encryption"><i class="fa fa-check"></i><b>22.2</b> Deniable encryption</a></li><li class="chapter" data-level="22.3" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#functional-encryption"><i class="fa fa-check"></i><b>22.3</b> Functional encryption</a></li><li class="chapter" data-level="22.4" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#the-software-patch-problem"><i class="fa fa-check"></i><b>22.4</b> The software patch problem</a></li><li class="chapter" data-level="22.5" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#software-obfuscation-1"><i class="fa fa-check"></i><b>22.5</b> Software obfuscation</a></li><li class="chapter" data-level="22.6" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#applications-of-obfuscation"><i class="fa fa-check"></i><b>22.6</b> Applications of obfuscation</a></li><li class="chapter" data-level="22.7" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#impossibility-of-obfuscation"><i class="fa fa-check"></i><b>22.7</b> Impossibility of obfuscation</a><ul><li class="chapter" data-level="22.7.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#proof-of-impossibility-of-vbb-obfuscation"><i class="fa fa-check"></i><b>22.7.1</b> Proof of impossibility of VBB obfuscation</a></li></ul></li><li class="chapter" data-level="22.8" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#indistinguishability-obfuscation"><i class="fa fa-check"></i><b>22.8</b> Indistinguishability obfuscation</a></li></ul></li><li class="chapter" data-level="23" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html"><i class="fa fa-check"></i><b>23</b> More obfuscation, exotic encryptions</a><ul><li class="chapter" data-level="23.1" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#slower-weaker-less-securer"><i class="fa fa-check"></i><b>23.1</b> Slower, weaker, less securer</a></li><li class="chapter" data-level="23.2" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#how-to-get-ibe-from-pairing-based-assumptions."><i class="fa fa-check"></i><b>23.2</b> How to get IBE from pairing based assumptions.</a></li><li class="chapter" data-level="23.3" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#beyond-pairing-based-cryptography"><i class="fa fa-check"></i><b>23.3</b> Beyond pairing based cryptography</a></li></ul></li><li class="chapter" data-level="24" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html"><i class="fa fa-check"></i><b>24</b> Anonymous communication</a><ul><li class="chapter" data-level="24.1" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#steganography"><i class="fa fa-check"></i><b>24.1</b> Steganography</a></li><li class="chapter" data-level="24.2" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#anonymous-routing"><i class="fa fa-check"></i><b>24.2</b> Anonymous routing</a></li><li class="chapter" data-level="24.3" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#tor"><i class="fa fa-check"></i><b>24.3</b> Tor</a></li><li class="chapter" data-level="24.4" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#telex"><i class="fa fa-check"></i><b>24.4</b> Telex</a></li><li class="chapter" data-level="24.5" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#riposte"><i class="fa fa-check"></i><b>24.5</b> Riposte</a></li></ul></li><li class="chapter" data-level="25" data-path="lec_24_policy.html"><a href="lec_24_policy.html"><i class="fa fa-check"></i><b>25</b> Ethical, moral, and policy dimensions to cryptography</a><ul><li class="chapter" data-level="25.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#reading-prior-to-lecture"><i class="fa fa-check"></i><b>25.1</b> Reading prior to lecture:</a></li><li class="chapter" data-level="25.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#case-studies."><i class="fa fa-check"></i><b>25.2</b> Case studies.</a><ul><li class="chapter" data-level="25.2.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#the-snowden-revelations"><i class="fa fa-check"></i><b>25.2.1</b> The Snowden revelations</a></li><li class="chapter" data-level="25.2.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#fbi-vs-apple-case"><i class="fa fa-check"></i><b>25.2.2</b> FBI vs Apple case</a></li><li class="chapter" data-level="25.2.3" data-path="lec_24_policy.html"><a href="lec_24_policy.html#juniper-backdoor-case-and-the-opm-break-in"><i class="fa fa-check"></i><b>25.2.3</b> Juniper backdoor case and the OPM break-in</a></li></ul></li></ul></li><li class="chapter" data-level="26" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html"><i class="fa fa-check"></i><b>26</b> Course recap</a><ul><li class="chapter" data-level="26.1" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#some-things-we-did-not-cover"><i class="fa fa-check"></i><b>26.1</b> Some things we did not cover</a></li><li class="chapter" data-level="26.2" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#what-i-hope-you-learned"><i class="fa fa-check"></i><b>26.2</b> What I hope you learned</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multiparty secure computation</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/crypto/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/crypto/lec_17_SFE.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="multiparty-secure-computation-i-definition-and-honest-but-curious-to-malicious-complier" data-number="18">Multiparty secure computation I: Definition and Honest-But-Curious to Malicious complier</h1>
<p>Wikipedia <a href="https://en.wikipedia.org/wiki/Cryptography">defines</a> cryptography as “the practice and study of techniques for secure communication in the presence of third parties called adversaries”. However, I think a better definition would be:</p>
<blockquote>
<p><em>Cryptography is about replacing trust with mathematics.</em></p>
</blockquote>
<p>After all, the reason we work so hard in cryptography is because a lack of trust. We wouldn’t need encryption if Alice and Bob could be guaranteed that their communication, despite going through wireless and wired networks controlled and snooped upon by a plethora of entities, would be as reliable as if it has been hand delivered by a letter-carrier as reliable as <a href="http://old.iolaregister.com/Local%20News/Stories/Weatherwontstopcarriers.html">Patti Whitcomb</a>, as opposed to the nosy Eve who might look in the messages, or the malicious Mallory, who might tamper with them. We wouldn’t need zero knowledge proofs if Vladimir could simply say “trust me Barack, this is an authentic nuke”. We wouldn’t need electronic signatures if we could trust that all software updates are designed to make our devices safer and not, to pick a random example, to turn our phones into surveillance devices.</p>
<p>Unfortunately, the world we live in is not as ideal, and we need these cryptographic tools. But what is the limit of what we can achieve? Are these examples of encryption, authentication, zero knowledge etc. isolated cases of good fortune, or are they special cases of a more general theory of what is possible in cryptography? It turns out that the latter is the case and there is in fact an extremely general formulation that (in some sense) captures all of the above and much more. This notion is called <em>multiparty secure computation</em> or sometimes <em>secure function evaluation</em> and is the topic of this lecture. We will show (a relaxed version of) what I like to call “the fundamental theorem of cryptography”, namely that under natural computational conjectures (and in particular the LWE conjecture, as well as the RSA or Factoring assumptions) essentially every cryptographic task can be achieved. This theorem emerged from the 1980’s works of Yao, Goldreich-Micali-Wigderson, and many others. As we’ll see, like the “fundamental theorems” of other fields, this is a results that closes off the field but rather opens up many other questions. But before we can even state the result, we need to talk about how can we even define security in a general setting.</p>
<h2 id="ideal-vs.-real-model-security." data-number="18.1">Ideal vs. Real Model Security.</h2>
<p>The key notion is that cryptography aims to replace <em>trust</em>. Therefore, we imagine an <em>ideal world</em> where there is some universally trusted party (cryptographer Silvio Micali likes to denote by Jimmy Carter, but feel free to swap in your own favorite trustworthy personality) that communicates with all participants of the protocol or interaction, including potentially the adversary. We define security by stating that whatever the adversary can achieve in our real world, could have also been achieved in the ideal world.</p>
<p>For example, for obtaining secure communication, Alice will send her message to the trusted party, who will then convey it to Bob. The adversary learns nothing about the message’s contents, nor can she change them. In the zero knowledge application, to prove that there exists some secret <span><span class="math inline">\(x\)</span></span> such that <span><span class="math inline">\(f(x)=1\)</span></span> where <span><span class="math inline">\(f(\cdot)\)</span></span> is a public function, the prover Alice sends to the trusted party her secret input <span><span class="math inline">\(x\)</span></span>, the trusted party then verifies that <span><span class="math inline">\(f(x)=1\)</span></span> and simply sends to Bob the message “the statement is true”. It does not reveal to Bob anything about the secret <span><span class="math inline">\(x\)</span></span> beyond that.</p>
<p>But this paradigm goes well beyond this. For example, <a href="https://en.wikipedia.org/wiki/Vickrey_auction">second price (or Vickrey) auctions</a> are known as a way to incentivize bidders to bid their true value. In these auctions, every potential buyer sends a sealed bid, and the item goes to the highest bidder, who only needs to pay the price of the second-highest bid. We could imagine a digital version, where buyers send encrypted versions of their bids. The auctioneer could announce who the winner is and what was the second largest bid, but could we really trust him to do so faithfully? Perhaps we would want an auction where even the auctioneer doesn’t learn anything about the bids beyond the identity of the winner and the value of the second highest bid? Wouldn’t it be great if there was a trusted party that all bidders could share with their private values, and it would announce the results of the auction but nothing more than that? This could be useful not just in second price auctions but to implement many other mechanisms, especially if you are a <a href="https://www.cs.purdue.edu/homes/aliaga/cs197-10/papers/bogetoft.pdf">Danish sugar beet farmer</a>.</p>
<p>There are other examples as well. Perhaps two hospitals might want to figure out if the same patient visited both, but do not want (or are legally not allowed) to share with one another the list of people that visited each one. A trusted party could get both lists and output only their intersection.</p>
<p>The list goes on and on. Maybe we want to aggregate securely information of the performance of <a href="https://eprint.iacr.org/2011/662.pdf">Estonian IT firms</a> or the financial health of <a href="http://arxiv.org/abs/1111.5228">wall street banks</a>. Almost every cryptographic task could become trivial if we just had access to a universally trusted party. But of course in the real world, we don’t. This is what makes the notion of <em>secure multiparty computation</em> so exciting.</p>
<h2 id="formally-defining-secure-multiparty-computation" data-number="18.2">Formally defining secure multiparty computation</h2>
<p>We now turn to formal definitions. As we discuss below, there are many variants of secure multiparty computation, and we pick one simple version below. A <em><span><span class="math inline">\(k\)</span></span>-party protocol</em> is a set of efficiently computable <span><span class="math inline">\(k\)</span></span> prescribed interactive strategies for all <span><span class="math inline">\(k\)</span></span> parties.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> We assume the existence of an authenticated and private point to point channel between every pair of parties (this can be implemented using signatures and encryptions).<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> A <em><span><span class="math inline">\(k\)</span></span> party functionality</em> is a probabilistic process <span><span class="math inline">\(F\)</span></span> mapping <span><span class="math inline">\(k\)</span></span> inputs in <span><span class="math inline">\(\{0,1\}^n\)</span></span> into <span><span class="math inline">\(k\)</span></span> outputs in <span><span class="math inline">\(\{0,1\}^n\)</span></span>.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>
<h3 id="first-attempt-a-slightly-too-ideal-definition" data-number="18.2.1">First attempt: a slightly “too ideal” definition</h3>
<p>Here is one attempt of a definition that is clean but a bit too strong, which nevertheless captures much of the spirit of secure multiparty computation:</p>
<div id="mpcnoaborts" class="definition" title="MPC without aborts" data-number="18.2.1" name="Definition 18.1 (MPC without aborts) ">
<p>Let <span><span class="math inline">\(F\)</span></span> be a <span><span class="math inline">\(k\)</span></span>-party functionality. A <em>secure protocol for <span><span class="math inline">\(F\)</span></span></em> is a protocol for <span><span class="math inline">\(k\)</span></span> parties satisfying that for every <span><span class="math inline">\(T\subseteq [k]\)</span></span> and every efficient adversary <span><span class="math inline">\(A\)</span></span>, there exists an efficient “ideal adversary” (i.e., efficient interactive algorithm) <span><span class="math inline">\(S\)</span></span> such that for every set of inputs <span><span class="math inline">\(\{ x_i \}_{i\in [k]\setminus T}\)</span></span> the following two distributions are computationally indistinguishable:</p>
<ul>
<li><p>The tuple <span><span class="math inline">\((y_1,\ldots,y_k)\)</span></span> of outputs of all the parties (both controlled and not controlled by the adversary) in an execution of the protocol where <span><span class="math inline">\(A\)</span></span> controls the parties in <span><span class="math inline">\(T\)</span></span> and the inputs of the parties not in <span><span class="math inline">\(T\)</span></span> are given by <span><span class="math inline">\(\{ x_i \}_{i\in [k]\setminus T}\)</span></span>.</p></li>
<li><p>The tuple <span><span class="math inline">\((y_1,\ldots,y_k)\)</span></span> that is computed using the following process:</p></li>
</ul>
<ol type="a">
<li><p>We let <span><span class="math inline">\(\{ x_i \}_{i \in T}\)</span></span> be chosen by <span><span class="math inline">\(S\)</span></span>, and compute <span><span class="math inline">\((y&#39;_1,\ldots,y&#39;_k)=F(x_1,\ldots,x_k)\)</span></span>.</p></li>
<li><p>For every <span><span class="math inline">\(i\in [k]\)</span></span>, if <span><span class="math inline">\(i\not\in T\)</span></span> (i.e., party <span><span class="math inline">\(i\)</span></span> is “honest”) then <span><span class="math inline">\(y_i=y&#39;_i\)</span></span> and otherwise, we let <span><span class="math inline">\(S\)</span></span> choose <span><span class="math inline">\(y_i\)</span></span>.</p></li>
</ol>
</div>
<p><br />
</p>
<p>That is, the protocol is secure if whatever an adversary can gain by taking complete control over the set of parties in <span><span class="math inline">\(T\)</span></span>, could have been gain by simply using this control to choose particular inputs <span><span class="math inline">\(\{ x_i \}_{i\in T}\)</span></span>, run the protocol honestly, and observe the outputs of the functionality.<br />
Note that in particular if <span><span class="math inline">\(T=\emptyset\)</span></span> (and hence there is no adversary) then if the parties’ inputs are <span><span class="math inline">\((x_1,\ldots,x_k)\)</span></span> then their outputs will equal <span><span class="math inline">\(F(x_1,\ldots,x_k)\)</span></span>.</p>
<h3 id="allowing-for-aborts" data-number="18.2.2">Allowing for aborts</h3>
<p>The definition above is a little too strong, in the following sense. Consider the case that <span><span class="math inline">\(k=2\)</span></span> where there are two parties Alice (Party <span><span class="math inline">\(1\)</span></span>) and Bob (Party <span><span class="math inline">\(2\)</span></span>) that wish to compute some output <span><span class="math inline">\(F(x_1,x_2)\)</span></span>. If Bob is controlled by the adversary then he clearly can simply abort the protocol and prevent Alice from computing <span><span class="math inline">\(y_1\)</span></span>. Thus, in this case in the actual execution of the protocol the output <span><span class="math inline">\(y_1\)</span></span> will be some error message (which we denote by <span><span class="math inline">\(\bot\)</span></span>). But we did not allow this possiblity for the idealized adversary <span><span class="math inline">\(S\)</span></span>: if <span><span class="math inline">\(1\not\in S\)</span></span> then it must be the case that the output <span><span class="math inline">\(y_1\)</span></span> is equal to <span><span class="math inline">\(y&#39;_1\)</span></span> for some <span><span class="math inline">\((y&#39;_1,y&#39;_2)=F(x_1,x_2)\)</span></span>.<br />
This means that we would be able to distinguish between the output in the real and ideal setting.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> This motivates the following, slightly more messy definition, that allows for the ability of the adversary to abort the execution at any point in time:</p>
<div id="MPCdef" class="definition" title="MPC with aborts" data-number="18.2.2" name="Definition 18.2 (MPC with aborts) ">
<p>Let <span><span class="math inline">\(F\)</span></span> be a <span><span class="math inline">\(k\)</span></span>-party functionality. A <em>secure protocol for <span><span class="math inline">\(F\)</span></span></em> is a protocol for <span><span class="math inline">\(k\)</span></span> parties satisfying that for every <span><span class="math inline">\(T\subseteq [k]\)</span></span> and every efficient adversary <span><span class="math inline">\(A\)</span></span>, there exists an efficient “ideal adversary” (i.e., efficient interactive algorithm) <span><span class="math inline">\(S\)</span></span> such that for every set of inputs <span><span class="math inline">\(\{ x_i \}_{i\in [k]\setminus T}\)</span></span> the following two distributions are computationally indistinguishable:</p>
<ul>
<li><p>The tuple <span><span class="math inline">\((y_1,\ldots,y_k)\)</span></span> of outputs of all the parties (both controlled and not controlled by the adversary) in an execution of the protocol where <span><span class="math inline">\(A\)</span></span> controls the parties in <span><span class="math inline">\(T\)</span></span> and the inputs of the parties not in <span><span class="math inline">\(T\)</span></span> are given by <span><span class="math inline">\(\{ x_i \}_{i\in [k]\setminus T}\)</span></span> we denote by <span><span class="math inline">\(y_i = \top\)</span></span> if the <span><span class="math inline">\(i^{th}\)</span></span> party aborted the protocol.</p></li>
<li><p>The tuple <span><span class="math inline">\((y_1,\ldots,y_k)\)</span></span> that is computed using the following process:</p></li>
</ul>
<ol type="a">
<li><p>We let <span><span class="math inline">\(\{ x_i \}_{i \in T}\)</span></span> be chosen by <span><span class="math inline">\(S\)</span></span>, and compute <span><span class="math inline">\((y&#39;_1,\ldots,y&#39;_k)=F(x_1,\ldots,x_k)\)</span></span>.</p></li>
<li><p>For <span><span class="math inline">\(i=1,\ldots,k\)</span></span> do the following: ask <span><span class="math inline">\(S\)</span></span> if it wishes to abort at this stage, and if it doesn’t then the <span><span class="math inline">\(i^{th}\)</span></span> party learns <span><span class="math inline">\(y&#39;_i\)</span></span>. If the adversary did abort then we exit the loop at this stage and the parties <span><span class="math inline">\(i+1,\ldots,k\)</span></span> (regardless if they are honest or malicious) do not learn the corresponding outputs.</p></li>
<li><p>Let <span><span class="math inline">\(k&#39;\)</span></span> be the last non-abort stage we reached above. For every <span><span class="math inline">\(i\not\in T\)</span></span>, if <span><span class="math inline">\(i \leq k&#39;\)</span></span> then <span><span class="math inline">\(y_i =y&#39;_i\)</span></span> and if <span><span class="math inline">\(i&gt;k&#39;\)</span></span> then <span><span class="math inline">\(y&#39;_i=\bot\)</span></span>. We let the adversary <span><span class="math inline">\(S\)</span></span> choose <span><span class="math inline">\(\{ y_i \}_{i\in T}\)</span></span>.</p></li>
</ol>
</div>
<figure>
<img src="../figure/./real-ideal.jpg" alt="21.1: We define security of a protocol implementing a functionality F by stipulating that for every adversary A that control a subset of the parties, A’s view in an actual execution of the protocol would be indistinguishable from its view in an ideal setting where all the parties send their inputs to an idealized and perfectly trusted party, who then computes the outputs and sends it to each party." id="tmplabelfig" /><figcaption>21.1: We define security of a protocol implementing a functionality <span><span class="math inline">\(F\)</span></span> by stipulating that for every adversary <span><span class="math inline">\(A\)</span></span> that control a subset of the parties, <span><span class="math inline">\(A\)</span></span>’s view in an actual execution of the protocol would be indistinguishable from its view in an ideal setting where all the parties send their inputs to an idealized and perfectly trusted party, who then computes the outputs and sends it to each party.</figcaption>
</figure>
<p>Here are some good exercises to make sure you follow the definition:</p>
<ul>
<li><p>Let <span><span class="math inline">\(F\)</span></span> be the two party functionality such that <span><span class="math inline">\(F(H\|C,H&#39;)\)</span></span> outputs <span><span class="math inline">\((1,1)\)</span></span> if the graph <span><span class="math inline">\(H\)</span></span> equals the graph <span><span class="math inline">\(H&#39;\)</span></span> and <span><span class="math inline">\(C\)</span></span> is a Hamiltonian cycle and otherwise outputs <span><span class="math inline">\((0,0)\)</span></span>. Prove that a protocol for computing <span><span class="math inline">\(F\)</span></span> is a zero knowledge proof<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> system for the language of Hamiltonicity.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup></p></li>
<li><p>Let <span><span class="math inline">\(F\)</span></span> be the <span><span class="math inline">\(k\)</span></span>-party functionality that on inputs <span><span class="math inline">\(x_1,\ldots,x_k \in \{0,1\}\)</span></span> outputs to all parties the majority value of the <span><span class="math inline">\(x_i\)</span></span>’s. Then, in any protocol that securely computes <span><span class="math inline">\(F\)</span></span>, for any adversary that controls less than half of the parties, if at least <span><span class="math inline">\(n/2+1\)</span></span> of the other parties’ inputs equal <span><span class="math inline">\(0\)</span></span>, then the adversary will not be able to cause an honest party to output <span><span class="math inline">\(1\)</span></span>.</p></li>
</ul>
<div id="section" class="pause" data-number="18.2.2" name="Pause">
<p>It is an excellent idea for you to pause here and try to work out at least informally these exercises.</p>
</div>
<p>Amazingly, we can obtain such a protocol for <em>every</em> functionality:</p>
<div id="MPCthm" class="theorem" title="Fundamental theorem of cryptography" data-number="18.2.2" name="Theorem 18.3 (Fundamental theorem of cryptography) ">
<p>Under reasonable assumptions<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup> for every polynomial-time computable <span><span class="math inline">\(k\)</span></span>-functionality <span><span class="math inline">\(F\)</span></span> there is a polynomial-time protocol that computes it securely.</p>
</div>
<p><a href='#MPCthm'>Theorem 18.3</a> was originally proven by Yao in 1982 for the special case of two party functionalities, and then proved for the general case by Goldreich, Micali, and Wigderson in 1987. As discussed below, many variants of this theorem has been shown, and this line of research is still ongoing.</p>
<h3 id="some-comments" data-number="18.2.3">Some comments:</h3>
<p>There is in fact not a single theorem but rather many variants of this fundamental theorem obtained by great many people, depending on the different security properties desired, as well as the different cryptographic and setup assumptions. Some of the issues studied in the literature include the following:</p>
<ul>
<li><p><strong>Fairness, guaranteed output delivery:</strong> The definition above does not attempt to protect against “denial of service” attacks, in the sense that the adversary is allowed, even in the ideal case, to prevent the honest parties from receiving their outputs.<br />
As mentioned above, without honest majority this is essential for simlar reasons to the issue we discussed in <a href="http://www.boazbarak.org/cs127/chap07_hash_functions.pdf">our lecture on bitcoin</a> why achieving consensus is hard if there isn’t a honest majority. When there is an honest majority, we can achieve the property of <em>guaranteed output delivery</em>, which offers protection against such “denial of service” attacks. Even when there is no guaranteed output delivery, we might want the property of <em>fairness</em>, whereas we guarantee that if the honest parties don’t get the output then neither does the adversary. There has been extensive study of fairness and there are protocols achieving variants on it under various computational and setup assumptions.</p></li>
<li><p><strong>Network models:</strong> The current definition assumes we have a set of <span><span class="math inline">\(k\)</span></span> parties with known identities with pairwise secure (confidential and authenticated) channels between them. Other network models studies include broadcast channel, non-private networks, and even <a href="https://eprint.iacr.org/2007/464">no authentication</a>).</p></li>
<li><p><strong>Setup assumptions:</strong> The definition does not assume a trusted third party, but people have studied different setup assumptions including a public key infrastructure, common reference string, and more.</p></li>
<li><p><strong>Adversarial power:</strong> It turns out that under certain condition, it can be possible to obtain secure multiparty computation with respect to adversaries that have unbounded computational power (so called “information theoretic security”). People have also studies different variants of adversaries including “honest but curious” or “passive adversaries”, as well as “covert” adversaries that only deviate from the protocol if they won’t be caught. Other settings studied limit the adversary’s ability to control parties (e.g., honest majority, smaller fraction of parties or particular patterns of control, adaptive vs static corruption).</p></li>
<li><p><strong>Concurrent compositions:</strong> The definition displayed above are for <em>standalone execution</em> which is known not to automatically imply security with respect to <em>concurrent composition</em>, where many copies of the same protocol (or different protocols) could be executed simultaneously. This opens up all sorts of new attacks.<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup> See <a href="http://u.cs.biu.ac.il/~lindell/thesis.html">Yehuda Lindell’s thesis</a> (or <a href="http://u.cs.biu.ac.il/~lindell/LNCSmonograph.html">this updated version</a>) for more. A very general notion known as “UC security” (which stands for “Universally Composable” or maybe “Ultimate Chuck”) has been proposed to achieve security in these settings, though at a price of additional setup assumptions, see <a href="http://www.cs.tau.ac.il/~canetti/materials/ICALP08.pdf">here</a> and <a href="http://eprint.iacr.org/2007/475">here</a>.</p></li>
<li><p><strong>Communication:</strong> The communication cost for <a href='#MPCthm'>Theorem 18.3</a> can be proportional to the size of the circuit that computes <span><span class="math inline">\(F\)</span></span>. This can be a very steep cost, especially when computing over large amounts of data. It turns out that we can sometimes avoid this cost using fully homomorphic encryption or other techniques.</p></li>
<li><p><strong>Efficiency vs. generality:</strong> While <a href='#MPCthm'>Theorem 18.3</a> tells us that essentially every protocol problem can be solved <em>in principle</em>, its proof will almost never yield a protocol you actually want to run since it has enormous efficiency overhead. The issue of efficiency is the biggest reason why secure multiparty computation has so far not had a great many practical applications. However, researchers have been showing more efficient tailor-made protocols for particular problems of interest, and there has been steady progress in making those results more practical. See <a href="http://crypto.biu.ac.il/5th-biu-winter-school">the slides and videos from this workshop</a> for more.</p></li>
</ul>
<p><strong>Is multiparty secure computation the end of crypto?</strong> The notion of secure multiparty computation seems so strong that you might think that once it is achieved, aside from efficiency issues, there is nothing else to be done in cryptography. This is very far from the truth. Multiparty secure computation do give a way to solve a great many problems in the setting where we have arbitrary rounds of interactions and unbounded communication, but this is far from being always the case. As we mentioned before, interaction can sometimes make a <em>qualitative</em> difference (when Alice and Bob are separated by time rather than space). As we’ve seen in the discussion of fully homomorphic encryption, there are also other properties, such as compact communication, which are not implied by multiparty secure computation but can make all the difference in contexts such as cloud computing. That said, multiparty secure computation is an extremely general paradigm that does apply to many cryptographic problems.</p>
<p><strong>Further reading:</strong> The <a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1004&amp;context=jpc">survey of Lindell and Pinkas</a> gives a good overview of the different variants and security properties considered in the literature, see also Section 7 in <a href="http://www.wisdom.weizmann.ac.il/~oded/foc-sur04.html">this survey of Goldreich</a>. Chapter 6 in <a href="http://www.cs.cornell.edu/courses/cs4830/2010fa/lecnotes.pdf">Pass and Shelat’s notes</a> is also a good source.</p>
<h2 id="example-second-price-auction-using-bitcoin" data-number="18.3">Example: Second price auction using bitcoin</h2>
<p>Suppose we have the following setup: an auctioneer wants to sell some item and run a second-price auction, where each party submits a sealed bid, and the highest bidder gets the item for the price of the second highest bid. However, as mentioned above, the bidders do not want the auctioneer to learn what their bid was, and in general nothing else other than the identity of the highest bidder and the value of the second highest bid. Moreover, we might want the payment is via an electronic currency such as bitcoin, so that the auctioneer not only gets the information about the winning bid but an actual self-certifying transaction they can use to get the payment.</p>
<p>Here is how we could obtain such a protocol using secure multiparty computation:</p>
<ul>
<li><p>We have <span><span class="math inline">\(k\)</span></span> parties where the first party is the auctioneer and parties <span><span class="math inline">\(2,\ldots,k\)</span></span> are bidders. Let’s assume for simplicity that each party <span><span class="math inline">\(i\)</span></span> has a public key <span><span class="math inline">\(v_i\)</span></span> that is associated with some bitcoin account.<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup> We treat all these keys as the public input.</p></li>
<li><p>The private input of bidder <span><span class="math inline">\(i\)</span></span> is the value <span><span class="math inline">\(x_i\)</span></span> that it wants to bid as well as the secret key <span><span class="math inline">\(s_i\)</span></span> that corresponds to their public key.</p></li>
<li><p>The functionality only provides an output to the auctioneer, which would be the identity <span><span class="math inline">\(i\)</span></span> of the winning bidder as well as a valid signature on this bidder transferring <span><span class="math inline">\(x\)</span></span> bitcoins to the key <span><span class="math inline">\(v_1\)</span></span> of the auctioneer, where <span><span class="math inline">\(x\)</span></span> is the value of the second largest valid bid (i.e., <span><span class="math inline">\(x\)</span></span> equals to the second largest <span><span class="math inline">\(x_j\)</span></span> such that <span><span class="math inline">\(s_j\)</span></span> is indeed the private key corresponding to <span><span class="math inline">\(v_j\)</span></span>.)</p></li>
</ul>
<p>It’s worthwhile to think about what a secure protocol for this functionality accomplishes. For example:</p>
<ul>
<li><p>The fact that in the ideal model the adversary needs to choose its queries independently means that the adversary cannot get any information about the honest parties’ bids before deciding on its bid.</p></li>
<li><p>Despite all parties using their signing keys as inputs to the protocol, we are guaranteed that no one will learn anything about another party’s signing key except the single signature that will be produced.</p></li>
<li><p>Note that if <span><span class="math inline">\(i\)</span></span> is the highest bidder and <span><span class="math inline">\(j\)</span></span> is the second highest, then at the end of the protocol we get a valid signature using <span><span class="math inline">\(s_i\)</span></span> on a transaction transferring <span><span class="math inline">\(x_j\)</span></span> bitcoins to <span><span class="math inline">\(v_1\)</span></span>, despite <span><span class="math inline">\(i\)</span></span> not knowing the value <span><span class="math inline">\(x_j\)</span></span> (and in fact never learning the identity of <span><span class="math inline">\(j\)</span></span>.) Nonetheless, <span><span class="math inline">\(i\)</span></span> is guaranteed that the signature produced will be on an amount not larger than its own bid and an amount that one of the other bidders actually bid for.</p></li>
</ul>
<p>I find the ability to obtain such strong notions of security pretty remarkable. This demonstrates the tremendous power of obtaining protocols for general functionalities.</p>
<h3 id="another-example-distributed-and-threshold-cryptography" data-number="18.3.1">Another example: distributed and threshold cryptography</h3>
<p>It sometimes makes sense to use multiparty secure computation for <em>cryptographic computations</em> as well. For example, there might be several reasons why we would want to “split” a secret key between several parties, so no party knows it completely.</p>
<ul>
<li><p>Some proposals for <em>key escrow</em> (giving government or other entity an option for decrypting communication) suggested to split a cryptographic key between several agencies or institutions (say the FBI, the courts, etc..) so that they must collaborate in order to decrypt communication, thus hopefully preventing unlawful access.</p></li>
<li><p>On the other side, a company might wish to split its own key between several servers residing in different countries, to ensure not one of them is completely under one jurisdiction. Or it might do such splitting for technical reasons, so that if there is a break in into a single site, the key is not compromised.</p></li>
</ul>
<p>There are several other such examples. One problem with this approach is that splitting a cryptographic key is not the same as cutting a 100 dollar bill in half. If you simply give half of the bits to each party, you could significantly harm security. (For example, it is possible to recover the full RSA key <a href="http://eprint.iacr.org/2008/510.pdf">from only <span><span class="math inline">\(27\%\)</span></span> of its bits</a>).</p>
<p>Here is a better approach, known as <a href="https://en.wikipedia.org/wiki/Secret_sharing">secret sharing</a>: To securely share a string <span><span class="math inline">\(s\in\{0,1\}^n\)</span></span> among <span><span class="math inline">\(k\)</span></span> parties so that any <span><span class="math inline">\(k-1\)</span></span> of them have no information about it, we choose <span><span class="math inline">\(s_1,\ldots,s_{k-1}\)</span></span> at random in <span><span class="math inline">\(\{0,1\}^n\)</span></span> and let <span><span class="math inline">\(s_k = s \oplus s_1 \oplus \cdots s_{k-1}\)</span></span> (<span><span class="math inline">\(\oplus\)</span></span> as usual denotes the XOR operation), and give party <span><span class="math inline">\(i\)</span></span> the string <span><span class="math inline">\(s_i\)</span></span>, which is known as the <em><span><span class="math inline">\(i^{th}\)</span></span> share</em> of <span><span class="math inline">\(s\)</span></span>. Note that <span><span class="math inline">\(s = s_1 \oplus \cdots \oplus s_t\)</span></span> and so given all <span><span class="math inline">\(k\)</span></span> pieces we can reconstruct the key. Clearly the first <span><span class="math inline">\(k-1\)</span></span> parties did not receive any information about <span><span class="math inline">\(s\)</span></span> (since their shares were generated independent of <span><span class="math inline">\(s\)</span></span>), but the following not-too-hard claim shows that this holds for <em>every</em> set of <span><span class="math inline">\(k-1\)</span></span> parties:</p>
<div id="secretsharinglem" class="lemma" data-number="18.3.1" name="Lemma 18.4">
<p>For every <span><span class="math inline">\(s\in\{0,1\}^n\)</span></span>, and set <span><span class="math inline">\(T\subseteq [k]\)</span></span> of size <span><span class="math inline">\(k-1\)</span></span>, we get exactly the same distribution over <span><span class="math inline">\((s_1,\ldots,s_k)\)</span></span> as above if we choose <span><span class="math inline">\(s_i\)</span></span> for <span><span class="math inline">\(i\in T\)</span></span> at random and set <span><span class="math inline">\(s_t = s \oplus_{i\in T} s_i\)</span></span> where <span><span class="math inline">\(t = [k]\setminus T\)</span></span>.</p>
</div>
<p>We leave the proof of <a href='#secretsharinglem'>Lemma 18.4</a> as an exercise.</p>
<p>Secret sharing solves the problem of protecting the key “at rest” but if we actually want to <em>use</em> the secret key in order to sign or decrypt some message, then it seems we need to collect all the pieces together into one place, which is exactly what we wanted to avoid doing. This is where multiparty secure computation comes into play, we can define a functionality <span><span class="math inline">\(F\)</span></span> taking public input <span><span class="math inline">\(m\)</span></span> and secret inputs <span><span class="math inline">\(s_1,\ldots,s_k\)</span></span> and producing a signature or decryption of <span><span class="math inline">\(m\)</span></span>. In fact, we can go beyond that and even have the parties sign or decrypt a message without them knowing what this message is, except that it satisfies some conditions.</p>
<p>Moreover, secret sharing can be generalized so that a threshold other than <span><span class="math inline">\(k\)</span></span> is necessary and sufficient to reconstruct the secret (and people have also studied more complicated access patterns). Similarly multiparty secure computation can be used to achieve distributed cryptography with finer access control mechanisms.</p>
<h2 id="proving-the-fundamental-theorem" data-number="18.4">Proving the fundamental theorem:</h2>
<p>We will complete the proof of (a relaxed version of) the fundamental theorem over this lecture and the next one. The proof consists of two phases:</p>
<ol type="1">
<li><p>A protocol for the “honest but curious” case using fully homomorphic encryption.</p></li>
<li><p>A reduction of the general case into the “honest but curious” case where the adversary follows the protocol precisely but merely attempts to learn some information on top of the output that it is “entitled to” learn. (This reduction is based on zero knowledge proofs and is due to Goldreich, Micali and Wigderson)</p></li>
</ol>
<p>We note that while fully homomorphic encryption yields a conceptually simple approach for the second step, it is not currently the most efficient approach, and rather most practical implementations are based on the technique known as “Yao’s Garbled Ciruits” (see <a href="http://u.cs.biu.ac.il/~lindell/efficient-protocols.html">this book</a> or <a href="https://eprint.iacr.org/2004/175.pdf">this paper</a> or <a href="https://www.cs.uic.edu/pub/Bits/PeterSnyder/Peter_Snyder_-_Garbled_Circuits_WCP_2_column.pdf">this survey</a> ) which in turn is based a notion known as <a href="https://en.wikipedia.org/wiki/Oblivious_transfer">oblivious transfer</a> which can be thought of as a “baby private information retrieval” (though it preceded the latter notion).</p>
<p>We will focus on the case of <em>two parties</em>. The same ideas extend to <span><span class="math inline">\(k&gt;2\)</span></span> parties but with some additional complications.</p>
<h2 id="malicious-to-honest-but-curious-reduction" data-number="18.5">Malicious to honest but curious reduction</h2>
<p>We start from the second stage. Giving a reduction transforming a protocol in the “honest but curious” setting into a protocol secure in the malicious setting. Note that a priori, it is not obvious at all that such a reduction should exist. In the “honest but curious” setting we assume the adversary follows the protocol to the letter. Thus a protocol where Alice gives away all her secrets to Bob if he merely <a href="https://xkcd.com/424/">asks her to do so politely</a> can be secure in the “honest but curious” setting if Bob’s instructions are not to ask. More seriously, it could very well be that Bob has an ability to deviate from the protocol in subtle ways that would be completely undetectable but allow him to learn Alice’s secrets. Any transformation of the protocol to obtain security in the malicious setting will need to rule out such deviations.</p>
<p>The main idea is the following: we do the compilation one party at a time - we first transform the protocol so that it will remain secure even if Alice tries to cheat, and then transform it so it will remain secure even if Bob tries to cheat. Let’s focus on Alice. Let’s imagine (without loss of generality) that Alice and Bob alternate sending messages in the protocol with Alice going first, and so Alice sends the odd messages and Bob sends the even ones. Lets denote by <span><span class="math inline">\(m_i\)</span></span> the message sent in the <span><span class="math inline">\(i^{th}\)</span></span> round of the protocol. Alice’s instructions can be thought of as a sequence of functions <span><span class="math inline">\(f_1,f_3,\cdots,f_t\)</span></span> (where <span><span class="math inline">\(t\)</span></span> is the last round in which Alice speaks) where each <span><span class="math inline">\(f_i\)</span></span> is an efficiently computable function mapping Alice’s secret input <span><span class="math inline">\(x_1\)</span></span>, (possibly) her random coins <span><span class="math inline">\(r_1\)</span></span>, and the transcript of the previous messages <span><span class="math inline">\(m_1,\ldots,m_{i-1}\)</span></span> to the next message <span><span class="math inline">\(m_i\)</span></span>. The functions <span><span class="math inline">\(\{ f_i \}\)</span></span> are publicly known and part of the protocol’s instructions. The only thing that Bob doesn’t know is <span><span class="math inline">\(x_1\)</span></span> and <span><span class="math inline">\(r_1\)</span></span>. So, our idea would be to change the protocol so that after Alice sends the message <span><span class="math inline">\(i\)</span></span>, she <em>proves</em> to Bob that it was indeed computed correctly using <span><span class="math inline">\(f_i\)</span></span>. If <span><span class="math inline">\(x_1\)</span></span> and <span><span class="math inline">\(r_1\)</span></span> weren’t secret, Alice could simply send those to Bob so he can verify the computation on his own. But because they are (and the security of the protocol could depend on that) we instead use a <em>zero knowledge proof</em>.</p>
<p>Let’s assume for starters that Alice’s strategy is <em>deterministic</em> (and so there is no random tape <span><span class="math inline">\(r_1\)</span></span>). A first attempt to ensure she can’t use a malicious strategy would be for Alice to follow the message <span><span class="math inline">\(m_i\)</span></span> with a zero knowledge proof that there exists some <span><span class="math inline">\(x_1\)</span></span> such that <span><span class="math inline">\(m_i=f(x_1,m_1,\ldots,m_{i-1})\)</span></span>. However, this will actually not be secure - it is worth while at this point for you to pause and think if you can understand the problem with this solution.</p>
<div id="section-1" class="pause" data-number="18.5" name="Pause">
<p>Really, please stop and think why this will not be secure.</p>
</div>

<div id="section-2" class="pause" data-number="18.5" name="Pause">
<p>Did you stop and think?</p>
</div>
<p>The problem is that at every step Alice proves that there exists <em>some</em> input <span><span class="math inline">\(x_1\)</span></span> that can explain her message but she doesn’t prove that it’s <em>the same input for all messages</em>. If Alice was being truly honest, she should have picked her input once and use it throughout the protocol, and she could not compute the first message according to the input <span><span class="math inline">\(x_1\)</span></span> and then the third message according to some input <span><span class="math inline">\(x&#39;_1 \neq x_1\)</span></span>. Of course we can’t have Alice reveal the input, as this would violate security. The solution is for Alice to <em>commit</em> in advance to the input. We have seen commitments before, but let us now formally define the notion:</p>
<div id="commitmentdef" class="definition" title="Commitment scheme" data-number="18.5" name="Definition 18.5 (Commitment scheme) ">
<p>A <em>commitment scheme</em> for strings of length <span><span class="math inline">\(\ell\)</span></span> is a two party protocol between the <em>sender</em> and <em>receiver</em> satisfying the following:</p>
<ul>
<li><p><strong>Hiding (sender’s security):</strong> For every two sender inputs <span><span class="math inline">\(x,x&#39; \in \{0,1\}^\ell\)</span></span>, and no matter what efficient strategy the receiver uses, it cannot distinguish between the interaction with the sender when the latter uses <span><span class="math inline">\(x\)</span></span> as opposed to when it uses <span><span class="math inline">\(x&#39;\)</span></span>.</p></li>
<li><p><strong>Binding (reciever’s security):</strong> No matter what (efficient or non efficient) strategy the sender uses, if the reciever follows the protocol then with probability <span><span class="math inline">\(1-negl(n)\)</span></span>, there will exist at most a single string <span><span class="math inline">\(x\in\{0,1\}^\ell\)</span></span> such that the transcript is consistent with the input <span><span class="math inline">\(x\)</span></span> and some sender randomness <span><span class="math inline">\(r\)</span></span>.</p></li>
</ul>
</div>
<p>That is, a commitment is the digital analog to placing a message in a sealed envelope to be opened at a later time. To commit to a message <span><span class="math inline">\(x\)</span></span> the sender and reciever interact according to the protocol, and to <em>open</em> the commitment the sender simply sends <span><span class="math inline">\(x\)</span></span> as well as the random coins it used during the commitment phase. The variant we defined above is known as <em>computationally hiding and statistically binding</em>, since the sender’s security is only guaranteed against efficient receivers while the binding property is guaranteed against all senders. There are also statistically hiding and computationally binding commitments, though it can be shown that we need to restrict to efficient strategies for at least one of the parties.</p>
<p>We have already seen a commitment scheme before (due to Naor): the receiver sends a random <span><span class="math inline">\(z\leftarrow_R\{0,1\}^{3n}\)</span></span> and the sender commits to a bit <span><span class="math inline">\(b\)</span></span> by choosing a random <span><span class="math inline">\(s\in\{0,1\}^n\)</span></span> and sending <span><span class="math inline">\(y = \ensuremath{\mathit{PRG}}(s)+ bz (\mod 2)\)</span></span> where <span><span class="math inline">\(\ensuremath{\mathit{PRG}}:\{0,1\}^n\rightarrow\{0,1\}^{3n}\)</span></span> is a pseudorandom generator. It’s a good exercise to verify that it satisfies the above definitions. By running this protocol <span><span class="math inline">\(\ell\)</span></span> times in parallel we can commit to a string of any polynomial length.</p>
<p>We can now describe the transformation ensuring the protocol is secure against a malicious Alice in full, for the case that that the original strategy of Alice is <em>deterministic</em> (and hence uses no random coins)</p>
<ul>
<li><p>Initially Alice and Bob engage in a commitment scheme where Alice commits to her input <span><span class="math inline">\(x_1\)</span></span>. Let <span><span class="math inline">\(\tau\)</span></span> be the transcript of this commitment phase and <span><span class="math inline">\(r_{com}\)</span></span> be the randomness Alice used during it.<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup></p></li>
<li><p>For <span><span class="math inline">\(i=1,2,\ldots\)</span></span>:</p>
<ul>
<li><p>If <span><span class="math inline">\(i\)</span></span> is even then Bob sends <span><span class="math inline">\(m_i\)</span></span> to Alice</p></li>
<li><p>If <span><span class="math inline">\(i\)</span></span> is odd then Alice sends <span><span class="math inline">\(m_i\)</span></span> to Bob and then they engage in a zero knowledge proof that there exists <span><span class="math inline">\(x_1,r_{com}\)</span></span> such that (1) <span><span class="math inline">\(x_1,r_com\)</span></span> is consistent with <span><span class="math inline">\(\tau\)</span></span>, and (2) <span><span class="math inline">\(m_i = f(x_1,m_1,\ldots,m_{i-1})\)</span></span>. The proof is repeated a sufficient number of times to ensure that if the statement is false then Bob rejects with <span><span class="math inline">\(1-negl(n)\)</span></span> probability.</p></li>
<li><p>If the proof is rejected then Bob aborts the protocol.</p></li>
</ul></li>
</ul>
<p>We will not prove security but will only sketch it here, see <a href="http://www.nowpublishers.com/article/Details/TCS-001">Section 7.3.2 in Goldreich’s survey</a> for a more detailed proof:</p>
<ul>
<li><p>To argue that we maintain security for <em>Alice</em> we use the zero knowledge property: we claim that Bob could not learn anything from the zero knowledge proofs precisely because he could have simulated them by himself. We also use the hiding property of the commitment scheme. To prove security formally we  need to show that whatever Bob learns in the modified protocol, he could have learned in the original protocol as well. We do this by <em>simulating</em> Bob by replacing the commitment scheme with commitment to some random junk instead of <span><span class="math inline">\(x_1\)</span></span> and the zero knowledge proofs with their simulated version. The proof of security requires a hybrid argument, and is again a good exercise to try to do it on your own.</p></li>
<li><p>To argue that we maintain security for <em>Bob</em> we use the binding property of the commitment scheme as well as the soundness property of the zero knowledge system. Once again for the formal proof we need to show that we could transform any potentially malicious strategy for Alice in the modified protocol into an “honest but curious” strategy in the original protocol (also allowing Alice the ability to abort the protocol). It turns out that to do so, it is not enough that the zero knowledge system is sound but we need a stronger property known as a <em>proof of knowledge</em>. We will not define it formally, but roughly speaking it means we can transform any prover strategy that convinces the verifier that a statement is true with non-negligible probability into an algorithm that outputs the underlying secret (i.e., <span><span class="math inline">\(x_1\)</span></span> and <span><span class="math inline">\(r_com\)</span></span> in our case). This is crucial in order to trasnform Alice’s potentially malicious strategy into an honest but curious strategy.</p></li>
</ul>
<p>We can repeat this transformation for Bob (or Charlie, David, etc.. in the <span><span class="math inline">\(k&gt;2\)</span></span> party case) to transform a protocol secure in the honest but curious setting into a protocol secure (allowing for aborts) in the malicious setting.</p>
<h3 id="handling-probabilistic-strategies" data-number="18.5.1">Handling probabilistic strategies:</h3>
<p>So far we assumed that the original strategy of Alice in the honest but curious is deterministic but of course we need to consider probabilistic strategies as well. One approach could be to simply think of Alice’s random tape <span><span class="math inline">\(r\)</span></span> as part of her secret input <span><span class="math inline">\(x_1\)</span></span>. However, while in the honest but curious setting Alice is still entitled to freely choose her own input <span><span class="math inline">\(x_1\)</span></span>, she is not entitled to choose the random tape as she wishes but is supposed to follow the instructions of the protocol and choose it uniformly at random. Hence we need to use a <em>coin tossing protocol</em> to choose the randomness, or more accurately what’s known as a “coin tossing in the well” protocol where Alice and Bob engage in a coin tossing protocol at the end of which they generate some random coins <span><span class="math inline">\(r\)</span></span> that only Alice knows but Bob is still guaranteed that they are random. Such a protocol can actually be achieved very simply. Suppose we want to generate <span><span class="math inline">\(m\)</span></span> coins:</p>
<ul>
<li>Alice selects <span><span class="math inline">\(r&#39;\leftarrow_R\{0,1\}^m\)</span></span> at random and engages in a <em>commitment protocol</em> to commit to <span><span class="math inline">\(r&#39;\)</span></span>.</li>
<li>Bob selects <span><span class="math inline">\(r&#39;&#39; \leftarrow_R\{0,1\}^m\)</span></span> and sends it to Alice in the clear.</li>
<li>The result of the coin tossing protocol will be the string <span><span class="math inline">\(r=r&#39;\oplus r&#39;&#39;\)</span></span>.</li>
</ul>
<p>Note that Alice knows <span><span class="math inline">\(r\)</span></span>. Bob doesn’t know <span><span class="math inline">\(r\)</span></span> but because he chose <span><span class="math inline">\(r&#39;&#39;\)</span></span> <em>after</em> Alice committed to <span><span class="math inline">\(r&#39;\)</span></span> he knows that it must be fully random regardless of Alice’s choice of <span><span class="math inline">\(r&#39;\)</span></span>. It can be shown that if we use this coin tossing protocol at the beginning and then modify the zero knowledge proofs to show that <span><span class="math inline">\(m_i=f(x_1,r_1,m_1,\ldots,m_{i-1})\)</span></span> where <span><span class="math inline">\(r\)</span></span> is the string that is consistent with the transcript of the coin tossing protocol, then we get a general transformation of an honest but curious adversary into the malicious setting.</p>
<p>The notion of multiparty secure computation - defining it and achieving it - is quite subtle and I do urge you to read some of the other references listed above as well. In particular, the slides and videos from the <a href="https://cyber.biu.ac.il/event/the-1st-biu-winter-school/">Bar Ilan winter school on secure computation and efficiency</a>, as well as the ones from the <a href="https://cyber.biu.ac.il/event/the-5th-biu-winter-school/">winter school on advances in practical multiparty computation</a> are great sources for this and related materials.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>Note that here <span><span class="math inline">\(k\)</span></span> is not a string which the secret key but the number of parties in the protocol.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>Protocols for <span><span class="math inline">\(k&gt;2\)</span></span> parties require also a <em>broadcast channel</em> but these can be <a href="http://epubs.siam.org/doi/abs/10.1137/0212045?journalCode=smjcat">implemented</a> using the combination of authenticated channels and digital signatures.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>Fixing the input and output sizes to <span><span class="math inline">\(n\)</span></span> is done for notational simplicity and is without loss of generality. More generally, the inputs and outputs could have sizes up to polynomial in <span><span class="math inline">\(n\)</span></span> and some inputs or output can also be empty. Also, note that one can define a more general notion of stateful functionalities, though it is not hard to reduce the task of building a protocol for stateful functionalities to building protocols for stateless ones.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>As a side note, we can avoid this issue if we have an honest majority of players - i.e. if <span><span class="math inline">\(|T|&lt;k/2\)</span></span>, but this of course makes no sense in the two party setting.)</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>Actually, if we want to be pedantic, this is what’s known as a zero knowledge <em>argument</em> system since soundness is only guaranteed against efficient provers. However, this distinction is not important in almost all applications.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p>Our treatment of the input graph <span><span class="math inline">\(H\)</span></span> is an instance of a general case. While the definition of a functionality only talks about private inputs, it’s very easy to include public inputs as well. If we want to include some public input <span><span class="math inline">\(Z\)</span></span> we can simply have <span><span class="math inline">\(Z\)</span></span> concatenated to all the private inputs (and the functionality check that they are all the same, otherwise outputting <code>error</code> or some similar result).</p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:7"><p>
<div>
<p>Originally this was shown under the assumption of trapdoor permutations (which can be derived from the Factoring or RSA conjectures) but it is known today under a variety of other assumptions, including in particular the LWE conjecture.</p>
</div>
<a href="#fnref:7" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:8"><p>
<div>
<p>One example of the kind of issues that can arise is the “grandmasters attack” whereby someone with no knowledge of chess could play two grandmasters simultaneously, relaying their moves to one another and thereby guaranteeing a win in at least one of the games (or a draw in both).</p>
</div>
<a href="#fnref:8" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:9"><p>
<div>
<p>As we discussed before, bitcoin doesn’t have the notion of accounts but rather what we mean by that for each one of the public keys, the public ledger contains a sufficiently large amount of bitcoins that have been transferred to these keys (in the sense that whomever can sign w.r.t. these keys can transfer the corresponding coins).</p>
</div>
<a href="#fnref:9" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:10"><p>
<div>
<p>Note that even though we assumed that in the original honest-but-curious protocol Alice used a deterministic strategy, we will transform the protocol into one in which Alice uses a randomized strategy in both the commitment and zero knowledge phases.</p>
</div>
<a href="#fnref:10" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/crypto/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/crypto/issues?q=Multiparty secure computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/29/2019 17:55:22</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/crypto/lec_17_SFE.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
