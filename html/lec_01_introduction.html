<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An intensive introduction to cryptography: Introduction</title>
  <meta name="description" content="Lecture notes on Cryptography by Boaz Barak">

  <meta property="og:title" content="An intensive introduction to cryptography: Introduction" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://intensecrypto.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="github-repo" content="boazbk/crypto" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An intensive introduction to cryptography" />
  <meta name="twitter:description" content="Lecture notes on Cryptography by Boaz Barak" />
  <meta name="twitter:image" content="https://intensecrypto.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">An intensive introduction to cryptography</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html"><i class="fa fa-check"></i><b>p</b> Foreword and Syllabus</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#syllabus"><i class="fa fa-check"></i><b>p.1</b> Syllabus</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#prerequisites"><i class="fa fa-check"></i><b>p.1.1</b> Prerequisites</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#why-is-cryptography-hard"><i class="fa fa-check"></i><b>p.2</b> Why is cryptography hard?</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html"><i class="fa fa-check"></i><b>0</b> Mathematical Background</a><ul><li class="chapter" data-level="0.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#a-quick-overview-of-mathematical-prerequisites"><i class="fa fa-check"></i><b>0.1</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="0.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#mathematical-proofs"><i class="fa fa-check"></i><b>0.2</b> Mathematical Proofs</a><ul><li class="chapter" data-level="0.2.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#example-the-existence-of-infinitely-many-primes."><i class="fa fa-check"></i><b>0.2.1</b> Example: The existence of infinitely many primes.</a></li></ul></li><li class="chapter" data-level="0.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#probability-and-sample-spaces"><i class="fa fa-check"></i><b>0.3</b> Probability and Sample spaces</a><ul><li class="chapter" data-level="0.3.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#random-variables"><i class="fa fa-check"></i><b>0.3.1</b> Random variables</a></li><li class="chapter" data-level="0.3.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#distributions-over-strings"><i class="fa fa-check"></i><b>0.3.2</b> Distributions over strings</a></li><li class="chapter" data-level="0.3.3" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>0.3.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="0.4" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#correlations-and-independence"><i class="fa fa-check"></i><b>0.4</b> Correlations and independence</a><ul><li class="chapter" data-level="0.4.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#independent-random-variables"><i class="fa fa-check"></i><b>0.4.1</b> Independent random variables</a></li><li class="chapter" data-level="0.4.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>0.4.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="0.5" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#concentration"><i class="fa fa-check"></i><b>0.5</b> Concentration</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>0.5.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="0.5.2" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#the-chernoff-bound"><i class="fa fa-check"></i><b>0.5.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_00_1_mathematical-background.html"><a href="lec_00_1_mathematical-background.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul><li class="chapter" data-level="1.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-encryptions"><i class="fa fa-check"></i><b>1.1</b> Defining encryptions</a><ul><li class="chapter" data-level="1.1.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#generating-randomness-in-actual-cryptographic-systems"><i class="fa fa-check"></i><b>1.1.1</b> Generating randomness in actual cryptographic systems</a></li></ul></li><li class="chapter" data-level="1.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#defining-the-secrecy-requirement."><i class="fa fa-check"></i><b>1.2</b> Defining the secrecy requirement.</a></li><li class="chapter" data-level="1.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#perfect-secrecy"><i class="fa fa-check"></i><b>1.3</b> Perfect Secrecy</a></li><li class="chapter" data-level="1.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>1.4</b> Necessity of long keys</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#advanced-comment-adding-probability-into-the-picture"><i class="fa fa-check"></i><b>1.4.1</b> Advanced comment: Adding probability into the picture</a></li></ul></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html"><i class="fa fa-check"></i><b>2</b> Computational Security</a><ul><li><ul><li class="chapter" data-level="2.0.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#proof-by-reduction"><i class="fa fa-check"></i><b>2.0.1</b> Proof by reduction</a></li></ul></li><li class="chapter" data-level="2.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#the-asymptotic-approach"><i class="fa fa-check"></i><b>2.1</b> The asymptotic approach</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#counting-number-of-operations."><i class="fa fa-check"></i><b>2.1.1</b> Counting number of operations.</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#our-first-conjecture"><i class="fa fa-check"></i><b>2.2</b> Our first conjecture</a></li><li class="chapter" data-level="2.3" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#why-care-about-the-cipher-conjecture"><i class="fa fa-check"></i><b>2.3</b> Why care about the cipher conjecture?</a></li><li class="chapter" data-level="2.4" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#prelude-computational-indistinguishability"><i class="fa fa-check"></i><b>2.4</b> Prelude: Computational Indistinguishability</a></li><li class="chapter" data-level="2.5" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#the-length-extension-theorem"><i class="fa fa-check"></i><b>2.5</b> The Length Extension Theorem</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_computational_security.html"><a href="lec_02_computational_security.html#appendix-the-computational-model"><i class="fa fa-check"></i><b>2.5.1</b> Appendix: The computational model</a></li></ul></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html"><i class="fa fa-check"></i><b>3</b> Pseudorandomness</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#stream-ciphers"><i class="fa fa-check"></i><b>3.1</b> Stream ciphers</a></li><li class="chapter" data-level="3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#what-do-pseudorandom-generators-actually-look-like"><i class="fa fa-check"></i><b>3.2</b> What do pseudorandom generators actually look like?</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-0-the-counter-generator"><i class="fa fa-check"></i><b>3.2.1</b> Attempt 0: The counter generator</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-1-the-linear-checksum-linear-feedback-shift-register-lfsr"><i class="fa fa-check"></i><b>3.2.2</b> Attempt 1: The linear checksum / linear feedback shift register (LFSR)</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#from-insecurity-to-security"><i class="fa fa-check"></i><b>3.2.3</b> From insecurity to security</a></li><li class="chapter" data-level="3.2.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#attempt-2-linear-congruential-generators-with-dropped-bits"><i class="fa fa-check"></i><b>3.2.4</b> Attempt 2: Linear Congruential Generators with dropped bits</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#successful-examples"><i class="fa fa-check"></i><b>3.3</b> Successful examples</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-1-subset-sum-generator"><i class="fa fa-check"></i><b>3.3.1</b> Case Study 1: Subset Sum Generator</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#case-study-2-rc4"><i class="fa fa-check"></i><b>3.3.2</b> Case Study 2: RC4</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_pseudorandom-generators.html"><a href="lec_03_pseudorandom-generators.html#non-constructive-existence-of-pseudorandom-generators"><i class="fa fa-check"></i><b>3.4</b> Non-constructive existence of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html"><i class="fa fa-check"></i><b>4</b> Pseudorandom functions</a><ul><li class="chapter" data-level="4.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#one-time-passwords-e.g.-google-authenticator-rsa-id-etc."><i class="fa fa-check"></i><b>4.1</b> One time passwords (e.g. Google Authenticator, RSA ID, etc.)</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#how-do-pseudorandom-functions-help-in-the-login-problem"><i class="fa fa-check"></i><b>4.1.1</b> How do pseudorandom functions help in the login problem?</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#message-authentication-codes"><i class="fa fa-check"></i><b>4.2</b> Message Authentication Codes</a></li><li class="chapter" data-level="4.3" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#macs-from-prfs"><i class="fa fa-check"></i><b>4.3</b> MACs from PRFs</a></li><li class="chapter" data-level="4.4" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#input-length-extension-for-macs-and-prfs"><i class="fa fa-check"></i><b>4.4</b> Input length extension for MACs and PRFs</a></li><li class="chapter" data-level="4.5" data-path="lec_04_pseudorandom-functions.html"><a href="lec_04_pseudorandom-functions.html#aside-natural-proofs"><i class="fa fa-check"></i><b>4.5</b> Aside: natural proofs</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html"><i class="fa fa-check"></i><b>5</b> Pseudorandom functions from pseudorandom generators</a><ul><li class="chapter" data-level="5.1" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#securely-encrypting-many-messages---chosen-plaintext-security"><i class="fa fa-check"></i><b>5.1</b> Securely encrypting many messages - chosen plaintext security</a></li><li class="chapter" data-level="5.2" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#pseudorandom-permutations-block-ciphers"><i class="fa fa-check"></i><b>5.2</b> Pseudorandom permutations / block ciphers</a></li><li class="chapter" data-level="5.3" data-path="lec_05_prf-from-prg.html"><a href="lec_05_prf-from-prg.html#encryption-modes"><i class="fa fa-check"></i><b>5.3</b> Encryption modes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html"><i class="fa fa-check"></i><b>6</b> Chosen Ciphertext Security</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#short-recap"><i class="fa fa-check"></i><b>6.1</b> Short recap</a></li><li class="chapter" data-level="6.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#going-beyond-cpa"><i class="fa fa-check"></i><b>6.2</b> Going beyond CPA</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#example-the-wired-equivalence-protocol-wep"><i class="fa fa-check"></i><b>6.2.1</b> Example: The Wired Equivalence Protocol (WEP)</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-security-1"><i class="fa fa-check"></i><b>6.2.2</b> Chosen ciphertext security</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#constructing-cca-secure-encryption"><i class="fa fa-check"></i><b>6.3</b> Constructing CCA secure encryption</a></li><li class="chapter" data-level="6.4" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#simplified-gcm-encryption"><i class="fa fa-check"></i><b>6.4</b> (Simplified) GCM encryption</a></li><li class="chapter" data-level="6.5" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#padding-chopping-and-their-pitfalls-the-buffer-overflow-of-cryptography"><i class="fa fa-check"></i><b>6.5</b> Padding, chopping, and their pitfalls: the buffer overflow of cryptography</a></li><li class="chapter" data-level="6.6" data-path="lec_06_CCA.html"><a href="lec_06_CCA.html#chosen-ciphertext-attack-as-implementing-metaphors"><i class="fa fa-check"></i><b>6.6</b> Chosen ciphertext attack as implementing metaphors</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html"><i class="fa fa-check"></i><b>7</b> Hash functions and random oracles</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-problem"><i class="fa fa-check"></i><b>7.1</b> The bitcoin problem</a><ul><li class="chapter" data-level="7.1.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-currency-problem"><i class="fa fa-check"></i><b>7.1.1</b> The currency problem</a></li><li class="chapter" data-level="7.1.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#bitcoin-architecture"><i class="fa fa-check"></i><b>7.1.2</b> Bitcoin architecture</a></li></ul></li><li class="chapter" data-level="7.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-bitcoin-ledger"><i class="fa fa-check"></i><b>7.2</b> The bitcoin ledger</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#from-proof-of-work-to-consensus-on-ledger"><i class="fa fa-check"></i><b>7.2.1</b> From proof of work to consensus on ledger</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#collision-resistance-hash-functions-and-creating-short-unique-identifiers"><i class="fa fa-check"></i><b>7.3</b> Collision resistance hash functions and creating short unique identifiers</a></li><li class="chapter" data-level="7.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-constructions-of-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4</b> Practical constructions of cryptographic hash functions</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#practical-random-ish-functions"><i class="fa fa-check"></i><b>7.4.1</b> Practical random-ish functions</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#some-history"><i class="fa fa-check"></i><b>7.4.2</b> Some history</a></li><li class="chapter" data-level="7.4.3" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#the-nsa-and-hash-functions."><i class="fa fa-check"></i><b>7.4.3</b> The NSA and hash functions.</a></li><li class="chapter" data-level="7.4.4" data-path="lec_07_hash_functions.html"><a href="lec_07_hash_functions.html#cryptographic-vs-non-cryptographic-hash-functions"><i class="fa fa-check"></i><b>7.4.4</b> Cryptographic vs non-cryptographic hash functions:</a></li></ul></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html"><i class="fa fa-check"></i><b>8</b> Key derivation, protecting passwords, slow hashes, Merkle trees</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#keys-from-passwords"><i class="fa fa-check"></i><b>8.1</b> Keys from passwords</a></li><li class="chapter" data-level="8.2" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#merkle-trees-and-verifying-storage."><i class="fa fa-check"></i><b>8.2</b> Merkle trees and verifying storage.</a></li><li class="chapter" data-level="8.3" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#proofs-of-retrievability"><i class="fa fa-check"></i><b>8.3</b> Proofs of Retrievability</a></li><li class="chapter" data-level="8.4" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#entropy-extraction"><i class="fa fa-check"></i><b>8.4</b> Entropy extraction</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_hash_functions_part2.html"><a href="lec_08_hash_functions_part2.html#forward-and-backward-secrecy"><i class="fa fa-check"></i><b>8.4.1</b> Forward and backward secrecy</a></li></ul></li></ul></li><li class="chapter" data-level="9" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html"><i class="fa fa-check"></i><b>9</b> Private key crypto recap</a><ul><li><ul><li class="chapter" data-level="9.0.1" data-path="lec_00_0_foreword.html"><a href="lec_00_0_foreword.html#attacks-on-private-key-cryptosystems"><i class="fa fa-check"></i><b>9.0.1</b> Attacks on private key cryptosystems</a></li></ul></li></ul></li><li class="chapter" data-level="10" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html"><i class="fa fa-check"></i><b>10</b> Public key cryptography</a><ul><li class="chapter" data-level="10.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#private-key-crypto-recap"><i class="fa fa-check"></i><b>10.1</b> Private key crypto recap</a></li><li class="chapter" data-level="10.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#public-key-encryptions-definition"><i class="fa fa-check"></i><b>10.2</b> Public Key Encryptions: Definition</a><ul><li class="chapter" data-level="10.2.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-obfuscation-paradigm"><i class="fa fa-check"></i><b>10.2.1</b> The obfuscation paradigm</a></li></ul></li><li class="chapter" data-level="10.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#some-concrete-candidates"><i class="fa fa-check"></i><b>10.3</b> Some concrete candidates:</a><ul><li class="chapter" data-level="10.3.1" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#diffie-hellman-encryption-aka-el-gamal"><i class="fa fa-check"></i><b>10.3.1</b> Diffie-Hellman Encryption (aka El-Gamal)</a></li><li class="chapter" data-level="10.3.2" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#sampling-random-primes"><i class="fa fa-check"></i><b>10.3.2</b> Sampling random primes</a></li><li class="chapter" data-level="10.3.3" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#a-little-bit-of-group-theory."><i class="fa fa-check"></i><b>10.3.3</b> A little bit of group theory.</a></li><li class="chapter" data-level="10.3.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#digital-signatures"><i class="fa fa-check"></i><b>10.3.4</b> Digital Signatures</a></li><li class="chapter" data-level="10.3.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#the-digital-signature-algorithm-dsa"><i class="fa fa-check"></i><b>10.3.5</b> The Digital Signature Algorithm (DSA)</a></li></ul></li><li class="chapter" data-level="10.4" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#putting-everything-together---security-in-practice."><i class="fa fa-check"></i><b>10.4</b> Putting everything together - security in practice.</a></li><li class="chapter" data-level="10.5" data-path="lec_10_public_key_intro.html"><a href="lec_10_public_key_intro.html#appendix-an-alternative-proof-of-the-density-of-primes"><i class="fa fa-check"></i><b>10.5</b> Appendix: An alternative proof of the density of primes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html"><i class="fa fa-check"></i><b>11</b> Concrete candidates for public key crypto</a><ul><li class="chapter" data-level="11.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#some-number-theory."><i class="fa fa-check"></i><b>11.1</b> Some number theory.</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#primaliy-testing"><i class="fa fa-check"></i><b>11.1.1</b> Primaliy testing</a></li><li class="chapter" data-level="11.1.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#fields"><i class="fa fa-check"></i><b>11.1.2</b> Fields</a></li><li class="chapter" data-level="11.1.3" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#chinese-remainder-theorem"><i class="fa fa-check"></i><b>11.1.3</b> Chinese remainder theorem</a></li><li class="chapter" data-level="11.1.4" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#the-rsa-and-rabin-functions"><i class="fa fa-check"></i><b>11.1.4</b> The RSA and Rabin functions</a></li><li class="chapter" data-level="11.1.5" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#abstraction-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.5</b> Abstraction: trapdoor permutations</a></li><li class="chapter" data-level="11.1.6" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#public-key-encryption-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.6</b> Public key encryption from trapdoor permutations</a></li><li class="chapter" data-level="11.1.7" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#digital-signatures-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.7</b> Digital signatures from trapdoor permutations</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_11_concrete_pkc.html"><a href="lec_11_concrete_pkc.html#hardcore-bits-and-security-without-random-oracles"><i class="fa fa-check"></i><b>11.2</b> Hardcore bits and security without random oracles</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html"><i class="fa fa-check"></i><b>12</b> Lattice based cryptography</a><ul><li class="chapter" data-level="12.1" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#a-world-without-gaussian-elimination"><i class="fa fa-check"></i><b>12.1</b> A world without Gaussian elimination</a></li><li class="chapter" data-level="12.2" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#security-in-the-real-world."><i class="fa fa-check"></i><b>12.2</b> Security in the real world.</a></li><li class="chapter" data-level="12.3" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#search-to-decision"><i class="fa fa-check"></i><b>12.3</b> Search to decision</a></li><li class="chapter" data-level="12.4" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#an-lwe-based-encryption-scheme"><i class="fa fa-check"></i><b>12.4</b> An LWE based encryption scheme</a></li><li class="chapter" data-level="12.5" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#but-what-are-lattices"><i class="fa fa-check"></i><b>12.5</b> But what are lattices?</a></li><li class="chapter" data-level="12.6" data-path="lec_12_lattices.html"><a href="lec_12_lattices.html#ring-based-lattices"><i class="fa fa-check"></i><b>12.6</b> Ring based lattices</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12a_CCA_public_key.html"><a href="lec_12a_CCA_public_key.html"><i class="fa fa-check"></i><b>13</b> Chosen ciphertext security for public key encryption</a></li><li class="chapter" data-level="14" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html"><i class="fa fa-check"></i><b>14</b> Establishing secure connections over insecure channels</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cryptographys-obsession-with-adjectives."><i class="fa fa-check"></i><b>14.1</b> Cryptography’s obsession with adjectives.</a></li><li class="chapter" data-level="14.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#basic-key-exchange-protocol"><i class="fa fa-check"></i><b>14.2</b> Basic Key Exchange protocol</a></li><li class="chapter" data-level="14.3" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#authenticated-key-exchange"><i class="fa fa-check"></i><b>14.3</b> Authenticated key exchange</a><ul><li class="chapter" data-level="14.3.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#bleichenbachers-attack-on-rsa-pkcs-v1.5-and-ssl-v3.0"><i class="fa fa-check"></i><b>14.3.1</b> Bleichenbacher’s attack on RSA PKCS V1.5 and SSL V3.0</a></li></ul></li><li class="chapter" data-level="14.4" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#chosen-ciphertext-attack-security-for-public-key-cryptography"><i class="fa fa-check"></i><b>14.4</b> Chosen ciphertext attack security for public key cryptography</a></li><li class="chapter" data-level="14.5" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#cca-secure-public-key-encryption-in-the-random-oracle-model"><i class="fa fa-check"></i><b>14.5</b> CCA secure public key encryption in the Random Oracle Model</a><ul><li class="chapter" data-level="14.5.1" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#defining-secure-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.1</b> Defining secure authenticated key exchange</a></li><li class="chapter" data-level="14.5.2" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#the-compiler-approach-for-authenticated-key-exchange"><i class="fa fa-check"></i><b>14.5.2</b> The compiler approach for authenticated key exchange</a></li></ul></li><li class="chapter" data-level="14.6" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#password-authenticated-key-exchange."><i class="fa fa-check"></i><b>14.6</b> Password authenticated key exchange.</a></li><li class="chapter" data-level="14.7" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#client-to-client-key-exchange-for-secure-text-messaging---zrtp-otr-textsecure"><i class="fa fa-check"></i><b>14.7</b> Client to client key exchange for secure text messaging - ZRTP, OTR, TextSecure</a></li><li class="chapter" data-level="14.8" data-path="lec_13_handshake.html"><a href="lec_13_handshake.html#heartbleed-and-logjam-attacks"><i class="fa fa-check"></i><b>14.8</b> Heartbleed and logjam attacks</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html"><i class="fa fa-check"></i><b>15</b> Zero knowledge proofs</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#applications-for-zero-knowledge-proofs."><i class="fa fa-check"></i><b>15.1</b> Applications for zero knowledge proofs.</a><ul><li class="chapter" data-level="15.1.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#nuclear-disarmament"><i class="fa fa-check"></i><b>15.1.1</b> Nuclear disarmament</a></li><li class="chapter" data-level="15.1.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#voting"><i class="fa fa-check"></i><b>15.1.2</b> Voting</a></li><li class="chapter" data-level="15.1.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#more-applications"><i class="fa fa-check"></i><b>15.1.3</b> More applications</a></li></ul></li><li class="chapter" data-level="15.2" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-and-constructing-zero-knowledge-proofs"><i class="fa fa-check"></i><b>15.2</b> Defining and constructing zero knowledge proofs</a></li><li class="chapter" data-level="15.3" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#defining-zero-knowledge"><i class="fa fa-check"></i><b>15.3</b> Defining zero knowledge</a></li><li class="chapter" data-level="15.4" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#zero-knowledge-proof-for-hamiltonicity."><i class="fa fa-check"></i><b>15.4</b> Zero knowledge proof for Hamiltonicity.</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#why-is-this-interesting"><i class="fa fa-check"></i><b>15.4.1</b> Why is this interesting?</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#parallel-repetition-and-turning-zero-knowledge-proofs-to-signatures."><i class="fa fa-check"></i><b>15.5</b> Parallel repetition and turning zero knowledge proofs to signatures.</a><ul><li class="chapter" data-level="15.5.1" data-path="lec_14_zero_knowledge.html"><a href="lec_14_zero_knowledge.html#bonus-features-of-zero-knowledge"><i class="fa fa-check"></i><b>15.5.1</b> Bonus features of zero knowledge</a></li></ul></li></ul></li><li class="chapter" data-level="16" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html"><i class="fa fa-check"></i><b>16</b> Fully homomorphic encryption: Introduction and bootstrapping</a><ul><li class="chapter" data-level="16.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#defining-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>16.1</b> Defining fully homomorphic encryption</a><ul><li class="chapter" data-level="16.1.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#another-application-fully-homomorphic-encryption-for-verifying-computation"><i class="fa fa-check"></i><b>16.1.1</b> Another application: fully homomorphic encryption for verifying computation</a></li></ul></li><li class="chapter" data-level="16.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#example-an-xor-homomorphic-encryption"><i class="fa fa-check"></i><b>16.2</b> Example: An XOR homomorphic encryption</a><ul><li class="chapter" data-level="16.2.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#abstraction-a-trapdoor-pseudorandom-generator."><i class="fa fa-check"></i><b>16.2.1</b> Abstraction: A trapdoor pseudorandom generator.</a></li></ul></li><li class="chapter" data-level="16.3" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#from-linear-homomorphism-to-full-homomorphism"><i class="fa fa-check"></i><b>16.3</b> From linear homomorphism to full homomorphism</a></li><li class="chapter" data-level="16.4" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#bootstrapping-fully-homomorphic-escape-velocity"><i class="fa fa-check"></i><b>16.4</b> Bootstrapping: Fully Homomorphic escape velocity</a><ul><li class="chapter" data-level="16.4.1" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#radioactive-legos-analogy"><i class="fa fa-check"></i><b>16.4.1</b> Radioactive legos analogy</a></li><li class="chapter" data-level="16.4.2" data-path="lec_15_FHE.html"><a href="lec_15_FHE.html#proving-the-bootstrapping-theorem"><i class="fa fa-check"></i><b>16.4.2</b> Proving the bootstrapping theorem</a></li></ul></li></ul></li><li class="chapter" data-level="17" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html"><i class="fa fa-check"></i><b>17</b> Fully homomorphic encryption : Construction</a><ul><li class="chapter" data-level="17.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#prelude-from-vectors-to-matrices"><i class="fa fa-check"></i><b>17.1</b> Prelude: from vectors to matrices</a></li><li class="chapter" data-level="17.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#real-world-partially-homomorphic-encryption"><i class="fa fa-check"></i><b>17.2</b> Real world partially homomorphic encryption</a></li><li class="chapter" data-level="17.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#noise-management-via-encoding"><i class="fa fa-check"></i><b>17.3</b> Noise management via encoding</a></li><li class="chapter" data-level="17.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#putting-it-all-together"><i class="fa fa-check"></i><b>17.4</b> Putting it all together</a></li><li class="chapter" data-level="17.5" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#analysis-of-our-scheme"><i class="fa fa-check"></i><b>17.5</b> Analysis of our scheme</a><ul><li class="chapter" data-level="17.5.1" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#correctness"><i class="fa fa-check"></i><b>17.5.1</b> Correctness</a></li><li class="chapter" data-level="17.5.2" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#cpa-security"><i class="fa fa-check"></i><b>17.5.2</b> CPA Security</a></li><li class="chapter" data-level="17.5.3" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#homomorphism"><i class="fa fa-check"></i><b>17.5.3</b> Homomorphism</a></li><li class="chapter" data-level="17.5.4" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#shallow-decryption-circuit"><i class="fa fa-check"></i><b>17.5.4</b> Shallow decryption circuit</a></li></ul></li><li class="chapter" data-level="17.6" data-path="lec_16_FHE_part2.html"><a href="lec_16_FHE_part2.html#example-application-private-information-retrieval"><i class="fa fa-check"></i><b>17.6</b> Example application: Private information retrieval</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html"><i class="fa fa-check"></i><b>18</b> Multiparty secure computation I: Definition and Honest-But-Curious to Malicious complier</a><ul><li class="chapter" data-level="18.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#ideal-vs.-real-model-security."><i class="fa fa-check"></i><b>18.1</b> Ideal vs. Real Model Security.</a></li><li class="chapter" data-level="18.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#formally-defining-secure-multiparty-computation"><i class="fa fa-check"></i><b>18.2</b> Formally defining secure multiparty computation</a><ul><li class="chapter" data-level="18.2.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#first-attempt-a-slightly-too-ideal-definition"><i class="fa fa-check"></i><b>18.2.1</b> First attempt: a slightly too ideal definition</a></li><li class="chapter" data-level="18.2.2" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#allowing-for-aborts"><i class="fa fa-check"></i><b>18.2.2</b> Allowing for aborts</a></li><li class="chapter" data-level="18.2.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#some-comments"><i class="fa fa-check"></i><b>18.2.3</b> Some comments:</a></li></ul></li><li class="chapter" data-level="18.3" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#example-second-price-auction-using-bitcoin"><i class="fa fa-check"></i><b>18.3</b> Example: Second price auction using bitcoin</a><ul><li class="chapter" data-level="18.3.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#another-example-distributed-and-threshold-cryptography"><i class="fa fa-check"></i><b>18.3.1</b> Another example: distributed and threshold cryptography</a></li></ul></li><li class="chapter" data-level="18.4" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#proving-the-fundamental-theorem"><i class="fa fa-check"></i><b>18.4</b> Proving the fundamental theorem:</a></li><li class="chapter" data-level="18.5" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#malicious-to-honest-but-curious-reduction"><i class="fa fa-check"></i><b>18.5</b> Malicious to honest but curious reduction</a><ul><li class="chapter" data-level="18.5.1" data-path="lec_17_SFE.html"><a href="lec_17_SFE.html#handling-probabilistic-strategies"><i class="fa fa-check"></i><b>18.5.1</b> Handling probabilistic strategies:</a></li></ul></li></ul></li><li class="chapter" data-level="19" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html"><i class="fa fa-check"></i><b>19</b> Multiparty secure computation: Construction using Fully Homomorphic Encryption</a><ul><li class="chapter" data-level="19.1" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#constructing-2-party-honest-but-curious-computation-from-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.1</b> Constructing 2 party honest but curious computation from fully homomorphic encryption</a></li><li class="chapter" data-level="19.2" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#achieving-circuit-privacy-in-a-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>19.2</b> Achieving circuit privacy in a fully homomorphic encryption</a></li><li class="chapter" data-level="19.3" data-path="lec_18_SFE_part2.html"><a href="lec_18_SFE_part2.html#bottom-line-a-two-party-honest-but-curious-two-party-secure-computation-protocol"><i class="fa fa-check"></i><b>19.3</b> Bottom line: A two party honest but curious two party secure computation protocol</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html"><i class="fa fa-check"></i><b>20</b> Quantum computing and cryptography I</a><ul><li><ul><li class="chapter" data-level="20.0.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>20.0.1</b> Quantum computing and computation - an executive summary.</a></li></ul></li><li class="chapter" data-level="20.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#quantum-101"><i class="fa fa-check"></i><b>20.1</b> Quantum 101</a><ul><li class="chapter" data-level="20.1.1" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>20.1.1</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="20.1.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bra-ket-notation"><i class="fa fa-check"></i><b>20.1.2</b> Bra-ket notation</a></li><li class="chapter" data-level="20.1.3" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#bells-inequality"><i class="fa fa-check"></i><b>20.1.3</b> Bell’s Inequality</a></li></ul></li><li class="chapter" data-level="20.2" data-path="lec_19_quantum.html"><a href="lec_19_quantum.html#grovers-algorithm"><i class="fa fa-check"></i><b>20.2</b> Grover’s Algorithm</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html"><i class="fa fa-check"></i><b>21</b> Quantum computing and cryptography II</a><ul><li class="chapter" data-level="21.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-order-finding-to-factoring-and-discrete-log"><i class="fa fa-check"></i><b>21.1</b> From order finding to factoring and discrete log</a></li><li class="chapter" data-level="21.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#finding-periods-of-a-function-simons-algorithm"><i class="fa fa-check"></i><b>21.2</b> Finding periods of a function: Simon’s Algorithm</a></li><li class="chapter" data-level="21.3" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#from-simon-to-shor"><i class="fa fa-check"></i><b>21.3</b> From Simon to Shor</a><ul><li class="chapter" data-level="21.3.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.1</b> The Fourier transform over \Z_m</a><ul><li class="chapter" data-level="21.3.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#fast-fourier-transform."><i class="fa fa-check"></i><b>21.3.1.1</b> Fast Fourier Transform.</a></li></ul></li><li class="chapter" data-level="21.3.2" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-fourier-transform-over-z_m"><i class="fa fa-check"></i><b>21.3.2</b> Quantum Fourier Transform over \Z_m</a></li></ul></li><li class="chapter" data-level="21.4" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#shors-order-finding-algorithm."><i class="fa fa-check"></i><b>21.4</b> Shor’s Order-Finding Algorithm.</a><ul><li class="chapter" data-level="21.4.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#analysis-the-case-that-rm"><i class="fa fa-check"></i><b>21.4.1</b> Analysis: the case that r|m</a><ul><li class="chapter" data-level="21.4.1.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#the-general-case"><i class="fa fa-check"></i><b>21.4.1.1</b> The general case</a></li></ul></li></ul></li><li class="chapter" data-level="21.5" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#rational-approximation-of-real-numbers"><i class="fa fa-check"></i><b>21.5</b> Rational approximation of real numbers</a><ul><li class="chapter" data-level="21.5.1" data-path="lec_20_quantum_part2.html"><a href="lec_20_quantum_part2.html#quantum-cryptography"><i class="fa fa-check"></i><b>21.5.1</b> Quantum cryptography</a></li></ul></li></ul></li><li class="chapter" data-level="22" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html"><i class="fa fa-check"></i><b>22</b> Software Obfuscation</a><ul><li class="chapter" data-level="22.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#witness-encryption"><i class="fa fa-check"></i><b>22.1</b> Witness encryption</a></li><li class="chapter" data-level="22.2" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#deniable-encryption"><i class="fa fa-check"></i><b>22.2</b> Deniable encryption</a></li><li class="chapter" data-level="22.3" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#functional-encryption"><i class="fa fa-check"></i><b>22.3</b> Functional encryption</a></li><li class="chapter" data-level="22.4" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#the-software-patch-problem"><i class="fa fa-check"></i><b>22.4</b> The software patch problem</a></li><li class="chapter" data-level="22.5" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#software-obfuscation-1"><i class="fa fa-check"></i><b>22.5</b> Software obfuscation</a></li><li class="chapter" data-level="22.6" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#applications-of-obfuscation"><i class="fa fa-check"></i><b>22.6</b> Applications of obfuscation</a></li><li class="chapter" data-level="22.7" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#impossibility-of-obfuscation"><i class="fa fa-check"></i><b>22.7</b> Impossibility of obfuscation</a><ul><li class="chapter" data-level="22.7.1" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#proof-of-impossibility-of-vbb-obfuscation"><i class="fa fa-check"></i><b>22.7.1</b> Proof of impossibility of VBB obfuscation</a></li></ul></li><li class="chapter" data-level="22.8" data-path="lec_21_obfuscation.html"><a href="lec_21_obfuscation.html#indistinguishability-obfuscation"><i class="fa fa-check"></i><b>22.8</b> Indistinguishability obfuscation</a></li></ul></li><li class="chapter" data-level="23" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html"><i class="fa fa-check"></i><b>23</b> More obfuscation, exotic encryptions</a><ul><li class="chapter" data-level="23.1" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#slower-weaker-less-securer"><i class="fa fa-check"></i><b>23.1</b> Slower, weaker, less securer</a></li><li class="chapter" data-level="23.2" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#how-to-get-ibe-from-pairing-based-assumptions."><i class="fa fa-check"></i><b>23.2</b> How to get IBE from pairing based assumptions.</a></li><li class="chapter" data-level="23.3" data-path="lec_22_obfuscation_part2.html"><a href="lec_22_obfuscation_part2.html#beyond-pairing-based-cryptography"><i class="fa fa-check"></i><b>23.3</b> Beyond pairing based cryptography</a></li></ul></li><li class="chapter" data-level="24" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html"><i class="fa fa-check"></i><b>24</b> Anonymous communication</a><ul><li class="chapter" data-level="24.1" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#steganography"><i class="fa fa-check"></i><b>24.1</b> Steganography</a></li><li class="chapter" data-level="24.2" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#anonymous-routing"><i class="fa fa-check"></i><b>24.2</b> Anonymous routing</a></li><li class="chapter" data-level="24.3" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#tor"><i class="fa fa-check"></i><b>24.3</b> Tor</a></li><li class="chapter" data-level="24.4" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#telex"><i class="fa fa-check"></i><b>24.4</b> Telex</a></li><li class="chapter" data-level="24.5" data-path="lec_23_anonymous.html"><a href="lec_23_anonymous.html#riposte"><i class="fa fa-check"></i><b>24.5</b> Riposte</a></li></ul></li><li class="chapter" data-level="25" data-path="lec_24_policy.html"><a href="lec_24_policy.html"><i class="fa fa-check"></i><b>25</b> Ethical, moral, and policy dimensions to cryptography</a><ul><li class="chapter" data-level="25.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#reading-prior-to-lecture"><i class="fa fa-check"></i><b>25.1</b> Reading prior to lecture:</a></li><li class="chapter" data-level="25.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#case-studies."><i class="fa fa-check"></i><b>25.2</b> Case studies.</a><ul><li class="chapter" data-level="25.2.1" data-path="lec_24_policy.html"><a href="lec_24_policy.html#the-snowden-revelations"><i class="fa fa-check"></i><b>25.2.1</b> The Snowden revelations</a></li><li class="chapter" data-level="25.2.2" data-path="lec_24_policy.html"><a href="lec_24_policy.html#fbi-vs-apple-case"><i class="fa fa-check"></i><b>25.2.2</b> FBI vs Apple case</a></li><li class="chapter" data-level="25.2.3" data-path="lec_24_policy.html"><a href="lec_24_policy.html#juniper-backdoor-case-and-the-opm-break-in"><i class="fa fa-check"></i><b>25.2.3</b> Juniper backdoor case and the OPM break-in</a></li></ul></li></ul></li><li class="chapter" data-level="26" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html"><i class="fa fa-check"></i><b>26</b> Course recap</a><ul><li class="chapter" data-level="26.1" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#some-things-we-did-not-cover"><i class="fa fa-check"></i><b>26.1</b> Some things we did not cover</a></li><li class="chapter" data-level="26.2" data-path="lec_25_course_recap.html"><a href="lec_25_course_recap.html#what-i-hope-you-learned"><i class="fa fa-check"></i><b>26.2</b> What I hope you learned</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/crypto/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/crypto/lec_01_introduction.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="introduction" data-number="1">Introduction</h1>
<p><strong>Additional reading:</strong> Sections 2.1 (Introduction) and 2.2 (Shannon ciphers and perfect security) in the Boneh Shoup book. Chapters 1 and 2 of Katz-Lindell book.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
<p>Ever since people started to communicate, there were some messages that they wanted kept secret. Thus cryptography has an old though arguably <em>undistinguished</em> history. For a long time cryptography shared similar features with Alchemy as a domain in which many otherwise smart people would be drawn into making fatal mistakes.</p>
<p>The definitive text on the history of cryptography is David Kahn’s “The Codebreakers”, whose title already hints at the ultimate fate of most cryptosystems.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> (See also “The Code Book” by Simon Singh.) We now recount just a few stories to get a feel for this field. But, before we do so, we should introduce the cast of characters. The basic setting of “encryption” or “secret writing” is the following: one person, whom we will call <strong>Alice</strong>, wishes to send another person, whom we will call <strong>Bob</strong>, a <strong>secret</strong> message. Since Alice and Bob are not in the same room (perhaps because Alice is imprisoned in a castle by her cousin the queen of England), they cannot communicate directly and need to send their message in writing. Alas, there is a third person, whom we will call <strong>Eve</strong>, that can see their message. Therefore Alice needs to find a way to <em>encode</em> or <em>encrypt</em> the message so that only Bob (and not Eve) will be able to understand it.</p>
<p>In 1587, Mary the queen of Scots, and the heir to the throne of England, wanted to arrange the assassination of her cousin, queen Elisabeth I of England, so that she could ascend to the throne and finally escape the house arrest under which she has been for the last 18 years. As part of this complicated plot, she sent a coded letter to Sir Anthony Babington. It is what’s known as a <em>substitution cipher</em> where each letter is transformed into a different symbol, and so the resulting letter looks something like the following (see <a href='#figmaryletter'>Figure 1</a>):</p>
<figure>
<img src="../figure/encrypted_letter.jpg" alt="1: Snippet from encrypted communication between queen Mary and Sir Babington" id="figmaryletter" /><figcaption>1: Snippet from encrypted communication between queen Mary and Sir Babington</figcaption>
</figure>
<p>At a first look, such a letter might seem rather inscrutable- a meaningless sequence of strange symbols. However, after some thought, one might recognize that these symbols <em>repeat</em> several times and moreover that different symbols repeat with different frequencies. Now it doesn’t take a large leap of faith to assume that perhaps each symbol corresponds to a different letter and the more frequent symbols correspond to letters that occur in the alphabet with higher frequency. From this observation, there is a short gap to completely breaking the cipher, which was in fact done by queen Elisabeth’s spies who used the decoded letters to learn of all the co-conspirators and to convict queen Mary of treason, a crime for which she was executed.</p>
<p>Trusting in superficial security measures (such as using “inscrutable” symbols) is a trap that users of cryptography have been falling into again and again over the years. As in many things, this is the subject of a great XKCD cartoon (see <a href='#xkcdnavajofig'>Figure 2</a>):</p>
<figure>
<img src="../figure/code_talkers.png" alt="2: On the added security of using uncommon symbols" id="xkcdnavajofig" style="width:80.0%" /><figcaption>2: On the added security of using uncommon symbols</figcaption>
</figure>
<p>The <a href="https://en.wikipedia.org/wiki/Vigen%C3%A8re_cipher">Vigenère cipher</a> is named after Blaise de Vigenère who described it in a book in 1586 (though it was invented earlier by Bellaso). The idea is to use a collection of substitution cyphers - if there are <span><span class="math inline">\(n\)</span></span> different ciphers then the first letter of the plaintext is encoded with the first cipher, the second with the second cipher, the <span><span class="math inline">\(n^{th}\)</span></span> with the <span><span class="math inline">\(n^{th}\)</span></span> cipher, and then the <span><span class="math inline">\(n+1^{st}\)</span></span> letter is again encoded with the first cipher. The key is usually a word or a phrase of <span><span class="math inline">\(n\)</span></span> letters, and the <span><span class="math inline">\(i^{th}\)</span></span> substitution cipher is obtained by shifting each letter <span><span class="math inline">\(k_i\)</span></span> positions in the alphabet. This “flattens” the frequencies and makes it much harder to do frequency analysis, which is why this cipher was considered “unbreakable” for 300+ years and got the nickname “le chiffre indéchiffrable” (“the unbreakable cipher”). Nevertheless, Charles Babbage cracked the Vigenère cipher in 1854 (though he did not publish it). In 1863 Friedrich Kasiski broke the cipher and published the result. The idea is that once you guess the length of the cipher, you can reduce the task to breaking a simple substitution cipher which can be done via frequency analysis (can you see why?). Confederate generals used Vigenère regularly during the civil war, and their messages were routinely cryptanalzed by Union officers.</p>
<figure>
<img src="../figure/confederate_cipher_disk.jpg" alt="21.1: Confederate Cipher Disk for implementing the Vigenère cipher" id="tmplabelfig" /><figcaption>21.1: Confederate Cipher Disk for implementing the Vigenère cipher</figcaption>
</figure>
<figure>
<img src="../figure/confederate_message.jpg" alt="21.1: Confederate encryption of the message “Gen’l Pemberton: You can expect no help from this side of the river. Let Gen’l Johnston know, if possible, when you can attack the same point on the enemy’s lines. Inform me also and I will endeavor to make a diversion. I have sent some caps. I subjoin a despatch from General Johnston.”" id="tmplabelfig" /><figcaption>21.1: Confederate encryption of the message “Gen’l Pemberton: You can expect no help from this side of the river. Let Gen’l Johnston know, if possible, when you can attack the same point on the enemy’s lines. Inform me also and I will endeavor to make a diversion. I have sent some caps. I subjoin a despatch from General Johnston.”</figcaption>
</figure>
<p>The story of the <em>Enigma</em> cipher had been told many times (see for example Kahn’s book as well as Andrew Hodges’ biography of Alan Turing). This was a mechanical cipher (looking like a typewriter) where each letter typed would get mapped into a different letter depending on the (rather complicated) key and current state of the machine which had several rotors that rotated at different paces. An identically wired machine at the other end could be used to decrypt. Just as many ciphers in history, this has also been believed by the Germans to be “impossible to break” and even quite late in the war they refused to believe it was broken despite mounting evidence to that effect. (In fact, some German generals refused to believe it was broken even <em>after</em> the war.) Breaking Enigma was an heroic effort which was initiated by the Poles and then completed by the British at Bletchley Park; as part of this effort they built arguably the world’s first large scale mechanical computation devices (though they looked more similar to washing machines than to iPhones). They were also helped along the way by some quirks and errors of the german operators. For example, the fact that their messages ended with “Heil Hitler” turned out to be quite useful. Here is one entertaining anecdote: the Enigma machine would never map a letter to itself. In March 1941, Mavis Batey, a cryptanalyst at Bletchley Park received a very long message that she tried to decrypt. She then noticed a curious property— the message did <em>not</em> contain the letter “L”.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> She realized that for such a long message not contain “L” could not happen by chance, and hence surmised that the original message probably composed <em>only</em> of L’s. That is, it must have been the case that the operator, perhaps to test the machine, have simply sent out a message where he repeatedly pressed the letter “L”. This observation helped her decode the next message, which helped inform of a planned Italian attack and secure a resounding British victory in what became known as “the Battle of Cape Matapan”. Mavis also helped break another Enigma machine which helped in the effort of feeding the Germans with the false information that the main allied invasion would take place in Pas de Calais rather than on Normandy. See <a href="http://www.cix.co.uk/~klockstone/hinsley.htm">this inteview with Sir Harry Hinsley</a> for more on the effect of breaking the Enigma on the war. General Eisenhower said that the intelligence from Bletchley park was of “priceless value” and made a “very decisive contribution to the Allied war effort”.</p>
<h2 id="defining-encryptions" data-number="1.1">Defining encryptions</h2>
<p>Many of the troubles that cryptosystem designers faced over history (and still face!) can be attributed to not properly defining or understanding what are the goals they want to achieve in the first place. We now turn to actually defining what is an encryption scheme. Clearly we can encode every message as a string of bits, i.e., an element of <span><span class="math inline">\(\{0,1\}^\ell\)</span></span> for some <span><span class="math inline">\(\ell\)</span></span>. Similarly, we can encode the <em>key</em> as a string of bits as well, i.e., an element of <span><span class="math inline">\(\{0,1\}^n\)</span></span> for some <span><span class="math inline">\(n\)</span></span>. Thus, we can think of an encryption scheme as composed of two functions. The <em>encryption function</em> <span><span class="math inline">\(E\)</span></span> maps a secret key <span><span class="math inline">\(k \in \{0,1\}^n\)</span></span> and a message (known also as <em>plaintext</em>) <span><span class="math inline">\(m\in \{0,1\}^\ell\)</span></span> into a <em>ciphertext</em> <span><span class="math inline">\(c \in \{0,1\}^L\)</span></span> for some <span><span class="math inline">\(L\)</span></span>. We write this as <span><span class="math inline">\(c = E_k(m)\)</span></span>. The <em>decryption function</em> <span><span class="math inline">\(D\)</span></span> does the reverse operation, mapping the secret key <span><span class="math inline">\(k\)</span></span> and the cyphertext <span><span class="math inline">\(c\)</span></span> back into the plaintext message <span><span class="math inline">\(m\)</span></span>, which we write as <span><span class="math inline">\(m = D_k(c)\)</span></span>. The basic equation is that if we use the same key for encryption and decryption, then we should get the same message back. That is, for every <span><span class="math inline">\(k \in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(m\in \{0,1\}^\ell\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[ m = D_k(E_k(m)) \;.\]</span></div></span></p>
<p>Formally, we make the following definition:</p>
<div id="encryptiondef" class="definition" title="Valid encryption scheme" data-number="1.1" name="Definition 0.1 (Valid encryption scheme) ">
<p>A pair of functions <span><span class="math inline">\((E,D)\)</span></span> mapping strings to strings is a <em>valid private key encryption scheme</em> (or <em>encryption scheme</em> for short) if there are some numbers <span><span class="math inline">\(n,\ell,L\)</span></span> such that <span><span class="math inline">\(E:\{0,1\}^n \times \{0,1\}^\ell \rightarrow \{0,1\}^L\)</span></span> and <span><span class="math inline">\(D:\{0,1\}^n \times \{0,1\}^L \rightarrow \{0,1\}^\ell\)</span></span> and for every for every <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(x \in \{0,1\}^{\ell}\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[
D(k,E(k,x))=x \;. \;\;(2)
\]</span><a id='eqvalidenc'></a></div></span> We will typically write the first input (i.e., the key) to the encryption and decryption functions as a subscribt, and so write <a href='#eqvalidenc'>Equation 2</a> as <span><span class="math inline">\(D_k(E_k(x))=x\)</span></span>.</p>
</div>
<blockquote>
<p><em>A note on notation:</em> We will always use <span><span class="math inline">\(i,j,\ell,n\)</span></span> to denote natural numbers. <span><span class="math inline">\(n\)</span></span> will often denote the length of our secret key, and <span><span class="math inline">\(\ell\)</span></span> the length of the message, sometimes also known as “block length” since longer messages are simply chopped into “blocks” of length <span><span class="math inline">\(\ell\)</span></span> and also appropriately padded. We will use <span><span class="math inline">\(k\)</span></span> to denote the secret key, <span><span class="math inline">\(m\)</span></span> to denote the secret plaintext message, and <span><span class="math inline">\(c\)</span></span> to denote the encrypted ciphertext. Note that <span><span class="math inline">\(c,m\)</span></span> and <span><span class="math inline">\(k\)</span></span> are bit strings of lengths <span><span class="math inline">\(o,\ell\)</span></span> and <span><span class="math inline">\(n\)</span></span> respectively. The length of the secret key is often known as the “security parameter” and in other texts it is often denoted by <span><span class="math inline">\(k\)</span></span> or <span><span class="math inline">\(\kappa\)</span></span>. We use <span><span class="math inline">\(n\)</span></span> to correspond with the standard algorithmic notation for input length (as in <span><span class="math inline">\(O(n)\)</span></span> time algorithms).</p>
</blockquote>
<p><a href='#encryptiondef'>Definition 0.1</a> says nothing about security and does not rule out trivial “encryption” schemes such as the scheme <span><span class="math inline">\(E_k(m) = m\)</span></span> that simply outputs the plaintext as is. Defining security is tricky, and we’ll take it one step at a time, but lets start by pondering what is secret and what is not. A priori we are thinking of an attacker Eve that simply sees the ciphertext <span><span class="math inline">\(y=E_k(x)\)</span></span> and does not know anything on how it was generated. So, it does not know the details of <span><span class="math inline">\(E\)</span></span> and <span><span class="math inline">\(D\)</span></span>, and certainly does not know the secret key <span><span class="math inline">\(k\)</span></span>. However, many of the troubles past cryptosystems went through was caused by them relying on “security through obscurity”— trusting that the fact their <em>methods</em> are not known to their enemy will protect them from being broken. This is a faulty assumption - if you reuse a method again and again (even with a different key each time) then eventually your adversaries will figure out what you are doing. And if Alice and Bob meet frequently in a secure location to decide on a new method, they might as well take the opportunity to exchange their secrets.. These considerations led Kerchoffs to state the following principle:</p>
<blockquote>
<p><em>A cryptosystem should be secure even if everything about the system, except the key, is public knowledge.</em> (Auguste Kerckhoffs, 1883)</p>
</blockquote>
<p>(The actual quote is “Il faut qu’il n’exige pas le secret, et qu’il puisse sans inconvénient tomber entre les mains de l’ennemi” loosely translated as “The system must not require secrecy and can be stolen by the enemy without causing trouble”. According to Steve Bellovin the NSA version is “assume that the first copy of any device we make is shipped to the Kremlin”.)</p>
<p>Why is it OK to assume the key is secret and not the algorithm? Because we can always choose a fresh key. But of course if we choose our key to be “1234” or “passw0rd!” then that is not exactly secure. In fact, if you use any deterministic algorithm to choose the key then eventually your adversary will figure out. Therefore for security we must choose the key at <em>random</em>. Thus following can be thought of as a restatement of Kerchkoffs’s principle:</p>
<blockquote>
<p><em>There is no secrecy without randomness</em></p>
</blockquote>
<p>This is such a crucial point that is worth repeating:</p>
<blockquote>
<p><em>There is no secrecy without randomness</em></p>
</blockquote>
<p>At the heart of every cryptographic scheme there is a secret key, and the secret key is always chosen at random. A corollary of that is that to understand cryptography, you need to know some probability theory. Fortunately, we don’t need much of probability- only probability over finite spaces, and basic notions such as expectation, variance, concentration and the union bound suffice for most of we need. In fact, understanding the following two statements will already get you much of what you need for cryptography:</p>
<ul>
<li><p>For every fixed string <span><span class="math inline">\(x\in\{0,1\}^n\)</span></span>, if you toss a coin <span><span class="math inline">\(n\)</span></span> times, the probability that the heads/tails pattern will be exactly <span><span class="math inline">\(x\)</span></span> is <span><span class="math inline">\(2^{-n}\)</span></span>.</p></li>
<li><p>A probability of <span><span class="math inline">\(2^{-128}\)</span></span> is really really small.</p></li>
</ul>
<h3 id="generating-randomness-in-actual-cryptographic-systems" data-number="1.1.1">Generating randomness in actual cryptographic systems</h3>
<p>How do we actually get random bits in actual systems? The main idea is to use a two stage approach. First we need to get some data that is <em>unpredictable</em> from the point of view of an attacker on our system. Some sources for this could be measuring latency on the network or hard drives (getting harder with solid state disk), user keyboard and mouse movement patterns (problematic when you need fresh randomness at boot time ), clock drift and more, there are some other sources including audio, video, and network. All of these can be problematic, especially for servers or virtual machines, and so hardware based random number generators based on phenomena such as thermal noise or nuclear decay are becoming more popular. Once we have some data <span><span class="math inline">\(X\)</span></span> that is unpredictable, we need to estimate the <em>entropy</em> in it. You can roughly imagine that <span><span class="math inline">\(X\)</span></span> has <span><span class="math inline">\(k\)</span></span> bits of entropy if the probability that an attacker can guess <span><span class="math inline">\(X\)</span></span> is at most <span><span class="math inline">\(2^{-k}\)</span></span>. People then use a <em>hash function</em> (an object we’ll talk about more later) to map <span><span class="math inline">\(X\)</span></span> into a string of length <span><span class="math inline">\(k\)</span></span> which is then hopefully distributed (close to) uniformly at random. All of this process, and especially understanding the amount of information an attacker may have on the entropy sources, is a bit of a dark art and indeed a number of attacks on cryptographic systems were actually enabled by weak generation of randomness. Here are a few examples.</p>
<p>One of the first attacks was on the SSL implementation of Netscape (<em>the</em> browser at the time). Netscape use the following “unpredicatable” information— the time of day and a process ID both of which turned out to be quite predictable (who knew attackers have clocks too?). Netscape tried to protect its security through “security through obscurity” by not releasing the source code for their pseudorandom generator, but it was reverse engineered by <a href="https://www.cs.berkeley.edu/~daw/papers/ddj-netscape.html">Ian Goldberg and David Wagner</a> (Ph.D students at the time) who demonstrated this attack.</p>
<p>In 2006 a programmer removed a line of code from the procedure to generate entropy in OpenSSL package distributed by Debian since it caused a warning in some automatic verification code. As a result for two years (until this was discovered) all the randomness generated by this procedure used only the process ID as an “unpredictable” source. This means that all communication done by users in that period is fairly easily breakable (and in particular, if some entities recorded that communication they could break it also retroactively). This caused a huge headache and a worldwide regeneration of keys, though it is believed that many of the weak keys are still used. See <a href="http://www.xkcd.com/424/">XKCD’s take</a> on that incident.</p>
<figure>
<img src="../figure/random_number.png" alt="21.1: XKCD Cartoon: Random number generator" id="tmplabelfig" /><figcaption>21.1: XKCD Cartoon: Random number generator</figcaption>
</figure>
<p>In 2012 two separate teams of researchers scanned a large number of RSA keys on the web and found out that about 4 percent of them are easy to break. The main issue were devices such as routers, internet-connected printers and such. These devices sometimes run variants of Linux- a desktop operating system- but without a hard drive, mouse or keyboard, they don’t have access to many of the entropy sources that desktop have. Coupled with some good old fashioned ignorance of cryptography and software bugs, this led to many keys that are downright trivial to break, see <a href="https://freedom-to-tinker.com/blog/nadiah/new-research-theres-no-need-panic-over-factorable-keys-just-mind-your-ps-and-qs/">this blog post</a> and <a href="https://factorable.net/">this web page</a> for more details.</p>
<p>After the entropy is collected and then “purified” or “extracted” to a uniformly random string that is, say, a few hundred bits long, we often need to “expand” it into a longer string that is also uniform (or at least looks like that for all practical purposes). We will discuss how to go about that in the next lecture. This step has its weaknesses too and in particular the Snowden documents, combined with observations of Shumow and Ferguson, strongly suggest that the NSA has deliberately inserted a <em>trapdoor</em> in one of the pseudorandom generators published by the National Institute of Standards and Technologies (NIST). Fortunately, this generator wasn’t widely adapted but apparently the NSA did pay 10 million dollars to RSA security so the latter would make this generator their default option in their products.</p>
<h2 id="defining-the-secrecy-requirement." data-number="1.2">Defining the secrecy requirement.</h2>
<p>Defining the secrecy requirement for an encryption is not simple. Over the course of history, many smart people got it wrong and convinced themselves that ciphers were impossible to break. The first person to truly ask the question in a rigorous way was Claude Shannon in 1945 (though a partial version of his manuscript was only declassified in 1949). Simply by asking this question, he made an enormous contribution to the science of cryptography and practical security. We now will try to examine how one might answer it.</p>
<p>Let me warn you ahead of time that we are going to insist on a <em>mathematically precise definition</em> of security. That means that the definition must capture security in all cases, and the existence of a single counterexample, no matter how “silly”, would make us rule out a candidate definition. This exercise of coming up with “silly” counterexamples might seem, well, silly. But in fact it is this method that has led Shannon to formulate his theory of secrecy, which (after much followup work) eventually revolutionized cryptography, and brought this science to a new age where Edgar Allan Poe’s maxim no longer holds, and we are able to design ciphers which human (or even nonhuman) ingenuity cannot break.</p>
<p>The most natural way to attack an encryption is for Eve to guess all possible keys. In many encryption schemes this number is enormous and this attack is completely infeasible. For example, the theoretical number of possibilities in the Enigma cipher was about <span><span class="math inline">\(10^{113}\)</span></span> which roughly means that even if we built a filled the milky way galaxy with computers operating at light speed, the sun would still die out before it finished examining all the possibilities.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> One can understand why the Germans thought it was impossible to break. (Note that despite the number of possibilities being so enormous, such a key can still be easily specified and shared between Alice and Bob by writing down <span><span class="math inline">\(113\)</span></span> digits on a piece of paper.) Ray Miller of the NSA had calculated that, in the way the Germans used the machine, the number of possibilities was “only” <span><span class="math inline">\(10^{23}\)</span></span>, but this is still extremely difficult to pull off even today, and many orders of magnitudes above the computational powers during the WW-II era. Thus clearly, it is sometimes possible to break an encryption without trying all possibilities. A corollary is that having a huge number of key combinations does not guarantee security, as an attacker might find a shortcut (as the allies did for Enigma) and recover the key without trying all options.</p>
<p>Since it is possible to recover the key with some tiny probability (e.g. by guessing it at random), perhaps one way to define security of an encryption scheme is that an attacker can never recover the key with probability significantly higher than that. Here is an attempt at such a definition:</p>
<div id="securefirstattemptdef" class="definition" title="Security of encryption: first attempt" data-number="1.2" name="Definition 0.2 (Security of encryption: first attempt) ">
<p>An encyption scheme <span><span class="math inline">\((E,D)\)</span></span> is <em><span><span class="math inline">\(n\)</span></span>-secure</em> if no matter what method Eve employs, the probability that she can recover the true key <span><span class="math inline">\(k\)</span></span> from the ciphertext <span><span class="math inline">\(c\)</span></span> is at most <span><span class="math inline">\(2^{-n}\)</span></span>.</p>
</div>
<div id="section" class="pause" data-number="1.2" name="Pause">
<p>When you see a mathematical definition that attempts to model some real-life phenomenon such as security, you should pause and ask yourself:</p>
<ol type="1">
<li>Do I understand mathematically what is the definition stating?<br />
</li>
<li>Is it a reasonable way to capture the real life phenomenon we are discussing?</li>
</ol>
<p>One way to answer question 2 is to try to think of both examples of objects that satisfy the definition and examples of objects that violate it, and see if this conforms to your intuition about whether these objects display the phenomenon we are trying to capture. Try to do this for <a href='#securefirstattemptdef'>Definition 0.2</a></p>
</div>
<p>You might wonder if <a href='#securefirstattemptdef'>Definition 0.2</a> is not <em>too strong</em>. After all how are we going ever to prove that Eve cannot recover the secret key no matter what she does? Edgar Allan Poe would say that there can always be a method that we overlooked. However, in fact this definition is too <em>weak</em>! Consider the following encryption: the secret key <span><span class="math inline">\(k\)</span></span> is chosen at random in <span><span class="math inline">\(\{0,1\}^n\)</span></span> but our encryption scheme simply ignores it and lets <span><span class="math inline">\(E_k(x)=x\)</span></span> and <span><span class="math inline">\(D_k(y)=y\)</span></span>. This is a valid encryption, but of course completely insecure as we are simply outputting the plaintext in the clear. Yet, no matter what Eve does, if she only sees <span><span class="math inline">\(c\)</span></span> and not <span><span class="math inline">\(k\)</span></span>, there is no way she can guess the true value of <span><span class="math inline">\(k\)</span></span> with probability better than <span><span class="math inline">\(2^{-n}\)</span></span>, since it was chosen completely at random and she gets no information about it. Formally, one can prove the following result:</p>
<div id="trivialsec" class="lemma" data-number="1.2" name="Lemma 0.3">
<p>Let <span><span class="math inline">\((E,D)\)</span></span> be the encryption scheme above. For every function <span><span class="math inline">\(Eve:\{0,1\}^\ell\rightarrow \{0,1\}^n\)</span></span> and for every <span><span class="math inline">\(x\in \{0,1\}^\ell\)</span></span>, the probability that <span><span class="math inline">\(Eve(E_k(x))=k\)</span></span> is exactly <span><span class="math inline">\(2^{-n}\)</span></span>.</p>
</div>
<div id="section-1" class="proof" data-ref="trivialsec" data-number="1.2" name="Proof">
<p>This follows because <span><span class="math inline">\(E_k(x)=x\)</span></span> and hence <span><span class="math inline">\(Eve(E_k(x))=Eve(x)\)</span></span> which is some fixed value <span><span class="math inline">\(k&#39;\in\{0,1\}^n\)</span></span> that is independent of <span><span class="math inline">\(k\)</span></span>. Hence the probability that <span><span class="math inline">\(k=k&#39;\)</span></span> is <span><span class="math inline">\(2^{-n}\)</span></span>. QED</p>
</div>
<p>The math behind the above argument is very simple, yet I urge you to read and re-read the last two paragraphs until you are sure that you completely understand why this encryption is in fact secure according to the above definition. This is a “toy example” of the kind of reasoning that we will be employing constantly throughout this course, and you want to make sure that you follow it.</p>
<p>So, <a href='#trivialsec'>Lemma 0.3</a> is true, but one might question its meaning. Clearly this silly example was not what we meant when stating this definition. However, as mentioned above, we are not willing to ignore even silly examples and must amend the definition to rule them out. One obvious objection is that we don’t care about hiding the key- it is the <em>message</em> that we are trying to keep secret. This suggests the next attempt:</p>
<div id="securesecondattemptdef" class="definition" title="Security of encryption: second attempt" data-number="1.2" name="Definition 0.4 (Security of encryption: second attempt) ">
<p>An encryption scheme <span><span class="math inline">\((E,D)\)</span></span> is <em><span><span class="math inline">\(n\)</span></span>-secure</em> if for every message <span><span class="math inline">\(x\)</span></span> no matter what method Eve employs, the probability that she can recover <span><span class="math inline">\(x\)</span></span> from the ciphertext <span><span class="math inline">\(y=E_k(x)\)</span></span> is at most <span><span class="math inline">\(2^{-n}\)</span></span>.</p>
</div>
<p>Now this seems like it captures our intended meaning. But remember that we are being anal, and truly insist that the definition holds as stated, namely that for every plaintext message <span><span class="math inline">\(x\)</span></span> and every function <span><span class="math inline">\(Eve:\{0,1\}^L\rightarrow\{0,1\}^\ell\)</span></span>, the probability over the choice of <span><span class="math inline">\(k\)</span></span> that <span><span class="math inline">\(Eve(E_k(x))=x\)</span></span> is at most <span><span class="math inline">\(2^{-n}\)</span></span>. But now we see that this is clearly impossible. After all, this is supposed to work for <em>every</em> message <span><span class="math inline">\(x\)</span></span> and <em>every</em> function <span><span class="math inline">\(Eve\)</span></span>, but clearly if <span><span class="math inline">\(x\)</span></span> is the all-zeroes message <span><span class="math inline">\(0^\ell\)</span></span> and <span><span class="math inline">\(Eve\)</span></span> is the function that ignores its input and simply outputs <span><span class="math inline">\(0^\ell\)</span></span>, then it will hold that <span><span class="math inline">\(Eve(E_k(x))=x\)</span></span> with probability one.</p>
<p>So, if before the definition was too weak, the new definition is too strong and is impossible to achieve. The problem is that of course we could guess a fixed message with probability one, so perhaps we could try to consider a definition with a <em>random</em> message. That is:</p>
<div id="securethirdattemptdef" class="definition" title="Security of encryption: third attempt" data-number="1.2" name="Definition 0.5 (Security of encryption: third attempt) ">
<p>An encyption scheme <span><span class="math inline">\((E,D)\)</span></span> is <em><span><span class="math inline">\(n\)</span></span>-secure</em> if no matter what method Eve employs, if <span><span class="math inline">\(x\)</span></span> is chosen at random from <span><span class="math inline">\(\{0,1\}^\ell\)</span></span>, the probability that she can recover <span><span class="math inline">\(x\)</span></span> from the ciphertext <span><span class="math inline">\(c=E_k(x)\)</span></span> is at most <span><span class="math inline">\(2^{-n}\)</span></span>.</p>
</div>
<p>This weakened definition can in fact be achieved, but we have again weakened it too much. Consider an encryption that hides the last <span><span class="math inline">\(\ell/2\)</span></span> bits of the message, but completely reveals the first <span><span class="math inline">\(\ell/2\)</span></span> bits. The probability of guessing a random message is <span><span class="math inline">\(2^{-\ell/2}\)</span></span>, and so such a scheme would be “<span><span class="math inline">\(\ell/2\)</span></span> secure” per <a href='#securethirdattemptdef'>Definition 0.5</a> but this is still a scheme that you would not want to use. The point is that in practice we don’t encrypt random messages— our messages might be in English, might have common headers, and might have even more structures based on the context. In fact, it may be that the message is either “Yes” or “No” (or perhaps either “Attack today” or “Attack tomorrow”) but we want to make sure Eve doesn’t learn which one it is. So, using an encryption scheme that reveals the first half of the message (or frankly even only the first bit) is unacceptable.</p>
<h2 id="perfect-secrecy" data-number="1.3">Perfect Secrecy</h2>
<p>So far all of our attempts at definitions oscillated between being too strong (and hence impossible) or too weak (and hence not guaranteeing actual security). The key insight of Shannon was that in a secure encryption scheme the ciphtertext should not reveal <em>any additional information</em> about the plaintext. So, if for example it was a priori possible for Eve to guess the plaintext with some probability <span><span class="math inline">\(1/k\)</span></span> (e.g., because there were only <span><span class="math inline">\(k\)</span></span> possibilities for it) then she should not be able to guess it with higher probability after seeing the ciphertext. This can be formalized as follows:</p>
<div id="perfectsecrecydef" class="definition" title="Perfect secrecy" data-number="1.3" name="Definition 0.6 (Perfect secrecy) ">
<p>An encryption scheme <span><span class="math inline">\((E,D)\)</span></span> is <em>perfectly secret</em> if there for every set <span><span class="math inline">\(M\subseteq\{0,1\}^\ell\)</span></span> of plaintexts, and for every strategy used by Eve, if we choose at random <span><span class="math inline">\(x\in M\)</span></span> and a random key <span><span class="math inline">\(k\in\{0,1\}^n\)</span></span>, then the probability that Eve guesses <span><span class="math inline">\(x\)</span></span> after seeing <span><span class="math inline">\(E_k(x)\)</span></span> is at most <span><span class="math inline">\(1/|M|\)</span></span>.</p>
</div>
<p>In particular, if we encrypt either “Yes” or “No” with probability <span><span class="math inline">\(1/2\)</span></span>, then Eve won’t be able to guess which one it is with probability better than half. In fact, that turns out to be the heart of the matter:</p>
<div id="twotomanythm" class="theorem" title="Two to many theorem" data-number="1.3" name="Theorem 0.7 (Two to many theorem) ">
<p>An encryption scheme <span><span class="math inline">\((E,D)\)</span></span> is perfectly secret if and only if for every two distinct plaintexts <span><span class="math inline">\(\{x_0,x_1\} \subseteq \{0,1\}^\ell\)</span></span> and every strategy used by Eve, if we choose at random <span><span class="math inline">\(b\in\{0,1\}\)</span></span> and a random key <span><span class="math inline">\(k\in\{0,1\}^n\)</span></span>, then the probability that Eve guesses <span><span class="math inline">\(x_b\)</span></span> after seeing <span><span class="math inline">\(E_k(x_b)\)</span></span> is at most <span><span class="math inline">\(1/2\)</span></span>.</p>
</div>
<div id="section-2" class="proof" data-ref="twotomanythm" data-number="1.3" name="Proof">
<p>The “only if” direction is obvious— this condition is a special case of the perfect secrecy condition for a set <span><span class="math inline">\(M\)</span></span> of size <span><span class="math inline">\(2\)</span></span>.</p>
<p>The “if” direction is trickier. We need to show that if there is some set <span><span class="math inline">\(M\)</span></span> (of size possibly much larger than <span><span class="math inline">\(2\)</span></span>) and some strategy for Eve to guess (based on the ciphertext) a plaintext chosen from <span><span class="math inline">\(M\)</span></span> with probability larger than <span><span class="math inline">\(1/|M|\)</span></span>, then there is also some set <span><span class="math inline">\(M&#39;\)</span></span> of size two and a strategy <span><span class="math inline">\(Eve&#39;\)</span></span> for Eve to guess a plaintext chosen from <span><span class="math inline">\(M&#39;\)</span></span> with probability larger than <span><span class="math inline">\(1/2\)</span></span>.</p>
<p>Let’s fix the message <span><span class="math inline">\(x_0\)</span></span> to be the all zeroes message and pick <span><span class="math inline">\(x_1\)</span></span> at random in <span><span class="math inline">\(M\)</span></span>. Under our assumption, it holds that for random key <span><span class="math inline">\(k\)</span></span> and message <span><span class="math inline">\(x_1\in M\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[\Pr_{k \leftarrow \{0,1\}^n, x_1 \leftarrow M}[Eve(E_k(x_1))=x_1]  &gt; 1/|M|\;.\]</span></div></span> On the other hand, for every choice of <span><span class="math inline">\(k\)</span></span>, <span><span class="math inline">\(x&#39;= Eve(E_k(x_0))\)</span></span> is a fixed string independent on the choice of <span><span class="math inline">\(x_1\)</span></span>, and so if we pick <span><span class="math inline">\(x_1\)</span></span> at random in <span><span class="math inline">\(M\)</span></span>, then the probability that <span><span class="math inline">\(x_1=x&#39;\)</span></span> is at most <span><span class="math inline">\(1/|M|\)</span></span>, or in other words <span>
<div class='myequationbox'><span class="math display">\[\Pr_{k \leftarrow \{0,1\}^n, x_1 \leftarrow M}[Eve(E_k(x_0))=x_1]  \leq  1/|M|\;.\]</span></div></span></p>
<p>Thus in particular, due to linearity of expectation, there <em>exists</em> some <span><span class="math inline">\(x_1\)</span></span> satisfying <span>
<div class='myequationbox'><span class="math display">\[ \Pr[Eve(E_k(x_1))=x_1]   &gt; \Pr[Eve(E_k(x_0))=x_1] \;.\]</span></div></span> (Can you see why? This is worthwhile stopping and reading again.) But this can be turned into an attacker <span><span class="math inline">\(Eve&#39;\)</span></span> such that for <span><span class="math inline">\(b \leftarrow_R \{0,1\}\)</span></span>. the probability that <span><span class="math inline">\(Eve&#39;(E_k(x_b))=x_b\)</span></span> is larger than <span><span class="math inline">\(1/2\)</span></span>. Indeed, we can define <span><span class="math inline">\(Eve&#39;(y)\)</span></span> to output <span><span class="math inline">\(x_1\)</span></span> if <span><span class="math inline">\(Eve(y)=x_1\)</span></span> and otherwise output a random message in <span><span class="math inline">\(\{ x_0 , x_1 \}\)</span></span>. The probability that <span><span class="math inline">\(Eve&#39;(y)\)</span></span> equals <span><span class="math inline">\(x_1\)</span></span> is higher when <span><span class="math inline">\(y=E_k(x_1)\)</span></span> than when <span><span class="math inline">\(y=E_k(x_0)\)</span></span>, and since <span><span class="math inline">\(Eve&#39;\)</span></span> outputs either <span><span class="math inline">\(x_0\)</span></span> or <span><span class="math inline">\(x_1\)</span></span>, this means that the probability that <span><span class="math inline">\(Eve&#39;(E_k(x_b))=x_b\)</span></span> is larger than <span><span class="math inline">\(1/2\)</span></span>. (Can you see why?)</p>
</div>
<div id="section-3" class="pause" data-number="1.3" name="Pause">
<p>The proof of <a href='#twotomanythm'>Theorem 0.7</a> is not trivial, and is worth reading again and making sure you understand it. An excellent exercise, which I urge you to pause and do now is to prove the following: <span><span class="math inline">\((E,D)\)</span></span> is perfectly secret if for every plaintexts <span><span class="math inline">\(x,x&#39; \in \{0,1\}^\ell\)</span></span>, the two random variables <span><span class="math inline">\(\{ E_k(x) \}\)</span></span> and <span><span class="math inline">\(\{ E_{k&#39;}(x&#39;) \}\)</span></span> (for randomly chosen keys <span><span class="math inline">\(k\)</span></span> and <span><span class="math inline">\(k&#39;\)</span></span>) have precisely the same distribution.</p>
</div>
<p>So, perfect secrecy is a natural condition, and does not seem to be too weak for applications, but can it actually be achieved? After all, the condition that two different plaintexts are mapped to the same distribution seems somewhat at odds with the condition that Bob would succeed in decrypting the ciphertexts and find out if the plaintext was in fact <span><span class="math inline">\(x\)</span></span> or <span><span class="math inline">\(x&#39;\)</span></span>. It turns out the answer is yes! For example, <a href='#onetimepadtwofig'>Figure 6</a> details a perfectly secret encryption for two bits.</p>
<figure>
<img src="../figure/onetimepadtwobits.png" alt="6: A perfectly secret encryption scheme for two-bit keys and messages. The blue vertices represent plaintexts and the red vertices represent ciphertexts, each edge mapping a plaintext x to a ciphertext y=E_k(x) is labeled with the corresponding key k. Since there are four possible keys, the degree of the graph is four and it is in fact a complete bipartite graph. The encryption scheme is valid in the sense that for every k\in \{0,1\}^2, the map x \mapsto E_k(x) is one-to-one, which in other words means that the set of edges labeled with k is a matching." id="onetimepadtwofig" class="margin" /><figcaption>6: A perfectly secret encryption scheme for two-bit keys and messages. The blue vertices represent plaintexts and the red vertices represent ciphertexts, each edge mapping a plaintext <span><span class="math inline">\(x\)</span></span> to a ciphertext <span><span class="math inline">\(y=E_k(x)\)</span></span> is labeled with the corresponding key <span><span class="math inline">\(k\)</span></span>. Since there are four possible keys, the degree of the graph is four and it is in fact a complete bipartite graph. The encryption scheme is valid in the sense that for every <span><span class="math inline">\(k\in \{0,1\}^2\)</span></span>, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> is one-to-one, which in other words means that the set of edges labeled with <span><span class="math inline">\(k\)</span></span> is a <em>matching</em>.</figcaption>
</figure>
<figure>
<img src="../figure/perfectsecrecy.png" alt="7: For any key length n, we can visualize an encryption scheme (E,D) as a graph with a vertex for every one of the 2^{L(n)} possible plaintexts and for every one of the ciphertexts in \{0,1\}^* of the form E_k(x) for k\in \{0,1\}^n and x\in \{0,1\}^{L(n)}. For every plaintext x and key k, we add an edge labeled k between x and E_k(x). By the validity condition, if we pick any fixed key k, the map x \mapsto E_k(x) must be one-to-one. The condition of perfect secrecy simply corresponds to requiring that every two plaintexts x and x&#39; have exactly the same set of neighbors (or multi-set, if there are parallel edges)." id="perfectsecfig" class="margin" /><figcaption>7: For any key length <span><span class="math inline">\(n\)</span></span>, we can visualize an encryption scheme <span><span class="math inline">\((E,D)\)</span></span> as a graph with a vertex for every one of the <span><span class="math inline">\(2^{L(n)}\)</span></span> possible plaintexts and for every one of the ciphertexts in <span><span class="math inline">\(\{0,1\}^*\)</span></span> of the form <span><span class="math inline">\(E_k(x)\)</span></span> for <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(x\in \{0,1\}^{L(n)}\)</span></span>. For every plaintext <span><span class="math inline">\(x\)</span></span> and key <span><span class="math inline">\(k\)</span></span>, we add an edge labeled <span><span class="math inline">\(k\)</span></span> between <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(E_k(x)\)</span></span>. By the validity condition, if we pick any fixed key <span><span class="math inline">\(k\)</span></span>, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> must be one-to-one. The condition of perfect secrecy simply corresponds to requiring that every two plaintexts <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(x&#39;\)</span></span> have exactly the same set of neighbors (or multi-set, if there are parallel edges).</figcaption>
</figure>
<p>In fact, this can be generalized to any number of bits:</p>
<div id="onetimepad" class="theorem" title="One Time Pad (Vernam 1917, Shannon 1949)" data-number="1.3" name="Theorem 0.8 (One Time Pad (Vernam 1917, Shannon 1949)) ">
<p>There is a perfectly secret valid encryption scheme <span><span class="math inline">\((E,D)\)</span></span> with <span><span class="math inline">\(L(n)=n\)</span></span>.</p>
</div>
<div id="section-4" class="proofidea" data-ref="onetimepad" data-number="1.3" name="Proofidea">
<p>Our scheme is the <a href="https://en.wikipedia.org/wiki/One-time_pad">one-time pad</a> also known as the “Vernam Cipher”, see <a href='#onetimepadfig'>Figure 8</a>. The encryption is exceedingly simple: to encrypt a message <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> with a key <span><span class="math inline">\(k \in \{0,1\}^n\)</span></span> we simply output <span><span class="math inline">\(x \oplus k\)</span></span> where <span><span class="math inline">\(\oplus\)</span></span> is the bitwise XOR operation that outputs the string corresponding to XORing each coordinate of <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(k\)</span></span>.</p>
</div>
<div id="section-5" class="proof" data-ref="onetimepad" data-number="1.3" name="Proof">
<p>For two binary strings <span><span class="math inline">\(a\)</span></span> and <span><span class="math inline">\(b\)</span></span> of the same length <span><span class="math inline">\(n\)</span></span>, we define <span><span class="math inline">\(a \oplus b\)</span></span> to be the string <span><span class="math inline">\(c \in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(c_i = a_i + b_i \mod 2\)</span></span> for every <span><span class="math inline">\(i\in [n]\)</span></span>. The encryption scheme <span><span class="math inline">\((E,D)\)</span></span> is defined as follows: <span><span class="math inline">\(E_k(x) = x\oplus k\)</span></span> and <span><span class="math inline">\(D_k(y)= y \oplus k\)</span></span>. By the associative law of addition (which works also modulo two), <span><span class="math inline">\(D_k(E_k(x))=(x\oplus k) \oplus k = x \oplus (k \oplus k) = x \oplus 0^n = x\)</span></span>, using the fact that for every bit <span><span class="math inline">\(\sigma \in \{0,1\}\)</span></span>, <span><span class="math inline">\(\sigma + \sigma \mod 2 = 0\)</span></span> and <span><span class="math inline">\(\sigma + 0 = \sigma \mod 2\)</span></span>. Hence <span><span class="math inline">\((E,D)\)</span></span> form a valid encryption.</p>
<p>To analyze the perfect secrecy property, we claim that for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, the distribution <span><span class="math inline">\(Y_x=E_k(x)\)</span></span> where <span><span class="math inline">\(k \sim \{0,1\}^n\)</span></span> is simply the uniform distribution over <span><span class="math inline">\(\{0,1\}^n\)</span></span>, and hence in particular the distributions <span><span class="math inline">\(Y_{x}\)</span></span> and <span><span class="math inline">\(Y_{x&#39;}\)</span></span> are identical for every <span><span class="math inline">\(x,x&#39; \in \{0,1\}^n\)</span></span>. Indeed, for every particular <span><span class="math inline">\(y\in \{0,1\}^n\)</span></span>, the value <span><span class="math inline">\(y\)</span></span> is output by <span><span class="math inline">\(Y_x\)</span></span> if and only if <span><span class="math inline">\(y = x \oplus k\)</span></span> which holds if and only if <span><span class="math inline">\(k= x \oplus y\)</span></span>. Since <span><span class="math inline">\(k\)</span></span> is chosen uniformly at random in <span><span class="math inline">\(\{0,1\}^n\)</span></span>, the probability that <span><span class="math inline">\(k\)</span></span> happens to equal <span><span class="math inline">\(k \oplus y\)</span></span> is exactly <span><span class="math inline">\(2^{-n}\)</span></span>, which means that every string <span><span class="math inline">\(y\)</span></span> is output by <span><span class="math inline">\(Y_x\)</span></span> with probability <span><span class="math inline">\(2^{-n}\)</span></span>.</p>
</div>
<figure>
<img src="../figure/onetimepad.png" alt="8: In the one time pad encryption scheme we encrypt a plaintext x\in \{0,1\}^n with a key k\in \{0,1\}^n by the ciphertext x \oplus k where \oplus denotes the bitwise XOR operation." id="onetimepadfig" class="margin" /><figcaption>8: In the <em>one time pad</em> encryption scheme we encrypt a plaintext <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> with a key <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> by the ciphertext <span><span class="math inline">\(x \oplus k\)</span></span> where <span><span class="math inline">\(\oplus\)</span></span> denotes the bitwise XOR operation.</figcaption>
</figure>
<div id="section-6" class="pause" data-number="1.3" name="Pause">
<p>The argument above is quite simple but is worth reading again. To understand why the one-time pad is perfectly secret, it is useful to envision it as a bipartite graph as we’ve done in <a href='#onetimepadtwofig'>Figure 6</a>. (In fact the encryption scheme of <a href='#onetimepadtwofig'>Figure 6</a> is precisely the one-time pad for <span><span class="math inline">\(n=2\)</span></span>.) For every <span><span class="math inline">\(n\)</span></span>, the one-time pad encryption scheme corresponds to a bipartite graph with <span><span class="math inline">\(2^n\)</span></span> vertices on the “left side” corresponding to the plaintexts in <span><span class="math inline">\(\{0,1\}^n\)</span></span> and <span><span class="math inline">\(2^n\)</span></span> vertices on the “right side” corresponding to the ciphertexts <span><span class="math inline">\(\{0,1\}^n\)</span></span>. For every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> and <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span>, we connect <span><span class="math inline">\(x\)</span></span> to the vertex <span><span class="math inline">\(y=E_k(x)\)</span></span> with an edge that we label with <span><span class="math inline">\(k\)</span></span>. One can see that this is the complete bipartite graph, where every vertex on the left is connected to <em>all</em> vertices on the right. In particular this means that for every left vertex <span><span class="math inline">\(x\)</span></span>, the distribution on the ciphertexts obtained by taking a random <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> and going to the neighbor of <span><span class="math inline">\(x\)</span></span> on the edge labeled <span><span class="math inline">\(k\)</span></span> is the uniform distribution over <span><span class="math inline">\(\{0,1\}^n\)</span></span>. This ensures the perfect secrecy condition.</p>
</div>
<h2 id="necessity-of-long-keys" data-number="1.4">Necessity of long keys</h2>
<p>So, does <a href='#onetimepad'>Theorem 0.8</a> give the final word on cryptography, and means that we can all communicate with perfect secrecy and live happily ever after? No it doesn’t. While the one-time pad is efficient, and gives perfect secrecy, it has one glaring disadvantage: to communicate <span><span class="math inline">\(n\)</span></span> bits you need to store a key of length <span><span class="math inline">\(n\)</span></span>. In contrast, practically used cryptosystems such as AES-128 have a short key of <span><span class="math inline">\(128\)</span></span> bits (i.e., <span><span class="math inline">\(16\)</span></span> bytes) that can be used to protect terabytes or more of communication! Imagine that we all needed to use the one time pad. If that was the case, then if you had to communicate with <span><span class="math inline">\(m\)</span></span> people, you would have to maintain (securely!) <span><span class="math inline">\(m\)</span></span> huge files that are each as long as the length of the maximum total communication you expect with that person. Imagine that every time you opened an account with Amazon, Google, or any other service, they would need to send you in the mail (ideally with a secure courier) a DVD full of random numbers, and every time you suspected a virus, you’d need to ask all these services for a fresh DVD. This doesn’t sound so appealing.</p>
<p>This is not just a theoretical issue. The Soviets have used the one-time pad for their confidential communication since before the 1940’s. In fact, even before Shannon’s work, the U.S. intelligence already knew in 1941 that the one-time pad is in principle “unbreakable” (see page 32 in the <a href="http://nsarchive.gwu.edu/NSAEBB/NSAEBB278/01.PDF">Venona document</a>). However, it turned out that the hassle of manufacturing so many keys for all the communication took its toll on the Soviets and they ended up reusing the same keys for more than one message. They did try to use them for completely different receivers in the (false) hope that this wouldn’t be detected. The <a href="https://en.wikipedia.org/wiki/Venona_project">Venona Project</a> of the U.S. Army was founded in February 1943 by Gene Grabeel (see <a href='#genegrabeelfig'>Figure 9</a>), a former home economics teacher from Madison Heights, Virgnia and Lt. Leonard Zubko. In October 1943, they had their breakthrough when it was discovered that the Russians were reusing their keys.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> In the 37 years of its existence, the project has resulted in a treasure chest of intelligence, exposing hundreds of KGB agents and Russian spies in the U.S. and other countries, including Julius Rosenberg, Harry Gold, Klaus Fuchs, Alger Hiss, Harry Dexter White and many others.</p>
<figure>
<img src="../figure/genevenona.png" alt="9: Gene Grabeel, who founded the U.S. Russian SigInt program on 1 Feb 1943. Photo taken in 1942, see Page 7 in the Venona historical study." id="genegrabeelfig" class="margin" /><figcaption>9: Gene Grabeel, who founded the U.S. Russian SigInt program on 1 Feb 1943. Photo taken in 1942, see Page 7 in the Venona historical study.</figcaption>
</figure>
<p>Unfortunately it turns out that (as shown by Shannon) that such long keys are <em>necessary</em> for perfect secrecy:</p>
<figure>
<img src="../figure/longkeygraph.png" alt="10: An encryption scheme where the number of keys is smaller than the number of plaintexts corresponds to a bipartite graph where the degree is smaller than the number of vertices on the left side. Together with the validity condition this implies that there will be two left vertices x,x&#39; with non-identical neighborhoods, and hence the scheme does not satisfy perfect secrecy." id="longkeygraphfig" class="margin" /><figcaption>10: An encryption scheme where the number of keys is smaller than the number of plaintexts corresponds to a bipartite graph where the degree is smaller than the number of vertices on the left side. Together with the validity condition this implies that there will be two left vertices <span><span class="math inline">\(x,x&#39;\)</span></span> with non-identical neighborhoods, and hence the scheme does <em>not</em> satisfy perfect secrecy.</figcaption>
</figure>
<div id="longkeysthm" class="theorem" title="Perfect secrecy requires long keys" data-number="1.4" name="Theorem 0.9 (Perfect secrecy requires long keys) ">
<p>For every perfectly secret encryption scheme <span><span class="math inline">\((E,D)\)</span></span> the length function <span><span class="math inline">\(L\)</span></span> satisfies <span><span class="math inline">\(L(n) \leq n\)</span></span>.</p>
</div>
<div id="section-7" class="proofidea" data-ref="longkeysthm" data-number="1.4" name="Proofidea">
<p>The idea behind the proof is illustrated in <a href='#longkeygraphfig'>Figure 10</a>. If the number of keys is smaller than the number of messages then the neighborhoods of all vertices in the corresponding graphs cannot be identical.</p>
</div>
<div id="section-8" class="proof" data-ref="longkeysthm" data-number="1.4" name="Proof">
<p>Let <span><span class="math inline">\(E,D\)</span></span> be a valid encryption scheme with messages of length <span><span class="math inline">\(L\)</span></span> and key of length <span><span class="math inline">\(n&lt;L\)</span></span>. We will show that <span><span class="math inline">\((E,D)\)</span></span> is not perfectly secret by providing two plaintexts <span><span class="math inline">\(x_0,x_1 \in \{0,1\}^L\)</span></span> such that the distributions <span><span class="math inline">\(Y_{x_0}\)</span></span> and <span><span class="math inline">\(Y_{x_1}\)</span></span> are not identical, where <span><span class="math inline">\(Y_x\)</span></span> is the distribution obtained by picking <span><span class="math inline">\(k \sim \{0,1\}^n\)</span></span> and outputting <span><span class="math inline">\(E_k(x)\)</span></span>. We choose <span><span class="math inline">\(x_0 = 0^L\)</span></span>. Let <span><span class="math inline">\(S_0 \subseteq \{0,1\}^*\)</span></span> be the set of all ciphertexts that have nonzero probability of being output in <span><span class="math inline">\(Y_{x_0}\)</span></span>. That is, <span><span class="math inline">\(S=\{ y \;|\; \exists_{k\in \{0,1\}^n} y=E_k(x_0) \}\)</span></span>. Since there are only <span><span class="math inline">\(2^n\)</span></span> keys, we know that <span><span class="math inline">\(|S_0| \leq 2^n\)</span></span>.</p>
<p>We will show the following claim:</p>
<p><strong>Claim I:</strong> There exists some <span><span class="math inline">\(x_1 \in \{0,1\}^L\)</span></span> and <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(E_k(x_1) \not\in S_0\)</span></span>.</p>
<p>Claim I implies that the string <span><span class="math inline">\(E_k(x_1)\)</span></span> has positive probability of being output by <span><span class="math inline">\(Y_{x_1}\)</span></span> and zero probability of being output by <span><span class="math inline">\(Y_{x_0}\)</span></span> and hence in particular <span><span class="math inline">\(Y_{x_0}\)</span></span> and <span><span class="math inline">\(Y_{x_1}\)</span></span> are not identical. To prove Claim I, just choose a fixed <span><span class="math inline">\(k\in \{0,1\}^n\)</span></span>. By the validity condition, the map <span><span class="math inline">\(x \mapsto E_k(x)\)</span></span> is a one to one map of <span><span class="math inline">\(\{0,1\}^L\)</span></span> to <span><span class="math inline">\(\{0,1\}^*\)</span></span> and hence in particular the <em>image</em> of this map: the set <span><span class="math inline">\(I = \{ y \;|\; \exists_{x\in \{0,1\}^L} y=E_k(x) \}\)</span></span> has size at least (in fact exactly) <span><span class="math inline">\(2^L\)</span></span>. Since <span><span class="math inline">\(|S_0| = 2^n &lt; 2^L\)</span></span>, this means that <span><span class="math inline">\(|I|&gt;|S_0|\)</span></span> and so in particular there exists some string <span><span class="math inline">\(y\)</span></span> in <span><span class="math inline">\(I \setminus S_0\)</span></span>. But by the definition of <span><span class="math inline">\(I\)</span></span> this means that there is some <span><span class="math inline">\(x\in \{0,1\}^L\)</span></span> such that <span><span class="math inline">\(E_k(x) \not\in S_0\)</span></span> which concludes the proof of Claim I and hence of <a href='#longkeysthm'>Theorem 0.9</a>.</p>
</div>
<h3 id="advanced-comment-adding-probability-into-the-picture" data-number="1.4.1">Advanced comment: Adding probability into the picture</h3>
<p>There is a sense in which both our secrecy and our impossiblity results might not be fully convincing, and that is that we did not explicitly consider algorithms that use <em>randomness</em> . For example, maybe Eve can break a perfectly secret encryption if she is not modeled as a deterministic function <span><span class="math inline">\(Eve:\{0,1\}^o\rightarrow\{0,1\}^\ell\)</span></span> but rather a <em>probabilistic</em> process. Similarly, maybe the encryption and decryption functions could be probabilistic processes as well. It turns out that none of those matter. For the former, note that a probabilistic process can be thought of as a <em>distribution</em> over functions, in the sense that we have a collection of functions <span><span class="math inline">\(f_1,...,f_N\)</span></span> mapping <span><span class="math inline">\(\{0,1\}^o\)</span></span> to <span><span class="math inline">\(\{0,1\}^\ell\)</span></span>, and some probabilities <span><span class="math inline">\(p_1,\ldots,p_N\)</span></span> (non-negative numbers summing to <span><span class="math inline">\(1\)</span></span>), so we now think of Eve as selecting the function <span><span class="math inline">\(f_i\)</span></span> with probability <span><span class="math inline">\(p_i\)</span></span>. But if none of those functions can give an advantage better than <span><span class="math inline">\(1/2\)</span></span>, then neither can this collection. A similar (though more involved) argument shows that the impossiblity result showing that the key must be at least as long as the message still holds even if the encryption and decryption algorithms are allowed to be probabilistic processes as well (working this out is a great exercise).</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>In the current state of these lecture notes, almost all references and credits are omitted unless the name has become standard in the literature, or I believe that the story of some discovery can serve a pedagogical point. See the Katz-Lindell book for historical notes and references. This lecture shares a lot of text with (though is not identical to) my lecture on cryptography in the <a href="http://introtcs.org">introduction to theoretical computer science</a> lecture notes.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>Traditionally, <em>cryptography</em> was the name for the activity of <em>making</em> codes, while <em>cryptoanalysis</em> is the name for the activity of <em>breaking</em> them, and <em>cryptology</em> is the name for the union of the two. These days <em>cryptography</em> is often used as the name for the broad science of constructing and analyzing the security of not just encryptions but many schemes and protocols for protecting the confidentiality and integrity of communication and computation.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>Here is a nice exercise: compute (up to an order of magnitude) the probability that a 50-letter long message composed of random letters will end up not containing the letter “L”.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>There are about <span><span class="math inline">\(10^{68}\)</span></span> atoms in the galaxy, so even if we assumed that each one of those atoms was a computer that can process say <span><span class="math inline">\(10^{21}\)</span></span> decryption attempts per second (as the speed of light is <span><span class="math inline">\(10^9\)</span></span> meters per second and the diameter of an atom is about <span><span class="math inline">\(10^{-12}\)</span></span> meters), then it would still take <span><span class="math inline">\(10^{113-89} = 10^{24}\)</span></span> seconds, which is about <span><span class="math inline">\(10^{17}\)</span></span> years to exhaust all possibilities, while the sun is estimated to burn out in about 5 billion years.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>Credit to this discovery is shared by Lt. Richard Hallock, Carrie Berry, Frank Lewis, and Lt. Karl Elmquist, and there are others that have made important contribution to this project. See pages 27 and 28 in the document.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/crypto/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/crypto/issues?q=Introduction+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/29/2019 17:55:28</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/crypto/lec_01_introduction.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
