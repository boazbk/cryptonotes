<!DOCTYPE html>
<html  lang="en">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Theoretical Computer Science: What if P equals NP?</title>
  <meta name="description" content="Textbook on Theoretical Computer Science by Boaz Barak">

  <meta property="og:title" content="Introduction to Theoretical Computer Science: What if P equals NP?" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://introtcs.org/" />
  <meta property="og:image" content="icons/cover.png" />
  <meta property="og:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="github-repo" content="boazbk/tcs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Theoretical Computer Science" />
  <meta name="twitter:description" content="Textbook on Theoretical Computer Science by Boaz Barak" />
  <meta name="twitter:image" content="https://introtcs.org/icons/cover.png" />

<meta name="author" content="Boaz Barak">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="shortcut icon" href="icons/favicon.ico" type="image/x-icon">

<!-- Boaz: resources -->

<!-- <script src="https://kit.fontawesome.com/ab08ce82a8.js"></script> -->

<link rel="stylesheet" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">


<!-- KaTeX -->


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
  integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
  integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload='renderMathInElement(document.body, {  throwOnError: false, macros: { "\\N": "\\mathbb{N}", "\\R": "\\mathbb{R}", "\\Z": "\\mathbb{Z}","\\E": "\\mathbb{E}","\\val": "\\mathrm{val}", "\\label": "\\;\\;\\;\\;\\;\\;\\;\\;","\\floor": "\\lfloor #1 \\rfloor","\\ceil": "\\lceil #1 \\rceil", "\\ensuremath": "#1"}});'>
</script>




<!-- KaTeX -->
<!-- pseudocode -->
<link rel="stylesheet" href="css/pseudocode.css">
<!-- <script src="js/pseudocode.min.js"></script> -->


<!-- Gitbook resources -->

  <script src="js/jquery.min.js"></script>
  <link href="css/style.css" rel="stylesheet" />
  
  <link href="css/plugin-table.css" rel="stylesheet" />
  <link href="css/plugin-bookdown.css" rel="stylesheet" />
  <link href="css/plugin-highlight.css" rel="stylesheet" />
  <link href="css/plugin-search.css" rel="stylesheet" />
  <link href="css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="css/moregitbook.css" rel="stylesheet" />

  <link href="css/resmisc.css" rel="stylesheet" />





<!-- Boaz: end resources -->



<!--bookdown:link_prev-->
<!--bookdown:link_next-->




<!-- bigfoot-->

<link href="css/bigfoot-default.css" rel="stylesheet" />
<script type="text/javascript" src="js/bigfoot.js"></script>

<script type="text/javascript">
    var bigfoot = jQuery.bigfoot(
        {
            deleteOnUnhover: false,
            preventPageScroll: false,
            hoverDelay: 250
        }
    );
</script>

<!-- end bigfoot -->


</head>

<body>



<!--bookdown:title:start-->
<!--bookdown:title:end-->


<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul class="summary">
<li><a href="./">Introduction to Theoretical Computer Science</a></li>
<li class="divider"></li><li class="chapter" data-level="p" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html"><i class="fa fa-check"></i><b>p</b> Preface</a><ul><li class="chapter" data-level="p.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-the-student"><i class="fa fa-check"></i><b>p.1</b> To the student</a><ul><li class="chapter" data-level="p.1.1" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#is-the-effort-worth-it"><i class="fa fa-check"></i><b>p.1.1</b> Is the effort worth it?</a></li></ul></li><li class="chapter" data-level="p.2" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#to-potential-instructors"><i class="fa fa-check"></i><b>p.2</b> To potential instructors</a></li><li class="chapter" data-level="p.3" data-path="lec_00_0_preface.html"><a href="lec_00_0_preface.html#acknowledgements"><i class="fa fa-check"></i><b>p.3</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="0" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html"><i class="fa fa-check"></i><b>0</b> Introduction</a><ul><li class="chapter" data-level="0.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#integer-multiplication-an-example-of-an-algorithm"><i class="fa fa-check"></i><b>0.1</b> Integer multiplication: an example of an algorithm</a></li><li class="chapter" data-level="0.2" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#karatsubasec"><i class="fa fa-check"></i><b>0.2</b> Extended Example: A faster way to multiply (optional)</a></li><li class="chapter" data-level="0.3" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#algsbeyondarithmetic"><i class="fa fa-check"></i><b>0.3</b> Algorithms beyond arithmetic</a></li><li class="chapter" data-level="0.4" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#on-the-importance-of-negative-results."><i class="fa fa-check"></i><b>0.4</b> On the importance of negative results.</a></li><li class="chapter" data-level="0.5" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#roadmapsec"><i class="fa fa-check"></i><b>0.5</b> Roadmap to the rest of this book</a><ul><li class="chapter" data-level="0.5.1" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#dependencies-between-chapters"><i class="fa fa-check"></i><b>0.5.1</b> Dependencies between chapters</a></li></ul></li><li class="chapter" data-level="0.6" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#exercises"><i class="fa fa-check"></i><b>0.6</b> Exercises</a></li><li class="chapter" data-level="0.7" data-path="lec_01_introduction.html"><a href="lec_01_introduction.html#bnotesintrosec"><i class="fa fa-check"></i><b>0.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a><ul><li class="chapter" data-level="1.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#manualbackground"><i class="fa fa-check"></i><b>1.1</b> This chapter: a reader’s manual</a></li><li class="chapter" data-level="1.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secmathoverview"><i class="fa fa-check"></i><b>1.2</b> A quick overview of mathematical prerequisites</a></li><li class="chapter" data-level="1.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#reading-mathematical-texts"><i class="fa fa-check"></i><b>1.3</b> Reading mathematical texts</a><ul><li class="chapter" data-level="1.3.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#definitions"><i class="fa fa-check"></i><b>1.3.1</b> Definitions</a></li><li class="chapter" data-level="1.3.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#assertions-theorems-lemmas-claims"><i class="fa fa-check"></i><b>1.3.2</b> Assertions: Theorems, lemmas, claims</a></li><li class="chapter" data-level="1.3.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li></ul></li><li class="chapter" data-level="1.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#basic-discrete-math-objects"><i class="fa fa-check"></i><b>1.4</b> Basic discrete math objects</a><ul><li class="chapter" data-level="1.4.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#sets"><i class="fa fa-check"></i><b>1.4.1</b> Sets</a></li><li class="chapter" data-level="1.4.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#specialsets"><i class="fa fa-check"></i><b>1.4.2</b> Special sets</a></li><li class="chapter" data-level="1.4.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#functionsec"><i class="fa fa-check"></i><b>1.4.3</b> Functions</a></li><li class="chapter" data-level="1.4.4" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#graphsec"><i class="fa fa-check"></i><b>1.4.4</b> Graphs</a></li><li class="chapter" data-level="1.4.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifiers"><i class="fa fa-check"></i><b>1.4.5</b> Logic operators and quantifiers</a></li><li class="chapter" data-level="1.4.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secquantifierssums"><i class="fa fa-check"></i><b>1.4.6</b> Quantifiers for summations and products</a></li><li class="chapter" data-level="1.4.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#boundvarsec"><i class="fa fa-check"></i><b>1.4.7</b> Parsing formulas: bound and free variables</a></li><li class="chapter" data-level="1.4.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#secbigohnotation"><i class="fa fa-check"></i><b>1.4.8</b> Asymptotics and Big-O notation</a></li><li class="chapter" data-level="1.4.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-rules-of-thumb-for-big-o-notation"><i class="fa fa-check"></i><b>1.4.9</b> Some rules of thumb for Big-O notation</a></li></ul></li><li class="chapter" data-level="1.5" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofsbackgroundsec"><i class="fa fa-check"></i><b>1.5</b> Proofs</a><ul><li class="chapter" data-level="1.5.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proofs-and-programs"><i class="fa fa-check"></i><b>1.5.1</b> Proofs and programs</a></li><li class="chapter" data-level="1.5.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proof-writing-style"><i class="fa fa-check"></i><b>1.5.2</b> Proof writing style</a></li><li class="chapter" data-level="1.5.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#patterns-in-proofs"><i class="fa fa-check"></i><b>1.5.3</b> Patterns in proofs</a></li></ul></li><li class="chapter" data-level="1.6" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#topsortsec"><i class="fa fa-check"></i><b>1.6</b> Extended example: Topological Sorting</a><ul><li class="chapter" data-level="1.6.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#inductionsec"><i class="fa fa-check"></i><b>1.6.1</b> Mathematical induction</a></li><li class="chapter" data-level="1.6.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#proving-the-result-by-induction"><i class="fa fa-check"></i><b>1.6.2</b> Proving the result by induction</a></li><li class="chapter" data-level="1.6.3" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#minimality-and-uniqueness"><i class="fa fa-check"></i><b>1.6.3</b> Minimality and uniqueness</a></li></ul></li><li class="chapter" data-level="1.7" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notationsec"><i class="fa fa-check"></i><b>1.7</b> This book: notation and conventions</a><ul><li class="chapter" data-level="1.7.1" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#conventionsec"><i class="fa fa-check"></i><b>1.7.1</b> Variable name conventions</a></li><li class="chapter" data-level="1.7.2" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#some-idioms"><i class="fa fa-check"></i><b>1.7.2</b> Some idioms</a></li></ul></li><li class="chapter" data-level="1.8" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li><li class="chapter" data-level="1.9" data-path="lec_00_1_math_background.html"><a href="lec_00_1_math_background.html#notesmathchap"><i class="fa fa-check"></i><b>1.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="2" data-path="lec_02_representation.html"><a href="lec_02_representation.html"><i class="fa fa-check"></i><b>2</b> Computation and Representation</a><ul><li class="chapter" data-level="2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-representations"><i class="fa fa-check"></i><b>2.1</b> Defining representations</a><ul><li class="chapter" data-level="2.1.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-natural-numbers"><i class="fa fa-check"></i><b>2.1.1</b> Representing natural numbers</a></li><li class="chapter" data-level="2.1.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#meaning-of-representations-discussion"><i class="fa fa-check"></i><b>2.1.2</b> Meaning of representations (discussion)</a></li></ul></li><li class="chapter" data-level="2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representations-beyond-natural-numbers"><i class="fa fa-check"></i><b>2.2</b> Representations beyond natural numbers</a><ul><li class="chapter" data-level="2.2.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#repnegativeintegerssec"><i class="fa fa-check"></i><b>2.2.1</b> Representing (potentially negative) integers</a></li><li class="chapter" data-level="2.2.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#twoscomplement"><i class="fa fa-check"></i><b>2.2.2</b> Two’s complement representation (optional)</a></li><li class="chapter" data-level="2.2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#rational-numbers-and-representing-pairs-of-strings"><i class="fa fa-check"></i><b>2.2.3</b> Rational numbers, and representing pairs of strings</a></li></ul></li><li class="chapter" data-level="2.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-real-numbers"><i class="fa fa-check"></i><b>2.3</b> Representing real numbers</a><ul><li class="chapter" data-level="2.3.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#cantorsec"><i class="fa fa-check"></i><b>2.3.1</b> Can we represent reals exactly?</a></li></ul></li><li class="chapter" data-level="2.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-objects-beyond-numbers"><i class="fa fa-check"></i><b>2.4</b> Representing objects beyond numbers</a><ul><li class="chapter" data-level="2.4.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#finite-representations"><i class="fa fa-check"></i><b>2.4.1</b> Finite representations</a></li><li class="chapter" data-level="2.4.2" data-path="lec_02_representation.html"><a href="lec_02_representation.html#prefixfreesec"><i class="fa fa-check"></i><b>2.4.2</b> Prefix-free encoding</a></li><li class="chapter" data-level="2.4.3" data-path="lec_02_representation.html"><a href="lec_02_representation.html#making-representations-prefix-free"><i class="fa fa-check"></i><b>2.4.3</b> Making representations prefix-free</a></li><li class="chapter" data-level="2.4.4" data-path="lec_02_representation.html"><a href="lec_02_representation.html#proof-by-python-optional"><i class="fa fa-check"></i><b>2.4.4</b> Proof by Python (optional)</a></li><li class="chapter" data-level="2.4.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-letters-and-text"><i class="fa fa-check"></i><b>2.4.5</b> Representing letters and text</a></li><li class="chapter" data-level="2.4.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-vectors-matrices-images"><i class="fa fa-check"></i><b>2.4.6</b> Representing vectors, matrices, images</a></li><li class="chapter" data-level="2.4.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-graphs"><i class="fa fa-check"></i><b>2.4.7</b> Representing graphs</a></li><li class="chapter" data-level="2.4.8" data-path="lec_02_representation.html"><a href="lec_02_representation.html#representing-lists-and-nested-lists"><i class="fa fa-check"></i><b>2.4.8</b> Representing lists and nested lists</a></li><li class="chapter" data-level="2.4.9" data-path="lec_02_representation.html"><a href="lec_02_representation.html#notation"><i class="fa fa-check"></i><b>2.4.9</b> Notation</a></li></ul></li><li class="chapter" data-level="2.5" data-path="lec_02_representation.html"><a href="lec_02_representation.html#defining-computational-tasks-as-mathematical-functions"><i class="fa fa-check"></i><b>2.5</b> Defining computational tasks as mathematical functions</a><ul><li class="chapter" data-level="2.5.1" data-path="lec_02_representation.html"><a href="lec_02_representation.html#secimplvsspec"><i class="fa fa-check"></i><b>2.5.1</b> Distinguish functions from programs!</a></li></ul></li><li class="chapter" data-level="2.6" data-path="lec_02_representation.html"><a href="lec_02_representation.html#exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li><li class="chapter" data-level="2.7" data-path="lec_02_representation.html"><a href="lec_02_representation.html#bibnotesrepres"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="3" data-path="lec_03_computation.html"><a href="lec_03_computation.html"><i class="fa fa-check"></i><b>3</b> Defining computation</a><ul><li class="chapter" data-level="3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#defining-computation"><i class="fa fa-check"></i><b>3.1</b> Defining computation</a></li><li class="chapter" data-level="3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#computing-using-and-or-and-not."><i class="fa fa-check"></i><b>3.2</b> Computing using AND, OR, and NOT.</a><ul><li class="chapter" data-level="3.2.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#some-properties-of-and-and-or"><i class="fa fa-check"></i><b>3.2.1</b> Some properties of AND and OR</a></li><li class="chapter" data-level="3.2.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#xoraonexample"><i class="fa fa-check"></i><b>3.2.2</b> Extended example: Computing \ensuremath{\mathit{XOR}} from \ensuremath{\mathit{AND}}, \ensuremath{\mathit{OR}}, and \ensuremath{\mathit{NOT}}</a></li><li class="chapter" data-level="3.2.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#informally-defining-basic-operations-and-algorithms"><i class="fa fa-check"></i><b>3.2.3</b> Informally defining basic operations and algorithms</a></li></ul></li><li class="chapter" data-level="3.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#booleancircuitfig"><i class="fa fa-check"></i><b>3.3</b> Boolean Circuits</a><ul><li class="chapter" data-level="3.3.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#boolean-circuits-a-formal-definition"><i class="fa fa-check"></i><b>3.3.1</b> Boolean circuits: a formal definition</a></li><li class="chapter" data-level="3.3.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-circuits-and-straight-line-programs"><i class="fa fa-check"></i><b>3.3.2</b> Equivalence of circuits and straight-line programs</a></li></ul></li><li class="chapter" data-level="3.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#physicalimplementationsec"><i class="fa fa-check"></i><b>3.4</b> Physical implementations of computing devices (digression)</a><ul><li class="chapter" data-level="3.4.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#transistors"><i class="fa fa-check"></i><b>3.4.1</b> Transistors</a></li><li class="chapter" data-level="3.4.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#logical-gates-from-transistors"><i class="fa fa-check"></i><b>3.4.2</b> Logical gates from transistors</a></li><li class="chapter" data-level="3.4.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biological-computing"><i class="fa fa-check"></i><b>3.4.3</b> Biological computing</a></li><li class="chapter" data-level="3.4.4" data-path="lec_03_computation.html"><a href="lec_03_computation.html#cellular-automata-and-the-game-of-life"><i class="fa fa-check"></i><b>3.4.4</b> Cellular automata and the game of life</a></li><li class="chapter" data-level="3.4.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#neural-networks"><i class="fa fa-check"></i><b>3.4.5</b> Neural networks</a></li><li class="chapter" data-level="3.4.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#a-computer-made-from-marbles-and-pipes"><i class="fa fa-check"></i><b>3.4.6</b> A computer made from marbles and pipes</a></li></ul></li><li class="chapter" data-level="3.5" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandsec"><i class="fa fa-check"></i><b>3.5</b> The NAND function</a><ul><li class="chapter" data-level="3.5.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nand-circuits"><i class="fa fa-check"></i><b>3.5.1</b> NAND Circuits</a></li><li class="chapter" data-level="3.5.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#more-examples-of-nand-circuits-optional"><i class="fa fa-check"></i><b>3.5.2</b> More examples of NAND circuits (optional)</a></li><li class="chapter" data-level="3.5.3" data-path="lec_03_computation.html"><a href="lec_03_computation.html#nandcircsec"><i class="fa fa-check"></i><b>3.5.3</b> The NAND-CIRC Programming language</a></li></ul></li><li class="chapter" data-level="3.6" data-path="lec_03_computation.html"><a href="lec_03_computation.html#equivalence-of-all-these-models"><i class="fa fa-check"></i><b>3.6</b> Equivalence of all these models</a><ul><li class="chapter" data-level="3.6.1" data-path="lec_03_computation.html"><a href="lec_03_computation.html#othergatessec"><i class="fa fa-check"></i><b>3.6.1</b> Circuits with other gate sets</a></li><li class="chapter" data-level="3.6.2" data-path="lec_03_computation.html"><a href="lec_03_computation.html#specvsimplrem"><i class="fa fa-check"></i><b>3.6.2</b> Specification vs. implementation (again)</a></li></ul></li><li class="chapter" data-level="3.7" data-path="lec_03_computation.html"><a href="lec_03_computation.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li><li class="chapter" data-level="3.8" data-path="lec_03_computation.html"><a href="lec_03_computation.html#biographical-notes"><i class="fa fa-check"></i><b>3.8</b> Biographical notes</a></li></ul></li><li class="chapter" data-level="4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html"><i class="fa fa-check"></i><b>4</b> Syntactic sugar, and computing every function</a><ul><li class="chapter" data-level="4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secsyntacticsugar"><i class="fa fa-check"></i><b>4.1</b> Some examples of syntactic sugar</a><ul><li class="chapter" data-level="4.1.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#user-defined-procedures"><i class="fa fa-check"></i><b>4.1.1</b> User-defined procedures</a></li><li class="chapter" data-level="4.1.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#functionsynsugarthmpython"><i class="fa fa-check"></i><b>4.1.2</b> Proof by Python (optional)</a></li><li class="chapter" data-level="4.1.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#ifstatementsec"><i class="fa fa-check"></i><b>4.1.3</b> Conditional statements</a></li></ul></li><li class="chapter" data-level="4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#addexample"><i class="fa fa-check"></i><b>4.2</b> Extended example: Addition and Multiplication (optional)</a></li><li class="chapter" data-level="4.3" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seclookupfunc"><i class="fa fa-check"></i><b>4.3</b> The LOOKUP function</a><ul><li class="chapter" data-level="4.3.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#constructing-a-nand-circ-program-for-lookup"><i class="fa fa-check"></i><b>4.3.1</b> Constructing a NAND-CIRC program for \ensuremath{\mathit{LOOKUP}}</a></li></ul></li><li class="chapter" data-level="4.4" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputeallfunctions"><i class="fa fa-check"></i><b>4.4</b> Computing every function</a><ul><li class="chapter" data-level="4.4.1" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#proof-of-nands-universality"><i class="fa fa-check"></i><b>4.4.1</b> Proof of NAND’s Universality</a></li><li class="chapter" data-level="4.4.2" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#tight-upper-bound"><i class="fa fa-check"></i><b>4.4.2</b> Improving by a factor of n (optional)</a></li></ul></li><li class="chapter" data-level="4.5" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#seccomputalternative"><i class="fa fa-check"></i><b>4.5</b> Computing every function: An alternative proof</a></li><li class="chapter" data-level="4.6" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#secdefinesizeclasses"><i class="fa fa-check"></i><b>4.6</b> The class \ensuremath{\mathit{SIZE}}(T)</a></li><li class="chapter" data-level="4.7" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li><li class="chapter" data-level="4.8" data-path="lec_03a_computing_every_function.html"><a href="lec_03a_computing_every_function.html#computeeveryfunctionbibnotes"><i class="fa fa-check"></i><b>4.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html"><i class="fa fa-check"></i><b>5</b> Code as data, data as code</a><ul><li class="chapter" data-level="5.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#representprogramsec"><i class="fa fa-check"></i><b>5.1</b> Representing programs as strings</a></li><li class="chapter" data-level="5.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#countingcircuitsec"><i class="fa fa-check"></i><b>5.2</b> Counting programs, and lower bounds on the size of NAND-CIRC programs</a><ul><li class="chapter" data-level="5.2.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#size-hierarchy-theorem-optional"><i class="fa fa-check"></i><b>5.2.1</b> Size hierarchy theorem (optional)</a></li></ul></li><li class="chapter" data-level="5.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#listoftuplesrepsec"><i class="fa fa-check"></i><b>5.3</b> The tuples representation</a><ul><li class="chapter" data-level="5.3.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#stringrepresentationrpgoramsec"><i class="fa fa-check"></i><b>5.3.1</b> From tuples to strings</a></li></ul></li><li class="chapter" data-level="5.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4</b> A NAND-CIRC interpreter in NAND-CIRC</a><ul><li class="chapter" data-level="5.4.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#efficient-universal-programs"><i class="fa fa-check"></i><b>5.4.1</b> Efficient universal programs</a></li><li class="chapter" data-level="5.4.2" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-nand-circ-interpeter-in-pseudocode"><i class="fa fa-check"></i><b>5.4.2</b> A NAND-CIRC interpeter in pseudocode</a></li><li class="chapter" data-level="5.4.3" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#nandevalpythonsec"><i class="fa fa-check"></i><b>5.4.3</b> A NAND interpreter in Python</a></li><li class="chapter" data-level="5.4.4" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#constructing-the-nand-circ-interpreter-in-nand-circ"><i class="fa fa-check"></i><b>5.4.4</b> Constructing the NAND-CIRC interpreter in NAND-CIRC</a></li></ul></li><li class="chapter" data-level="5.5" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#a-python-interpreter-in-nand-circ-discussion"><i class="fa fa-check"></i><b>5.5</b> A Python interpreter in NAND-CIRC (discussion)</a></li><li class="chapter" data-level="5.6" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#PECTTsec"><i class="fa fa-check"></i><b>5.6</b> The physical extended Church-Turing thesis (discussion)</a><ul><li class="chapter" data-level="5.6.1" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#attempts-at-refuting-the-pectt"><i class="fa fa-check"></i><b>5.6.1</b> Attempts at refuting the PECTT</a></li></ul></li><li class="chapter" data-level="5.7" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#recap-of-part-i-finite-computation"><i class="fa fa-check"></i><b>5.7</b> Recap of Part I: Finite Computation</a></li><li class="chapter" data-level="5.8" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#exercises"><i class="fa fa-check"></i><b>5.8</b> Exercises</a></li><li class="chapter" data-level="5.9" data-path="lec_04_code_and_data.html"><a href="lec_04_code_and_data.html#bibnotescodeasdata"><i class="fa fa-check"></i><b>5.9</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="6" data-path="lec_06_loops.html"><a href="lec_06_loops.html"><i class="fa fa-check"></i><b>6</b> Loops and infinity</a><ul><li class="chapter" data-level="6.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines"><i class="fa fa-check"></i><b>6.1</b> Turing Machines</a><ul><li class="chapter" data-level="6.1.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turingmachinepalindrome"><i class="fa fa-check"></i><b>6.1.1</b> Extended example: A Turing machine for palindromes</a></li><li class="chapter" data-level="6.1.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-a-formal-definition"><i class="fa fa-check"></i><b>6.1.2</b> Turing machines: a formal definition</a></li><li class="chapter" data-level="6.1.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#computable-functions"><i class="fa fa-check"></i><b>6.1.3</b> Computable functions</a></li><li class="chapter" data-level="6.1.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#infinite-loops-and-partial-functions"><i class="fa fa-check"></i><b>6.1.4</b> Infinite loops and partial functions</a></li></ul></li><li class="chapter" data-level="6.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#turing-machines-as-programming-languages"><i class="fa fa-check"></i><b>6.2</b> Turing machines as programming languages</a><ul><li class="chapter" data-level="6.2.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#the-nand-tm-programming-language"><i class="fa fa-check"></i><b>6.2.1</b> The NAND-TM Programming language</a></li><li class="chapter" data-level="6.2.2" data-path="lec_06_loops.html"><a href="lec_06_loops.html#sneak-peak-nand-tm-vs-turing-machines"><i class="fa fa-check"></i><b>6.2.2</b> Sneak peak: NAND-TM vs Turing machines</a></li><li class="chapter" data-level="6.2.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#examples"><i class="fa fa-check"></i><b>6.2.3</b> Examples</a></li></ul></li><li class="chapter" data-level="6.3" data-path="lec_06_loops.html"><a href="lec_06_loops.html#equivalence-of-turing-machines-and-nand-tm-programs"><i class="fa fa-check"></i><b>6.3</b> Equivalence of Turing machines and NAND-TM programs</a><ul><li class="chapter" data-level="6.3.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#specification-vs-implementation-again"><i class="fa fa-check"></i><b>6.3.1</b> Specification vs implementation (again)</a></li></ul></li><li class="chapter" data-level="6.4" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nand-tm-syntactic-sugar"><i class="fa fa-check"></i><b>6.4</b> NAND-TM syntactic sugar</a><ul><li class="chapter" data-level="6.4.1" data-path="lec_06_loops.html"><a href="lec_06_loops.html#nandtminnerloopssec"><i class="fa fa-check"></i><b>6.4.1</b> GOTO and inner loops</a></li></ul></li><li class="chapter" data-level="6.5" data-path="lec_06_loops.html"><a href="lec_06_loops.html#uniformity-and-nand-vs-nand-tm-discussion"><i class="fa fa-check"></i><b>6.5</b> Uniformity, and NAND vs NAND-TM (discussion)</a></li><li class="chapter" data-level="6.6" data-path="lec_06_loops.html"><a href="lec_06_loops.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li><li class="chapter" data-level="6.7" data-path="lec_06_loops.html"><a href="lec_06_loops.html#chaploopnotes"><i class="fa fa-check"></i><b>6.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html"><i class="fa fa-check"></i><b>7</b> Equivalent models of computation</a><ul><li class="chapter" data-level="7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ram-machines-and-nand-ram"><i class="fa fa-check"></i><b>7.1</b> RAM machines and NAND-RAM</a></li><li class="chapter" data-level="7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#nandtmgorydetailssec"><i class="fa fa-check"></i><b>7.2</b> The gory details (optional)</a><ul><li class="chapter" data-level="7.2.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#indexed-access-in-nand-tm"><i class="fa fa-check"></i><b>7.2.1</b> Indexed access in NAND-TM</a></li><li class="chapter" data-level="7.2.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#two-dimensional-arrays-in-nand-tm"><i class="fa fa-check"></i><b>7.2.2</b> Two dimensional arrays in NAND-TM</a></li><li class="chapter" data-level="7.2.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#all-the-rest"><i class="fa fa-check"></i><b>7.2.3</b> All the rest</a></li></ul></li><li class="chapter" data-level="7.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turing-equivalence-discussion"><i class="fa fa-check"></i><b>7.3</b> Turing equivalence (discussion)</a><ul><li class="chapter" data-level="7.3.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-best-of-both-worlds-paradigm"><i class="fa fa-check"></i><b>7.3.1</b> The Best of both worlds paradigm</a></li><li class="chapter" data-level="7.3.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lets-talk-about-abstractions."><i class="fa fa-check"></i><b>7.3.2</b> Let’s talk about abstractions.</a></li><li class="chapter" data-level="7.3.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingcompletesec"><i class="fa fa-check"></i><b>7.3.3</b> Turing completeness and equivalence, a formal definition (optional)</a></li></ul></li><li class="chapter" data-level="7.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#cellularautomatasec"><i class="fa fa-check"></i><b>7.4</b> Cellular automata</a><ul><li class="chapter" data-level="7.4.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#one-dimensional-cellular-automata-are-turing-complete"><i class="fa fa-check"></i><b>7.4.1</b> One dimensional cellular automata are Turing complete</a></li><li class="chapter" data-level="7.4.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#turingmachinesconfigsec"><i class="fa fa-check"></i><b>7.4.2</b> Configurations of Turing machines and the next-step function</a></li></ul></li><li class="chapter" data-level="7.5" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacalculussec"><i class="fa fa-check"></i><b>7.5</b> Lambda calculus and functional programming languages</a><ul><li class="chapter" data-level="7.5.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#applying-functions-to-functions"><i class="fa fa-check"></i><b>7.5.1</b> Applying functions to functions</a></li><li class="chapter" data-level="7.5.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#curryingsec"><i class="fa fa-check"></i><b>7.5.2</b> Obtaining multi-argument functions via Currying</a></li><li class="chapter" data-level="7.5.3" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#formal-description-of-the-λ-calculus."><i class="fa fa-check"></i><b>7.5.3</b> Formal description of the λ calculus.</a></li><li class="chapter" data-level="7.5.4" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#infiniteloopslambda"><i class="fa fa-check"></i><b>7.5.4</b> Infinite loops in the λ calculus</a></li></ul></li><li class="chapter" data-level="7.6" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6</b> The Enhanced λ calculus</a><ul><li class="chapter" data-level="7.6.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#computing-a-function-in-the-enhanced-λ-calculus"><i class="fa fa-check"></i><b>7.6.1</b> Computing a function in the enhanced λ calculus</a></li><li class="chapter" data-level="7.6.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#enhanced-λ-calculus-is-turing-complete"><i class="fa fa-check"></i><b>7.6.2</b> Enhanced λ calculus is Turing-complete</a></li></ul></li><li class="chapter" data-level="7.7" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#lambdacacluluspuresec"><i class="fa fa-check"></i><b>7.7</b> From enhanced to pure λ calculus</a><ul><li class="chapter" data-level="7.7.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#list-processing"><i class="fa fa-check"></i><b>7.7.1</b> List processing</a></li><li class="chapter" data-level="7.7.2" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#ycombinatorsec"><i class="fa fa-check"></i><b>7.7.2</b> The Y combinator, or recursion without recursion</a></li></ul></li><li class="chapter" data-level="7.8" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#churchturingdiscussionsec"><i class="fa fa-check"></i><b>7.8</b> The Church-Turing Thesis (discussion)</a><ul><li class="chapter" data-level="7.8.1" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#different-models-of-computation"><i class="fa fa-check"></i><b>7.8.1</b> Different models of computation</a></li></ul></li><li class="chapter" data-level="7.9" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#exercises"><i class="fa fa-check"></i><b>7.9</b> Exercises</a></li><li class="chapter" data-level="7.10" data-path="lec_07_other_models.html"><a href="lec_07_other_models.html#othermodelsbibnotes"><i class="fa fa-check"></i><b>7.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="8" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html"><i class="fa fa-check"></i><b>8</b> Universality and uncomputability</a><ul><li class="chapter" data-level="8.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#universality-or-a-meta-circular-evaluator"><i class="fa fa-check"></i><b>8.1</b> Universality or a meta-circular evaluator</a><ul><li class="chapter" data-level="8.1.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#representtmsec"><i class="fa fa-check"></i><b>8.1.1</b> Proving the existence of a universal Turing Machine</a></li><li class="chapter" data-level="8.1.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#implications-of-universality-discussion"><i class="fa fa-check"></i><b>8.1.2</b> Implications of universality (discussion)</a></li></ul></li><li class="chapter" data-level="8.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-every-function-computable"><i class="fa fa-check"></i><b>8.2</b> Is every function computable?</a></li><li class="chapter" data-level="8.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltingsec"><i class="fa fa-check"></i><b>8.3</b> The Halting problem</a><ul><li class="chapter" data-level="8.3.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-the-halting-problem-really-hard-discussion"><i class="fa fa-check"></i><b>8.3.1</b> Is the Halting problem really hard? (discussion)</a></li><li class="chapter" data-level="8.3.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#haltalternativesec"><i class="fa fa-check"></i><b>8.3.2</b> A direct proof of the uncomputability of \ensuremath{\mathit{HALT}} (optional)</a></li></ul></li><li class="chapter" data-level="8.4" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#reductionsuncompsec"><i class="fa fa-check"></i><b>8.4</b> Reductions</a><ul><li class="chapter" data-level="8.4.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#example-halting-on-the-zero-problem"><i class="fa fa-check"></i><b>8.4.1</b> Example: Halting on the zero problem</a></li></ul></li><li class="chapter" data-level="8.5" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#rices-theorem-and-the-impossibility-of-general-software-verification"><i class="fa fa-check"></i><b>8.5</b> Rice’s Theorem and the impossibility of general software verification</a><ul><li class="chapter" data-level="8.5.1" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#ricethmsec"><i class="fa fa-check"></i><b>8.5.1</b> Rice’s Theorem</a></li><li class="chapter" data-level="8.5.2" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#halting-and-rices-theorem-for-other-turing-complete-models"><i class="fa fa-check"></i><b>8.5.2</b> Halting and Rice’s Theorem for other Turing-complete models</a></li><li class="chapter" data-level="8.5.3" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#is-software-verification-doomed-discussion"><i class="fa fa-check"></i><b>8.5.3</b> Is software verification doomed? (discussion)</a></li></ul></li><li class="chapter" data-level="8.6" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li><li class="chapter" data-level="8.7" data-path="lec_08_uncomputability.html"><a href="lec_08_uncomputability.html#uncomputablebibnotes"><i class="fa fa-check"></i><b>8.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html"><i class="fa fa-check"></i><b>9</b> Restricted computational models</a><ul><li class="chapter" data-level="9.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#turing-completeness-as-a-bug"><i class="fa fa-check"></i><b>9.1</b> Turing completeness as a bug</a></li><li class="chapter" data-level="9.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-expressions"><i class="fa fa-check"></i><b>9.2</b> Regular expressions</a></li><li class="chapter" data-level="9.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#deterministic-finite-automata-and-efficient-matching-of-regular-expressions-optional"><i class="fa fa-check"></i><b>9.3</b> Deterministic finite automata, and efficient matching of regular expressions (optional)</a><ul><li class="chapter" data-level="9.3.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#matching-regular-expressions-using-constant-memory"><i class="fa fa-check"></i><b>9.3.1</b> Matching regular expressions using constant memory</a></li><li class="chapter" data-level="9.3.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#secdfa"><i class="fa fa-check"></i><b>9.3.2</b> Deterministic Finite Automata</a></li><li class="chapter" data-level="9.3.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#regular-functions-are-closed-under-complement"><i class="fa fa-check"></i><b>9.3.3</b> Regular functions are closed under complement</a></li></ul></li><li class="chapter" data-level="9.4" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-regular-expressions"><i class="fa fa-check"></i><b>9.4</b> Limitations of regular expressions</a></li><li class="chapter" data-level="9.5" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#other-semantic-properties-of-regular-expressions"><i class="fa fa-check"></i><b>9.5</b> Other semantic properties of regular expressions</a></li><li class="chapter" data-level="9.6" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#seccfg"><i class="fa fa-check"></i><b>9.6</b> Context free grammars</a><ul><li class="chapter" data-level="9.6.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#context-free-grammars-as-a-computational-model"><i class="fa fa-check"></i><b>9.6.1</b> Context-free grammars as a computational model</a></li><li class="chapter" data-level="9.6.2" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#the-power-of-context-free-grammars"><i class="fa fa-check"></i><b>9.6.2</b> The power of context free grammars</a></li><li class="chapter" data-level="9.6.3" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#limitations-of-context-free-grammars-optional"><i class="fa fa-check"></i><b>9.6.3</b> Limitations of context-free grammars (optional)</a></li></ul></li><li class="chapter" data-level="9.7" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#semantic-properties-of-context-free-languages"><i class="fa fa-check"></i><b>9.7</b> Semantic properties of context free languages</a><ul><li class="chapter" data-level="9.7.1" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#uncomputability-of-context-free-grammar-equivalence-optional"><i class="fa fa-check"></i><b>9.7.1</b> Uncomputability of context-free grammar equivalence (optional)</a></li></ul></li><li class="chapter" data-level="9.8" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#summary-of-semantic-properties-for-regular-expressions-and-context-free-grammars"><i class="fa fa-check"></i><b>9.8</b> Summary of semantic properties for regular expressions and context-free grammars</a></li><li class="chapter" data-level="9.9" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li><li class="chapter" data-level="9.10" data-path="lec_08a_restricted_models.html"><a href="lec_08a_restricted_models.html#bibliographical-notes"><i class="fa fa-check"></i><b>9.10</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="10" data-path="lec_09_godel.html"><a href="lec_09_godel.html"><i class="fa fa-check"></i><b>10</b> Is every theorem provable?</a><ul><li class="chapter" data-level="10.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofdef"><i class="fa fa-check"></i><b>10.1</b> Hilbert’s Program and Gödel’s Incompleteness Theorem</a><ul><li class="chapter" data-level="10.1.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#godelproofsystemssec"><i class="fa fa-check"></i><b>10.1.1</b> Defining Proof Systems</a></li></ul></li><li class="chapter" data-level="10.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#gödels-incompleteness-theorem-computational-variant"><i class="fa fa-check"></i><b>10.2</b> Gödel’s Incompleteness Theorem: Computational variant</a></li><li class="chapter" data-level="10.3" data-path="lec_09_godel.html"><a href="lec_09_godel.html#quantified-integer-statements"><i class="fa fa-check"></i><b>10.3</b> Quantified integer statements</a></li><li class="chapter" data-level="10.4" data-path="lec_09_godel.html"><a href="lec_09_godel.html#diophantine-equations-and-the-mrdp-theorem"><i class="fa fa-check"></i><b>10.4</b> Diophantine equations and the MRDP Theorem</a></li><li class="chapter" data-level="10.5" data-path="lec_09_godel.html"><a href="lec_09_godel.html#hardness-of-quantified-integer-statements"><i class="fa fa-check"></i><b>10.5</b> Hardness of quantified integer statements</a><ul><li class="chapter" data-level="10.5.1" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-1-quantified-mixed-statements-and-computation-histories"><i class="fa fa-check"></i><b>10.5.1</b> Step 1: Quantified mixed statements and computation histories</a></li><li class="chapter" data-level="10.5.2" data-path="lec_09_godel.html"><a href="lec_09_godel.html#step-2-reducing-mixed-statements-to-integer-statements"><i class="fa fa-check"></i><b>10.5.2</b> Step 2: Reducing mixed statements to integer statements</a></li></ul></li><li class="chapter" data-level="10.6" data-path="lec_09_godel.html"><a href="lec_09_godel.html#exercises"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li><li class="chapter" data-level="10.7" data-path="lec_09_godel.html"><a href="lec_09_godel.html#bibliographical-notes"><i class="fa fa-check"></i><b>10.7</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="11" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html"><i class="fa fa-check"></i><b>11</b> Efficient computation</a><ul><li class="chapter" data-level="11.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#problems-on-graphs"><i class="fa fa-check"></i><b>11.1</b> Problems on graphs</a><ul><li class="chapter" data-level="11.1.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-shortest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.1</b> Finding the shortest path in a graph</a></li><li class="chapter" data-level="11.1.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-longest-path-in-a-graph"><i class="fa fa-check"></i><b>11.1.2</b> Finding the longest path in a graph</a></li><li class="chapter" data-level="11.1.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#mincutsec"><i class="fa fa-check"></i><b>11.1.3</b> Finding the minimum cut in a graph</a></li><li class="chapter" data-level="11.1.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#linerprogsec"><i class="fa fa-check"></i><b>11.1.4</b> Min-Cut Max-Flow and Linear programming</a></li><li class="chapter" data-level="11.1.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-the-maximum-cut-in-a-graph"><i class="fa fa-check"></i><b>11.1.5</b> Finding the maximum cut in a graph</a></li><li class="chapter" data-level="11.1.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#a-note-on-convexity"><i class="fa fa-check"></i><b>11.1.6</b> A note on convexity</a></li></ul></li><li class="chapter" data-level="11.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#beyond-graphs"><i class="fa fa-check"></i><b>11.2</b> Beyond graphs</a><ul><li class="chapter" data-level="11.2.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#sat"><i class="fa fa-check"></i><b>11.2.1</b> SAT</a></li><li class="chapter" data-level="11.2.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-linear-equations"><i class="fa fa-check"></i><b>11.2.2</b> Solving linear equations</a></li><li class="chapter" data-level="11.2.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#solving-quadratic-equations"><i class="fa fa-check"></i><b>11.2.3</b> Solving quadratic equations</a></li></ul></li><li class="chapter" data-level="11.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#more-advanced-examples"><i class="fa fa-check"></i><b>11.3</b> More advanced examples</a><ul><li class="chapter" data-level="11.3.1" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>11.3.1</b> Determinant of a matrix</a></li><li class="chapter" data-level="11.3.2" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#permanent-of-a-matrix"><i class="fa fa-check"></i><b>11.3.2</b> Permanent of a matrix</a></li><li class="chapter" data-level="11.3.3" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-zero-sum-equilibrium"><i class="fa fa-check"></i><b>11.3.3</b> Finding a zero-sum equilibrium</a></li><li class="chapter" data-level="11.3.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#finding-a-nash-equilibrium"><i class="fa fa-check"></i><b>11.3.4</b> Finding a Nash equilibrium</a></li><li class="chapter" data-level="11.3.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#primality-testing"><i class="fa fa-check"></i><b>11.3.5</b> Primality testing</a></li><li class="chapter" data-level="11.3.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#integer-factoring"><i class="fa fa-check"></i><b>11.3.6</b> Integer factoring</a></li></ul></li><li class="chapter" data-level="11.4" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#our-current-knowledge"><i class="fa fa-check"></i><b>11.4</b> Our current knowledge</a></li><li class="chapter" data-level="11.5" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#exercises"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li><li class="chapter" data-level="11.6" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#effalgnotes"><i class="fa fa-check"></i><b>11.6</b> Bibliographical notes</a></li><li class="chapter" data-level="11.7" data-path="lec_10_efficient_alg.html"><a href="lec_10_efficient_alg.html#further-explorations"><i class="fa fa-check"></i><b>11.7</b> Further explorations</a></li></ul></li><li class="chapter" data-level="12" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html"><i class="fa fa-check"></i><b>12</b> Modeling running time</a><ul><li class="chapter" data-level="12.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#formally-defining-running-time"><i class="fa fa-check"></i><b>12.1</b> Formally defining running time</a><ul><li class="chapter" data-level="12.1.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#polynomial-and-exponential-time"><i class="fa fa-check"></i><b>12.1.1</b> Polynomial and Exponential Time</a></li></ul></li><li class="chapter" data-level="12.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#modeling-running-time-using-ram-machines-nand-ram"><i class="fa fa-check"></i><b>12.2</b> Modeling running time using RAM Machines / NAND-RAM</a></li><li class="chapter" data-level="12.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#ECTTsec"><i class="fa fa-check"></i><b>12.3</b> Extended Church-Turing Thesis (discussion)</a></li><li class="chapter" data-level="12.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#efficient-universal-machine-a-nand-ram-interpreter-in-nand-ram"><i class="fa fa-check"></i><b>12.4</b> Efficient universal machine: a NAND-RAM interpreter in NAND-RAM</a><ul><li class="chapter" data-level="12.4.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#timed-universal-turing-machine"><i class="fa fa-check"></i><b>12.4.1</b> Timed Universal Turing Machine</a></li></ul></li><li class="chapter" data-level="12.5" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#the-time-hierarchy-theorem"><i class="fa fa-check"></i><b>12.5</b> The time hierarchy theorem</a></li><li class="chapter" data-level="12.6" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#nonuniformcompsec"><i class="fa fa-check"></i><b>12.6</b> Non uniform computation</a><ul><li class="chapter" data-level="12.6.1" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#obliviousnandtm"><i class="fa fa-check"></i><b>12.6.1</b> Oblivious NAND-TM programs</a></li><li class="chapter" data-level="12.6.2" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#unrollloopsec"><i class="fa fa-check"></i><b>12.6.2</b> Unrolling the loop: algorithmic transformation of Turing Machines to circuits</a></li><li class="chapter" data-level="12.6.3" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#can-uniform-algorithms-simulate-non-uniform-ones"><i class="fa fa-check"></i><b>12.6.3</b> Can uniform algorithms simulate non uniform ones?</a></li><li class="chapter" data-level="12.6.4" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#uniform-vs.-nonuniform-computation-a-recap"><i class="fa fa-check"></i><b>12.6.4</b> Uniform vs. Nonuniform computation: A recap</a></li></ul></li><li class="chapter" data-level="12.7" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#exercises"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li><li class="chapter" data-level="12.8" data-path="lec_11_running_time.html"><a href="lec_11_running_time.html#bibnotesrunningtime"><i class="fa fa-check"></i><b>12.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="13" data-path="lec_12_NP.html"><a href="lec_12_NP.html"><i class="fa fa-check"></i><b>13</b> Polynomial-time reductions</a><ul><li class="chapter" data-level="13.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#formaldefdecisionexamplessec"><i class="fa fa-check"></i><b>13.1</b> Formal definitions of problems</a></li><li class="chapter" data-level="13.2" data-path="lec_12_NP.html"><a href="lec_12_NP.html#polytimeredsec"><i class="fa fa-check"></i><b>13.2</b> Polynomial-time reductions</a></li><li class="chapter" data-level="13.3" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-zero-one-equations"><i class="fa fa-check"></i><b>13.3</b> Reducing 3SAT to zero one equations</a><ul><li class="chapter" data-level="13.3.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#quadratic-equations"><i class="fa fa-check"></i><b>13.3.1</b> Quadratic equations</a></li></ul></li><li class="chapter" data-level="13.4" data-path="lec_12_NP.html"><a href="lec_12_NP.html#the-independent-set-problem"><i class="fa fa-check"></i><b>13.4</b> The independent set problem</a></li><li class="chapter" data-level="13.5" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-independent-set-to-maximum-cut"><i class="fa fa-check"></i><b>13.5</b> Reducing Independent Set to Maximum Cut</a></li><li class="chapter" data-level="13.6" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reducing-3sat-to-longest-path"><i class="fa fa-check"></i><b>13.6</b> Reducing 3SAT to Longest Path</a><ul><li class="chapter" data-level="13.6.1" data-path="lec_12_NP.html"><a href="lec_12_NP.html#summary-of-relations"><i class="fa fa-check"></i><b>13.6.1</b> Summary of relations</a></li></ul></li><li class="chapter" data-level="13.7" data-path="lec_12_NP.html"><a href="lec_12_NP.html#exercises"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li><li class="chapter" data-level="13.8" data-path="lec_12_NP.html"><a href="lec_12_NP.html#reductionsbibnotes"><i class="fa fa-check"></i><b>13.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="14" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html"><i class="fa fa-check"></i><b>14</b> NP, NP completeness, and the Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-class-mathbfnp"><i class="fa fa-check"></i><b>14.1</b> The class \mathbf{NP}</a><ul><li class="chapter" data-level="14.1.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#examples-of-functions-in-mathbfnp"><i class="fa fa-check"></i><b>14.1.1</b> Examples of functions in \mathbf{NP}</a></li><li class="chapter" data-level="14.1.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#basic-facts-about-mathbfnp"><i class="fa fa-check"></i><b>14.1.2</b> Basic facts about \mathbf{NP}</a></li></ul></li><li class="chapter" data-level="14.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-mathbfnp-to-3sat-the-cook-levin-theorem"><i class="fa fa-check"></i><b>14.2</b> From \mathbf{NP} to 3SAT: The Cook-Levin Theorem</a><ul><li class="chapter" data-level="14.2.1" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#what-does-this-mean"><i class="fa fa-check"></i><b>14.2.1</b> What does this mean?</a></li><li class="chapter" data-level="14.2.2" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-cook-levin-theorem-proof-outline"><i class="fa fa-check"></i><b>14.2.2</b> The Cook-Levin Theorem: Proof outline</a></li></ul></li><li class="chapter" data-level="14.3" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-nandsat-problem-and-why-it-is-mathbfnp-hard."><i class="fa fa-check"></i><b>14.3</b> The \ensuremath{\mathit{NANDSAT}} Problem, and why it is \mathbf{NP} hard.</a></li><li class="chapter" data-level="14.4" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#the-3nand-problem"><i class="fa fa-check"></i><b>14.4</b> The 3\ensuremath{\mathit{NAND}} problem</a></li><li class="chapter" data-level="14.5" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#from-3nand-to-3sat"><i class="fa fa-check"></i><b>14.5</b> From 3\ensuremath{\mathit{NAND}} to 3\ensuremath{\mathit{SAT}}</a></li><li class="chapter" data-level="14.6" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#wrapping-up"><i class="fa fa-check"></i><b>14.6</b> Wrapping up</a></li><li class="chapter" data-level="14.7" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#exercises"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li><li class="chapter" data-level="14.8" data-path="lec_13_Cook_Levin.html"><a href="lec_13_Cook_Levin.html#bibliographical-notes"><i class="fa fa-check"></i><b>14.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="15" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html"><i class="fa fa-check"></i><b>15</b> What if P equals NP?</a><ul><li class="chapter" data-level="15.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#search-to-decision-reduction"><i class="fa fa-check"></i><b>15.1</b> Search-to-decision reduction</a></li><li class="chapter" data-level="15.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#optimizationsection"><i class="fa fa-check"></i><b>15.2</b> Optimization</a><ul><li class="chapter" data-level="15.2.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-supervised-learning"><i class="fa fa-check"></i><b>15.2.1</b> Example: Supervised learning</a></li><li class="chapter" data-level="15.2.2" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#example-breaking-cryptosystems"><i class="fa fa-check"></i><b>15.2.2</b> Example: Breaking cryptosystems</a></li></ul></li><li class="chapter" data-level="15.3" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#finding-mathematical-proofs"><i class="fa fa-check"></i><b>15.3</b> Finding mathematical proofs</a></li><li class="chapter" data-level="15.4" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#quantifier-elimination-advanced"><i class="fa fa-check"></i><b>15.4</b> Quantifier elimination (advanced)</a><ul><li class="chapter" data-level="15.4.1" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#selfimprovingsat"><i class="fa fa-check"></i><b>15.4.1</b> Application: self improving algorithm for 3\ensuremath{\mathit{SAT}}</a></li></ul></li><li class="chapter" data-level="15.5" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#approximating-counting-problems-and-posterior-sampling-advanced-optional"><i class="fa fa-check"></i><b>15.5</b> Approximating counting problems and posterior sampling (advanced, optional)</a></li><li class="chapter" data-level="15.6" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-does-all-of-this-imply"><i class="fa fa-check"></i><b>15.6</b> What does all of this imply?</a></li><li class="chapter" data-level="15.7" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#can-mathbfp-neq-mathbfnp-be-neither-true-nor-false"><i class="fa fa-check"></i><b>15.7</b> Can \mathbf{P} \neq \mathbf{NP} be neither true nor false?</a></li><li class="chapter" data-level="15.8" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#is-mathbfpmathbfnp-in-practice"><i class="fa fa-check"></i><b>15.8</b> Is \mathbf{P}=\mathbf{NP} in practice?</a></li><li class="chapter" data-level="15.9" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#what-if-mathbfp-neq-mathbfnp"><i class="fa fa-check"></i><b>15.9</b> What if \mathbf{P} \neq \mathbf{NP}?</a></li><li class="chapter" data-level="15.10" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#exercises"><i class="fa fa-check"></i><b>15.10</b> Exercises</a></li><li class="chapter" data-level="15.11" data-path="lec_14_PvsNP.html"><a href="lec_14_PvsNP.html#bibliographical-notes"><i class="fa fa-check"></i><b>15.11</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="16" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html"><i class="fa fa-check"></i><b>16</b> Space bounded computation</a><ul><li class="chapter" data-level="16.1" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#lecture-summary"><i class="fa fa-check"></i><b>16.1</b> Lecture summary</a></li><li class="chapter" data-level="16.2" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#exercises"><i class="fa fa-check"></i><b>16.2</b> Exercises</a></li><li class="chapter" data-level="16.3" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#bibliographical-notes"><i class="fa fa-check"></i><b>16.3</b> Bibliographical notes</a></li><li class="chapter" data-level="16.4" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#further-explorations"><i class="fa fa-check"></i><b>16.4</b> Further explorations</a></li><li class="chapter" data-level="16.5" data-path="lec_14a_space_complexity.html"><a href="lec_14a_space_complexity.html#acknowledgements"><i class="fa fa-check"></i><b>16.5</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="17" data-path="lec_15_probability.html"><a href="lec_15_probability.html"><i class="fa fa-check"></i><b>17</b> Probability Theory 101</a><ul><li class="chapter" data-level="17.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-coins"><i class="fa fa-check"></i><b>17.1</b> Random coins</a><ul><li class="chapter" data-level="17.1.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#random-variables"><i class="fa fa-check"></i><b>17.1.1</b> Random variables</a></li><li class="chapter" data-level="17.1.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#distributions-over-strings"><i class="fa fa-check"></i><b>17.1.2</b> Distributions over strings</a></li><li class="chapter" data-level="17.1.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>17.1.3</b> More general sample spaces.</a></li></ul></li><li class="chapter" data-level="17.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#correlations-and-independence"><i class="fa fa-check"></i><b>17.2</b> Correlations and independence</a><ul><li class="chapter" data-level="17.2.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#independent-random-variables"><i class="fa fa-check"></i><b>17.2.1</b> Independent random variables</a></li><li class="chapter" data-level="17.2.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>17.2.2</b> Collections of independent random variables.</a></li></ul></li><li class="chapter" data-level="17.3" data-path="lec_15_probability.html"><a href="lec_15_probability.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>17.3</b> Concentration and tail bounds</a><ul><li class="chapter" data-level="17.3.1" data-path="lec_15_probability.html"><a href="lec_15_probability.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>17.3.1</b> Chebyshev’s Inequality</a></li><li class="chapter" data-level="17.3.2" data-path="lec_15_probability.html"><a href="lec_15_probability.html#the-chernoff-bound"><i class="fa fa-check"></i><b>17.3.2</b> The Chernoff bound</a></li></ul></li><li class="chapter" data-level="17.4" data-path="lec_15_probability.html"><a href="lec_15_probability.html#exercises"><i class="fa fa-check"></i><b>17.4</b> Exercises</a></li><li class="chapter" data-level="17.5" data-path="lec_15_probability.html"><a href="lec_15_probability.html#bibliographical-notes"><i class="fa fa-check"></i><b>17.5</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="18" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html"><i class="fa fa-check"></i><b>18</b> Probabilistic computation</a><ul><li class="chapter" data-level="18.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#finding-approximately-good-maximum-cuts."><i class="fa fa-check"></i><b>18.1</b> Finding approximately good maximum cuts.</a><ul><li class="chapter" data-level="18.1.1" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#amplifying-the-success-of-randomized-algorithms"><i class="fa fa-check"></i><b>18.1.1</b> Amplifying the success of randomized algorithms</a></li><li class="chapter" data-level="18.1.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#success-amplification"><i class="fa fa-check"></i><b>18.1.2</b> Success amplification</a></li><li class="chapter" data-level="18.1.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#two-sided-amplification"><i class="fa fa-check"></i><b>18.1.3</b> Two-sided amplification</a></li><li class="chapter" data-level="18.1.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#what-does-this-mean"><i class="fa fa-check"></i><b>18.1.4</b> What does this mean?</a></li><li class="chapter" data-level="18.1.5" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#solving-sat-through-randomization"><i class="fa fa-check"></i><b>18.1.5</b> Solving SAT through randomization</a></li><li class="chapter" data-level="18.1.6" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bipartite-matching."><i class="fa fa-check"></i><b>18.1.6</b> Bipartite matching.</a></li></ul></li><li class="chapter" data-level="18.2" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#exercises"><i class="fa fa-check"></i><b>18.2</b> Exercises</a></li><li class="chapter" data-level="18.3" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#bibliographical-notes"><i class="fa fa-check"></i><b>18.3</b> Bibliographical notes</a></li><li class="chapter" data-level="18.4" data-path="lec_16_randomized_alg.html"><a href="lec_16_randomized_alg.html#acknowledgements"><i class="fa fa-check"></i><b>18.4</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="19" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html"><i class="fa fa-check"></i><b>19</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modeling-randomized-computation"><i class="fa fa-check"></i><b>19.1</b> Modeling randomized computation</a><ul><li class="chapter" data-level="19.1.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#an-alternative-view-random-coins-as-an-extra-input"><i class="fa fa-check"></i><b>19.1.1</b> An alternative view: random coins as an extra input</a></li><li class="chapter" data-level="19.1.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#successamptwosided"><i class="fa fa-check"></i><b>19.1.2</b> Success amplification of two-sided error algorithms</a></li></ul></li><li class="chapter" data-level="19.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfbpp-and-mathbfnp-completeness"><i class="fa fa-check"></i><b>19.2</b> \mathbf{BPP} and \mathbf{NP} completeness</a></li><li class="chapter" data-level="19.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#the-power-of-randomization"><i class="fa fa-check"></i><b>19.3</b> The power of randomization</a><ul><li class="chapter" data-level="19.3.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#solving-mathbfbpp-in-exponential-time"><i class="fa fa-check"></i><b>19.3.1</b> Solving \mathbf{BPP} in exponential time</a></li><li class="chapter" data-level="19.3.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#simulating-randomized-algorithms-by-circuits"><i class="fa fa-check"></i><b>19.3.2</b> Simulating randomized algorithms by circuits</a></li></ul></li><li class="chapter" data-level="19.4" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#derandomization"><i class="fa fa-check"></i><b>19.4</b> Derandomization</a><ul><li class="chapter" data-level="19.4.1" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.1</b> Pseudorandom generators</a></li><li class="chapter" data-level="19.4.2" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#optimalprgconj"><i class="fa fa-check"></i><b>19.4.2</b> From existence to constructivity</a></li><li class="chapter" data-level="19.4.3" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#usefulness-of-pseudorandom-generators"><i class="fa fa-check"></i><b>19.4.3</b> Usefulness of pseudorandom generators</a></li></ul></li><li class="chapter" data-level="19.5" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#mathbfpmathbfnp-and-mathbfbpp-vs-mathbfp"><i class="fa fa-check"></i><b>19.5</b> \mathbf{P}=\mathbf{NP} and \mathbf{BPP} vs \mathbf{P}</a></li><li class="chapter" data-level="19.6" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#non-constructive-existence-of-pseudorandom-generators-advanced-optional"><i class="fa fa-check"></i><b>19.6</b> Non-constructive existence of pseudorandom generators (advanced, optional)</a></li><li class="chapter" data-level="19.7" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li><li class="chapter" data-level="19.8" data-path="lec_17_model_rand.html"><a href="lec_17_model_rand.html#modelrandbibnotes"><i class="fa fa-check"></i><b>19.8</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="20" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html"><i class="fa fa-check"></i><b>20</b> Cryptography</a><ul><li class="chapter" data-level="20.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#classical-cryptosystems"><i class="fa fa-check"></i><b>20.1</b> Classical cryptosystems</a></li><li class="chapter" data-level="20.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-encryption"><i class="fa fa-check"></i><b>20.2</b> Defining encryption</a></li><li class="chapter" data-level="20.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>20.3</b> Defining security of encryption</a></li><li class="chapter" data-level="20.4" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#perfect-secrecy"><i class="fa fa-check"></i><b>20.4</b> Perfect secrecy</a><ul><li class="chapter" data-level="20.4.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#example-perfect-secrecy-in-the-battlefield"><i class="fa fa-check"></i><b>20.4.1</b> Example: Perfect secrecy in the battlefield</a></li><li class="chapter" data-level="20.4.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#constructing-perfectly-secret-encryption"><i class="fa fa-check"></i><b>20.4.2</b> Constructing perfectly secret encryption</a></li></ul></li><li class="chapter" data-level="20.5" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>20.5</b> Necessity of long keys</a></li><li class="chapter" data-level="20.6" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy"><i class="fa fa-check"></i><b>20.6</b> Computational secrecy</a><ul><li class="chapter" data-level="20.6.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#stream-ciphers-or-the-derandomized-one-time-pad"><i class="fa fa-check"></i><b>20.6.1</b> Stream ciphers or the derandomized one-time pad</a></li></ul></li><li class="chapter" data-level="20.7" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#computational-secrecy-and-mathbfnp"><i class="fa fa-check"></i><b>20.7</b> Computational secrecy and \mathbf{NP}</a></li><li class="chapter" data-level="20.8" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#public-key-cryptography"><i class="fa fa-check"></i><b>20.8</b> Public key cryptography</a><ul><li class="chapter" data-level="20.8.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#defining-public-key-encryption"><i class="fa fa-check"></i><b>20.8.1</b> Defining public key encryption</a></li><li class="chapter" data-level="20.8.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#diffie-hellman-key-exchange"><i class="fa fa-check"></i><b>20.8.2</b> Diffie-Hellman key exchange</a></li></ul></li><li class="chapter" data-level="20.9" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#other-security-notions"><i class="fa fa-check"></i><b>20.9</b> Other security notions</a></li><li class="chapter" data-level="20.10" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#magic"><i class="fa fa-check"></i><b>20.10</b> Magic</a><ul><li class="chapter" data-level="20.10.1" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#zero-knowledge-proofs"><i class="fa fa-check"></i><b>20.10.1</b> Zero knowledge proofs</a></li><li class="chapter" data-level="20.10.2" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#fully-homomorphic-encryption"><i class="fa fa-check"></i><b>20.10.2</b> Fully homomorphic encryption</a></li><li class="chapter" data-level="20.10.3" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#multiparty-secure-computation"><i class="fa fa-check"></i><b>20.10.3</b> Multiparty secure computation</a></li></ul></li><li class="chapter" data-level="20.11" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#exercises"><i class="fa fa-check"></i><b>20.11</b> Exercises</a></li><li class="chapter" data-level="20.12" data-path="lec_19_cryptography.html"><a href="lec_19_cryptography.html#bibliographical-notes"><i class="fa fa-check"></i><b>20.12</b> Bibliographical notes</a></li></ul></li><li class="chapter" data-level="21" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html"><i class="fa fa-check"></i><b>21</b> Proofs and algorithms</a><ul><li class="chapter" data-level="21.1" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#lecture-summary"><i class="fa fa-check"></i><b>21.1</b> Lecture summary</a></li><li class="chapter" data-level="21.2" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#exercises"><i class="fa fa-check"></i><b>21.2</b> Exercises</a></li><li class="chapter" data-level="21.3" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#bibliographical-notes"><i class="fa fa-check"></i><b>21.3</b> Bibliographical notes</a></li><li class="chapter" data-level="21.4" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#further-explorations"><i class="fa fa-check"></i><b>21.4</b> Further explorations</a></li><li class="chapter" data-level="21.5" data-path="lec_24_proofs.html"><a href="lec_24_proofs.html#acknowledgements"><i class="fa fa-check"></i><b>21.5</b> Acknowledgements</a></li></ul></li><li class="chapter" data-level="22" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html"><i class="fa fa-check"></i><b>22</b> Quantum computing</a><ul><li class="chapter" data-level="22.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>22.1</b> The double slit experiment</a></li><li class="chapter" data-level="22.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes"><i class="fa fa-check"></i><b>22.2</b> Quantum amplitudes</a><ul><li class="chapter" data-level="22.2.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#linear-algebra-quick-review"><i class="fa fa-check"></i><b>22.2.1</b> Linear algebra quick review</a></li></ul></li><li class="chapter" data-level="22.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#bellineqsec"><i class="fa fa-check"></i><b>22.3</b> Bell’s Inequality</a></li><li class="chapter" data-level="22.4" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-weirdness"><i class="fa fa-check"></i><b>22.4</b> Quantum weirdness</a></li><li class="chapter" data-level="22.5" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>22.5</b> Quantum computing and computation - an executive summary.</a></li><li class="chapter" data-level="22.6" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems"><i class="fa fa-check"></i><b>22.6</b> Quantum systems</a><ul><li class="chapter" data-level="22.6.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-amplitudes-1"><i class="fa fa-check"></i><b>22.6.1</b> Quantum amplitudes</a></li><li class="chapter" data-level="22.6.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-systems-an-executive-summary"><i class="fa fa-check"></i><b>22.6.2</b> Quantum systems: an executive summary</a></li></ul></li><li class="chapter" data-level="22.7" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#analysis-of-bells-inequality-optional"><i class="fa fa-check"></i><b>22.7</b> Analysis of Bell’s Inequality (optional)</a></li><li class="chapter" data-level="22.8" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-computation"><i class="fa fa-check"></i><b>22.8</b> Quantum computation</a><ul><li class="chapter" data-level="22.8.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-circuits"><i class="fa fa-check"></i><b>22.8.1</b> Quantum circuits</a></li><li class="chapter" data-level="22.8.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#qnand-circ-programs-optional"><i class="fa fa-check"></i><b>22.8.2</b> QNAND-CIRC programs (optional)</a></li><li class="chapter" data-level="22.8.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#uniform-computation"><i class="fa fa-check"></i><b>22.8.3</b> Uniform computation</a></li></ul></li><li class="chapter" data-level="22.9" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>22.9</b> Physically realizing quantum computation</a></li><li class="chapter" data-level="22.10" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-hearing-the-shape-of-prime-factors"><i class="fa fa-check"></i><b>22.10</b> Shor’s Algorithm: Hearing the shape of prime factors</a><ul><li class="chapter" data-level="22.10.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#period-finding"><i class="fa fa-check"></i><b>22.10.1</b> Period finding</a></li><li class="chapter" data-level="22.10.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#shors-algorithm-a-birds-eye-view"><i class="fa fa-check"></i><b>22.10.2</b> Shor’s Algorithm: A bird’s eye view</a></li></ul></li><li class="chapter" data-level="22.11" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-advanced-optional"><i class="fa fa-check"></i><b>22.11</b> Quantum Fourier Transform (advanced, optional)</a><ul><li class="chapter" data-level="22.11.1" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantum-fourier-transform-over-the-boolean-cube-simons-algorithm"><i class="fa fa-check"></i><b>22.11.1</b> Quantum Fourier Transform over the Boolean Cube: Simon’s Algorithm</a></li><li class="chapter" data-level="22.11.2" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-fourier-to-period-finding-simons-algorithm-advanced-optional"><i class="fa fa-check"></i><b>22.11.2</b> From Fourier to Period finding: Simon’s Algorithm (advanced, optional)</a></li><li class="chapter" data-level="22.11.3" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#from-simon-to-shor-advanced-optional"><i class="fa fa-check"></i><b>22.11.3</b> From Simon to Shor (advanced, optional)</a></li></ul></li><li class="chapter" data-level="22.12" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#exercises"><i class="fa fa-check"></i><b>22.12</b> Exercises</a></li><li class="chapter" data-level="22.13" data-path="lec_26_quantum_computing.html"><a href="lec_26_quantum_computing.html#quantumbibnotessec"><i class="fa fa-check"></i><b>22.13</b> Bibliographical notes</a></li></ul></li><li class="divider"></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-header" role="navigation">
      <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">What if P equals NP?</a>
      </h1>
    </div>

    <div class="book-body">
      <div class="body-inner">


        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->

<div  class="section level2">

<!-- link to pdf version -->


<!-- start of header referring to comments -->
<div><p></p><p style="color:#871640;"><i class="fas fa-wrench"></i> See any bugs/typos/confusing explanations? <a href="https://github.com/boazbk/tcs/issues/new">Open a GitHub issue</a>. You can also <a href="#commentform">comment below</a> <i class="fas fa-wrench"></i></p></div>



<div><p style="color:#871640;">&#x2605; See also the <a id="pdflink" href='https://files.boazbarak.org/introtcs/lec_14_PvsNP.pdf'><b>PDF version of this chapter</b></a> (better formatting/references) &#x2605;</p></div>

<!-- end of header referring to comments -->

<!--- start of actual content -->

<h1 id="chappvsnp" data-number="15">What if P equals NP?</h1>
<div id="section" class="objectives" name="Objectives">
<ul>
<li>Explore the consequences of <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span><br />
</li>
<li><em>Search-to-decision</em> reduction: transform algorithms that solve decision version to search version for <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete problems.<br />
</li>
<li>Optimization and learning problems<br />
</li>
<li>Quantifier elimination and solving problems in the polynomial hierarchy.<br />
</li>
<li>What is the evidence for <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> vs <span><span class="math inline">\(\mathbf{P}\neq \mathbf{NP}\)</span></span>?</li>
</ul>
</div>
<blockquote>
<p><em>“You don’t have to believe in God, but you should believe in The Book.”</em>, Paul Erdős, 1985.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>
</blockquote>
<blockquote>
<p><em>“No more half measures, Walter”</em>, Mike Ehrmantraut in “Breaking Bad”, 2010.</p>
</blockquote>
<blockquote>
<p><em>“The evidence in favor of [<span><span class="math inline">\(\mathbf{P}\neq \mathbf{NP}\)</span></span>] and [ its algebraic counterpart ] is so overwhelming, and the consequences of their failure are so grotesque, that their status may perhaps be compared to that of physical laws rather than that of ordinary mathematical conjectures.”</em>, Volker Strassen, laudation for Leslie Valiant, 1986.</p>
</blockquote>
<blockquote>
<p><em>“Suppose aliens invade the earth and threaten to obliterate it in a year’s time unless human beings can find the [fifth Ramsey number]. We could marshal the world’s best minds and fastest computers, and within a year we could probably calculate the value. If the aliens demanded the [sixth Ramsey number], however, we would have no choice but to launch a preemptive attack.”</em>, Paul Erdős, as quoted by Graham and Spencer, 1990.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>
</blockquote>
<p>We have mentioned that the question of whether <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, which is equivalent to whether there is a polynomial-time algorithm for <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span>, is the great open question of Computer Science. But why is it so important? In this chapter, we will try to figure out the implications of such an algorithm.</p>
<p>First, let us get one qualm out of the way. Sometimes people say, <em>“What if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> but the best algorithm for 3SAT takes <span><span class="math inline">\(n^{1000}\)</span></span> time?”</em> Well, <span><span class="math inline">\(n^{1000}\)</span></span> is much larger than, say, <span><span class="math inline">\(2^{0.001\sqrt{n}}\)</span></span> for any input smaller than <span><span class="math inline">\(2^{50}\)</span></span>, as large as a harddrive as you will encounter, and so another way to phrase this question is to say “what if the complexity of 3SAT is exponential for all inputs that we will ever encounter, but then grows much smaller than that?” To me this sounds like the computer science equivalent of asking, “what if the laws of physics change completely once they are out of the range of our telescopes?”. Sure, this is a valid possibility, but wondering about it does not sound like the most productive use of our time.</p>
<p>So, as the saying goes, we’ll keep an open mind, but not so open that our brains fall out, and assume from now on that:</p>
<ul>
<li>There is a mathematical god,</li>
</ul>
<p>and</p>
<ul>
<li>She does not “pussyfoot around” or take “half measures”.</li>
</ul>
<p>What we mean by this is that we will consider two extreme scenarios:</p>
<ul>
<li><p><strong>3SAT is very easy:</strong> <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> has an <span><span class="math inline">\(O(n)\)</span></span> or <span><span class="math inline">\(O(n^2)\)</span></span> time algorithm with a not too huge constant (say smaller than <span><span class="math inline">\(10^6\)</span></span>.)</p></li>
<li><p><strong>3SAt is very hard:</strong> <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> is exponentially hard and cannot be solved faster than <span><span class="math inline">\(2^{\epsilon n}\)</span></span> for some not too tiny <span><span class="math inline">\(\epsilon&gt;0\)</span></span> (say at least <span><span class="math inline">\(10^{-6}\)</span></span>). We can even make the stronger assumption that for every sufficiently large <span><span class="math inline">\(n\)</span></span>, the restriction of <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> to inputs of length <span><span class="math inline">\(n\)</span></span> cannot be computer by a circuit of fewer than <span><span class="math inline">\(2^{\epsilon n}\)</span></span> gates.</p></li>
</ul>
<p>At the time of writing, the fastest known algorithm for <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> requires more than <span><span class="math inline">\(2^{0.35 n}\)</span></span> to solve <span><span class="math inline">\(n\)</span></span> variable formulas, while we do not even know how to rule out the possibility that we can compute <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> using <span><span class="math inline">\(10n\)</span></span> gates. To put it in perspective, for the case <span><span class="math inline">\(n=1000\)</span></span> our lower and upper bounds for the computational costs are apart by a factor of about <span><span class="math inline">\(10^{100}\)</span></span>. As far as we know, it could be the case that <span><span class="math inline">\(1000\)</span></span>-variable <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> can be solved in a millisecond on a first-generation iPhone, and it can also be the case that such instances require more than the age of the universe to solve on the world’s fastest supercomputer.</p>
<p>So far, most of our evidence points to the latter possibility of 3SAT being exponentially hard, but we have not ruled out the former possibility either. In this chapter we will explore some of the consequences of the “<span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> easy” scenario.</p>
<h2 id="search-to-decision-reduction" data-number="15.1">Search-to-decision reduction</h2>
<p>A priori, having a fast algorithm for 3SAT might not seem so impressive. Sure, such an algorithm allows us to decide the satisfiability of not just 3CNF formulas but also of quadratic equations, as well as find out whether there is a long path in a graph, and solve many other decision problems. But this is not typically what we want to do. It’s not enough to know <em>if</em> a formula is satisfiable: we want to discover the actual satisfying assignment. Similarly, it’s not enough to find out if a graph has a long path: we want to actually <em>find</em> the path.</p>
<p>It turns out that if we can solve these decision problems, we can solve the corresponding search problems as well:</p>
<div id="search-dec-thm" class="theorem" title="Search vs Decision" name="Theorem 15.1 (Search vs Decision) ">
<p>Suppose that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>. Then for every polynomial-time algorithm <span><span class="math inline">\(V\)</span></span> and <span><span class="math inline">\(a,b \in \N\)</span></span>,there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{FIND}}_V\)</span></span> such that for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, if there exists <span><span class="math inline">\(y\in \{0,1\}^{an^b}\)</span></span> satisfying <span><span class="math inline">\(V(xy)=1\)</span></span>, then <span><span class="math inline">\(\ensuremath{\mathit{FIND}}_V(x)\)</span></span> finds some string <span><span class="math inline">\(y&#39;\)</span></span> satisfying this condition.</p>
</div>
<div id="section-1" class="pause" name="Pause">
<p>To understand what the statement of <a href='#search-dec-thm'>Theorem 15.1</a> means, let us look at the special case of the <span><span class="math inline">\(\ensuremath{\mathit{MAXCUT}}\)</span></span> problem. It is not hard to see that there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{VERIFYCUT}}\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{VERIFYCUT}}(G,k,S)=1\)</span></span> if and only if <span><span class="math inline">\(S\)</span></span> is a subset of <span><span class="math inline">\(G\)</span></span>’s vertices that cuts at least <span><span class="math inline">\(k\)</span></span> edges. <a href='#search-dec-thm'>Theorem 15.1</a> implies that if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{FINDCUT}}\)</span></span> that on input <span><span class="math inline">\(G,k\)</span></span> outputs a set <span><span class="math inline">\(S\)</span></span> such that <span><span class="math inline">\(\ensuremath{\mathit{VERIFYCUT}}(G,k,S)=1\)</span></span> if such a set exists. This means that if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, by trying all values of <span><span class="math inline">\(k\)</span></span> we can find in polynomial time a maximum cut in any given graph. We can use a similar argument to show that if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can find a satisfying assignment for every satisfiable 3CNF formula, find the longest path in a graph, solve integer programming, and so and so forth.</p>
</div>
<div id="section-2" class="proofidea" data-ref="search-dec-thm" name="Proofidea">
<p>The idea behind the proof of <a href='#search-dec-thm'>Theorem 15.1</a> is simple; let us demonstrate it for the special case of <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span>. (In fact, this case is not so “special”<span><span class="math inline">\(-\)</span></span> since <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> is <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete, we can reduce the task of solving the search problem for <span><span class="math inline">\(\ensuremath{\mathit{MAXCUT}}\)</span></span> or any other problem in <span><span class="math inline">\(\mathbf{NP}\)</span></span> to the task of solving it for <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span>.) Suppose that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> and we are given a satisfiable 3CNF formula <span><span class="math inline">\(\varphi\)</span></span>, and we now want to find a satisfying assignment <span><span class="math inline">\(y\)</span></span> for <span><span class="math inline">\(\varphi\)</span></span>. Define <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}_0(\varphi)\)</span></span> to output <span><span class="math inline">\(1\)</span></span> if there is a satisfying assignment <span><span class="math inline">\(y\)</span></span> for <span><span class="math inline">\(\varphi\)</span></span> such that its first bit is <span><span class="math inline">\(0\)</span></span>, and similarly define <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}_1(\varphi)=1\)</span></span> if there is a satisfying assignment <span><span class="math inline">\(y\)</span></span> with <span><span class="math inline">\(y_0=1\)</span></span>. The key observation is that both <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}_0\)</span></span> and <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}_1\)</span></span> are in <span><span class="math inline">\(\mathbf{NP}\)</span></span>, and so if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can compute them in polynomial time as well. Thus we can use this to find the first bit of the satisfying assignment. We can continue in this way to recover all the bits.</p>
</div>
<div class="proof" data-ref="search-dec-thm" name="Proof 15.1">
<p>Let <span><span class="math inline">\(V\)</span></span> be some polynomial time algorithm and <span><span class="math inline">\(a,b \in \N\)</span></span> some constants. Define the function <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V\)</span></span> as follows: For every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> and <span><span class="math inline">\(z \in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V(x,z)=1\)</span></span> if and only if there exists some <span><span class="math inline">\(y \in \{0,1\}^{an^b - |z|}\)</span></span> (where <span><span class="math inline">\(n=|x|)\)</span></span> such that <span><span class="math inline">\(V(xzy)=1\)</span></span>. That is, <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V(x,z)\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if there is some string <span><span class="math inline">\(w\)</span></span> of length <span><span class="math inline">\(a|x|^b\)</span></span> such that <span><span class="math inline">\(V(x,w)=1\)</span></span> and the first <span><span class="math inline">\(|z|\)</span></span> bits of <span><span class="math inline">\(w\)</span></span> are <span><span class="math inline">\(z_0,\ldots,z_{\ell-1}\)</span></span>. Since, given <span><span class="math inline">\(x,y,z\)</span></span> as above, we can check in polynomial time if <span><span class="math inline">\(V(xzy)=1\)</span></span>, the function <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V\)</span></span> is in <span><span class="math inline">\(\mathbf{NP}\)</span></span> and hence if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> we can compute it in polynomial time.</p>
<p>Now for every such polynomial-time <span><span class="math inline">\(V\)</span></span> and <span><span class="math inline">\(a,b\in\N\)</span></span>, we can implement <span><span class="math inline">\(\ensuremath{\mathit{FIND}}_V(x)\)</span></span> as follows:</p>
<div  class="pseudocodeoutput">
<div class="ps-root">
<div class="ps-algorithm with-caption" id = searchtodecisionalg>
<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;">
<span class="ps-keyword">Algorithm 2 </span>$FIND_V$: Search to decision reduction</p>
<div class="ps-algorithmic"><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">Input:</span>  \(x\in \{0,1\}^n\)<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">Output:</span>  \(z\in \{0,1\}^{an^b}\) s.t. \(V(xz)=1\), if such \(z\) exists. Otherwise output the empty string.<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> Initially \(z_0=z_1=\cdots=z_{an^b-1}=0\).<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">for</span>{\(\ell=0,\ldots,an^b-1\)} 
                <div class="ps-block" style="margin-left:1.2em;">
                <p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> Let \(b_0 \leftarrow STARTSWITH_V(xz_{0}\cdots z_{\ell-1}0)\).<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"> Let   \(b_1  \leftarrow STARTSWITH_V(xz_{0}\cdots z_{\ell-1}1)\).<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">if</span>{\(b_0=b_1=0\)} 
                <div class="ps-block" style="margin-left:1.2em;">
                <p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">return</span> ""  <span class="ps-comment"><i>#  Can't extend  \(xz_0\ldots z_{\ell-1</i></span>
</div><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">endif</span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">if</span>{\(b_0=1\)} 
                <div class="ps-block" style="margin-left:1.2em;">
                <p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;">  \(z_\ell \leftarrow 0\) <span class="ps-comment"><i>#  Can extend \(xz_0\ldots x_{\ell-1</i></span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">else</span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;">  \(z_\ell \leftarrow 1\) <span class="ps-comment"><i>#  Can extend \(xz_0\ldots x_{\ell-1</i></span>
</div><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">endif</span>
</div><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">endfor</span><p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"><span class="ps-keyword">return</span> \(z_0,\ldots,z_{an^b-1}\)<p class="ps-line" style="text-indent:-1.2em;padding-left:1.2em;"></div>
</div>
</div>
</div>
<p>To analyze <a href='#searchtodecisionalg'>Algorithm 15.2</a>, note that it makes <span><span class="math inline">\(2an^{b}\)</span></span> invocations to <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V\)</span></span> and hence if the latter is polynomial-time, then so is <a href='#searchtodecisionalg'>Algorithm 15.2</a> Now suppose that <span><span class="math inline">\(x\)</span></span> is such that there exists <em>some</em> <span><span class="math inline">\(y\)</span></span> satisfying <span><span class="math inline">\(V(xy)=1\)</span></span>. We claim that at every step <span><span class="math inline">\(\ell=0,\ldots,an^b-1\)</span></span>, we maintain the invariant that there exists <span><span class="math inline">\(y\in \{0,1\}^{an^b}\)</span></span> whose first <span><span class="math inline">\(\ell\)</span></span> bits are <span><span class="math inline">\(z\)</span></span> s.t. <span><span class="math inline">\(V(xy)=1\)</span></span>. Note that this claim implies the theorem, since in particular it means that for <span><span class="math inline">\(\ell = an^b-1\)</span></span>, <span><span class="math inline">\(z\)</span></span> satisfies <span><span class="math inline">\(V(xz)=1\)</span></span>.</p>
<p>We prove the claim by induction. For <span><span class="math inline">\(\ell=0\)</span></span>, this holds vacuously. Now for every <span><span class="math inline">\(\ell &gt; 0\)</span></span>, if the call <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V(xz_0\cdots z_{\ell-1}0)\)</span></span> returns <span><span class="math inline">\(1\)</span></span>, then we are guaranteed the invariant by definition of <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V\)</span></span>. Now under our inductive hypothesis, there is <span><span class="math inline">\(y_\ell,\ldots,y_{an^b-1}\)</span></span> such that <span><span class="math inline">\(P(xz_0,\ldots,z_{\ell-1}y_\ell,\ldots,y_{an^b-1})=1\)</span></span>. If the call to <span><span class="math inline">\(\ensuremath{\mathit{STARTSWITH}}_V(xz_0\cdots z_{\ell-1}0)\)</span></span> returns <span><span class="math inline">\(0\)</span></span> then it must be the case that <span><span class="math inline">\(y_\ell=1\)</span></span>, and hence when we set <span><span class="math inline">\(z_\ell=1\)</span></span> we maintain the invariant.</p>
</div>
<h2 id="optimizationsection" data-number="15.2">Optimization</h2>
<p><a href='#search-dec-thm'>Theorem 15.1</a> allows us to find solutions for <span><span class="math inline">\(\mathbf{NP}\)</span></span> problems if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, but it is not immediately clear that we can find the <em>optimal</em> solution. For example, suppose that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, and you are given a graph <span><span class="math inline">\(G\)</span></span>. Can you find the <em>longest</em> simple path in <span><span class="math inline">\(G\)</span></span> in polynomial time?</p>
<div id="section-3" class="pause" name="Pause">
<p>This is actually an excellent question for you to attempt on your own. That is, assuming <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, give a polynomial-time algorithm that on input a graph <span><span class="math inline">\(G\)</span></span>, outputs a maximally long simple path in the graph <span><span class="math inline">\(G\)</span></span>.</p>
</div>
<p>The answer is <em>Yes</em>. The idea is simple: if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can find out in polynomial time if an <span><span class="math inline">\(n\)</span></span>-vertex graph <span><span class="math inline">\(G\)</span></span> contains a simple path of length <span><span class="math inline">\(n\)</span></span>, and moreover, by <a href='#search-dec-thm'>Theorem 15.1</a>, if <span><span class="math inline">\(G\)</span></span> does contain such a path, then we can find it. (Can you see why?) If <span><span class="math inline">\(G\)</span></span> does not contain a simple path of length <span><span class="math inline">\(n\)</span></span>, then we will check if it contains a simple path of length <span><span class="math inline">\(n-1\)</span></span>, and continue in this way to find the largest <span><span class="math inline">\(k\)</span></span> such that <span><span class="math inline">\(G\)</span></span> contains a simple path of length <span><span class="math inline">\(k\)</span></span>.</p>
<p>The above reasoning was not specifically tailored to finding paths in graphs. In fact, it can be vastly generalized to proving the following result:</p>
<div id="optimizationnp" class="theorem" title="Optimization from $\mathbf{P}=\mathbf{NP}$" name="Theorem 15.3 (Optimization from $\mathbf{P}=\mathbf{NP}$) ">
<p>Suppose that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>. Then for every polynomial-time computable function <span><span class="math inline">\(f:\{0,1\}^* \rightarrow \N\)</span></span> (identifying <span><span class="math inline">\(f(x)\)</span></span> with natural numbers via the binary representation) there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{OPT}}\)</span></span> such that on input <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span>
<div class='myequationbox'><span class="math display">\[\ensuremath{\mathit{OPT}}(x,1^m) = \max_{y\in \{0,1\}^m} f(x,y) \;.\]</span></div></span></p>
<p>Moreover under the same assumption, there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{FINDOPT}}\)</span></span> such that for every <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{FINDOPT}}(x,1^m)\)</span></span> outputs <span><span class="math inline">\(y^* \in \{0,1\}^*\)</span></span> such that <span><span class="math inline">\(f(x,y^*)=\max_{y\in \{0,1\}^m} f(x,y)\)</span></span>.</p>
</div>
<div id="section-4" class="pause" name="Pause">
<p>The statement of <a href='#optimizationnp'>Theorem 15.3</a> is a bit cumbersome. To understand it, think how it would subsume the example above of a polynomial time algorithm for finding the maximum length path in a graph. In this case the function <span><span class="math inline">\(f\)</span></span> would be the map that on input a pair <span><span class="math inline">\(x,y\)</span></span> outputs <span><span class="math inline">\(0\)</span></span> if the pair <span><span class="math inline">\((x,y)\)</span></span> does not represent some graph and a simple path inside the graph respectively; otherwise <span><span class="math inline">\(f(x,y)\)</span></span> would equal the length of the path <span><span class="math inline">\(y\)</span></span> in the graph <span><span class="math inline">\(x\)</span></span>. Since a path in an <span><span class="math inline">\(n\)</span></span> vertex graph can be represented by at most <span><span class="math inline">\(n \log n\)</span></span> bits, for every <span><span class="math inline">\(x\)</span></span> representing a graph of <span><span class="math inline">\(n\)</span></span> vertices, finding <span><span class="math inline">\(\max_{y\in \{0,1\}^{n \log n}}f(x,y)\)</span></span> corresponds to finding the length of the maximum simple path in the graph corresponding to <span><span class="math inline">\(x\)</span></span>, and finding the string <span><span class="math inline">\(y^*\)</span></span> that achieves this maximum corresponds to actually finding the path.</p>
</div>
<div id="section-5" class="proofidea" data-ref="optimizationnp" name="Proofidea">
<p>The proof follows by generalizing our ideas from the longest path example above. Let <span><span class="math inline">\(f\)</span></span> be as in the theorem statement. If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then for every for every string <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> and number <span><span class="math inline">\(k\)</span></span>, we can test in in <span><span class="math inline">\(poly(|x|,m)\)</span></span> time whether there exists <span><span class="math inline">\(y\)</span></span> such that <span><span class="math inline">\(f(x,y) \geq k\)</span></span>, or in other words test whether <span><span class="math inline">\(\max_{y \in \{0,1\}^m} f(x,y) \geq k\)</span></span>. If <span><span class="math inline">\(f(x,y)\)</span></span> is an integer between <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(poly(|x|+|y|)\)</span></span> (as is the case in the example of longest path) then we can just try out all possibilities for <span><span class="math inline">\(k\)</span></span> to find the maximum number <span><span class="math inline">\(k\)</span></span> for which <span><span class="math inline">\(\max_y f(x,y) \geq k\)</span></span>. Otherwise, we can use <em>binary search</em> to hone down on the right value. Once we do so, we can use search-to-decision to actually find the string <span><span class="math inline">\(y^*\)</span></span> that achieves the maximum.</p>
</div>
<div class="proof" data-ref="optimizationnp" name="Proof 15.2">
<p>For every <span><span class="math inline">\(f\)</span></span> as in the theorem statement, we can define the Boolean function <span><span class="math inline">\(F:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> as follows.</p>
<p><span>
<div class='myequationbox'><span class="math display">\[F(x,1^m,k)= \begin{cases} 1 &amp; \exists_{y\in \{0,1\}^m} f(x,y) \geq k \\ 0 &amp; \text{otherwise} \end{cases}\]</span></div></span></p>
<p>Since <span><span class="math inline">\(f\)</span></span> is computable in polynomial time, <span><span class="math inline">\(F\)</span></span> is in <span><span class="math inline">\(\mathbf{NP}\)</span></span>, and so under our assumption that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, <span><span class="math inline">\(F\)</span></span> itself can be computed in polynomial time. Now, for every <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(m\)</span></span>, we can compute the largest <span><span class="math inline">\(k\)</span></span> such that <span><span class="math inline">\(F(x,1^m,k)=1\)</span></span> by a binary search. Specifically, we will do this as follows:</p>
<ol type="1">
<li><p>We maintain two numbers <span><span class="math inline">\(a,b\)</span></span> such that we are guaranteed that <span><span class="math inline">\(a \leq \max_{y\in \{0,1\}^m} f(x,y) &lt; b\)</span></span>.</p></li>
<li><p>Initially we set <span><span class="math inline">\(a=0\)</span></span> and <span><span class="math inline">\(b=2^{T(n)}\)</span></span> where <span><span class="math inline">\(T(n)\)</span></span> is the running time of <span><span class="math inline">\(f\)</span></span>. (A function with <span><span class="math inline">\(T(n)\)</span></span> running time can’t output more than <span><span class="math inline">\(T(n)\)</span></span> bits and so can’t output a number larger than <span><span class="math inline">\(2^{T(n)}\)</span></span>.)</p></li>
<li><p>At each point in time, we compute the midpoint <span><span class="math inline">\(c = \floor{(a+b)/2})\)</span></span> and let <span><span class="math inline">\(y=F(1^n,c)\)</span></span>.</p>
<ol type="a">
<li><p>If <span><span class="math inline">\(y=1\)</span></span> then we set <span><span class="math inline">\(a=c\)</span></span> and leave <span><span class="math inline">\(b\)</span></span> as it is.</p></li>
<li><p>If <span><span class="math inline">\(y=0\)</span></span> then we set <span><span class="math inline">\(b=c\)</span></span> and leave <span><span class="math inline">\(a\)</span></span> as it is.</p></li>
</ol></li>
<li><p>We then go back to step 3, until <span><span class="math inline">\(b \leq a+1\)</span></span>.</p></li>
</ol>
<p>Since <span><span class="math inline">\(|b-a|\)</span></span> shrinks by a factor of <span><span class="math inline">\(2\)</span></span>, within <span><span class="math inline">\(\log_2 2^{T(n)}= T(n)\)</span></span> steps, we will get to the point at which <span><span class="math inline">\(b\leq a+1\)</span></span>, and then we can simply output <span><span class="math inline">\(a\)</span></span>. Once we find the maximum value of <span><span class="math inline">\(k\)</span></span> such that <span><span class="math inline">\(F(x,1^m,k)=1\)</span></span>, we can use the search to decision reduction of <a href='#search-dec-thm'>Theorem 15.1</a> to obtain the actual value <span><span class="math inline">\(y^* \in \{0,1\}^m\)</span></span> such that <span><span class="math inline">\(f(x,y^*)=k\)</span></span>.</p>
</div>
<div id="optimizationexample" class="example" title="Integer programming" name="Example 15.4 (Integer programming) ">
<p>One application for <a href='#optimizationnp'>Theorem 15.3</a> is in solving <em>optimization problems</em>. For example, the task of <em>linear programming</em> is to find <span><span class="math inline">\(y \in \R^n\)</span></span> that maximizes some linear objective <span><span class="math inline">\(\sum_{i=0}^{n-1}c_i y_i\)</span></span> subject to the constraint that <span><span class="math inline">\(y\)</span></span> satisfies linear inequalities of the form <span><span class="math inline">\(\sum_{i=0}^{n-1} a_i y_i \leq c\)</span></span>. As we discussed in <a href='lec_10_efficient_alg.html#mincutsec'>Subsection 11.1.3</a>, there is a known polynomial-time algorithm for linear programming. However, if we want to place additional constraints on <span><span class="math inline">\(y\)</span></span>, such as requiring the coordinates of <span><span class="math inline">\(y\)</span></span> to be <em>integer</em> or <em><span><span class="math inline">\(0/1\)</span></span> valued</em> then the best-known algorithms run in exponential time in the worst case. However, if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then <a href='#optimizationnp'>Theorem 15.3</a> tells us that we would be able to solve all problems of this form in polynomial time. For every string <span><span class="math inline">\(x\)</span></span> that describes a set of constraints and objective, we will define a function <span><span class="math inline">\(f\)</span></span> such that if <span><span class="math inline">\(y\)</span></span> satisfies the constraints of <span><span class="math inline">\(x\)</span></span> then <span><span class="math inline">\(f(x,y)\)</span></span> is the value of the objective, and otherwise we set <span><span class="math inline">\(f(x,y) = -M\)</span></span> where <span><span class="math inline">\(M\)</span></span> is some large number. We can then use <a href='#optimizationnp'>Theorem 15.3</a> to compute the <span><span class="math inline">\(y\)</span></span> that maximizes <span><span class="math inline">\(f(x,y)\)</span></span> and that will give us the assignment for the variables that satisfies our constraints and maximizes the objective. (If the computation results in <span><span class="math inline">\(y\)</span></span> such that <span><span class="math inline">\(f(x,y)=-M\)</span></span> then we can double <span><span class="math inline">\(M\)</span></span> and try again; if the true maximum objective is achieved by some string <span><span class="math inline">\(y^*\)</span></span>, then eventually <span><span class="math inline">\(M\)</span></span> will be large enough so that <span><span class="math inline">\(-M\)</span></span> would be smaller than the objective achieved by <span><span class="math inline">\(y^*\)</span></span>, and hence when we run procedure of <a href='#optimizationnp'>Theorem 15.3</a> we would get a value larger than <span><span class="math inline">\(-M\)</span></span>.)</p>
</div>
<div id="binarysearchrm" class="remark" title="Need for binary search." name="Remark 15.5 (Need for binary search.) ">
<p>In many examples, such as the case of finding longest path, we don’t need to use the binary search step in <a href='#optimizationnp'>Theorem 15.3</a>, and can simply enumerate over all possible values for <span><span class="math inline">\(k\)</span></span> until we find the correct one. One example where we do need to use this binary search step is in the case of the problem of finding a maximum length path in a <em>weighted</em> graph. This is the problem where <span><span class="math inline">\(G\)</span></span> is a weighted graph, and every edge of <span><span class="math inline">\(G\)</span></span> is given a weight which is a number between <span><span class="math inline">\(0\)</span></span> and <span><span class="math inline">\(2^k\)</span></span>. <a href='#optimizationnp'>Theorem 15.3</a> shows that we can find the maximum-weight simple path in <span><span class="math inline">\(G\)</span></span> (i.e., simple path maximizing the sum of the weights of its edges) in time polynomial in the number of vertices and in <span><span class="math inline">\(k\)</span></span>.</p>
<p>Beyond just this example there is a vast field of <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">mathematical optimization</a> that studies problems of the same form as in <a href='#optimizationnp'>Theorem 15.3</a>. In the context of optimization, <span><span class="math inline">\(x\)</span></span> typically denotes a set of constraints over some variables (that can be Boolean, integer, or real valued), <span><span class="math inline">\(y\)</span></span> encodes an assignment to these variables, and <span><span class="math inline">\(f(x,y)\)</span></span> is the value of some <em>objective function</em> that we want to maximize. Given that we don’t know efficient algorithms for <span><span class="math inline">\(\mathbf{NP}\)</span></span> complete problems, researchers in optimization research study special cases of functions <span><span class="math inline">\(f\)</span></span> (such as linear programming and semidefinite programming) where it <em>is</em> possible to optimize the value efficiently. Optimization is widely used in a great many scientific areas including: machine learning, engineering, economics and operations research.</p>
</div>
<h3 id="example-supervised-learning" data-number="15.2.1">Example: Supervised learning</h3>
<p>One classical optimization task is <em>supervised learning</em>. In supervised learning we are given a list of <em>examples</em> <span><span class="math inline">\(x_0,x_1,\ldots,x_{m-1}\)</span></span> (where we can think of each <span><span class="math inline">\(x_i\)</span></span> as a string in <span><span class="math inline">\(\{0,1\}^n\)</span></span> for some <span><span class="math inline">\(n\)</span></span>) and the <em>labels</em> for them <span><span class="math inline">\(y_0,\ldots,y_{n-1}\)</span></span> (which we will think of simply bits, i.e., <span><span class="math inline">\(y_i\in \{0,1\}\)</span></span>). For example, we can think of the <span><span class="math inline">\(x_i\)</span></span>’s as images of either dogs or cats, for which <span><span class="math inline">\(y_i=1\)</span></span> in the former case and <span><span class="math inline">\(y_i=0\)</span></span> in the latter case. Our goal is to come up with a <em>hypothesis</em> or <em>predictor</em> <span><span class="math inline">\(h:\{0,1\}^n \rightarrow \{0,1\}\)</span></span> such that if we are given a new example <span><span class="math inline">\(x\)</span></span> that has an (unknown to us) label <span><span class="math inline">\(y\)</span></span>, then with high probability <span><span class="math inline">\(h\)</span></span> will <em>predict</em> the label. That is, with high probability it will hold that <span><span class="math inline">\(h(x)=y\)</span></span>. The idea in supervised learning is to use the <em>Occam’s Razor principle</em>: the simplest hypothesis that explains the data is likely to be correct. There are several ways to model this, but one popular approach is to pick some fairly simple function <span><span class="math inline">\(H:\{0,1\}^{k+n} \rightarrow \{0,1\}\)</span></span>. We think of the first <span><span class="math inline">\(k\)</span></span> inputs as the <em>parameters</em> and the last <span><span class="math inline">\(n\)</span></span> inputs as the example data. (For example, we can think of the first <span><span class="math inline">\(k\)</span></span> inputs of <span><span class="math inline">\(H\)</span></span> as specifying the weights and connections for some neural network that will then be applied on the latter <span><span class="math inline">\(n\)</span></span> inputs.) We can then phrase the supervised learning problem as finding, given a set of labeled examples <span><span class="math inline">\(S=\{ (x_0,y_0),\ldots,(x_{m-1},y_{m-1}) \}\)</span></span>, the set of parameters <span><span class="math inline">\(\theta_0,\ldots,\theta_{k-1} \in \{0,1\}\)</span></span> that minimizes the number of errors made by the predictor <span><span class="math inline">\(x \mapsto H(\theta,x)\)</span></span>.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>
<p>In other words, we can define for every set <span><span class="math inline">\(S\)</span></span> as above the function <span><span class="math inline">\(F_S:\{0,1\}^k \rightarrow [m]\)</span></span> such that <span><span class="math inline">\(F_S(\theta) = \sum_{(x,y)\in S} |H(\theta,x)-y|\)</span></span>. Now, finding the value <span><span class="math inline">\(\theta\)</span></span> that minimizes <span><span class="math inline">\(F_S(\theta)\)</span></span> is equivalent to solving the supervised learning problem with respect to <span><span class="math inline">\(H\)</span></span>. For every polynomial-time computable <span><span class="math inline">\(H:\{0,1\}^{k+n} \rightarrow \{0,1\}\)</span></span>, the task of minimizing <span><span class="math inline">\(F_S(\theta)\)</span></span> can be “massaged” to fit the form of <a href='#optimizationnp'>Theorem 15.3</a> and hence if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, then we can solve the supervised learning problem in great generality. In fact, this observation extends to essentially any learning model, and allows for finding the optimal predictors given the minimum number of examples. (This is in contrast to many current learning algorithms, which often rely on having access to an extremely large number of examples<span><span class="math inline">\(-\)</span></span> far beyond the minimum needed, and in particular far beyond the number of examples humans use for the same tasks.)</p>
<h3 id="example-breaking-cryptosystems" data-number="15.2.2">Example: Breaking cryptosystems</h3>
<p>We will discuss <em>cryptography</em> later in this course, but it turns out that if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then almost every cryptosystem can be efficiently broken. One approach is to treat finding an encryption key as an instance of a supervised learning problem. If there is an encryption scheme that maps a “plaintext” message <span><span class="math inline">\(p\)</span></span> and a key <span><span class="math inline">\(\theta\)</span></span> to a “ciphertext” <span><span class="math inline">\(c\)</span></span>, then given examples of ciphertext/plaintext pairs of the form <span><span class="math inline">\((c_0,p_0),\ldots,(c_{m-1},p_{m-1})\)</span></span>, our goal is to find the key <span><span class="math inline">\(\theta\)</span></span> such that <span><span class="math inline">\(E(\theta,p_i)=c_i\)</span></span> where <span><span class="math inline">\(E\)</span></span> is the encryption algorithm. While you might think getting such “labeled examples” is unrealistic, it turns out (as many amateur home-brew crypto designers learn the hard way) that this is actually quite common in real-life scenarios, and that it is also possible to relax the assumption to having more minimal prior information about the plaintext (e.g., that it is English text). We defer a more formal treatment to <a href='lec_19_cryptography.html#chapcryptography'>Chapter 20</a>.</p>
<h2 id="finding-mathematical-proofs" data-number="15.3">Finding mathematical proofs</h2>
<p>In the context of Gödel’s Theorem, we discussed the notion of a <em>proof system</em> (see <a href='lec_09_godel.html#godelproofdef'>Section 10.1</a>). Generally speaking, a <em>proof system</em> can be thought of as an algorithm <span><span class="math inline">\(V:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> (known as the <em>verifier</em>) such that given a <em>statement</em> <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> and a <em>candidate proof</em> <span><span class="math inline">\(w\in \{0,1\}^*\)</span></span>, <span><span class="math inline">\(V(x,w)=1\)</span></span> if and only if <span><span class="math inline">\(w\)</span></span> encodes a valid proof for the statement <span><span class="math inline">\(x\)</span></span>. Any type of proof system that is used in mathematics for geometry, number theory, analysis, etc., is an instance of this form. In fact, standard mathematical proof systems have an even simpler form where the proof <span><span class="math inline">\(w\)</span></span> encodes a <em>sequence</em> of lines <span><span class="math inline">\(w^0,\ldots,w^m\)</span></span> (each of which is itself a binary string) such that each line <span><span class="math inline">\(w^i\)</span></span> is either an <em>axiom</em> or follows from some prior lines through an application of some <em>inference rule</em>. For example, <a href="https://en.wikipedia.org/wiki/Peano_axioms">Peano’s axioms</a> encode a set of axioms and rules for the natural numbers, and one can use them to formalize proofs in number theory. Also, there are some even stronger axiomatic systems, the most popular one being <a href="https://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory">Zermelo–Fraenkel with the Axiom of Choice</a> or ZFC for short. Thus, although mathematicians typically write their papers in natural language, proofs of number theorists can typically be translated to ZFC or similar systems, and so in particular the existence of an <span><span class="math inline">\(n\)</span></span>-page proof for a statement <span><span class="math inline">\(x\)</span></span> implies that there exists a string <span><span class="math inline">\(w\)</span></span> of length <span><span class="math inline">\(poly(n)\)</span></span> (in fact often <span><span class="math inline">\(O(n)\)</span></span> or <span><span class="math inline">\(O(n^2)\)</span></span>) that encodes the proof in such a system. Moreover, because verifying a proof simply involves going over each line and checking that it does indeed follow from the prior lines, it is fairly easy to do that in <span><span class="math inline">\(O(|w|)\)</span></span> or <span><span class="math inline">\(O(|w|^2)\)</span></span> (where as usual <span><span class="math inline">\(|w|\)</span></span> denotes the length of the proof <span><span class="math inline">\(w\)</span></span>). This means that for every reasonable proof system <span><span class="math inline">\(V\)</span></span>, the following function <span><span class="math inline">\(\ensuremath{\mathit{SHORTPROOF}}_V:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> is in <span><span class="math inline">\(\mathbf{NP}\)</span></span>, where for every input of the form <span><span class="math inline">\(x1^m\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{SHORTPROOF}}_V(x,1^m)=1\)</span></span> if and only if there exists <span><span class="math inline">\(w\in \{0,1\}^*\)</span></span> with <span><span class="math inline">\(|w|\leq m\)</span></span> s.t. <span><span class="math inline">\(V(xw)=1\)</span></span>. That is, <span><span class="math inline">\(\ensuremath{\mathit{SHORTPROOF}}_V(x,1^m)=1\)</span></span> if there is a proof (in the system <span><span class="math inline">\(V\)</span></span>) of length at most <span><span class="math inline">\(m\)</span></span> bits that <span><span class="math inline">\(x\)</span></span> is true. Thus, if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, then despite Gödel’s Incompleteness Theorems, we can still automate mathematics in the sense of finding proofs that are not too long for every statement that has one. (Frankly speaking, if the shortest proof for some statement requires a terabyte, then human mathematicians won’t ever find this proof either.) For this reason, Gödel himself felt that the question of whether <span><span class="math inline">\(\ensuremath{\mathit{SHORTPROOF}}_V\)</span></span> has a polynomial time algorithm is of great interest. As Gödel wrote <a href="https://rjlipton.wordpress.com/the-gdel-letter/">in a letter to John von Neumann</a> in 1956 (before the concept of <span><span class="math inline">\(\mathbf{NP}\)</span></span> or even “polynomial time” was formally defined):</p>
<blockquote>
<p>One can obviously easily construct a Turing machine, which for every formula <span><span class="math inline">\(F\)</span></span> in first order predicate logic and every natural number <span><span class="math inline">\(n\)</span></span>, allows one to decide if there is a proof of <span><span class="math inline">\(F\)</span></span> of length <span><span class="math inline">\(n\)</span></span> (length = number of symbols). Let <span><span class="math inline">\(\psi(F,n)\)</span></span> be the number of steps the machine requires for this and let <span><span class="math inline">\(\varphi(n) = \max_F \psi(F,n)\)</span></span>. The question is how fast <span><span class="math inline">\(\varphi(n)\)</span></span> grows for an optimal machine. One can show that <span><span class="math inline">\(\varphi \geq k \cdot n\)</span></span> [for some constant <span><span class="math inline">\(k&gt;0\)</span></span>]. If there really were a machine with <span><span class="math inline">\(\varphi(n) \sim k \cdot n\)</span></span> (or even <span><span class="math inline">\(\sim k\cdot n^2\)</span></span>), this would have consequences of the greatest importance. Namely, it would obviously mean that in spite of the undecidability of the Entscheidungsproblem,<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> the mental work of a mathematician concerning Yes-or-No questions could be completely replaced by a machine. After all, one would simply have to choose the natural number <span><span class="math inline">\(n\)</span></span> so large that when the machine does not deliver a result, it makes no sense to think more about the problem.</p>
</blockquote>
<p>For many reasonable proof systems (including the one that Gödel referred to), <span><span class="math inline">\(\ensuremath{\mathit{SHORTPROOF}}_V\)</span></span> is in fact <span><span class="math inline">\(\mathbf{NP}\)</span></span>-complete, and so Gödel can be thought of as the first person to formulate the <span><span class="math inline">\(\mathbf{P}\)</span></span> vs <span><span class="math inline">\(\mathbf{NP}\)</span></span> question. Unfortunately, the letter was <a href="https://www.win.tue.nl/~gwoegi/P-versus-NP/sipser.pdf">only discovered in 1988</a>.</p>
<h2 id="quantifier-elimination-advanced" data-number="15.4">Quantifier elimination (advanced)</h2>
<p>If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can solve all <span><span class="math inline">\(\mathbf{NP}\)</span></span> <em>search</em> and <em>optimization</em> problems in polynomial time. But can we do more? It turns out that the answer is that <em>Yes we can!</em></p>
<p>An <span><span class="math inline">\(\mathbf{NP}\)</span></span> decision problem can be thought of as the task of deciding, given some string <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span> the truth of a statement of the form <span>
<div class='myequationbox'><span class="math display">\[
\exists_{y\in \{0,1\}^{p(|x|)}} V(xy)=1
\]</span></div></span> for some polynomial-time algorithm <span><span class="math inline">\(V\)</span></span> and polynomial <span><span class="math inline">\(p:\N \rightarrow \N\)</span></span>. That is, we are trying to determine, given some string <span><span class="math inline">\(x\)</span></span>, whether <em>there exists</em> a string <span><span class="math inline">\(y\)</span></span> such that <span><span class="math inline">\(x\)</span></span> and <span><span class="math inline">\(y\)</span></span> satisfy some polynomial-time checkable condition <span><span class="math inline">\(V\)</span></span>. For example, in the <em>independent set</em> problem, the string <span><span class="math inline">\(x\)</span></span> represents a graph <span><span class="math inline">\(G\)</span></span> and a number <span><span class="math inline">\(k\)</span></span>, the string <span><span class="math inline">\(y\)</span></span> represents some subset <span><span class="math inline">\(S\)</span></span> of <span><span class="math inline">\(G\)</span></span>’s vertices, and the condition that we check is whether <span><span class="math inline">\(|S| \geq k\)</span></span> and there is no edge <span><span class="math inline">\(\{u,v\}\)</span></span> in <span><span class="math inline">\(G\)</span></span> such that both <span><span class="math inline">\(u\in S\)</span></span> and <span><span class="math inline">\(v\in S\)</span></span>.</p>
<p>We can consider more general statements such as checking, given a string <span><span class="math inline">\(x\in \{0,1\}^*\)</span></span>, the truth of a statement of the form <span>
<div class='myequationbox'><span class="math display">\[
\exists_{y \in \{0,1\}^{p_0(|x|)}} \forall_{z \in \{0,1\}^{p_1(|x|)}} V(xyz)=1 \;, \;\;(15.4)
\]</span><a id='existsforalleq'></a></div></span> which in words corresponds to checking, given some string <span><span class="math inline">\(x\)</span></span>, whether <em>there exists</em> a string <span><span class="math inline">\(y\)</span></span> such that <em>for every</em> string <span><span class="math inline">\(z\)</span></span>, the triple <span><span class="math inline">\((x,y,z)\)</span></span> satisfy some polynomial-time checkable condition. We can also consider more levels of quantifiers such as checking the truth of the statement <span>
<div class='myequationbox'><span class="math display">\[
\exists_{y \in \{0,1\}^{p_0(|x|)}} \forall_{z\in \{0,1\}^{p_1(|x|)}}\exists_{w\in \{0,1\}^{p_2(|x|)}} V(xyzw)=1 \;\;(15.5)
\]</span><a id='existsforallexistseq'></a></div></span> and so on and so forth.</p>
<p>For example, given an <span><span class="math inline">\(n\)</span></span>-input NAND-CIRC program <span><span class="math inline">\(P\)</span></span>, we might want to find the <em>smallest</em> NAND-CIRC program <span><span class="math inline">\(P&#39;\)</span></span> that computes the same function as <span><span class="math inline">\(P\)</span></span>. The question of whether there is such a <span><span class="math inline">\(P&#39;\)</span></span> that can be described by a string of at most <span><span class="math inline">\(s\)</span></span> bits can be phrased as</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\exists_{P&#39; \in \{0,1\}^{s}} \forall_{x\in \{0,1\}^n} P(x)=P&#39;(x) \;\;(15.6)
\]</span><a id='circmineq'></a></div></span> which has the form <a href='#existsforalleq'>Equation 15.4</a>.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> Another example of a statement involving <span><span class="math inline">\(a\)</span></span> levels of quantifiers would be to check, given a chess position <span><span class="math inline">\(x\)</span></span>, whether there is a strategy that guarantees that White wins within <span><span class="math inline">\(a\)</span></span> steps. For example is <span><span class="math inline">\(a=3\)</span></span> we would want to check if given the board position <span><span class="math inline">\(x\)</span></span>, <em>there exists</em> a move <span><span class="math inline">\(y\)</span></span> for White such that <em>for every</em> move <span><span class="math inline">\(z\)</span></span> for Black <em>there exists</em> a move <span><span class="math inline">\(w\)</span></span> for White that ends in a a checkmate.</p>
<p>It turns out that if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can solve these kinds of problems as well:</p>
<div id="PH-collapse-thm" class="theorem" title="Polynomial hierarchy collapse" name="Theorem 15.6 (Polynomial hierarchy collapse) ">
<p>If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then for every <span><span class="math inline">\(a\in \N\)</span></span>, polynomial <span><span class="math inline">\(p:\N \rightarrow \N\)</span></span> and polynomial-time algorithm <span><span class="math inline">\(V\)</span></span>, there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{SOLVE}}_{V,a}\)</span></span> that on input <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> returns <span><span class="math inline">\(1\)</span></span> if and only if <span>
<div class='myequationbox'><span class="math display">\[
\exists_{y_0\in \{0,1\}^m} \forall_{y_1\in \{0,1\}^m} \cdots  \mathcal{Q}_{y_{a-1}\in \{0,1\}^m} V(xy_0y_1 \cdots y_{a-1})=1 \;\;(15.7)
\]</span><a id='eq:QBF'></a></div></span> where <span><span class="math inline">\(m=p(n)\)</span></span> and <span><span class="math inline">\(\mathcal{Q}\)</span></span> is either <span><span class="math inline">\(\exists\)</span></span> or <span><span class="math inline">\(\forall\)</span></span> depending on whether <span><span class="math inline">\(a\)</span></span> is odd or even, respectively.<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup></p>
</div>
<div id="section-6" class="proofidea" data-ref="PH-collapse-thm" name="Proofidea">
<p>To understand the idea behind the proof, consider the special case where we want to decide, given <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, whether for every <span><span class="math inline">\(y \in \{0,1\}^n\)</span></span> there exists <span><span class="math inline">\(z\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(V(xyz)=1\)</span></span>. Consider the function <span><span class="math inline">\(F\)</span></span> such that <span><span class="math inline">\(F(xy)=1\)</span></span> if there exists <span><span class="math inline">\(z\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(V(xyz)=1\)</span></span>. Since <span><span class="math inline">\(V\)</span></span> runs in polynomial-time <span><span class="math inline">\(F\in \mathbf{NP}\)</span></span> and hence if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, then there is an algorithm <span><span class="math inline">\(V&#39;\)</span></span> that on input <span><span class="math inline">\(x,y\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if there exists <span><span class="math inline">\(z\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(V(xyz)=1\)</span></span>. Now we can see that the original statement we consider is true if and only if for every <span><span class="math inline">\(y\in \{0,1\}^n\)</span></span>, <span><span class="math inline">\(V&#39;(xy)=1\)</span></span>, which means it is false if and only if the following condition <span><span class="math inline">\((*)\)</span></span> holds: there exists some <span><span class="math inline">\(y\in \{0,1\}^n\)</span></span> such that <span><span class="math inline">\(V&#39;(xy)=0\)</span></span>. But for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, the question of whether the condition <span><span class="math inline">\((*)\)</span></span> is itself in <span><span class="math inline">\(\mathbf{NP}\)</span></span> (as we assumed <span><span class="math inline">\(V&#39;\)</span></span> can be computed in polynomial time) and hence under the assumption that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> we can determine in polynomial time whether the condition <span><span class="math inline">\((*)\)</span></span>, and hence our original statement, is true.</p>
</div>
<div class="proof" data-ref="PH-collapse-thm" name="Proof 15.4">
<p>We prove the theorem by induction. We assume that there is a polynomial-time algorithm <span><span class="math inline">\(\ensuremath{\mathit{SOLVE}}_{V,a-1}\)</span></span> that can solve the problem <a href='#eq:QBF'>Equation 15.7</a> for <span><span class="math inline">\(a-1\)</span></span> and use that to solve the problem for <span><span class="math inline">\(a\)</span></span>. For <span><span class="math inline">\(a=1\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{SOLVE}}_{V,a-1}(x)=1\)</span></span> iff <span><span class="math inline">\(V(x)=1\)</span></span> which is a polynomial-time computation since <span><span class="math inline">\(V\)</span></span> runs in polynomial time. For every <span><span class="math inline">\(x,y_0\)</span></span>, define the statement <span><span class="math inline">\(\varphi_{x,y_0}\)</span></span> to be the following:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\varphi_{x,y_0} = \forall_{y_1\in \{0,1\}^m} \exists_{y_2 \in \{0,1\}^m} \cdots  \mathcal{Q}_{y_{a-1}\in \{0,1\}^m} V(xy_0y_1 \cdots y_{a-1})=1
\]</span></div></span></p>
<p>By the definition of <span><span class="math inline">\(\ensuremath{\mathit{SOLVE}}_{V,a}\)</span></span>, for every <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, our goal is that <span><span class="math inline">\(\ensuremath{\mathit{SOLVE}}_{V,a}(x)=1\)</span></span> if and only if there exists <span><span class="math inline">\(y_0 \in \{0,1\}^m\)</span></span> such that <span><span class="math inline">\(\varphi_{x,y_0}\)</span></span> is true.</p>
<p>The <em>negation</em> of <span><span class="math inline">\(\varphi_{x,y_0}\)</span></span> is the statement</p>
<p><span>
<div class='myequationbox'><span class="math display">\[
\overline{\varphi}_{x,y_0} = \exists_{y_1\in \{0,1\}^m} \forall_{y_2 \in \{0,1\}^m}\cdots  \overline{\mathcal{Q}}_{y_{a-1}\in \{0,1\}^m} V(xy_0y_1 \cdots y_{a-1})=0
\]</span></div></span> where <span><span class="math inline">\(\overline{\mathcal{Q}}\)</span></span> is <span><span class="math inline">\(\exists\)</span></span> if <span><span class="math inline">\(\mathcal{Q}\)</span></span> was <span><span class="math inline">\(\forall\)</span></span> and <span><span class="math inline">\(\overline{\mathcal{Q}}\)</span></span> is <span><span class="math inline">\(\forall\)</span></span> otherwise. (Please stop and verify that you understand why this is true, this is a generalization of the fact that if <span><span class="math inline">\(\Psi\)</span></span> is some logical condition then the negation of <span><span class="math inline">\(\exists_y \forall_z \Psi(y,z)\)</span></span> is <span><span class="math inline">\(\forall_y \exists_z \neg \Psi(y,z)\)</span></span>.)</p>
<p>The crucial observation is that <span><span class="math inline">\(\overline{\varphi}_{x,y_0}\)</span></span> is exactly a statement of the form we consider with <span><span class="math inline">\(a-1\)</span></span> quantifiers instead of <span><span class="math inline">\(a\)</span></span>, and hence by our inductive hypothesis there is some polynomial time algorithm <span><span class="math inline">\(\overline{S}\)</span></span> that on input <span><span class="math inline">\(xy_0\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(\overline{\varphi}_{x,y_0}\)</span></span> is true. If we let <span><span class="math inline">\(S\)</span></span> be the algorithm that on input <span><span class="math inline">\(x,y_0\)</span></span> outputs <span><span class="math inline">\(1-\overline{S}(xy_0)\)</span></span> then we see that <span><span class="math inline">\(S\)</span></span> outputs <span><span class="math inline">\(1\)</span></span> if and only if <span><span class="math inline">\(\varphi_{x,y_0}\)</span></span> is true. Hence we can rephrase the original statement <a href='#eq:QBF'>Equation 15.7</a> as follows:</p>
<p><span>
<div class='myequationbox'><span class="math display">\[\exists_{y_0 \in \{0,1\}^m} S(xy_0)=1 \;\;(15.10) \]</span><a id='equivalentqbfinducteq'></a></div></span></p>
<p>but since <span><span class="math inline">\(S\)</span></span> is a polynomial-time algorithm, <a href='#equivalentqbfinducteq'>Equation 15.10</a> is clearly a statement in <span><span class="math inline">\(\mathbf{NP}\)</span></span> and hence under our assumption that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> there is a polynomial time algorithm that on input <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span>, will determine if <a href='#equivalentqbfinducteq'>Equation 15.10</a> is true and so also if the original statement <a href='#eq:QBF'>Equation 15.7</a> is true.</p>
</div>
<p>The algorithm of <a href='#PH-collapse-thm'>Theorem 15.6</a> can also solve the search problem as well: find the value <span><span class="math inline">\(y_0\)</span></span> that certifies the truth of <a href='#eq:QBF'>Equation 15.7</a>. We note that while this algorithm is in polynomial time, the exponent of this polynomial blows up quite fast. If the original NANDSAT algorithm required <span><span class="math inline">\(\Omega(n^2)\)</span></span> time, solving <span><span class="math inline">\(a\)</span></span> levels of quantifiers would require time <span><span class="math inline">\(\Omega(n^{2^a})\)</span></span>.<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup></p>
<h3 id="selfimprovingsat" data-number="15.4.1">Application: self improving algorithm for <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span></h3>
<p>Suppose that we found a polynomial-time algorithm <span><span class="math inline">\(A\)</span></span> for <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> that is “good but not great”. For example, maybe our algorithm runs in time <span><span class="math inline">\(cn^2\)</span></span> for some not too small constant <span><span class="math inline">\(c\)</span></span>. However, it’s possible that the <em>best possible</em> SAT algorithm is actually much more efficient than that. Perhaps, as we guessed before, there is a circuit <span><span class="math inline">\(C^*\)</span></span> of at most <span><span class="math inline">\(10^6 n\)</span></span> gates that computes 3SAT on <span><span class="math inline">\(n\)</span></span> variables, and we simply haven’t discovered it yet. We can use <a href='#PH-collapse-thm'>Theorem 15.6</a> to “bootstrap” our original “good but not great” 3SAT algorithm to discover the optimal one. The idea is that we can phrase the question of whether there exists a size <span><span class="math inline">\(s\)</span></span> circuit that computes 3SAT for all length <span><span class="math inline">\(n\)</span></span> inputs as follows: <em>there exists</em> a size <span><span class="math inline">\(\leq s\)</span></span> circuit <span><span class="math inline">\(C\)</span></span> such that <em>for every</em> formula <span><span class="math inline">\(\varphi\)</span></span> described by a string of length at most <span><span class="math inline">\(n\)</span></span>, if <span><span class="math inline">\(C(\varphi)=1\)</span></span> then <em>there exists</em> an assignment <span><span class="math inline">\(x\)</span></span> to the variables of <span><span class="math inline">\(\varphi\)</span></span> that satisfies it. One can see that this is a statement of the form <a href='#existsforallexistseq'>Equation 15.5</a> and hence if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> we can solve it in polynomial time as well. We can therefore imagine investing huge computational resources in running <span><span class="math inline">\(A\)</span></span> one time to discover the circuit <span><span class="math inline">\(C^*\)</span></span> and then using <span><span class="math inline">\(C^*\)</span></span> for all further computation.</p>
<h2 id="approximating-counting-problems-and-posterior-sampling-advanced-optional" data-number="15.5">Approximating counting problems and posterior sampling (advanced, optional)</h2>
<p>Given a Boolean circuit <span><span class="math inline">\(C\)</span></span>, if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can find an input <span><span class="math inline">\(x\)</span></span> (if one exists) such that <span><span class="math inline">\(C(x)=1\)</span></span>. But what if there is more than one <span><span class="math inline">\(x\)</span></span> like that? Clearly we can’t efficiently output all such <span><span class="math inline">\(x\)</span></span>’s; there might be exponentially many. But we can get an arbitrarily good multiplicative approximation (i.e., a <span><span class="math inline">\(1\pm \epsilon\)</span></span> factor for arbitrarily small <span><span class="math inline">\(\epsilon&gt;0\)</span></span>) for the number of such <span><span class="math inline">\(x\)</span></span>’s, as well as output a (nearly) uniform member of this set. The details are beyond the scope of this book, but this result is formally stated in the following theorem (whose proof is omitted).</p>
<div id="approxcountingnp" class="theorem" title="Approximate counting if $\mathbf{P}=\mathbf{NP}$" name="Theorem 15.7 (Approximate counting if $\mathbf{P}=\mathbf{NP}$) ">
<p>Let <span><span class="math inline">\(V:\{0,1\}^* \rightarrow \{0,1\}\)</span></span> be some polynomial-time algorithm, and suppose that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>. Then there exists an algorithm <span><span class="math inline">\(\ensuremath{\mathit{COUNT}}_V\)</span></span> that on input <span><span class="math inline">\(x,1^m,\epsilon\)</span></span>, runs in time polynomial in <span><span class="math inline">\(|x|,m,1/\epsilon\)</span></span> and outputs a number in <span><span class="math inline">\([2^m+1]\)</span></span> satisfying</p>
<p><span>
<div class='myequationbox'><span class="math display">\[(1-\epsilon)\ensuremath{\mathit{COUNT}}_V(x,m,\epsilon) \leq \Bigl|\{ y \in \{0,1\}^m \;:\; V(xy)=1 \} \Bigr| \leq (1+\epsilon)\ensuremath{\mathit{COUNT}}_V(x,m,\epsilon) \;.
\]</span></div></span></p>
</div>
<p>In other words, the algorithm <span><span class="math inline">\(\ensuremath{\mathit{COUNT}}_V\)</span></span> gives an approximation up to a factor of <span><span class="math inline">\(1 \pm \epsilon\)</span></span> for the number of <em>witnesses</em> for <span><span class="math inline">\(x\)</span></span> with respect to the verifying algorithm <span><span class="math inline">\(V\)</span></span>. Once again, to understand this theorem it can be useful to see how it implies that if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then there is a polynomial-time algorithm that given a graph <span><span class="math inline">\(G\)</span></span> and a number <span><span class="math inline">\(k\)</span></span>, can compute a number <span><span class="math inline">\(K\)</span></span> that is within a <span><span class="math inline">\(1 \pm 0.01\)</span></span> factor equal to the number of simple paths in <span><span class="math inline">\(G\)</span></span> of length <span><span class="math inline">\(k\)</span></span>. (That is, <span><span class="math inline">\(K\)</span></span> is between <span><span class="math inline">\(0.99\)</span></span> to <span><span class="math inline">\(1.01\)</span></span> times the number of such paths.)</p>
<p><strong>Posterior sampling and probabilistic programming.</strong> The algorithm for counting can also be extended to <em>sampling</em> from a given posterior distribution. That is, if <span><span class="math inline">\(C:\{0,1\}^n \rightarrow \{0,1\}^m\)</span></span> is a Boolean circuit and <span><span class="math inline">\(y\in \{0,1\}^m\)</span></span>, then if <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> we can sample from (a close approximation of) the distribution of uniform <span><span class="math inline">\(x\in \{0,1\}^n\)</span></span> conditioned on <span><span class="math inline">\(C(x)=y\)</span></span>. This task is known as <em>posterior sampling</em> and is crucial for Bayesian data analysis. These days it is known how to achieve posterior sampling only for circuits <span><span class="math inline">\(C\)</span></span> of very special form, and even in these cases more often than not we do have guarantees on the quality of the sampling algorithm. The field of making inferences by sampling from posterior distribution specified by circuits or programs is known as <a href="https://en.wikipedia.org/wiki/Probabilistic_programming_language">probabilistic programming</a>.</p>
<h2 id="what-does-all-of-this-imply" data-number="15.6">What does all of this imply?</h2>
<p>So, what will happen if we have a <span><span class="math inline">\(10^6n\)</span></span> algorithm for <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span>? We have mentioned that <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard problems arise in many contexts, and indeed scientists, engineers, programmers and others routinely encounter such problems in their daily work. A better <span><span class="math inline">\(3\ensuremath{\mathit{SAT}}\)</span></span> algorithm will probably make their lives easier, but that is the wrong place to look for the most foundational consequences. Indeed, while the invention of electronic computers did of course make it easier to do calculations that people were already doing with mechanical devices and pen and paper, the main applications computers are used for today were not even imagined before their invention.</p>
<p>An exponentially faster algorithm for all <span><span class="math inline">\(\mathbf{NP}\)</span></span> problems would be no less radical an improvement (and indeed, in some sense would be more) than the computer itself, and it is as hard for us to imagine what it would imply as it was for Babbage to envision today’s world. For starters, such an algorithm would completely change the way we program computers. Since we could automatically find the “best” (in any measure we chose) program that achieves a certain task, we would not need to define <em>how</em> to achieve a task, but only specify tests as to what would be a good solution, and could also ensure that a program satisfies an exponential number of tests without actually running them.</p>
<p>The possibility that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> is often described as “automating creativity”. There is something to that analogy, as we often think of a creative solution as one that is hard to discover but that, once the “spark” hits, is easy to verify. But there is also an element of hubris to that statement, implying that the most impressive consequence of such an algorithmic breakthrough will be that computers would succeed in doing something that humans already do today. In fact, creativity already is to a large extent automated or minimized (e.g., just see how much popular media content is mass-produced), and as in most professions we should expect to see the need for humans diminish with time even if <span><span class="math inline">\(\mathbf{P}\neq \mathbf{NP}\)</span></span>.</p>
<p>Nevertheless, artificial intelligence, like many other fields, will clearly be greatly impacted by an efficient 3SAT algorithm. For example, it is clearly much easier to find a better Chess-playing algorithm when, given any algorithm <span><span class="math inline">\(P\)</span></span>, you can find the smallest algorithm <span><span class="math inline">\(P&#39;\)</span></span> that plays Chess better than <span><span class="math inline">\(P\)</span></span>. Moreover, as we mentioned above, much of machine learning (and statistical reasoning in general) is about finding “simple” concepts that explain the observed data, and if <span><span class="math inline">\(\mathbf{NP}=\mathbf{P}\)</span></span>, we could search for such concepts automatically for any notion of “simplicity” we see fit. In fact, we could even “skip the middle man” and do an automatic search for the learning algorithm with smallest generalization error. Ultimately the field of Artificial Intelligence is about trying to “shortcut” billions of years of evolution to obtain artificial programs that match (or beat) the performance of natural ones, and a fast algorithm for <span><span class="math inline">\(\mathbf{NP}\)</span></span> would provide the ultimate shortcut.<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup></p>
<p>More generally, a faster algorithm for <span><span class="math inline">\(\mathbf{NP}\)</span></span> problems would be immensely useful in any field where one is faced with computational or quantitative problems<span><span class="math inline">\(-\)</span></span> which is basically all fields of science, math, and engineering. This will not only help with concrete problems such as designing a better bridge, or finding a better drug, but also with addressing basic mysteries such as trying to find scientific theories or “laws of nature”. In a <a href="http://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">fascinating talk</a>, physicist Nima Arkani-Hamed discusses the effort of finding scientific theories in much the same language as one would describe solving an <span><span class="math inline">\(\mathbf{NP}\)</span></span> problem, for which the solution is easy to verify or seems “inevitable”, once found, but that requires searching through a huge landscape of possibilities to reach, and that often can get “stuck” at local optima:</p>
<blockquote>
<p><em>“the laws of nature have this amazing feeling of inevitability… which is associated with local perfection.”</em></p>
</blockquote>
<blockquote>
<p><em>“The classical picture of the world is the top of a local mountain in the space of ideas. And you go up to the top and it looks amazing up there and absolutely incredible. And you learn that there is a taller mountain out there. Find it, Mount Quantum…. they’re not smoothly connected … you’ve got to make a jump to go from classical to quantum … This also tells you why we have such major challenges in trying to extend our understanding of physics. We don’t have these knobs, and little wheels, and twiddles that we can turn. We have to learn how to make these jumps. And it is a tall order. And that’s why things are difficult.”</em></p>
</blockquote>
<p>Finding an efficient algorithm for <span><span class="math inline">\(\mathbf{NP}\)</span></span> amounts to always being able to search through an exponential space and find not just the “local” mountain, but the tallest peak.</p>
<p>But perhaps more than any computational speedups, a fast algorithm for <span><span class="math inline">\(\mathbf{NP}\)</span></span> problems would bring about a <em>new type of understanding</em>. In many of the areas where <span><span class="math inline">\(\mathbf{NP}\)</span></span>-completeness arises, it is not as much a barrier for solving computational problems as it is a barrier for obtaining “closed-form formulas” or other types of more constructive descriptions of the behavior of natural, biological, social and other systems. A better algorithm for <span><span class="math inline">\(\mathbf{NP}\)</span></span>, even if it is “merely” <span><span class="math inline">\(2^{\sqrt{n}}\)</span></span>-time, seems to require obtaining a new way to understand these types of systems, whether it is characterizing Nash equilibria, spin-glass configurations, entangled quantum states, or any of the other questions where <span><span class="math inline">\(\mathbf{NP}\)</span></span> is currently a barrier for analytical understanding. Such new insights would be very fruitful regardless of their computational utility.</p>
<div id="pnpconsequences" class="bigidea" name="Bigidea 22">
<p>If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, we can efficiently solve a fantastic number of decision, search, optimization, counting, and sampling problems from all areas of human endeavors.</p>
</div>
<h2 id="can-mathbfp-neq-mathbfnp-be-neither-true-nor-false" data-number="15.7">Can <span><span class="math inline">\(\mathbf{P} \neq \mathbf{NP}\)</span></span> be neither true nor false?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Continuum_hypothesis">Continuum Hypothesis</a> is a conjecture made by Georg Cantor in 1878, positing the non-existence of a certain type of infinite cardinality. (One way to phrase it is that for every infinite subset <span><span class="math inline">\(S\)</span></span> of the real numbers <span><span class="math inline">\(\R\)</span></span>, either there is a one-to-one and onto function <span><span class="math inline">\(f:S \rightarrow \R\)</span></span> or there is a one-to-one and onto function <span><span class="math inline">\(f:S \rightarrow \N\)</span></span>.) This was considered one of the most important open problems in set theory, and settling its truth or falseness was the first problem put forward by Hilbert in the 1900 address we mentioned before. However, using the theories developed by Gödel and Turing, in 1963 Paul Cohen proved that both the Continuum Hypothesis and its negation are consistent with the standard axioms of set theory (i.e., the Zermelo-Fraenkel axioms + the Axiom of choice, or “ZFC” for short). Formally, what he proved is that if ZFC is consistent, then so is ZFC when we assume either the continuum hypothesis or its negation.</p>
<p>Today, many (though not all) mathematicians interpret this result as saying that the Continuum Hypothesis is neither true nor false, but rather is an axiomatic choice that we are free to make one way or the other. Could the same hold for <span><span class="math inline">\(\mathbf{P} \neq \mathbf{NP}\)</span></span>?</p>
<p>In short, the answer is <em>No</em>. For example, suppose that we are trying to decide between the “3SAT is easy” conjecture (there is an <span><span class="math inline">\(10^6n\)</span></span> time algorithm for 3SAT) and the “3SAT is hard” conjecture (for every <span><span class="math inline">\(n\)</span></span>, any NAND-CIRC program that solves <span><span class="math inline">\(n\)</span></span> variable 3SAT takes <span><span class="math inline">\(2^{10^{-6}n}\)</span></span> lines). Then, since for <span><span class="math inline">\(n = 10^8\)</span></span>, <span><span class="math inline">\(2^{10^{-6}n} &gt; 10^6 n\)</span></span>, this boils down to the finite question of deciding whether or not there is a <span><span class="math inline">\(10^{13}\)</span></span>-line NAND-CIRC program deciding 3SAT on formulas with <span><span class="math inline">\(10^8\)</span></span> variables. If there is such a program then there is a finite proof of its existence, namely the approximately 1TB file describing the program, and for which the verification is the (finite in principle though infeasible in practice) process of checking that it succeeds on all inputs.<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup> If there isn’t such a program, then there is also a finite proof of that, though any such proof would take longer since we would need to enumerate over all <em>programs</em> as well. Ultimately, since it boils down to a finite statement about bits and numbers; either the statement or its negation must follow from the standard axioms of arithmetic in a finite number of arithmetic steps. Thus, we cannot justify our ignorance in distinguishing between the “3SAT easy” and “3SAT hard” cases by claiming that this might be an inherently ill-defined question. Similar reasoning (with different numbers) applies to other variants of the <span><span class="math inline">\(\mathbf{P}\)</span></span> vs <span><span class="math inline">\(\mathbf{NP}\)</span></span> question. We note that in the case that 3SAT is hard, it may well be that there is no <em>short</em> proof of this fact using the standard axioms, and this is a question that people have been studying in various restricted forms of proof systems.</p>
<h2 id="is-mathbfpmathbfnp-in-practice" data-number="15.8">Is <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> “in practice”?</h2>
<p>The fact that a problem is <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard means that we believe there is no efficient algorithm that solve it in the <em>worst case</em>. It does not, however, mean that every single instance of the problem is hard. For example, if all the clauses in a 3SAT instance <span><span class="math inline">\(\varphi\)</span></span> contain the same variable <span><span class="math inline">\(x_i\)</span></span> (possibly in negated form), then by guessing a value to <span><span class="math inline">\(x_i\)</span></span> we can reduce <span><span class="math inline">\(\varphi\)</span></span> to a 2SAT instance which can then be efficiently solved. Generalizations of this simple idea are used in “SAT solvers”, which are algorithms that have solved certain specific interesting SAT formulas with thousands of variables, despite the fact that we believe SAT to be exponentially hard in the worst case. Similarly, a lot of problems arising in economics and machine learning are <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard.<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup> And yet vendors and customers manage to figure out market-clearing prices (as economists like to point out, there is milk on the shelves) and mice succeed in distinguishing cats from dogs. Hence people (and machines) seem to regularly succeed in solving interesting instances of <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard problems, typically by using some combination of guessing while making local improvements.</p>
<p>It is also true that there are many interesting instances of <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard problems that we do <em>not</em> currently know how to solve. Across all application areas, whether it is scientific computing, optimization, control or more, people often encounter hard instances of <span><span class="math inline">\(\mathbf{NP}\)</span></span> problems on which our current algorithms fail. In fact, as we will see, all of our digital security infrastructure relies on the fact that some concrete and easy-to-generate instances of, say, 3SAT (or, equivalently, any other <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard problem) are exponentially hard to solve.</p>
<p>Thus it would be wrong to say that <span><span class="math inline">\(\mathbf{NP}\)</span></span> is easy “in practice”, nor would it be correct to take <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hardness as the “final word” on the complexity of a problem, particularly when we have more information about how any given instance is generated. Understanding both the “typical complexity” of <span><span class="math inline">\(\mathbf{NP}\)</span></span> problems, as well as the power and limitations of certain heuristics (such as various local-search based algorithms) is a very active area of research. We will see more on these topics later in this course.</p>
<p><sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup></p>
<h2 id="what-if-mathbfp-neq-mathbfnp" data-number="15.9">What if <span><span class="math inline">\(\mathbf{P} \neq \mathbf{NP}\)</span></span>?</h2>
<p>So, <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> would give us all kinds of fantastical outcomes. But we strongly suspect that <span><span class="math inline">\(\mathbf{P} \neq \mathbf{NP}\)</span></span>, and moreover that there is no much-better-than-brute-force algorithm for 3SAT. If indeed that is the case, is it all bad news?</p>
<p>One might think that impossibility results, telling you that you <em>cannot</em> do something, is the kind of cloud that does not have a silver lining. But in fact, as we already alluded to before, it does. A hard (in a sufficiently strong sense) problem in <span><span class="math inline">\(\mathbf{NP}\)</span></span> can be used to create a code that <em>cannot be broken</em>, a task that for thousands of years has been the dream of not just spies but of many scientists and mathematicians over the generations. But the complexity viewpoint turned out to yield much more than simple codes, achieving tasks that people had previously not even dared to dream of. These include the notion of <em>public key cryptography</em>, allowing two people to communicate securely without ever having exchanged a secret key; <em>electronic cash</em>, allowing private and secure transaction without a central authority; and <em>secure multiparty computation</em>, enabling parties to compute a joint function on private inputs without revealing any extra information about it. Also, as we will see, computational hardness can be used to replace the role of <em>randomness</em> in many settings.</p>
<p>Furthermore, while it is often convenient to pretend that computational problems are simply handed to us, and that our job as computer scientists is to find the most efficient algorithm for them, this is not how things work in most computing applications. Typically even formulating the problem to solve is a highly non-trivial task. When we discover that the problem we want to solve is <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard, this might be a useful sign that we used the wrong formulation for it.</p>
<p>Beyond all these, the quest to understand computational hardness <span><span class="math inline">\(-\)</span></span> including the discoveries of lower bounds for restricted computational models, as well as new types of reductions (such as those arising from “probabilistically checkable proofs”) <span><span class="math inline">\(-\)</span></span> has already had surprising <em>positive</em> applications to problems in algorithm design, as well as in coding for both communication and storage. This is not surprising since, as we mentioned before, from group theory to the theory of relativity, the pursuit of impossibility results has often been one of the most fruitful enterprises of mankind.</p>
<div class="recap" name="Recap 15.9">
<ul>
<li><p>The question of whether <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> is one of the most important and fascinating questions of computer science and science at large, touching on all fields of the natural and social sciences, as well as mathematics and engineering.</p></li>
<li><p>Our current evidence and understanding supports the “SAT hard” scenario that there is no much-better-than-brute-force algorithm for 3SAT or many other <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard problems.</p></li>
<li><p>We are very far from <em>proving</em> this, however. Researchers have studied proving lower bounds on the number of gates to compute explicit functions in <em>restricted forms</em> of circuits, and have made some advances in this effort, along the way generating mathematical tools that have found other uses. However, we have made essentially no headway in proving lower bounds for <em>general</em> models of computation such as Boolean circuits and Turing machines. Indeed, we currently do not even know how to rule out the possibility that for every <span><span class="math inline">\(n\in \N\)</span></span>, <span><span class="math inline">\(\ensuremath{\mathit{SAT}}\)</span></span> restricted to <span><span class="math inline">\(n\)</span></span>-length inputs has a Boolean circuit of less than <span><span class="math inline">\(10n\)</span></span> gates (even though there <em>exist</em> <span><span class="math inline">\(n\)</span></span>-input functions that require at least <span><span class="math inline">\(2^n/(10n)\)</span></span> gates to compute).</p></li>
<li><p>Understanding how to cope with this computational intractability, and even benefit from it, comprises much of the research in theoretical computer science.</p></li>
</ul>
</div>
<h2 id="exercises" data-number="15.10">Exercises</h2>
<h2 id="bibliographical-notes" data-number="15.11">Bibliographical notes</h2>
<p>As mentioned before, Aaronson’s survey  (<a href="https://scholar.google.com/scholar?hl=en&q=Aaronson+P+=?+NP" target="_blank">Aaronson, 2016</a>)  is a great exposition of the <span><span class="math inline">\(\mathbf{P}\)</span></span> vs <span><span class="math inline">\(\mathbf{NP}\)</span></span> problem. Another recommended survey by Aaronson is  (<a href="https://scholar.google.com/scholar?hl=en&q=Aaronson+NP-complete+problems+and+physical+reality" target="_blank">Aaronson, 2005</a>)  which discusses the question of whether <span><span class="math inline">\(\mathbf{NP}\)</span></span> complete problems could be computed by any physical means.</p>
<p>The paper  (<a href="https://scholar.google.com/scholar?hl=en&q=Buchfuhrer,+Umans+The+complexity+of+Boolean+formula+minimization" target="_blank">Buchfuhrer, Umans, 2011</a>)  discusses some results about problems in the polynomial hierarchy.</p>
<div id="footnotediv" class="footnotes">
<ol>
<li class="footnote" id="fn:1"><p>
<div>
<p>Paul Erdős (1913-1996) was one of the most prolific mathematicians of all times. Though he was an atheist, Erdős often referred to “The Book” in which God keeps the most elegant proof of each mathematical theorem.</p>
</div>
<a href="#fnref:1" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:2"><p>
<div>
<p>The <span><span class="math inline">\(k\)</span></span>-th Ramsey number, denoted as <span><span class="math inline">\(R(k,k)\)</span></span>, is the smallest number <span><span class="math inline">\(n\)</span></span> such that for every graph <span><span class="math inline">\(G\)</span></span> on <span><span class="math inline">\(n\)</span></span> vertices, both <span><span class="math inline">\(G\)</span></span> and its complement contain a <span><span class="math inline">\(k\)</span></span>-sized independent set. If <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> then we can compute <span><span class="math inline">\(R(k,k)\)</span></span> in time polynomial in <span><span class="math inline">\(2^k\)</span></span>, while otherwise it can potentially take closer to <span><span class="math inline">\(2^{2^{2k}}\)</span></span> steps.</p>
</div>
<a href="#fnref:2" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:3"><p>
<div>
<p>This is often known as <a href="https://goo.gl/F9AgG8">Empirical Risk Minimization</a>.</p>
</div>
<a href="#fnref:3" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:4"><p>
<div>
<p>The undecidability of <a href="https://en.wikipedia.org/wiki/Entscheidungsproblem">Entscheidungsproblem</a> refers to the uncomputability of the function that maps a statement in <a href="https://en.wikipedia.org/wiki/First-order_logic">first order logic</a> to <span><span class="math inline">\(1\)</span></span> if and only if that statement has a proof.</p>
</div>
<a href="#fnref:4" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:5"><p>
<div>
<p>Since NAND-CIRC programs are equivalent to Boolean circuits, the search problem corresponding to <a href='#circmineq'>Equation 15.6</a> known as the <a href="https://goo.gl/iykqbh">circuit minimization problem</a> and is widely studied in Engineering. You can skip ahead to <a href='#selfimprovingsat'>Subsection 15.4.1</a> to see a particularly compelling application of this.</p>
</div>
<a href="#fnref:5" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:6"><p>
<div>
<p>For the ease of notation, we assume that all the strings we quantify over have the same length <span><span class="math inline">\(m=p(n)\)</span></span>, but using simple padding one can show that this captures the general case of strings of different polynomial lengths.</p>
</div>
<a href="#fnref:6" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:7"><p>
<div>
<p>We do not know whether such loss is inherent. As far as we can tell, it’s possible that the <em>quantified boolean formula</em> problem has a linear-time algorithm. We will, however, see later in this course that it satisfies a notion known as <span><span class="math inline">\(\mathbf{PSPACE}\)</span></span>-hardness that is even stronger than <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hardness.</p>
</div>
<a href="#fnref:7" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:8"><p>
<div>
<p>One interesting theory is that <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span> and evolution has already discovered this algorithm, which we are already using without realizing it. At the moment, there seems to be very little evidence for such a scenario. In fact, we have some partial results in the other direction showing that, regardless of whether <span><span class="math inline">\(\mathbf{P}=\mathbf{NP}\)</span></span>, many types of “local search” or “evolutionary” algorithms require exponential time to solve 3SAT and other <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard problems.</p>
</div>
<a href="#fnref:8" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:9"><p>
<div>
<p>This inefficiency is not necessarily inherent. Later in this course we may discuss results in program-checking, interactive proofs, and average-case complexity, that can be used for efficient verification of proofs of related statements. In contrast, the inefficiency of verifying <em>failure</em> of all programs could well be inherent.</p>
</div>
<a href="#fnref:9" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:10"><p>
<div>
<p>Actually, the computational difficulty of problems in economics such as finding optimal (or any) equilibria is quite subtle. Some variants of such problems are <span><span class="math inline">\(\mathbf{NP}\)</span></span>-hard, while others have a certain “intermediate” complexity.</p>
</div>
<a href="#fnref:10" title="return to article"> ↩</a><p></li>
<li class="footnote" id="fn:11"><p>
<div>
<p>Talk more about coping with NP hardness. Main two approaches are <em>heuristics</em> such as SAT solvers that succeed on <em>some</em> instances, and <em>proxy measures</em> such as mathematical relaxations that instead of solving problem <span><span class="math inline">\(X\)</span></span> (e.g., an integer program) solve program <span><span class="math inline">\(X&#39;\)</span></span> (e.g., a linear program) that is related to that. Maybe give compressed sensing as an example, and least square minimization as a proxy for maximum apostoriori probability.</p>
</div>
<a href="#fnref:11" title="return to article"> ↩</a><p></li>
</ol>
</div>
<!--bookdown:body:end-->


<!-- end of  actual content -->

<!-- start of comments -->


<a name="commentform"></a>
<h2 id="comments" class="nocount">Comments</h2>

<p>Comments are posted on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a> using the <a href="https://utteranc.es">utteranc.es</a> app.
A GitHub login is required to comment.
If you don't want to authorize the app to post on your behalf, you can also comment directly on the <a href="https://github.com/boazbk/tcs/issues?q=Defining Computation+in%3Atitle">GitHub issue for this page</a>.


<p>


<script src="https://utteranc.es/client.js" 
repo="boazbk/tcs" 
issue-term="title" 
label="comments"
theme="github-light" 
crossorigin="anonymous" async>
  </script>


<!-- end of comments -->

<p>Compiled on 12/02/2019 19:01:51</p>

<p>Copyright 2019, Boaz Barak.


<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License"
    style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is
licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons
  Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

<p>Produced using <a href="https://pandoc.org/">pandoc</a> and <a href="http://scorreia.com/software/panflute/">panflute</a> with templates derived from <a href="https://www.gitbook.com/">gitbook</a> and <a href="https://bookdown.org/">bookdown</a>.</p>



</div>


            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->



    </div>
  </div>
<!--bookdown:config-->
<script src="js/app.min.js"></script>
<script src="js/lunr.js"></script>
<script src="js/plugin-search.js"></script>
<script src="js/plugin-sharing.js"></script>
<script src="js/plugin-fontsettings.js"></script>
<script src="js/fullscreen.js"></script>
<script src="js/plugin-bookdown.js"></script>
<script src="js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"history": {
"link": null,
"text": null
},
"download": ["https://files.boazbarak.org/introtcs/lec_14_PvsNP.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>


</body>

</html>
